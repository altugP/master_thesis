{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The raw files were all gathered using [these queries](./2024-06-18T20-19-02_queries.md)\n",
    "> on June 18th, 2024 at roughly 8pm using access via Ulm University's VPN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file illustrates the filters used before abstract screening. The applied\n",
    "filters are only able to filter out matches that are marked correctly and\n",
    "provide the accurate and sufficient metadata. As this is not the case,\n",
    "additional manual filtering is required after running this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rispy\n",
    "import bibtexparser\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bib(path: str) -> pd.DataFrame:\n",
    "  '''Loads search results from a .bib file into a pandas DataFrame'''\n",
    "  with open(path, 'r', encoding='utf-8') as file:\n",
    "    bib_data = bibtexparser.load(file)\n",
    "  return pd.DataFrame(bib_data.entries)\n",
    "\n",
    "\n",
    "def load_ris(path: str) -> pd.DataFrame:\n",
    "  '''Loads search results from a .ris file into a pandas DataFrame'''\n",
    "  with open(path, 'r', encoding='utf-8') as file:\n",
    "    ris_data = rispy.load(file)\n",
    "  return pd.DataFrame(ris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 943 entries from ACM Digital Library\n",
      "Loaded 1117 entries from APA PsycInfo\n",
      "Loaded 204 entries from IEEE Xplore\n",
      "Loaded 2911 entries from PubMed & MEDLINE\n",
      "Loaded 1807 entries from Web of Science CORE\n",
      "Loaded 300 entries from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "# load ACM Digital Library results\n",
    "acm_df = load_bib('./data/raw/acm_digitallibrary.bib')\n",
    "print(f'Loaded {acm_df.shape[0]} entries from ACM Digital Library')\n",
    "\n",
    "# load APA PsycInfo results\n",
    "apa_df = load_ris('./data/raw/apa_psycinfo.ris')\n",
    "print(f'Loaded {apa_df.shape[0]} entries from APA PsycInfo')\n",
    "\n",
    "# load IEEE Xplore results\n",
    "ieee_df = load_ris('./data/raw/ieee_xplore_fromDOIs.ris')\n",
    "print(f'Loaded {ieee_df.shape[0]} entries from IEEE Xplore')\n",
    "\n",
    "# load PubMed results (with extra abstract data from PubMed2XLSX)\n",
    "pubmed_df = pd.read_csv('./data/raw/pubmed_base.csv')\n",
    "pubmed2xl_df = pd.read_csv('./data/raw/pd2xl.csv')\n",
    "pubmed_df.set_index('PMID', inplace=True)\n",
    "pubmed2xl_df.set_index('PMID', inplace=True)\n",
    "pubmed_df['Abstract'] = pubmed2xl_df['Abstract']\n",
    "print(f'Loaded {pubmed_df.shape[0]} entries from PubMed & MEDLINE')\n",
    "\n",
    "# load Web of Science results\n",
    "wos_df = load_bib('./data/raw/webofscience_0001-1000.bib')\n",
    "wos_df = pd.concat([wos_df, load_bib('./data/raw/webofscience_1001-1807.bib')])\n",
    "print(f'Loaded {wos_df.shape[0]} entries from Web of Science CORE')\n",
    "\n",
    "# load Google Scholar results\n",
    "gs_df = pd.read_csv('./data/raw/googlescholar_appended.csv')\n",
    "print(f'Loaded {gs_df.shape[0]} entries from Google Scholar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_entries() -> int:\n",
    "  '''Returns the number of elements across all loaded dataframes'''\n",
    "  dfs: list[pd.DataFrame] = [acm_df, apa_df, ieee_df, pubmed_df, wos_df, gs_df]\n",
    "  return sum(map(lambda x: x.shape[0], dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Loaded 7282 across all databases using this search strategy\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Loaded {get_num_entries()} across all databases using this search strategy')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_bib(df: pd.DataFrame, fname: str) -> None:\n",
    "  '''Exports the contents of a dataframe to a bib file'''\n",
    "  df = df.map(str)  # convert all values to str, as bib files need them\n",
    "  bib_db = bibtexparser.bibdatabase.BibDatabase()  # BibTex file structure\n",
    "  bib_db.entries = df.to_dict(orient='records')  # set the records as contents\n",
    "  writer = bibtexparser.bwriter.BibTexWriter()\n",
    "  with open(fname, 'w', encoding='utf-8') as file:\n",
    "    file.write(writer.write(bib_db))\n",
    "\n",
    "def export_to_ris(df: pd.DataFrame, fname: str) -> None:\n",
    "  '''Exports the contents of a DataFrame to an RIS file'''\n",
    "  # convert all values to strings, as RIS files expect flattened strings\n",
    "  df = df.map(lambda x: x if isinstance(x, dict) or isinstance(x, list) else '' if pd.isna(x) else str(x))\n",
    "  with open(fname, 'w', encoding='utf-8') as file:\n",
    "    rispy.dump(df.to_dict(orient='records'), file)\n",
    "\n",
    "\n",
    "def export_to_csv(df: pd.DataFrame, fname: str) -> None:\n",
    "  '''Exports the contents of a DataFrame to a CSV file'''\n",
    "  df.to_csv(fname, index=False)\n",
    "\n",
    "\n",
    "def get_filtered_out_entries(df: pd.DataFrame,\n",
    "                             df_filtered: pd.DataFrame) -> pd.DataFrame:\n",
    "  '''Given the original dataframe and the filtered dataframe this returns a\n",
    "     dataframe containing only the filtered out entries'''\n",
    "  return df[~df.index.isin(df_filtered.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 1: Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first filter removes all publications that resulted in a match for the query\n",
    "but cannot realistically include mobile application systems. The reason for that\n",
    "assumption is that neither the original iPhone nor the first Android-based\n",
    "smartphone were released before autumn 2008 and were realistically not available\n",
    "before the year 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that no research groups got early access to the iPhone for their\n",
    "research as researchers were not the target audience for the first smartphones\n",
    "but rather the general public."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Google Scholar, five matches have no year information attributed\n",
    "to them. Manual inspection reveals, that there are versions of those matches,\n",
    "that were released after 2009. Therefore, none of those entries are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before = get_num_entries()  # number of entries before applying filter\n",
    "cutoff_year = 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 23 publications from ACM Digital Library\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on ACM Digital Library\n",
    "acm_df_filtered = acm_df[acm_df['year'].astype(int) >= cutoff_year]\n",
    "acm_df_excluded = get_filtered_out_entries(acm_df, acm_df_filtered)\n",
    "print(f'Removed {(acm_df_excluded.shape[0])} publications from ACM Digital Library')\n",
    "export_to_bib(acm_df_filtered, './data/filter1_Date/acm_filter_date_in.bib')\n",
    "export_to_bib(acm_df_excluded, './data/filter1_Date/acm_filter_date_out.bib')\n",
    "acm_df = acm_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 4 publications from APA PsycInfo\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on APA PsycInfo\n",
    "apa_df_filtered = apa_df[apa_df['publication_year'].str.rstrip('//').astype(int) >= cutoff_year]\n",
    "apa_df_excluded = get_filtered_out_entries(apa_df, apa_df_filtered)\n",
    "print(f'Removed {(apa_df_excluded.shape[0])} publications from APA PsycInfo')\n",
    "export_to_ris(apa_df_filtered, './data/filter1_Date/apa_filter_date_in.ris')\n",
    "export_to_ris(apa_df_excluded, './data/filter1_Date/apa_filter_date_out.ris')\n",
    "apa_df = apa_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 7 publications from IEEE Xplore\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on IEEE Xplore\n",
    "ieee_df_filtered = ieee_df[ieee_df['year'].astype(int) >= cutoff_year]\n",
    "ieee_df_excluded = get_filtered_out_entries(ieee_df, ieee_df_filtered)\n",
    "print(f'Removed {(ieee_df_excluded.shape[0])} publications from IEEE Xplore')\n",
    "export_to_ris(ieee_df_filtered, './data/filter1_Date/ieee_filter_date_in.ris')\n",
    "export_to_ris(ieee_df_excluded, './data/filter1_Date/ieee_filter_date_out.ris')\n",
    "ieee_df = ieee_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 publications from PubMed & MEDLINE\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on PubMed & MEDLINE\n",
    "pubmed_df_filtered = pubmed_df[pubmed_df['Publication Year'].astype(int) >= cutoff_year]\n",
    "pubmed_df_excluded = get_filtered_out_entries(pubmed_df, pubmed_df_filtered)\n",
    "print(f'Removed {(pubmed_df_excluded.shape[0])} publications from PubMed & MEDLINE')\n",
    "export_to_csv(pubmed_df_filtered, './data/filter1_Date/pubmed_filter_date_in.csv')\n",
    "export_to_csv(pubmed_df_excluded, './data/filter1_Date/pubmed_filter_date_out.csv')\n",
    "pubmed_df = pubmed_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 publications from Web of Science CORE\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on Web of Science\n",
    "wos_df_filtered = wos_df[wos_df['year'].astype(int) >= cutoff_year]\n",
    "wos_df_excluded = get_filtered_out_entries(wos_df, wos_df_filtered)\n",
    "print(f'Removed {(wos_df_excluded.shape[0])} publications from Web of Science CORE')\n",
    "export_to_bib(wos_df_filtered, './data/filter1_Date/wos_filter_date_in.bib')\n",
    "export_to_bib(wos_df_excluded, './data/filter1_Date/wos_filter_date_out.bib')\n",
    "wos_df = wos_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "# apply year filter on Google Scholar\n",
    "gs_df['Year'] = gs_df['Year'].fillna(5000)  # to keep nan values\n",
    "gs_df_filtered = gs_df[gs_df['Year'] >= cutoff_year]\n",
    "gs_df_filtered['Year'] = gs_df_filtered['Year'].replace(5000, np.nan)\n",
    "gs_df_excluded = get_filtered_out_entries(gs_df, gs_df_filtered)\n",
    "print(f'Removed {(gs_df_excluded.shape[0])} publications from Google Scholar')\n",
    "export_to_csv(gs_df_filtered, './data/filter1_Date/gs_filter_date_in.csv')\n",
    "export_to_csv(gs_df_excluded, './data/filter1_Date/gs_filter_date_out.csv')\n",
    "gs_df = gs_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Removed a total of 44 publications that were released before 2009\n",
      "  => 7238 entries left in total\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Removed a total of {num_before - get_num_entries()} publications that were released before {cutoff_year}')\n",
    "print(f'  => {get_num_entries()} entries left in total')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 2: Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filter makes sure to only include publications that are written in English.\n",
    "Being written in English is the only metric we have to affirm the publication\n",
    "was meant for a broader and international audience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering titles can be done programatically. Filtering abstracts has to be done\n",
    "manually, as not all matches have abstracts in the result set due to some\n",
    "specifics in the databases such as also matching proceedings i.e. collections\n",
    "of papers for search queries (if a match contains multiple papers, they usually\n",
    "do not provide an abstract)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using language detection tools such as langdetect results in a couple of false\n",
    "positives, rendering them unusable. Therefore, this filter only goes over the\n",
    "provided metadata and removes all entries that are marked as written in a\n",
    "language other then English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of APA PsycInfo, many matches are not labeled correctly. To not\n",
    "falsely remove any English matches, all matches with no language label are\n",
    "assumed to be written in English, even if that is not necessarily true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before = get_num_entries()  # number of entries before applying filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 1113 197 2906 1802 300\n"
     ]
    }
   ],
   "source": [
    "print(acm_df.shape[0],\n",
    "      apa_df.shape[0],\n",
    "      ieee_df.shape[0],\n",
    "      pubmed_df.shape[0],\n",
    "      wos_df.shape[0],\n",
    "      gs_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from ACM Digital Library\n"
     ]
    }
   ],
   "source": [
    "# ACM Digital Library does not provide metadata for this\n",
    "acm_df_filtered = acm_df\n",
    "acm_df_excluded = get_filtered_out_entries(acm_df, acm_df_filtered)\n",
    "print(f'Removed {(acm_df_excluded.shape[0])} publications from ACM Digital Library')\n",
    "export_to_bib(acm_df_filtered, './data/filter2_Language/acm_filter_lang_in.bib')\n",
    "export_to_bib(acm_df_excluded, './data/filter2_Language/acm_filter_lang_out.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 12 publications from APA PsycInfo\n"
     ]
    }
   ],
   "source": [
    "# read internal lang classification on APA PsycInfo\n",
    "apa_df['language'] = apa_df['language'].fillna('English')  # to keep nan values\n",
    "apa_df_filtered = apa_df[apa_df['language'] == 'English']\n",
    "apa_df_excluded = get_filtered_out_entries(apa_df, apa_df_filtered)\n",
    "print(f'Removed {(apa_df_excluded.shape[0])} publications from APA PsycInfo')\n",
    "export_to_ris(apa_df_filtered, './data/filter2_Language/apa_filter_lang_in.ris')\n",
    "export_to_ris(apa_df_excluded, './data/filter2_Language/apa_filter_lang_out.ris')\n",
    "apa_df = apa_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from IEEE Xplore\n"
     ]
    }
   ],
   "source": [
    "# IEEE Xplore only publishes English articles\n",
    "ieee_df_filtered = ieee_df\n",
    "ieee_df_excluded = get_filtered_out_entries(ieee_df, ieee_df_filtered)\n",
    "print(f'Removed {ieee_df_excluded.shape[0]} publications from IEEE Xplore')\n",
    "export_to_ris(ieee_df_filtered, './data/filter2_Language/ieee_filter_lang_in.ris')\n",
    "export_to_ris(ieee_df_excluded, './data/filter2_Language/ieee_filter_lang_out.ris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from PubMed & MEDLINE\n"
     ]
    }
   ],
   "source": [
    "# PubMed & MEDLINE do not provide metadata for this\n",
    "pubmed_df_filtered = pubmed_df\n",
    "pubmed_df_excluded = get_filtered_out_entries(pubmed_df, pubmed_df_filtered)\n",
    "print(f'Removed {(pubmed_df_excluded.shape[0])} publications from PubMed & MEDLINE')\n",
    "export_to_csv(pubmed_df_filtered, './data/filter2_Language/pubmed_filter_lang_in.csv')\n",
    "export_to_csv(pubmed_df_excluded, './data/filter2_Language/pubmed_filter_lang_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from Web of Science CORE\n"
     ]
    }
   ],
   "source": [
    "# read internal lang classification on Web of Science\n",
    "wos_df_filtered = wos_df[wos_df['language'] == 'English']\n",
    "wos_df_excluded = get_filtered_out_entries(wos_df, wos_df_filtered)\n",
    "print(f'Removed {(wos_df_excluded.shape[0])} publications from Web of Science CORE')\n",
    "export_to_bib(wos_df_filtered, './data/filter2_Language/wos_filter_lang_in.bib')\n",
    "export_to_bib(wos_df_excluded, './data/filter2_Language/wos_filter_lang_out.bib')\n",
    "wos_df = wos_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "# Google Scholar does not provide metadata for this\n",
    "gs_df_filtered = gs_df\n",
    "gs_df_excluded = get_filtered_out_entries(gs_df, gs_df_filtered)\n",
    "print(f'Removed {(gs_df_excluded.shape[0])} publications from Google Scholar')\n",
    "export_to_csv(gs_df_filtered, './data/filter2_Language/gs_filter_lang_in.csv')\n",
    "export_to_csv(gs_df_excluded, './data/filter2_Language/gs_filter_lang_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Removed a total of 25 publications that were not written fully in English\n",
      "  => 7213 entries left in total\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Removed a total of {num_before - get_num_entries()} publications that were not written fully in English')\n",
    "print(f'  => {get_num_entries()} entries left in total')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 1101 197 2906 1789 300\n"
     ]
    }
   ],
   "source": [
    "print(acm_df.shape[0],\n",
    "      apa_df.shape[0],\n",
    "      ieee_df.shape[0],\n",
    "      pubmed_df.shape[0],\n",
    "      wos_df.shape[0],\n",
    "      gs_df.shape[0])\n",
    "# 920 1113 197 2906 1802 300\n",
    "#     12            13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 3: Publication Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of matches contain proceedings, teaching books or other collections of\n",
    "papers. These are not standalone publications and therefore should not be\n",
    "relevant for a scoping review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some entries are marked as `@book` inside bib files. These however, are not\n",
    "necessarily books, as many of them look like chapters or standalone articles\n",
    "instead. Therefore, this filter goes over all databases that have some sort of\n",
    "entry type in their metadata and removes all of them that are defined as being\n",
    "some sort of collection of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before = get_num_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 175 publications from ACM Digital Library\n"
     ]
    }
   ],
   "source": [
    "# print(acm_df['ENTRYTYPE'].value_counts())\n",
    "acm_df_filtered = acm_df[acm_df['ENTRYTYPE'].isin(['inproceedings', 'article', 'inbook', 'incollection'])]\n",
    "acm_df_excluded = get_filtered_out_entries(acm_df, acm_df_filtered)\n",
    "print(f'Removed {(acm_df_excluded.shape[0])} publications from ACM Digital Library')\n",
    "export_to_bib(acm_df_filtered, './data/filter3_PublicationType/acm_filter_pubtype_in.bib')\n",
    "export_to_bib(acm_df_excluded, './data/filter3_PublicationType/acm_filter_pubtype_out.bib')\n",
    "acm_df = acm_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from APA PsycInfo\n"
     ]
    }
   ],
   "source": [
    "# all matches in APA PsycInfo are marked as JOUR i.e. journal entry\n",
    "print('Removed 0 publications from APA PsycInfo')\n",
    "export_to_ris(apa_df, './data/filter3_PublicationType/apa_filter_pubtype_in.ris')\n",
    "export_to_ris(get_filtered_out_entries(apa_df, apa_df), './data/filter3_PublicationType/apa_filter_pubtype_out.ris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from IEEE Xplore\n"
     ]
    }
   ],
   "source": [
    "# IEEE Xplore does not provide metadata for this, but also only publishes \n",
    "# standalone articles in their IEEE Proceedings\n",
    "print('Removed 0 publications from IEEE Xplore')\n",
    "export_to_ris(ieee_df, './data/filter3_PublicationType/ieee_filter_pubtype_in.ris')\n",
    "export_to_ris(get_filtered_out_entries(ieee_df, ieee_df), './data/filter3_PublicationType/ieee_filter_pubtype_out.ris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from PubMed & MEDLINE\n"
     ]
    }
   ],
   "source": [
    "# PubMed & MEDLINE do not provide metadata for this, but all publications are\n",
    "# available as single paper PDF so they must be standalone\n",
    "print('Removed 0 publications from PubMed & MEDLINE')\n",
    "export_to_csv(pubmed_df, './data/filter3_PublicationType/pubmed_filter_pubtype_in.csv')\n",
    "export_to_csv(get_filtered_out_entries(pubmed_df, pubmed_df), './data/filter3_PublicationType/pubmed_filter_pubtype_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from Web of Science CORE\n"
     ]
    }
   ],
   "source": [
    "# print(wos_df['ENTRYTYPE'].value_counts())\n",
    "wos_df_filtered = wos_df[wos_df['ENTRYTYPE'].isin(['inproceedings', 'article', 'inbook', 'incollection'])]\n",
    "wos_df_excluded = get_filtered_out_entries(wos_df, wos_df_filtered)\n",
    "print(f'Removed {(wos_df_excluded.shape[0])} publications from Web of Science CORE')\n",
    "export_to_bib(wos_df_filtered, './data/filter3_PublicationType/wos_filter_pubtype_in.bib')\n",
    "export_to_bib(wos_df_excluded, './data/filter3_PublicationType/wos_filter_pubtype_out.bib')\n",
    "wos_df = wos_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 publications from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "# Google Scholar does not provide metadata for this\n",
    "print('Removed 0 publications from Google Scholar')\n",
    "export_to_csv(gs_df, './data/filter3_PublicationType/gs_filter_pubtype_in.csv')\n",
    "export_to_csv(get_filtered_out_entries(gs_df, gs_df), './data/filter3_PublicationType/gs_filter_pubtype_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Removed a total of 175 publications that were not written fully in English\n",
      "  => 7038 entries left in total\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Removed a total of {num_before - get_num_entries()} publications that were not written fully in English')\n",
    "print(f'  => {get_num_entries()} entries left in total')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 4: Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews are not publications about new technologies meaning they are not useful\n",
    "for scoping reviews. Therefore, all publications that resemble any type of review\n",
    "(Meta-Analysis, Systematic Review, Literature Review, ...) are filtered out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has to be done manually, as just looking through tags to see which article\n",
    "is classified this way is insufficient. Not all articles are correctly labeled.\n",
    "Additionally, looking through all titles and abstracts for the words like\n",
    "\"review\" is prone to errors, as some publications can be part review part new\n",
    "solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before = get_num_entries()\n",
    "\n",
    "def filter_out_reviews(df: pd.DataFrame, title_key: str) -> pd.DataFrame:\n",
    "  keywords = ['Meta-Analysis', 'Systematic Literature Review',\n",
    "              'Systematic Review', 'Literature Review', 'Scoping Review',\n",
    "              'Rapid Review', 'Umbrella Review', 'Narrative Review',\n",
    "              'Mapping Review', 'Critical Review', 'Protocol', 'Meta-Review',\n",
    "              'Analytic Review', 'Review and Analysis', 'Analysis and Review']\n",
    "  pattern = '|'.join(keywords)  # regex pattern\n",
    "  matches = df[title_key].str.contains(pattern, case=False, na=False)\n",
    "  filtered_df = df[~matches]\n",
    "  return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 21 publications from ACM Digital Library\n"
     ]
    }
   ],
   "source": [
    "acm_df_filtered = filter_out_reviews(acm_df, 'title')\n",
    "acm_df_excluded = get_filtered_out_entries(acm_df, acm_df_filtered)\n",
    "print(f'Removed {(acm_df_excluded.shape[0])} publications from ACM Digital Library')\n",
    "export_to_bib(acm_df_filtered, './data/filter4_Reviews/acm_filter_rev_in.bib')\n",
    "export_to_bib(acm_df_excluded, './data/filter4_Reviews/acm_filter_rev_out.bib')\n",
    "acm_df = acm_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 179 publications from APA PsycInfo\n"
     ]
    }
   ],
   "source": [
    "apa_df_filtered = filter_out_reviews(apa_df, 'primary_title')\n",
    "apa_df_excluded = get_filtered_out_entries(apa_df, apa_df_filtered)\n",
    "print(f'Removed {(apa_df_excluded.shape[0])} publications from APA PsycInfo')\n",
    "export_to_ris(apa_df_filtered, './data/filter4_Reviews/apa_filter_rev_in.ris')\n",
    "export_to_ris(apa_df_excluded, './data/filter4_Reviews/apa_filter_rev_out.ris')\n",
    "apa_df = apa_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5 publications from IEEE Xplore\n"
     ]
    }
   ],
   "source": [
    "ieee_df_filtered = filter_out_reviews(ieee_df, 'title')\n",
    "ieee_df_excluded = get_filtered_out_entries(ieee_df, ieee_df_filtered)\n",
    "print(f'Removed {(ieee_df_excluded.shape[0])} publications from IEEE Xplore')\n",
    "export_to_ris(ieee_df_filtered, './data/filter4_Reviews/ieee_filter_rev_in.ris')\n",
    "export_to_ris(ieee_df_excluded, './data/filter4_Reviews/ieee_filter_rev_out.ris')\n",
    "ieee_df = ieee_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 794 publications from PubMed & MEDLINE\n"
     ]
    }
   ],
   "source": [
    "pubmed_df_filtered = filter_out_reviews(pubmed_df, 'Title')\n",
    "pubmed_df_excluded = get_filtered_out_entries(pubmed_df, pubmed_df_filtered)\n",
    "print(f'Removed {(pubmed_df_excluded.shape[0])} publications from PubMed & MEDLINE')\n",
    "export_to_csv(pubmed_df_filtered, './data/filter4_Reviews/pubmed_filter_rev_in.csv')\n",
    "export_to_csv(pubmed_df_excluded, './data/filter4_Reviews/pubmed_filter_rev_out.csv')\n",
    "pubmed_df = pubmed_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 135 publications from Web of Science CORE\n"
     ]
    }
   ],
   "source": [
    "wos_df_filtered = filter_out_reviews(wos_df, 'title')\n",
    "wos_df_excluded = get_filtered_out_entries(wos_df, wos_df_filtered)\n",
    "print(f'Removed {(wos_df_excluded.shape[0])} publications from Web of Science CORE')\n",
    "export_to_bib(wos_df_filtered, './data/filter4_Reviews/wos_filter_rev_in.bib')\n",
    "export_to_bib(wos_df_excluded, './data/filter4_Reviews/wos_filter_rev_out.bib')\n",
    "wos_df = wos_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 60 publications from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "gs_df_filtered = filter_out_reviews(gs_df, 'Title')\n",
    "gs_df_excluded = get_filtered_out_entries(gs_df, gs_df_filtered)\n",
    "print(f'Removed {(gs_df_excluded.shape[0])} publications from Google Scholar')\n",
    "export_to_csv(gs_df_filtered, './data/filter4_Reviews/gs_filter_rev_in.csv')\n",
    "export_to_csv(gs_df_excluded, './data/filter4_Reviews/gs_filter_rev_out.csv')\n",
    "gs_df = gs_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Removed a total of 1501 publications that had some sort of review-tag in their primary title\n",
      "  => 5537 entries left in total\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Removed a total of {num_before - get_num_entries()} publications that had some sort of review-tag in their primary title')\n",
    "print(f'  => {get_num_entries()} entries left in total')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 5: DOI Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real deduplication process has to happen using some software tool with AI\n",
    "or statistical help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be done programatically is looking at identical DOIs. The following\n",
    "code passages count how often each DOI is present across all results and remove\n",
    "all entries for each DOI group across all databases until only one is left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This naive approach introduces a subjective ordering:\n",
    "  * PubMed & MEDLINE\n",
    "  * ACM Digital Library\n",
    "  * IEEE Xplore\n",
    "  * Web of Science CORE\n",
    "  * APA PsycInfo\n",
    "  * Google Scholar\n",
    "\n",
    "Entries are removed from bottom to the top, e.g. if 2 publications with the same\n",
    "DOI are found, one of which being from PubMed and the other from Google Scholar,\n",
    "then the entry from Google Scholar is removed. The ordering is based on how much\n",
    "usable information is being provided and how easy it is to access the full-text\n",
    "for each publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_before = get_num_entries()\n",
    "\n",
    "_doi_pattern = re.compile(r'10\\.\\d{4,9}/[-._;()/:A-Z0-9]+', re.IGNORECASE)\n",
    "def extract_doi(doi: any) -> str:\n",
    "  '''Given a DOI string or a \"https://dx.doi.org/<DOI>\" string this returns\n",
    "     only the relevant DOI substring'''\n",
    "  if pd.isna(doi) or len(str(doi)) < 5:\n",
    "    return ''\n",
    "  match = _doi_pattern.search(str(doi))\n",
    "  return match.group(0).lower() if match else str(doi).lower()\n",
    "\n",
    "\n",
    "# make all DOIs uniform and value only\n",
    "acm_df['doi'] = acm_df['doi'].apply(extract_doi)\n",
    "apa_df['doi'] = apa_df['doi'].apply(extract_doi)\n",
    "ieee_df['doi'] = ieee_df['doi'].apply(extract_doi)\n",
    "pubmed_df['DOI'] = pubmed_df['DOI'].apply(extract_doi)\n",
    "wos_df['doi'] = wos_df['doi'].apply(extract_doi)\n",
    "gs_df['DOI'] = gs_df['DOI'].apply(extract_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3055 total duplicates\n",
      "Must keep at least 1355 of those\n",
      "=> Should remove 1700\n"
     ]
    }
   ],
   "source": [
    "# ordered list of dfs with the corresponding keys for the DOI columns\n",
    "dfs = [(pubmed_df, 'DOI'),\n",
    "       (acm_df, 'doi'),\n",
    "       (ieee_df, 'doi'),\n",
    "       (wos_df, 'doi'),\n",
    "       (apa_df, 'doi'),\n",
    "       (gs_df, 'DOI')]\n",
    "# dataframe indexes have to be resetted before counting duplicates\n",
    "for df, _ in dfs:\n",
    "  df.reset_index(drop=True, inplace=True)\n",
    "# copies must be made after index reset, otherwise comparing indices is useless\n",
    "dfs_copy = [pubmed_df.copy(), acm_df.copy(), ieee_df.copy(), wos_df.copy(),\n",
    "            apa_df.copy(), gs_df.copy()]\n",
    "\n",
    "# dict to count all DOI occurrences, all DOI keys with value >1 are duplicates\n",
    "doi_counts = defaultdict(int)\n",
    "\n",
    "# finding duplicate dois across all dataframes\n",
    "for i, data in enumerate(dfs):\n",
    "  df, doi_key = data\n",
    "  for doi in df[doi_key]:\n",
    "    doi_clean = extract_doi(str(doi)).lower()\n",
    "    doi_counts[doi_clean] += 1\n",
    "duplicate_dois = [(doi, count) for doi, count in doi_counts.items() if pd.notna(doi) and count > 1 and len(doi) > 5]\n",
    "\n",
    "print(f'Found {sum(count for _, count in duplicate_dois)} total duplicates')\n",
    "print(f'Must keep at least {len(duplicate_dois)} of those')\n",
    "print(f'=> Should remove {sum(count for _, count in duplicate_dois) - len(duplicate_dois)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked 0 elements for removal from PubMed & MEDLINE\n",
      "Marked 6 elements for removal from ACM Digital Library\n",
      "Marked 6 elements for removal from IEEE Xplore\n",
      "Marked 1116 elements for removal from Web of Science CORE\n",
      "Marked 545 elements for removal from APA PsycInfo\n",
      "Marked 27 elements for removal from Google Scholar\n",
      "=> Marked a total of 1700 elements for removal across all databases\n"
     ]
    }
   ],
   "source": [
    "# list of lists, [i] = indexes in dataframes[i] to remove\n",
    "indices_to_delete = {i: [] for i in range(len(dfs))}\n",
    "\n",
    "# iterate over all duplicates\n",
    "for doi, count in duplicate_dois:\n",
    "  found = 0\n",
    "  for df_index, (df, col) in enumerate(dfs):\n",
    "    indices = df.index[df[col] == doi].tolist()\n",
    "    if found == 0 and indices:\n",
    "      # always keep the first found DOI row\n",
    "      indices_to_delete[df_index].extend(indices[1:])\n",
    "      found += len(indices)\n",
    "    else:\n",
    "      # if found=/=0, these new ones cannot contain the first DOI occurrance\n",
    "      indices_to_delete[df_index].extend(indices)\n",
    "\n",
    "# quick debug on what was marked for removal\n",
    "n_marked_total = 0\n",
    "for i, name in enumerate(['PubMed & MEDLINE', 'ACM Digital Library',\n",
    "                          'IEEE Xplore', 'Web of Science CORE',\n",
    "                          'APA PsycInfo', 'Google Scholar']):\n",
    "  n_marked = len(indices_to_delete[list(indices_to_delete.keys())[i]])\n",
    "  n_marked_total += n_marked\n",
    "  print(f'Marked {n_marked} elements for removal from {name}')\n",
    "print(f'=> Marked a total of {n_marked_total} elements for removal across all databases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 elements from PubMed & MEDLINE\n",
      "Dropped 6 elements from ACM Digital Library\n",
      "Dropped 6 elements from IEEE Xplore\n",
      "Dropped 1116 elements from Web of Science CORE\n",
      "Dropped 545 elements from APA PsycInfo\n",
      "Dropped 27 elements from Google Scholar\n",
      "=> Dropped a total of 1700 elements for removal across all databases\n"
     ]
    }
   ],
   "source": [
    "# dropping the marked rows\n",
    "n_deleted_total = 0\n",
    "for i, name in enumerate(['PubMed & MEDLINE', 'ACM Digital Library',\n",
    "                          'IEEE Xplore', 'Web of Science CORE',\n",
    "                          'APA PsycInfo', 'Google Scholar']):\n",
    "  df = dfs[i][0]\n",
    "  indices = indices_to_delete[list(indices_to_delete.keys())[i]]\n",
    "  n_before = df.shape[0]\n",
    "  df.drop(indices, inplace=True)\n",
    "  n_after = df.shape[0]\n",
    "  n_deleted = n_before - n_after\n",
    "  n_deleted_total += n_deleted\n",
    "  print(f'Dropped {n_deleted} elements from {name}')\n",
    "print(f'=> Dropped a total of {n_deleted_total} elements for removal across all databases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 6 publications from ACM Digital Library\n",
      "Removed 545 publications from APA PsycInfo\n",
      "Removed 6 publications from IEEE Xplore\n",
      "Removed 0 publications from PubMed & MEDLINE\n",
      "Removed 1116 publications from Web of Science CORE\n",
      "Removed 27 publications from Google Scholar\n"
     ]
    }
   ],
   "source": [
    "# exporting all in and out files\n",
    "acm_df_filtered = acm_df\n",
    "acm_df = dfs_copy[1]\n",
    "acm_df_excluded = get_filtered_out_entries(acm_df, acm_df_filtered)\n",
    "print(f'Removed {(acm_df_excluded.shape[0])} publications from ACM Digital Library')\n",
    "export_to_bib(acm_df_filtered, './data/filter5_DoiDeduplication/acm_filter_dedup_in.bib')\n",
    "export_to_bib(acm_df_excluded, './data/filter5_DoiDeduplication/acm_filter_dedup_out.bib')\n",
    "acm_df = acm_df_filtered\n",
    "\n",
    "apa_df_filtered = apa_df\n",
    "apa_df = dfs_copy[4]\n",
    "apa_df_excluded = get_filtered_out_entries(apa_df, apa_df_filtered)\n",
    "print(f'Removed {(apa_df_excluded.shape[0])} publications from APA PsycInfo')\n",
    "export_to_ris(apa_df_filtered, './data/filter5_DoiDeduplication/apa_filter_dedup_in.ris')\n",
    "export_to_ris(apa_df_excluded, './data/filter5_DoiDeduplication/apa_filter_dedup_out.ris')\n",
    "apa_df = apa_df_filtered\n",
    "\n",
    "ieee_df_filtered = ieee_df\n",
    "ieee_df = dfs_copy[2]\n",
    "ieee_df_excluded = get_filtered_out_entries(ieee_df, ieee_df_filtered)\n",
    "print(f'Removed {(ieee_df_excluded.shape[0])} publications from IEEE Xplore')\n",
    "export_to_ris(ieee_df_filtered, './data/filter5_DoiDeduplication/ieee_filter_dedup_in.ris')\n",
    "export_to_ris(ieee_df_excluded, './data/filter5_DoiDeduplication/ieee_filter_dedup_out.ris')\n",
    "ieee_df = ieee_df_filtered\n",
    "\n",
    "pubmed_df_filtered = pubmed_df\n",
    "pubmed_df = dfs_copy[0]\n",
    "pubmed_df_excluded = get_filtered_out_entries(pubmed_df, pubmed_df_filtered)\n",
    "print(f'Removed {(pubmed_df_excluded.shape[0])} publications from PubMed & MEDLINE')\n",
    "export_to_csv(pubmed_df_filtered, './data/filter5_DoiDeduplication/pubmed_filter_dedup_in.csv')\n",
    "export_to_csv(pubmed_df_excluded, './data/filter5_DoiDeduplication/pubmed_filter_dedup_out.csv')\n",
    "pubmed_df = pubmed_df_filtered\n",
    "\n",
    "wos_df_filtered = wos_df\n",
    "wos_df = dfs_copy[3]\n",
    "wos_df_excluded = get_filtered_out_entries(wos_df, wos_df_filtered)\n",
    "print(f'Removed {(wos_df_excluded.shape[0])} publications from Web of Science CORE')\n",
    "export_to_bib(wos_df_filtered, './data/filter5_DoiDeduplication/wos_filter_dedup_in.bib')\n",
    "export_to_bib(wos_df_excluded, './data/filter5_DoiDeduplication/wos_filter_dedup_out.bib')\n",
    "wos_df = wos_df_filtered\n",
    "\n",
    "gs_df_filtered = gs_df\n",
    "gs_df = dfs_copy[5]\n",
    "gs_df_excluded = get_filtered_out_entries(gs_df, gs_df_filtered)\n",
    "print(f'Removed {(gs_df_excluded.shape[0])} publications from Google Scholar')\n",
    "export_to_csv(gs_df_filtered, './data/filter5_DoiDeduplication/gs_filter_dedup_in.csv')\n",
    "export_to_csv(gs_df_excluded, './data/filter5_DoiDeduplication/gs_filter_dedup_out.csv')\n",
    "gs_df = gs_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Removed a total of 1700 publications had an identical DOI to at least one other publication\n",
      "  => 3837 entries left in total\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------------------')\n",
    "print(f'Removed a total of {num_before - get_num_entries()} publications had an identical DOI to at least one other publication')\n",
    "print(f'  => {get_num_entries()} entries left in total')\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter 6: Manual Deduplication using Rayyan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the first 5 filters, our review tool\n",
    "[Rayyan](https://www.rayyan.ai/) detected additional duplicates. These are\n",
    "mainly duplicates that did not get caught in the previous filter. The reasons\n",
    "for that are:\n",
    "\n",
    "* some duplicates have no DOI in their metadata\n",
    "* some duplicates have different DOIs but refer to the same publication\n",
    "  * e.g. 10.1007/978-3-031-21333-5 refers to the *Proceedings of the International Conference on Ubiquitous Computing & Ambient Intelligence (UCAmI 2022)*\n",
    "  * e.g. 10.1007/978-3-031-21333-5_88 refers to the same publication, but specifies the correct chapter/element number\n",
    "* some duplicates have different DOIs, but one is a corrigendum/correction/new version/... of the other(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all made decisions in determining what is and is not a duplicate can\n",
    "be found [here](./rayyan_deduplication.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rayyan export does not mark from which data source entries got removed. A\n",
    "list of all removed entries as well as all included entries can be found in\n",
    "[filter6_RayyanDeduplication](./data/filter6_RayyanDeduplication/) in form of\n",
    "two CSV files.\n",
    "\n",
    "* [articles_in](./data/filter6_RayyanDeduplication/articles_in.csv) contains all **3727** articles that are included in the abstract screening\n",
    "* [articles_out](./data/filter6_RayyanDeduplication/articles_out.csv) contains all **110** articles that are excluded from the abstract screening due to being marked as duplicate of another included paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
