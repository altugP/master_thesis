label,name,description,readme
1,ohmyform,"free open source alternative to typeform, tellform, or google forms","!ohmyform # ohmyform !project status !latest release [!docker pulls](https://hub.docker.com/r/ohmyform/ohmyform) !last commit [!deploy](https://heroku.com/deploy?template=https://github.com/ohmyform/ohmyform/tree/master) demo username and password are just `demo`. we will reset the demo instance at least once for every new release and possibly more often so do not rely on it for sending actual forms expect no notice for resets. > an *open source alternative to typeform* that can create stunning mobile-ready forms, surveys and questionnaires. [!discord](https://discord.gg/mjqauaz) [!financial contributors on open collective](https://opencollective.com/ohmyform-sustainability) ## table of contents <!-- toc --> - ohmyform - table of contents - features - on the roadmap - how to contribute - quickstart - where to get help <!-- /toc --> ## features - multi-language support - possible question types - editable start and end pages - export submissions to xls, json or csv - native analytics and google analytics support - embeddable forms - forms as a service api - customizable notifications on form submission - web hooks on form submission - deployable with heroku and dockerhub - postgresql and sqlite <!-- todo: determine roadmap for ohmyform if it is to be different from ohmyform's roadmap. --> <!-- ### on the roadmap (tentative pending refactor) --> ### on the roadmap - custom subdomains for each user - implement encryption for all form data - add typeform api integration - add party integration support (aka slack) - create wiki for easy installation and setup - add stripe/payment form field - add custom background and dropdown field images - add file upload form field <!-- todo: add a contributing.md. --> ## how to contribute please checkout our contributing guide on ways to contribute to ohmyform. ## quickstart follow documentation hosted on ohmyform.com it will be the main and hopefully only location to obtain the up to date documentation. if you pull the repository do not forget to execute: `git submodule update --init` ### some technical insights api ui ## where to get help ## alternative social twitter instagram ## contributors ### code contributors this project exists thanks to all the people who contribute. [contribute]. [!contributors](https://github.com/ohmyform/ohmyform/graphs/contributors) ### financial contributors become a financial contributor and help us sustain our community. [contribute] #### individuals [!individuals](https://opencollective.com/ohmyform-sustainability) #### organizations support this project with your organization. your logo will show up here with a link to your website. [contribute]"
1,stopp-corona-android,android source code,"align=""center""> <br> <img src=""./app/src/main/ic_launcher-playstore.png"" alt=""stop corona logo"" <br> stopp corona <br> **important**: the development has stopped with <p align=""center""> <a href=""https://play.google.com/store/apps/details?id=at.roteskreuz.stopcorona""><img </p> <p align=""center""> <a href=""#about"">about</a> <a href=""#checklist-to-make-project-buildable"">important checklist to make project buildable</a> <a href=""#download"">download</a> <a href=""#license"">license</a> </p> ## about the **stopp corona** project is an open source project for bluetooth based contact tracing deployed by the austrian red cross in austria. for developers interested in contributing, other organizations interested in joining forces please have a look at the following documents: * covenant: the project's ideals and goals * cooperation and funding: support the development or join the project * code of conduct: fair guidelines for a friendly discourse **stopp corona** helps you to keep track of encounters with friends, family or co-workers and save them anonymously. should you contract the corona virus (to be precise: the <a disease caused by the virus</a>) all your encounters of the last hours will be informed automatically and anonymously. and vice versa of course. you too will be notified instantly and anonymously should one of your saved encounters report to have contracted the virus. helping all of you to take appropriate measures such as. - keep a safe distance meters) from others - avoid social contacts - self-quarantine as a precaution together we can break the chain of infection. not only by protecting ourselves, but also by preventing others from being infected. say hello with a digital handshake. it will definitely be a while before we will actually shake each others hands again. in the meantime: use **stopp corona**'s digital handshake. if you and the person you encounter have installed the app, you can simply select each other. the app will anonymously save your meeting. should one of you fall sick with the corona virus the other will receive an instant notification. ### self-check your corona status how are you feeling today? just answer the clinically proven questionnaire to check yourself for corona symptoms daily. ### report suspected infections should your symptoms match those of a corona infection, you can choose to inform your encounters. this is extremely important so stop the virus from spreading. everyone you saved in the last hours will get an anonymous notification. so do not you worry: your personal data is safe with us. if you suspect to have contracted the corona virus, please stay at home and contact your attending physician via telephone. if that is not possible, call the corona-hotline please do not visit your doctors office or a hospital in person! ### medical confirmation if you are officially tested for the corona virus and your test comes back positive, please notify your encounters immediately. of course the notification will also be anonymous. this app was developed in cooperation with the uniqa foundation. app concept and implementation was created with the support of accenture austria. care for you. care for me. that is how we protect ourselves. ## checklist to make project buildable add your own `hostname`, `base_url`, `hostname_tan`, `base_url_tan`, `hostname_cdn`, `base_url_cdn` and potentially other `buildconfigfield`s as shown in the app/build.gradle ## download you can download application from play store. <a href=""https://play.google.com/store/apps/details?id=at.roteskreuz.stopcorona""><img alt=""get it on google play"" src=""https://play.google.com/intl/en_us/badges/static/images/badges/en_badge_web_generic.png""/></a> ## license this code is distributed under the gnu affero general public license version see the license.txt file for more info. notices for third party libraries in this repository are contained in notice.txt."
1,RADAR-Questionnaire,questionnaire mobile application (active app) for radar-base,"## radar-questionnaire !travis ci [!bch compliance](https://bettercodehub.com/) [!codacy a hybrid mobile application to actively capture data for the radar-base platform. ## note we use the ionic framework, which is built with angular and wraps apache cordova. ### recommended package versions it is recommended that you install the following versions or later: ``` node ionic npm ``` ## install first install node.js and yarn. globally install ionic and cordova: ``` $ npm i -g ionic cordova ``` in the project folder run `npm i` to install dependencies: ``` $ npm i ``` cordova provides a simple command to install the plugins and platforms set in `package.json` or `config.xml`. ``` $ cordova prepare ``` to run the application in the browser use: ``` $ ionic serve ``` ## guidelines use the following command to sort, format and fix common css problems: ``` $ npm run fix:css ``` use the following command before commiting to fix all common styling and sorting problems: ``` $ npm run fix:all ``` ## platforms in order to add platforms to target, you must install the required sdks. ### android to add the android platform, you need to have the android sdk pre installed. this step also adds the plugins listed in `config.xml` to the project. ``` $ ionic cordova platform add android ``` run the app in an android device: ``` $ ionic cordova run android ``` run the app in an android emulator: ``` $ ionic cordova emulate android ``` ### ios to add the ios platform, you need to have xcode pre installed. ``` $ ionic cordova platform add ios ``` run the app in an ios device: ``` $ ionic cordova run ios ``` ## firebase if using firebase for notifications, analytics, or remote config, create your firebase project. then, add your ios or android app to the firebase project. once added, please download the app's `google-services.json` file (for android) and `googleservice-info.plist` (for ios), and add it to the root directory. ### package name when you add your ios or android app to the firebase project, make sure you name your `package name` as app-id - android : `org.phidatalab.radar_armt` - ios: `org.phidatalab.radar-armt` ### remote notifications if using fcm pull notifications instead of the local ones, please specify the fcm sender id (as mentioned in fcm settings) in `src/assets/data/defaultconfig.ts` and the default notification type to fcm (this is already the default value). ```ts export const fcmpluginprojectsenderid = 'your-sender-id' export const defaultnotificationtype = 'fcm' ``` in order for notifications to be sent, you must run your own app server. it is part of the radar-base stack, and specific docs can be found here. #### ios remote push notifications for android remote notifications, setting your sender id and adding your `google-services.json` file is enough to begin receiving notifications. however, for ios notifications, you must add either an apns authentication key or apns certificate to connect with apple push notifications. this can be added in the firebase project's cloud messaging settings. ### remote config certain values can be overriden using firebase remote config. specifically, the following variables are supported: | parameter | description | default value | | ------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- | | `oauth_client_id` | client id to connect to the managementportal with | `armt` | | `oauth_client_secret` | client secret to connect to the managementportal with | `` | | `oauth_refresh_seconds` | after how many seconds to refresh the oauth token | minutes) | | `protocol_repo` | github repo where the protocol definitions are located. | `radar-base/radar-armt-protocols` | | `protocol_branch` | github branch where the protocol definitions should be read from | `master` | | `protocol_path` | path inside a project name that should be read for a protocol | `protocol.json` | | `kafka_specification_url` | url of the kafka topic specification | | | `platform_instance` | title of radar base / platform instance | `radar-cns` | | `participant_attribute_order` | map that specifies the order in which the attributes are matched with the protocol path | `{human-readable-identifier: | | `schedule_year_coverage` | schedule coverage in years (length of schedule to generate tasks until) | | | `notification_messaging_type` | notifications type (either 'fcm_rest' or 'local' notifications) | `fcm_rest` | | `app_server_url` | default app server url. | `{defaultendpoint + '/appserver'}` | | `github_fetch_strategy` | default github fetch strategy for github requests (default or appserver). | `default` | | `app_credits_title` | title of the popup box that appears when you tap on the app logo on the left hand side of the homepage. | `credits` | | `app_credits_body` | body of the popup box that appears when you tap on the app logo on the left hand side of the homepage. | `made with &hearts; for you by the radar-base community.` | | `auto_next_questionnaire_types` | string list of question/question input types where the questionnaire will automatically move to the next question upon answering the question. it is recommended to always include timed and audio types. | `timed,audio` | | `skippable_questionnaire_types` | string list of question/question input types where the next button is enabled by default, allowing the question to be skippable. | `audio` | | `show_task_calendar_name` | the task calendar by default shows the task timestamp instead of the task name. this allows showing of the task name instead of the timestamp. | `false` | | `show_task_progress_count` | in the questionnaire page, by default, only the task progress bar is shown. this config will enable the showing of the ""question number / total questions"" count. | `false` | #### conditions conditions can be added to remote config variables to target specific groups of users. different condition rule types are supported: app, platform, country/region, user property, date/time, and random percentile. for example a `protocol_branch` config value can be different based on the user property `projectid`. #### protocol attributes a user/subject can have `attributes` which are taken from management portal. these could determine what protocol would be pulled for the user from github (radar armt protocols). the repository should follow the format: `/project_name/attribute-key/attribute-value/protocol.json`. please note that a default `protocol.json` file must always be present in the project directory, e.g.: `/project_name/protocol.json`. if multiple attributes are present for the user, the `participant_attribute_order` from the remote config will be used to determine which attribute takes precedence. if this is not present, the default value is `{human-readable-identifier: the human readable id will always be the highest priority. if an order value is not present for the attribute, the default value (`max_int_value`) would be used. ### analytics in order to personalize firebase events and remote config variables, certain user properties may be added to the firebase console. specifically, the following user properties are supported: | property | description | | ----------------- | ----------------------------------------------------------------- | | `subjectid` | custom identifier for the user | | `humanreadableid` | human readable identifier for the user | | `baseurl` | custom identifier for the base url of the project | | `projectid` | custom identifier for the project that a user belongs to | | `sourceid` | custom identifier for the source the application is registered as | | `enrolmentdate` | enrolment date of the user | further details on the events that are already logged, default events, and default user properties can be found on the radar base wiki pages. ## other config options you can change the default config locally in `src/assets/data/defaultconfig.ts`. some of these can also be modified in firebase remote config. the main configs you may want to modify are: the client secret for oauth authorisation with the management portal (empty by default). ```ts export const defaultoauthclientsecret = '' ``` the default endpoint of where the radar-base platform is hosted. ```ts export const defaultendpoint = 'https://your-hosted-radar-platform-base-url/' ``` the default appserver configs. ```ts // the notification type (either 'fcm_rest' or 'local' notifications, note: 'fcm_xmpp' support was removed in export const defaultnotificationtype: string = 'fcm_rest' // app server url export const defaultappserverurl = defaultendpoint + '/appserver' ``` you can also change the default github source details where the questionnaire scheduling protocols and questionnaire schemas are hosted. ```ts // the github repository where the protocols are located export const defaultprotocolgithubrepo = 'radar-base/radar-armt-protocols' // the name of the branch in the protocol repository export const defaultprotocolbranch = 'master' // the name of the repository where the questionnaire schemas are located export const defaultschemagithubrepo = 'radar-base/radar-schemas' // the name of the branch in the schema repository export const defaultschemabranch = 'master' // the github content fetching mechanism, if this is done by a direct request to github or a request through the app server. (remote config key: `github_fetch_strategy`, values: `default` (direct to github) or `appserver`) export const defaultgithubfetchstrategy = 'default' ``` ## adding language support translations must be specified or modified in the localisations file `(src/assets/data/localisations.ts)`. when adding additional text in the localisations file, additional keys must also be added to `src/app/shared/enums/localisations.ts`. to add additional languages, the following default config `(src/assets/data/defaultconfig.ts)` variable must be updated: ```ts export const defaultsettingssupportedlanguages: languagesetting[] = [] ``` ## publishing to the google playstore instructions to build a signed apk for publishing on the playstore - clone the armt project from github. configure it as per instructions above. run the following to build the app ```she will npm install npm run build ionic cordova platform add android ionic cordova build --release android ``` this will generate an apk at `<your-project-path>/platforms/android/app/build/outputs/apk/release/app-release-unsigned.apk` create a keystore for signing the apk. keep this safe as this is tied to your play releases and only apks signed by this can be released to the playstore after the intitial release. you will need to then sign this apk using jarsigner ``` jarsigner -verbose -sigalg -digestalg -storepass <your-keystore-pass> -keystore <your-keystore-path> <your-project-path>/platforms/android/app/build/outputs/apk/release/app-release-unsigned.apk alias_name; ``` then you will need to align the apk using zipalign (https://developer.android.com/studio/command-line/zipalign) like- ``` -v <your-project-path>/platforms/android/app/build/outputs/apk/release/app-release-unsigned.apk <your-project-path>/platforms/android/app/build/outputs/apk/release/radar-armt-app-$app_version.apk; ``` now the apk is ready to be uploaded to the playstore at path `<your-project-path>/platforms/android/app/build/outputs/apk/release/radar-armt-app-$app_version.apk` note: the signing and aligning can also be done by importing the android project at path `<your-project-path>/platforms/android/` into android studio. ## questionnaire input types the questionnaire input types supported are `audio`, `checkbox`, `descriptive`, `info-screen`, `matrix-radio`, `radio`, `range-info`, `range-input`, `slider`, `text`, `date`, `time`, and `timed-test`. ### descriptive input type the descriptive input supports html in the `field_label` property of a questionnaire in the questionnaire definition. the css will automatically be inherited from the app. here is an example input: ``` hello this is an example of a descriptive input text. <br> <br> <b>this is a bold text</b> <br> is an <br> is an <br> is an is an is an <br> <iframe title=""youtube video player"" allowfullscreen></iframe> <br><br> this is an example of an image: <br> <img ``` here is the output: <img ## common errors here are some common errors you might find during installation. ### error: cordova-custom-config when you are running `ionic cordova run ios`, you might encounter the problem, we solved this problem by refering this issue with `cordova-custom-config`. we enter the following command at the root directory. ``` cd plugins/cordova-custom-config npm install ```"
1,c3-pro-ios-framework,combining fhir and researchkit,"<img src=""./assets/logo.png"" this is the **ios** framework, written in swift, for our research framework. combining [ fhir][fhir] and [researchkit][], usually for data storage into this framework allows you to use fhir _questionnaire_ resources directly with researchkit and will return fhir _questionnaireresponse_ that you can send to your server. in addition, a fhir _contract_ resource can be used to carry trial eligibility requirements and define content to be shown during consenting. subsequently, the contract can be signed with a fhir _patient_ resource and returned to your server, indicating consent. there are additional utilities for _encryption_, _geolocation_, _de-identification_ and _data queueing_ that go well with a research app. these are individual modules, meaning you can use only the parts you need. see below for what is included. #### usage taking a _pure swift_ approach, you will not be able to use this framework with objective-c alone. instead, you can use swift code in your app, using a [mix and match][mix-match] approach, to connect the components to the objective-c bits in your app. see below for **important swift and fhir version** considerations. installation [ sample app][sample app] [ technical documentation][docs] ```swift import ``` #### versions the `master` branch requires xcode and _should_ always be compatible with the latest released version. it is on `swift and `fhir the `develop` branch may contain new developments and have different requirements, it is currently on `swift and `fhir see the releases tab for previous releases, for newer versions look for `feature/x` branches. see changelog.md for updates. this framework combines several versioned technologies, here is an overview over what is included: version | swift | researchkit | fhir | &nbsp; -----------|---------|-------------|-------|---------------- | | | | | | | | ballot | | | | | | | | _not supported_ | | | | | | | | | | | | modules ------- the framework consists of several modules that complement each other. ### study introduction shows the well-known _welcome to my study_ screens that allows users to inform themselves before joining your study. study intro ### eligibility & consent using a fhir `contract` resource representing the **consent document**, can render eligibility questions and the consenting workflow. consent ### questionnaires enables use of a fhir `questionnaire` resource as direct input to a researchkit **survey** task and return the encoded answers as a fhir resource. also serves as return format of **activity data** collected on the phone. questionnaire ### dataqueue `dataqueue` is a fhir server implementation used to move fhir resources, created on device, to a fhir server, without the need for user interaction nor -confirmation. dataqueue ### profilemanager, users & tasks a collection of classes and protocols that make it easier to enroll, link and withdraw users from a research app. `dataqueue` is a fhir server implementation used to move fhir resources, created on device, to a fhir server, without the need for user interaction nor -confirmation. profile & user ### healthkit & coremotion (activity data) `activityreporter` implementations for _healthkit_ and _coremotion_. the latter includes persistence of activity data past the days ios default. extensions to _healthkit_ classes to easily query for samples and to represent quantities in fhir. healthkit ### system service permissions facilities to request permission to send notifications, access healthkit and others. these can be integrated into the consent flow. systemservices notifications ### encryption aes and rsa encryption facilities that come in handy. these work with facilities officially exposed by ios, meaning you **do not need to add openssl** to your app. encryption ### de-identification & geocoder helps creating de-identified patient resources, consistent with _hipaa safe harbor_ guidelines, with birthdate and zip (determined by _geocoder_) truncated accordingly. deidentifier localization ------------ the framework uses `nslocalizedstring` on the table name, meaning it is looking at the file for string localization. there is an extension on _string_ so we can simply use `""my in code. if you are looking for localizable strings in code, search for this variable. license ------- this work is apache licensed. be sure to take a look at the notice.txt file, and do not forget to also add the licensing information of the submodules somewhere in your product: - researchkit - cryptoswift - sqliteswift - jsonwebtoken.swift [fhir]: [researchkit]: http://researchkit.github.io [mix-match]: https://developer.apple.com/library/ios/documentation/swift/conceptual/buildingcocoaapps/mixandmatch.html [sample app]: [docs]:"
0,della,della is a django app for managing secret santa/gift exchange.,"# della della is a django app for managing secret santa/gift exchange. it is written for small communities where participants are in the range of but not more (why so?). ## features della has very limited set of features, however, if you need some extra feature then feel free to tweet me and i _might_ consider adding it. - user signup (with invite code) - messaging and secret/sneaky messaging (with email notifications) - gallery - admin features - drawing names, sending mass emails ## screenshots check here. ## system requirements - python - postgresql (or mysql) - nginx - supervisord ### other requirements della uses sparkpost to send emails. so you need sparkpost api key and also an email address which can be used to send emails with sparkpost. while signing up, every participant needs an invite code, which can be set to any string by admin. these settings are to be set in `della/settings/secret.py` as `sparkpost_api_key`, `sender_email` and `invite_code`. ## deployment clone the repo and rename/copy `della/settings/sample_secret.py` to `della/settings/secret.py` and set the variables appropriately. install the requirements install -r requirements.txt setup ngnix (use `configs/nginx`) setup uwsgi (use `configs/uwsgi.conf`) setup supervisord (use `configs/supervisor.conf`) once everything is setup, cd into della directory and run following: install -r requirements.txt manage.py migrate --settings=della.settings.production manage.py collectstatic --settings=della.settings.production --noinput manage.py createsuperuser --settings=della.settings.production manage.py makemigrations background_task --settings=della.settings.production manage.py migrate --settings=della.settings.production systemctl start della.uwsgi.service supervisorctl start della_background_tasks ## to do - add tests - mark/confirm gifts received (or not) - add commenting system for gallery - allow multiple exchanges - ability to set preference questionnaire for exchanges ## name the name della comes from o. henry's short story the gift of the magi. ## send me love you will probably going to use a vps to host della, please consider using any of the following referral links: - digital ocean - vultr - ramnode or some bitcoins: thank you! ## contributing check the logged issues with tag `enhancement`. do submit a new issue if you have any ui/ux suggestion. ## license the mighty mit license. please check `license` for more details."
0,adyen-php-api-library,adyen api library for php,"!php # adyen php api library this is the officially supported php library for using adyen's apis. [!version](https://packagist.org/packages/adyen/php-api-library) ## supported api versions the library supports all apis under the following services: | api | description | service name | supported version | |------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|--------------------------| | bin lookup api | the bin lookup api provides endpoints for retrieving information based on a given bin. | binlookup | | | capital api | adyen capital allows you to build an embedded financing offering for your users to serve their operational needs. | capital | | | checkout api | adyen checkout api provides a simple and flexible way to initiate and authorise online payments. you can use the same integration for payments made with cards (including secure), mobile wallets, and local payment methods (for example, ideal and sofort). | checkout | | | configuration api | the configuration api enables you to create a platform where you can onboard your users as account holders and create balance accounts, cards, and business accounts. | balanceplatform | | | dataprotection api | adyen data protection api provides a way for you to process subject erasure requests as mandated in gdpr. use our api to submit a request to delete shopper's data, including payment details and other related information (for example, delivery address or shopper email) | dataprotection | | | management api | configure and manage your adyen company and merchant accounts, stores, and payment terminals. | management | | | payments api | a set of api endpoints that allow you to initiate, settle, and modify payments on the adyen payments platform. you can use the api to accept card payments (including one-click and secure), bank transfers, ewallets, and many other payment methods. | payments | | | recurring api | the recurring apis allow you to manage and remove your tokens or saved payment details. tokens should be created with validation during a payment request. | recurring | | | payouts api | a set of api endpoints that allow you to store payout details, confirm, or decline a payout. | payout | | | binlookup api | endpoints for retrieving information, such as cost estimates, and secure supported version based on a given bin. current supported version | binlookup | | | stored value api | manage both online and point-of-sale gift cards and other stored-value cards. | storedvalue | | | legal entity management api | the legal entity management api enables you to manage legal entities that contain information required for verification | legalentitymanagement | | | transfers api | the transfers api provides endpoints that you can use to get information about all your transactions, move funds within your balance platform or send funds from your balance platform to a transfer instrument. | transfers | | | balance control api | the balance control api let us you transfer funds between merchant accounts that belong to the same legal entity and are under the same company account. | balancecontrol | | | hosted onboarding api | the hosted onboarding api provides endpoints that you can use to generate links to adyen-hosted pages, such as an onboarding page or a pci compliance questionnaire. you can provide these links to your account holders so that they can complete their onboarding. | hostedonboardingpages | | | account api | the account api provides endpoints for managing account-related entities on your platform. these related entities include account holders, accounts, bank accounts, shareholders, and verification-related documents. the management operations include actions such as creation, retrieval, updating, and deletion of them. | account | | | fund api | the fund api provides endpoints for managing the funds in the accounts on your platform. these management operations include, for example, the transfer of funds from one account to another, the payout of funds to an account holder, and the retrieval of balances in an account. | fund | | | terminal api (cloud communications) | our point-of-sale integration. | cloud-based terminal api | cloud-based terminal api | | | terminal api (local communications) | our point-of-sale integration. | local-based terminal api | local-based terminal api | | | pos terminal management api | this api provides endpoints for managing your point-of-sale (pos) payment terminals. you can use the api to obtain information about a specific terminal, retrieve overviews of your terminals and stores, and assign terminals to a merchant account or store. | posterminalmanagement | | | disputes api | you can use the disputes api to automate the dispute handling process so that you can respond to disputes and chargebacks as soon as they are initiated. the disputes api let us you retrieve defense reasons, supply and delete defense documents, and accept or defend disputes. | disputes | | ## supported webhook versions the library supports all webhooks under the following model directories: | webhooks | description | model name | supported version | |---------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|-------------------| | authentication webhooks | adyen sends this webhook when the process of cardholder authentication is finalized, whether it is completed successfully, fails, or expires. | acswebhooks | | | configuration webhooks | you can use these webhooks to build your implementation. for example, you can use this information to update internal statuses when the status of a capability is changed. | configurationwebhooks | | | transfer webhooks | you can use these webhooks to build your implementation. for example, you can use this information to update balances in your own dashboards or to keep track of incoming funds. | transferwebhooks | | | transaction webhooks | adyen sends webhooks to inform your system about incoming and outgoing transfers in your platform. you can use these webhooks to build your implementation. for example, you can use this information to update balances in your own dashboards or to keep track of incoming funds. | transactionwebhooks | | | report webhooks | you can download reports programmatically by making an http get request, or manually from your balance platform customer area | reportwebhooks | | | management webhooks | adyen uses webhooks to inform your system about events that happen with your adyen company and merchant accounts, stores, payment terminals, and payment methods when using management api. | managementwebhooks | | | notification webhooks | we use webhooks to send you updates about payment status updates, newly available reports, and other events that you can subscribe to. for more information, refer to our documentation | notification | | for more information, refer to our documentation or the api explorer. ## prerequisites - adyen test account - api key. for testing, your api credential needs to have the api pci payments role. - php or later - curl with ssl support. - the php extensions: ctype, curl, json, mbstring and openssl. - see composer require list for the complete list of dependencies. ### legacy version support if using php versions or lower, download our library version ## installation you can use composer. follow the installation instructions if you do not already have composer installed. ~~~~ bash composer require adyen/php-api-library ~~~~ in your php script, make sure you include the autoloader: ~~~~ php require __dir__ . '/vendor/autoload.php'; ~~~~ alternatively, you can download the release on github. ## using the library ### general use with api key set up the client as a singleton resource; you will use it for the api calls that you make to adyen: ~~~~ php $client = new \adyen\client(); $client->setxapikey(""your api key""); $client->setenvironment(\adyen\environment::test); $service = new \adyen\service\checkout\paymentsapi($client); // create paymentmethod object $paymentmethod = new checkoutpaymentmethod(); $paymentmethod ->settype(""scheme"") // creating amount object $amount = new amount(); $amount ->setcurrency(""eur""); // create the actual payments request $paymentrequest = new paymentrequest(); $paymentrequest ->setmerchantaccount(""your merchant account"") ->setpaymentmethod($paymentmethod) ->setamount($amount) ->setreference(""payment-test"") ->setreturnurl(""https://your-company.com/...""); $result = $service->payments($paymentrequest); ~~~~ ### general use with api key for live environment ~~~~ php $client = new \adyen\client(); $client->setxapikey(""your api key""); $client->setenvironment(\adyen\environment::live, 'your live url prefix'); ... ~~~~ ### general use with basic auth ~~~~ php $client = new \adyen\client(); $client->setusername(""your username""); $client->setpassword(""your password""); $client->setenvironment(\adyen\environment::test); ... ~~~~ ### instantiating the request objects through the arrayaccess implementation (for easy migration) ~~~~ php ... $service = new \adyen\service\checkout\paymentsapi($client); $params = array( 'merchantaccount' => ""yourmerchantaccount"", 'reference' => 'amount' => array('currency' => ""brl"", 'value' => 'countrycode' => ""br"", 'shopperreference' => ""youruniqueshopperid"", 'shopperemail' => ""test@email.com"", 'shopperlocale' => ""pt_br"", 'billingaddress' => array(...), 'deliveryaddress' => array(...), ); $createpaymentlinkrequest = new createpaymentlinkrequest($params); $result = $service->paymentlinks($createpaymentlinkrequest); $paymentlink = $result->geturl(); // or use $result['url'] if you want to use arrayaccess ~~~~ ### using banking webhooks ~~~~ php ... $jsonstring = 'webhook_payload'; $isvalid = $hmac->validatehmac(""your_hmac_key"", ""your_hmac_sign"", $jsonstring); if ($isvalid) { $webhookparser = new bankingwebhookparser($jsonstring); $result = $webhookparser->getgenericwebhook(); } ~~~~ ### using management webhooks ~~~~ php ... $jsonstring = 'webhook_payload'; $isvalid = $hmac->validatehmac(""your_hmac_key"", ""your_hmac_sign"", $jsonstring); if ($isvalid) { $webhookparser = new managementwebhookparser($jsonstring); $result = $webhookparser->getgenericwebhook(); } ~~~~ ### example integration for a closer look at how our php library works, clone our laravel example integration. this includes commented code, highlighting key features and concepts, and examples of api calls that can be made using the library. ### running the tests for the test cases you need the pci permission enabled on you account. there are no test cases for cse because credit card data is encrypted through our javascript library. by default the test will then be skipped. if you have these permissions fill in your account details in the config/test.ini file to let the test work. to make the automatic testing cases work for your account change the credentials in the config/test.ini file. ## feedback we value your input! help us enhance our api libraries and improve the integration experience by providing your feedback. please take a moment to fill out our feedback form to share your thoughts, suggestions or ideas. ## contributing we encourage you to contribute to this repository, so everyone can benefit from new features, bug fixes, and any other improvements. have a look at our contributing guidelines to find out how to raise a pull request. ## support if you have a feature request, or spotted a bug or a technical problem, create an issue here. for other questions, contact our support team. ## licence this repository is available under the mit license. ## see also * example integration * adyen docs * api explorer"
0,ringo,simple bot for notifying admins on new telegram user join requests.,"[!test](https://github.com/why-not-try-calmer/ringo/actions/workflows/test.yml) [!publish](https://github.com/why-not-try-calmer/ringo/actions/workflows/publish.yml) ## overview this bot provides a simple click-based verification workflow for your telegram users. it requires that you have enabled the options `only members can send messages` as well as `use chat join requests`; only the latter is strictly necessary but goes hand in hand with the former. you can see the bot in action here. if you like the bot, feel free to use it in your own chats, fork this repository or even pay a coffee or a beer to the developer. at any rate please mind the license. ## how it works there are two modes of operation: __manual mode__ the user registers a ""join request"" against your chat by clicking the ""request to join"" button. you admins accept / reject the request from any chat of their convenience provided it is where the bot forwards the join request. __auto mode__ the user registers a ""join request"" against your chat by clicking the ""request to join"" button. (same as before) the bot opens a new private chat with the user. from there the user can confirm by using the button provided there. your admins do not have anything to do. __questionnaire mode__ the user registers a ""join request"" against your chat by clicking the ""request to join"" button. the bot sends questions to the user in a private message, and collects answers one by one, reporting to the admins of the chat from which the bot is controlled when all answers. upon reviewing the answers the admins can either accept or deny the join request. ## commands the bot uses exactly two commands in addition to `/help` (which aliases to `/start`): - `/set ...>`: configure the bot to your liking. here is the list of possibles keys (the values are always text strings): - `chat_id`: the chat_id of the chat where the bot should listen for join requests (you cannot manually set this value) - `chat_url`: the full url (https://t.me/...) of the chat where the bot should listen for join requests (you can and __should__ set this value) - `mode <auto | manual | questionnaire>`: see the previous section for explanations - `helper_chat_id_`: chat_id of the chat to which the both should forward join requests notifications (only used in __manual__ mode) - `verification_msg`: the message the bot should send to users trying to verify after landing a join requests. naturall it is not convenient to set a long verification message in this way, so for that key it might be preferable to use a line break, as in: ``` /set mode auto verification_message sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. ``` - `questionnaire`: the questionnaire to send to the user trying to join, with an introductions, a set of questions, and an outro. each part and each question must be separated with a linebreak, as in: ``` /set mode questionnaire hello, please take this short survey so that we can make sure you are worthy of joining this chat. question ... question ... question ... thanks very much! admins will now accept or decline your join request. ``` - `paused <on | off>`: _off_ pauses the bot for this chat, _off_ makes it active - `show_join_time <on | off>`: _off_ does not show the time it took for a user to join the target chat after being sent an invite, _on_ shows it - `changelog < on | off>`: _off_ let us you opt-out of changelog notification messages - `/reset` (no parameter): resets the bot to its default settings relative to chat(s) you manage ## tests run test with `python -m pytest -s --asyncio-mode=strict -v` ## deploy since i do not plan on investing heavy resources on deployment it is better if users deploy their own copy of this bot. the easiest way is to use docker / podman. create a new directoy, cd to it and then: clone this repository: `git clone https://github.com/why-not-try-calmer/ringo.git .` cd to it and there create your own ssl certificate (for encoding/decoding https requests to/from telegram): `openssl req -newkey -nodes -keyout private.key -days -out cert.pem`. follow the interactive instructions. build the image: `docker build . -t ringo` (use `docker` if you are able to use `podman`) deploy: `docker run -p --env-file .env localhost/ringo` the last command assumes that you are using an .env file to pass secrets to the bot. this is required if you do not set envars containing the needed secret by some other means. the bot expects the following envars (random examples): ``` admin=userid_of_admin <- the chat the operator is going to use to administrate the bot endpoint=https://some.you are.l <- the webhook's url mongo_conn_string=mongodb+srv://myapp:mypass@myhost/?retrywrites=true&w=majority <- the mongo db connection string <- your telegram token ``` notice that telegram as per their official documentation requires you to use any of or as your host_port. if you want to have the bot listen to a custom port, there is the option to add a `port` envar. then command above will read instead: deploy: `docker run -p <host_port>:<custom_container_port> --env-file .env localhost/ringo` finally to start the bot run `python -m app` if you want to register a webhook hook and receive updates with the built-in server. otherwise start with `python -m app --polling`."
1,companion-kit,this is the official repository of the maslo companion kit,"# maslo companion kit !github stars [!open source? yes!](https://github.com/naereen/badges/) !twitter follow ## overview companions are personal, trusted, and adaptable ais that meet people where they are and help them get to where they want to be. they are surface agnostic and can live on websites, mobile apps, computers, in car dashboards, and more. maslo companion kit is a fully functional and customizable mobile application project for ios and android to grow your own companion. out of the box features include: * email/sms/so authentication methods * text and voice check-ins * mood and location logging * editable/customizable prompts * customizable notifications/reminders to check in * administer assessments and questionnaires * administration capability to summarize information by client * custom companion branding * algorithms to generate insights from signals - options include anxiety, depression, anger, well-being, energy, mindfulness, and more. maslo has packaged components that allow customers & developers to easily customize and deploy the entire suite of maslo capabilities in ways that meet their business needs. ## use cases * check-in companion for therapists and their clients * resilience building companion for coaches and their clients * clinical trials companion for researchers and their participants * education companion for self guided and directed personalized learning * career companion for finding jobs and building skills * and so much more... there are many possibilities! on with it. get to growing your maslo! ## getting started ### requirements * node.js (`nevermind` is preferable) * expo cli npm ``` npm i -g expo-cli ``` yarn ``` yarn global add expo-cli ``` * firebase tools: npm ``` npm i -g firebase-tools ``` yarn ``` yarn global add firebase-tools ``` ### mobile dependecies to get better user experience on mobile app, there will be needed to clone two dependecies that are for mobile: maslo-persona and react-native-switch-pro. firstly, from the root folder, navigate to the mobile/dependencies folder. ```bash cd mobile/dependencies ``` and then, clone the maslo-persona into the persona folder. ```bash git clone https://github.com/heymaslo/maslo-persona.git persona ``` make sure the cloned project folder is **persona**, not **maslo-persona**. change to the dev-tool branch. ```bash git checkout ""dev-ts"" ``` and lastly, clone react-native-switch-pro. ```bash git clone https://github.com/heymaslo/react-native-switch-pro.git ``` install all dependencies and validate node.js version: ### do this in root, mobile and dashboard directories to install all the needed packages. yarn ```bash yarn all ``` npm ``` npm install ``` ### structure (basics) this repo organized as monorepo with simplified structure/flow. roots are: * `common` platform independent helpers, utils, dtos, project models and other re-usable code. * `dashboard` react-based web app for managing clients (care provider role) * `mobile` expo/react native-based mobile for clients * `server` firebase-based project for api and database * `config` build time front-end project configuration and helpers for compiling them. ### configuration files references frontend (mobile, dashboard and web) core configuration resides in files `./config/example_app.js` (rename to `app.js` and fill the config fields). it includes: * firebase config (inclduing dashboard and mobile) * integrations (google, sentry) settings * features settings (on/off) * and build configs like hostname, mobile app config (expo) name, expo release channel. common configuration file `./common/constants/features.ts`. * enable/disable dashboard features * enable/disable mobile features * allow check-ins delete * allow check-ins privateness * ask for location this configuration structure implies difference between `development`, `staging` and `production` environments per each project which may not be always necessary. mobile app expo configuration: `./mobile/app.json` according to expo docs firebase config `./server/.firebaserc` environment config file `./server/functions/.env` (should be created if not exists). * .env file content `google_application_credentials=/path/to/json/credentials` the creditial file is created on firebase console under the project settings. generate the credential clicking on ***generate new private key*** button and save this to a folder. do not forget to add this json file to the git ignore. backend config file `server/functions/src/services/config/app.ts` ### features used in google cloud console and firebase * enable sign in methods in firebase authentication tab: `email/password` + `email link`, `google` and `apple`. * iam: https://console.developers.google.com/apis/api/iam.googleapis.com/overview. * cloud speech-to-text api: https://console.developers.google.com/apis/api/speech.googleapis.com/overview * natural language api: https://console.developers.google.com/apis/api/language.googleapis.com/overview * cloud vision ai api: https://console.developers.google.com/apis/api/vision.googleapis.com/overview * blaze plan ### state management application state is stored and managed by the controllers layer. controllers expose getters for the state and methods to mutate it. entry point for controllers is appcontroller (mobile: `mobile/src/controllers/index.ts`, dashboard: `dashboard/src/app/controllers/index.ts`). observing is organized via mobx. it allows with a minimum amount of user code to catch events when some data changes. ## mobile ### run & build app to run project locally via expo run `yarn start` from the `mobile/` folder for building an apk (app bundle) or ipa use commands ``` yarn build:(ios|android):(stage|prod) ``` and manage all keystores/credentials via expo. it is important to use that command because there is a wrapper that ensures correct environment is caught up. ### upload `ipa` to testflight via fastlane install fastlane https://fastlane.tools/ ```bash fastlane pilot upload --skip_waiting_for_build_processing --skip_submission --ipa 'path/to/ipa' ``` ## dashboard ### how to run to run project locally run `yarn dev` from the `dashboard/` folder ## backend ### how to run make sure `server/functions/.env` file exists. (even blank) make sure `server/functions/.runtimeconfig.json` exists with ```json { ""envs"": { ""project_name"": ""[appname]"", ""sendgrid_api_key"": ""..."", ""sendgrid_emails_validation_api_key"": ""..."", ""is_prod"": ""false"" // set false for staging, ""devlogin"": true, ""twilio_phone_number_from"": ""..."", ""twilio_auth_token"": ""..."", ""twilio_account_sid"": ""..."" } } ``` run `yarn dev:functions` ## how to deploy ### back-end/dashboard to staging/production deployment to firebase services is managed by firebase cli and wrapped in convenience npm commands in root package.json: * `deploy:dashboard:(stage|prod)` builds dashboard app with webpack and deploys it to configured hosting in current firebase project. * `deploy:server:(stage|prod)` server (functions, firestore rules and indexes) for more details examine those commands, they are basically combined from other more specific ones. ### deploy mobile apps to play market and app store expo covers all the deployment process in their documentation (and here specifically), but the highlights are: * making standalone builds is required only when some native features have changed, including bundled assets, app permissions or dynamic links configuration. also, it is required when the expo sdk or application version changes and when there is a need to use another expo account. * since currently the mobile project uses expo managed workflow, for all other cases like updated js code or most types of assets ota (over-the-air) flow will work via publishing. * expo account is required for deploying/publishing via expo. standalone builds queue, apps published js and assets are associated with this account. it is totally not a problem to deploy a new standalone build using another expo account, but is required to make publishing work later. ## external dependencies the following dependencies are organized as git submodules: * maslo persona logic and animations for maslo persona orb. * react native switch pro a package for rendering switch in right now apps; in this fork the component was refactored to typescript with adaptations to the new react lifecycle. ## analytics the mobile apps use firebase analytics at a basic level (without logging events). dashboard uses google analytics with a custom library (`common/services/analytics`). ## notifications mobile app uses local and push notifications. most related types are defined in `common/models/notifications.ts`. notificationtypes enum defines the following types: retention local notifications for reminding a user to make a check-in. a user can adjust them in settings. customprompt push sent to a client for a scheduled prompt. assessment push sent to a client when an assessment has been activated by a coach in their dashboard. newdocumentlinkshared push sent to a client when a document link has been shared with them by a coach. ## persona maslo persona orb is responsible for rendering persona animations in webgl context using shaders geometry and gsap library. it also exposes platform-dependant wrappers: for dom used in dashboard, in clients overview just as an interface element. for expo used in mobile; basically almost on every screen it takes a significant part of the user interface. ## structure ### common commons contain platform-independent code to be re-used in dashboard, mobile and server apps. it describes business logic models, dtos, utils, helpers and even some controllers and viewmodels. #### services, helpers, utils services contain cross-platform wrappers for client-side firebase, localization and analytics. helpers was designed to contain re-usable business logic code, while utils should contain general utilities like math, strings, validation etc. #### models models are database entities or just data structures with some additional helper logic for manipulating objects. also they define dtos and enums. #### repository layer database repositories wrap all access to firestore. it allows to specify an api for working with the db, add some additional validations and make compound queries and transactions. #### intakeforms `common/models/intakeforms` intakeforms (aka assessments) feature for allowing coach to collect some data from their clients in form of questionnaires. index.ts and types.ts define data structure types, types of assessments and types enabled by default. all other files are definitions for specific assessment types. #### prompts `common/models/prompts` this folder contains models definitions for few connected features: * custom prompts they are connected by sharing the same data structure their data stored in (promptslibrary and clientlibrarystate in `common/models/prompts/prompt.ts`) and endpoint (intakeformsendpoint in `common/abstractions/functions.ts`). ## dashboard and mobile dashboard and mobile apps use the customized mvvm pattern with an additional layer of controllers. * models. describe data structures stored in db and mediator entities; may contain some additional helper code. * controllers. stateful components usually organized in hierarchy. contain client side business logic (but disregard which frontend engine is used), synchronize with db, make api calls and expose observable data to be read by viewmodels. this layer depends only on models and api. * viewmodels. implements all logic for views, but with no dependency on the view layer. transforms data from controllers, wraps actions and makes sure view knows what to show and what to do when a user interacts. * views. responsible only for visualization of certain viewmodels, should present data as is, rarely do any kind of logic. should not access controllers or db/apis directly. ### routing and statemachine state machine is a system that switches ui and persona states according to a scenario. each state is a screen with some ui and interactive elements. since the app has only one instance of persona on the screen, its state is managed as well by each state. persona should react to global operations (like in progress state presented by listen animation) as well as to actions within a state, being at the same time on the top of all ui. so every state can manage this via special context (ipersonaviewcontext). scenario is a declarative data structure that defines transitions between states. there are enter and exit conditions for each state which are tied to the application state or user produced triggers. conditions and triggers can be combined with logical and or or operations. triggers are defined globally but can be processed locally on transition level. conditions are based on observable getters so whenever the value of the getter changes the condition raises re-computing of transition so scenario can decide to switch a state. main benefit of such an approach is flexibility. each state can be transitioned to any other based on defined conditions for the application state. application state mutates according to user flow, so the scenario stays declarative, clean and basically defines the user flow. also, scenario can be easily tweaked according to app configuration like enabling/disabling some features. scenario is splitted to parts: * scenario runner (`mobile/src/statemachine/scenario.runner.tsx`) runs a given scenario, takes care of mounting correct state, observing and computing conditions and triggers, making transitions. * scenario itself (`mobile/src/statemachine/scenario.ts`) app specific, declares transitions for each state. * scenario viewmodel (`mobile/src/statemachine/scenario.viewmodel.ts`) app specific, declares all necessary conditions for building transitions. and director of this party is statemachine (`mobile/src/statemachine/machine.tsx`) which renders scenario runner configured with a particular scenario, persona and connects them via an instance of istateviewcontext. ### backend backend uses firebase functions, so it consists of a set of endpoints grouped together by logical apis. all endpoints reference can be found in `common/abstractions/functions.ts.` every physical and logical endpoint is described via functiondefinition class (`common/abstractions/functions.definition.ts`) with all required meta including in/out data structures definition. on the server side, it allows firebase to make it up and running using functionfactory (`server/functions/src/utils/createfunction.ts`). on the client side, the another functionfactory (`common/services/firebase/functionfactory.ts`) allows clients to make typed promise-based requests to the endpoint using common function definition. #### cron jobs there are types of cron jobs (`server/functions/src/cron.ts`) * scheduled events triggered every minutes to process project events (like sending push notifications for specific events). * export and import db triggered every for making a backup of the firestore database and importing it into the bigquery project. #### database according to firestore, data is organized in documents, collections and sub-collections of documents. each document has data, that should always be described it typescript types/interfaces. collections paths are hardcoded in `common/database/collections.ts` file; explicit usage of collection paths not via this file should be avoided. #### database structure & access rules * by default, read/write access to all documents is restricted to frontend clients. * the most of write operations are done via api so all necessary validation is guaranteed to take place. * `users` * collection of `userprofile`s, an entiy for all users in the system * id is `auth.uid`. * user can read only their own user profile. * `{userid}/public/info` * `userpublicprofile` for fetching display name and avatar url by any authenticated user. * `{userid}/localsettings` * collection of `userlocalsettings`, each is some service info stored for consistency, analytics and debug, for each device user has used. * id is a device unique identifier * user can read & write their own entries. * `coaches` * collection of `coachprofile`, profile data related to coach role. * id is `auth.uid`. * coach can read their own coach profile. * `{coachid}/clients` * collection of `clientcard`, client info from coach perspective; can be in different states, so not always tied to real client user. * id is a unique string. * coach can read/write their client cards. * `{clientcardid}/sessions` * collection of sessions entries `clientsessionentry` * id is a unique string. * coach can read and create these entries. client can (possibly in future) read * `{clientcardid}/insights` * collection of sessions entries `intelligentinsightfeedback` * id is a unique string. * coach can read and create these entries. * `{clientcardid}/documents` * collection of sessions entries `documententry` * id is a unique string. * coach can read and create these entries. * `{clientcardid}/timetracking` * collection of sessions entries `timetrackingentry` * id is a unique string. * coach can read and create these entries. * `invitations` * collection of `invitation`, invitation for client (and maybe coaches in future). * id is invited persons's email. * also it contains statuses history (see `entitywithstatus`) * `clients` * collection of `clientprofile`, profile data related to client role. * id is `auth.uid`. * client can read their own profile * `{clientid}/accounts` * collection of `clientaccount`s, which connects client & coach. created at the moment client accepts coachs's invitation. in such way client can have multiple accounts, each should be represented in this collection so client may take active or choose one from the list. * id is `clientcard`'s id, so it should be easier to track this relation. * client can read all their accounts and all nested documents. * `{clientcardid}/journal` * collection of `clientjournalentry`s, data related to one journal entry. also contains related metadata. * id is a unique string. * coach can read jorunal entries related to their account. * `{clientcardid}/intakeforms` * collection of `assessmentdata`s, data related to each assessment entry posted by client. * id is a unique string. * coach can read assessment entries related to their account. * `{clientcardid}/events` * collection of `anyevent`s, data related to in-app events assigned by coach. attow events are processed each minutes. processed events being cleared after after trigger time. * id is a unique string. * coach can read events entries related to their account. * `records` * collection of `recorddata`, each for `journal` or `session` entry. an item represents entry's processing result. * id is a unique string. * coach and client can read only entries related to their accounts. * `tips` * collection of `statictipitem`. attow each item is added manually via firebase dashboard. * id is a unique string * client can read all values * `prompts` * collection of `promptslibrary`s. each is a coach's library of custom prompts and tips. * id is `auth.uid` (`coachid`) of coach. * coach can read only their own library. * `{coachid}/clientprompts` * collection of `clientprompts`, each is a client's personal settings/data for this coach's library. * id is `auth.uid` (`clientid`) of client. * client has access to library only if their current state is present #### api api is exposed via firebase cloud functions. function can be an api endpoint, scheduler listener or pubsub listener. each endpoint might handle few types of requests to make amount of functions deployed as less as possible. these requests types are group into endpoints by features, logic and services. every request type for every endpoint in the system has clear and straightforward declaration, grouped by namespaces. a declaration allows all calls to be consistent across platforms. ## data policy regarding mobile companion applications maslo's companion kit is an open source software stack that relies on differing technologies to supply user experiences, signal processing and data movement for users and administrators. maslo's approach to security and privacy is based on the idea that security and privacy is an ongoing process and not a state of technology. we have implemented a variety of best practices and best technologies to provide ongoing improvements to secure and private services. it may be of specific interest to know the following: * some data persists on the phone/device in the form of caches. this cached data uses the default encryption of the host os and device. * all data in motion (going to and from apis) is encrypted via the latest ssl technologies * all data stored in the cloud (google or amazon, depending on partner) is encrypted in motion and at rest. * all data access is logged on device and in cloud. only device users with specific accounts can access data on their device. only maslo users with specifically approved credentials may access user or pii data. again, all access is logged and separation of concern is managed (data scientists do not get access to pii, developer do not use production data etc). all access must be approved by legal or ceo. maslo users the following technologies which may be referenced for their own security and privacy details: * expo and react native for mobile application source code - https://docs.expo.io/regulatory-compliance/data-and-privacy-protection/ and https://reactnative.dev/docs/security * google cloud and amazon aws https://cloud.google.com/security and https://aws.amazon.com/compliance/data-privacy-faq/ interested parties may want more info on maslo privacy and security: https://github.com/heymaslo/data-privacy"
0,GiftFinder,"a fullstack postgresql-express-react-node web application for gift suggestions, wishlist sharing and gift reservation within user-groups. mui css framework. deployed to heroku.","# giftfinder have you ever bothered by searching for a perfect gift for your beloved ones. giftfinder brings you a lot of ideas, inspirations and guides you with your preferences and categories. you can view gifts falling into different cateogries (fetched from etsy api). as a registered user, you are able to add any gift you like to your wish list. a user has a default wish list, she can also create new wish lists corresponding to different occasions (such as birthday, wedding, graduation, mother's day etc). you could set these lists as private, shared, or public. if it is private, only you can see it. if it is public, everyone on the internet can see it if they have the link. a user can delete item from a list and can move the items to a different list she created. you can also manually add an item to your wish list with external website links, name, images, price and description. all the gift items will show up in your list nicely. best of all, you could share any of your wish lists to your friends by creating groups. within your group, only the members that are within that group are able to view your shared lists. a member within a group could mark a gift in your wishlist as reserved or purchased (under work) -- every other member can see it, thus will not prepare a repeated gift for you for that occasion. members in the same group could communicate or messaging each other by a built-in chat widget, which makes discussion of purchasing a gift for someone much easier by sharing ideas or products that may directly found on our website. what is more, it features a personalized questionnaire to help you find the best gift ideas for your beloved ones. there are still much more to explore! (this is our team capstone project while attending fullstack academy. it is a pern stack - a web app developed using postgresql, express, react, node.js and mui. want to discover what is it and how we implement it? clone it and try it out!) ## screenshots ### home page <img src=""public/assets/giftfinder_homepage.png"" alt=""giftfinder app main page""> ### create groups log in as a user, you are able to create a group and invite friends to your group. <img src=""public/assets/giftfinder_creategroup_invitefriends.png"" alt=""giftfinder creating group and inviting friends""> ### create your own wish list and share it within your groups <img src=""public/assets/giftfinder_createsharewishlist.png"" alt=""giftfinder create and share wish list""> ### shop for your friend's wish list within the same group log in as a different user, you could view the shared wish list of friends in the same group, shop for them! you could mark their wish list items as reserved or purchased, every member can see! <img src=""public/assets/giftfinder_shopforsharedwishlist.png"" alt=""giftfinder shop for your friends""> ### personalized questionnaire - gifts picked just for you! <img src=""public/assets/giftfinder_personalizedquestionnaire.png"" alt=""giftfinder personalized questionnaire""> ## built with * react * node.js + express * etsy api * postgresql + sequelize * mui * cometchat * figma ## heroku the application is deployed at: ## setup * `npm install` * create two postgres databases * these commands will create both your **development** and **test** databases ``` createdb giftfinder createdb giftfinder-test ``` * by default, running `npm test` will use your test database, while regular development uses development database ## start sync and seed your database by running `npm run seed`. running `npm run start:dev` will make great things happen! - start:dev will both start your server and build your client side files using webpack - start:dev:logger is the same as start:dev, but you will see your sql queries (can be helpful for debugging) - start:dev:seed will start your server and also seed your database (this is useful when you are making schema changes and you do not want to run your seed script separately) ## future steps * considering using non-relational db, i.e. mongodb, redis to manage our groups and wish list. * exploring supabase for hosting our db and backend * add in-app notification inbox center, using magicbell * add machine learning for recommending gift search. ## license !license mit license ## contributors * **ying ying feng** - ui (javascript, html, css, mui) / website design, logo / questionnaire / redux store / etsy api / server * **savannah lin** - database / apis / google oauth / passport.js login / filtering, sorting, pagination, web scraper * **maribel jaramillo** - server / database setup / models / etsy api / wish list / front-end * **simon cheng** - mui / react components / models / gift list / cometchat ## github info ying ying feng, savannah lin, maribel jaramillo, simon cheng"
1,questionnaire,a questionnaire management website built for researchers.,"# questionnaire system this system is designed to facilitate researchers in the psychology department, assisting researchers to get rid of manually creating tons of google forms and recording thousands of respondents through excel files. researchers set up questionnaires, assigned them to respondents, and sent notification emails. respondents fill them out afterward. the system enables researchers to manage and do statistics on them via this system. each questionnaire contains at most four-part, each part for one role (students, parents, teachers, counselors.) every part has zero or multiple questions, which can be multiple-choice or essay questions. there is an effective time for every questionnaire. it is possible for researchers to prepare questionnaires in advance and assign them to a group of respondents. these questionnaires will remain invisible and thus cannot be accessed until the effective time. functions provided: * questionnaire related: create, modify, delete, fill out, preview, export, assign to respondents, send notification emails * users related: register, login, check pending questionnaires, check questionnaire/user statistics ## technical stack * frontend: react, redux, react-router-dom, styled-components, formik, yup, material ui * backend: go, gin, gorm, mysql * host: aws, docker ## demo ### questionnaire page !questionnaire page ### main page !main page ### assign feature !assign feature ### notify feature !notify feature ### create page !create page !create page ### preview feature !preview feature ### user page !user page"
0,ninja-job-board,simple and powerful wp job board,"wp job board plugin for wordpress --- wp job board us a light weight plugin that adds a job board along with application form to your wordpress website. <b>description</b> want to hire your next effective and energetic employee then wp job board can help. with this plugin you can post a job circular right into your wordpress site and manage the whole hiring process from your wordpress dashboard. wp job board is a self-hosted wordpress plugin where you can build a questionnaire form by drag and drop form builder. <b>the following form fields are available to build your:</b> - applicant name - applicant email - file upload field - single line text - texarea field - number field - dropdown select field - radio choice field - checkboxes - date field - hidden input field - markup html - form steps to breakdown your form to several pages. - more is coming soon. #### application management with built-in application management system, you can see the total applications of your job post. you can also set application status as well as internal status. in individual application view page, you can see the complete submitted data, uploaded applicant cv. you can also change the application status and internal status easily. one of the important feature is, you can add notes to each application. #### super fast and light weight form this is a super fast form builder and it is only loads css and js if you add the form in a page. every line of css and js is useful and there has no extra css and js. for a normal form, it is loads less than css and js combined. this form builder plugin will not slow down your site. it is the fastest form builder plugin in wordpress. it has also a nice interface to give detailed information of your job post. #### features tracker - job posting with information *(done)* - application form builder *(done)* - cv management system *(done)* - application status management *(done)* - filter applications based on status *(done)* - search applications with keywords/full text search *(done)* - email notification system management *(done)* - export data as csv/excel/json *(on development) - send bulk emails to the applicants and filter by application status (on development) - application assesment for hr department (on development) this plugin is a very planned project, and we have a long term development plan for this. we already invested around human working hours (+coffees) on it, and we have the intention to spend much more on it. please let us know what features you want, and we are happy to add that in our development sprint. #### installation this section describes how to install the plugin and get it working. e.g. upload the plugin files to the /wp-content/plugins/ directory, or install the plugin through the wordpress plugins screen directly. activate the plugin through the plugins screen in wordpress use the wppay forms -> all forms -> add a form to create a form and get started. ##### how to build - `npm install` - `npm run dev` # for dev build - `npm run watch` # for development and auto compile - `npm run production` # form production build ##### other plugins by wpmanageninja <ul> <li><a href=""https://wordpress.org/plugins/ninja-tables/"" target=""_blank"">ninja tables wp data table plugin for wordpress</a></li> <li><a href=""https://wordpress.org/plugins/fluentform/"" target=""_blank"">wp fluent form contact form plugin for wordpress with advanced form builder features</a></li> <li><a href=""https://wpmanageninja.com/downloads/wppayform-pro-wordpress-payments-form-builder/"" target=""_blank"">wppayform - wordpress payments made simple</a></li> </ul> ##### changelog = - july = - initial release"
0,rm-case-service,this microservice manages cases.,"# case service this repository contains the case service. this microservice is a restful web service implemented using spring boot. it manages cases, where a case represents an expected response from an sample unit such as a business or a household. every sample unit in the survey sample must have at least one associated case. each case can have multiple questionnaires associated with it, but it must have at least one. each questionnaire has a question set and a unique access code (uac). interesting things that happen during the life cycle of a case are recorded as case events. case life cycle transitions are published as jms messages for interested parties to subscribe to. # inbound process casecreation message arrives from the sample service on the pubsub input channel `casecreationchannel`. this channel is processed by the casecreationreceiver class which includes validation fo the message. the casecreationreceiver calls the caseservice to create the initial case. the caseservice then creates a case group based on the sampleunit parent and saves it to the database. to do this it has to obtain the survey id, so it calls back to the collection exercise service with the collection exercise id in order to swap it for a survey id the caseservice then creates a child case for every sampleunit child, saving each one to the database as it goes. all these child cases are created with a status of sampled_init ready for the iac scheduler. finally, it sends out some case created events to the event publisher. ## outbound process the casedistributionscheduler runs on a scheduled job every seconds it retrieves all cases in sampled_init or replacement_init state once it has a count of these it sends a request to the iac service to generate iac codes for these cases it then updates all cases with a generated iac code (unless one fails in which case its left in the database for the next run) publish an event to the event publisher (unsure what this is for?) it adds an iac case audit record prepares a case notification to inform the action service that a new case is ready. the casenotificationpublisher publish this to action via pub sub ## improvement process as a part of the improvement process the outbound process will be replaced by merging action to case service. currently, the improvement is in progress and is feature flag off. as a part of this improvement collection exercise service will now call `/process-event` endpoint in case service rather than action service to process the events. ### action process/ event process collection exercise service gives a call to `/process-event` endpoint which is an async call. which calls `processcaseactionservice`. `processcaseactionservice` then calls two async services i.e.`processemailactionservice` and `processletteractionservice`. `processemailactionservice` and `processletteractionservice` calls back collection exercise service with the collection exercise id in order to swap it for a survey id and then the survey service to confirm the correctness. the services also calls party service to retried party information required for emails and letters. `processemailactionservice` then uses `notifyemailservice` to publish pubsub email messages via `notifyemailchannel`. `processletteractionservice` uses `uploadobjectgcs` to upload the created file to the gcp and then uses `notifyletterservice` to send letter message to pubsub via `printfilechannel`. `/retry-event` follows the same process to retry first fail operation for event processing which is trigger by kubernetes cron job. `/action-template` is provided to create new action template. ### receipt process cases are receipted by sdx-gateway via the case.responses via the case-receipt-inbound flow for some reason the inbound channel is always offline. this creates a final case event stating that the response has been received. ### report scheduling the reportscheduler is driven by the report cron expression. it creates a lock on redis to ensure only one instance can run at any given time. this scheduler executes the casereportservice which subsequently runs two stored procedures - generate case event reports and generate response chasing reports. these two procedures run nightly at and populate the report table. ## this service calls other service rest api collection exercise - get collection exercise - used to obtain the survey id for a specific collection exercise id iac service - generates an iac code for a case. this allows a respondent to enroll into the collection exercise. survey service - to confirm survey associated to the collection exercise for event processing. party service - to gather party information required for letters and emails event. ## micro service interactions this service calls other services via rabbit: action-service - case.lifecycleevents (aka case notifications) the rest api is called by: ras-frontstage - /cases/{case_id} - /cases/iac/{enrolment_code} - /cases/partyid/{party_id} - /cases/{case_id}/events - /categories action-service - /cases/{caseid} - /cases/{caseid}/events - /cases/{caseid}/iac - /casegroups/{casegroupid} response-operations-ui - /cases/{case_id}?iac=true - /cases/{case_id}/events - /cases/casegroupid/{case_group_id} - /cases/partyid/{business_party_id} - /cases/partyid/{business_party_id} - /cases/{case_id}/iac - /cases/{case_id}/events ras-party - /cases/iac/{enrolment_code} - /cases/{case_id}/events - /cases/casegroupid/{case_group_id} - /casegroups/partyid/{business_id} action-event - `/process-event` - `/retry-event` - `/action-template` ## this service is passed messages from collection-exercise via the case.casedelivery sdx-gateway via the case.responses queue ## improvements suggested improvements can be found here: improvements ## running * run ```bash cp .maven.settings.xml # this only needs to be done once to set up mavens settings file mvn clean install mvn spring-boot:run ``` # code styler to use the code styler please goto this url (https://github.com/google/google-java-format) and follow the intellij instructions or eclipse depending on what you use ## api open api spec can be found here ## integration tests use the command 'mvn clean install' this will run the tests in docker. note: you may need to a service account and key can be found locally in your environment and use the command ""export google_application_credentials='/[path]/[name_of_key].json'"" (remove the double quotes) ## to test see curltests.txt under /test/resources ## copyright copyright (c) crown copyright (office for national statistics)"
0,capacitor-notification-extensions,"notification extensions for handling data notification, and client-side filtering, ....","# capacitor-notification-extensions github link: https://github.com/no-dap/capacitor-notification-extensions capacitor plugin with some features >- background-handled data notification >- client-side notification filtering (sqlite based) > - custom boolean filters > - time based filters >- force-fire `localnotificationreceived` event listener which is not working properly > in localnotification plugin > those features all works fine irrelevant with the app's state(on foreground, on background, or not on process). # dependency !maintained !license !ionic-capacitor works fine with capacitor not compatible with capacitor use sqlite via helper(from capacitor sqlite plugin) # installation ```bash npm i capacitor-notification-extensions --save ``` ## android add notificationextension class to your mainactivity. ```java public class mainactivity extends bridgeactivity { @override public void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); // initializes the bridge this.init(savedinstancestate, new arraylist<class<? extends plugin>>() {{ add(yourawesomeplugins.class); ... add(notificationextension.class); add(localnotificationextension.class); }}); } } ``` add meta data and intent filter to manifest inside application tag and add db_name to string values. - androidmanifest.xml ```xml <?xml <manifest> <application...> ... <activity ...> <intent-filter> <action android:name=""com.woot.notification.extensions.intent.action.launch"" /> <category android:name=""android.intent.category.default"" /> </intent-filter> </activity> <meta-data android:name=""com.woot.notification.extensions.local_database_name"" android:value=""@string/db_name"" /> </application> </manifest> ``` - strings.xml ```xml <?xml <resources> <string name=""db_name"">todo</string> </resources> ``` ## ios add silent notification to your appdelegate ```swift class appdelegate: uiresponder, uiappicationdelegate { ... func application(_ application: uiapplication, didreceiveremotenotification userinfo: [anyhashable : any], fetchcompletionhandler completionhandler: @escaping (uibackgroundfetchresult) -> void) { notificationcenter.default.post(name: notification.name(""silentnotification""), object: nil, userinfo: userinfo) } ... } ``` add some data to your info.plist ```xml <?xml <!doctype plist public ""-//apple//dtd plist <plist <dict> ... <key>localdatabase</key> <string>todo</string> ... <key>uibackgroundmodes</key> <array> <string>remote-notification</string> </array> ... </dict> </plist> ``` ## electron have no plans to support yet. # documentation ## notificationextension >if you are new on firebase messaging, i recommend reading this documentation first to understand about two concepts of notification message. > notificationextension class is child of default plugin pushnotification. you can check arguments and return of methods from the link above. this plugin creates a sqlite table `notification_extensions_filter` with its own schema. ### data notification payload message in both platform should not contain `notification` key which makes message as alert message. - android get data from `yourmessagepayload.data`. (check how payload parsed) - ios get data from `yourmessagepayload.apns.payload.aps.custom_data`. (check how payload parsed) --- both platforms' payload should contain keys below. - isshown: optional, boolean string('true' or 'false'), always true if not exists. - body: optional, string, body of notification message - title: optional, string, title of notification message - filter: optional, comma-separated string, hide notification if matched filter with false value exists. - any other data you that want to use in your application ### filters all key-value based filters which is added or removed by addfilters and removefilters method will be saved in the local database. there are two filters that specially checks before show notification, which is time-based filter and logged-in filter. - logged-in filter if you add a filter with key `is_logged_in`, this filter will always be checked on a message received even if payload does not contain filter key. - time-based filter if you add a filter with addtimefilter method, three rows will be generated in the local database. (filter_start_from, filter_end_at, is_time_filter_on) this filter will always be checked on a message received even if payload does not contain filter key. addtimefilter method only takes string with `hh:mm` format and will raise some validation error if is malformed. ### usage in your js application, ```typescript import { plugins } from '@capacitor/core'; const { notificationextension } = plugins notificationextension.addlistener('pushnotificationactionperformed', (notification: pushnotificationactionperformed) => { // same as pushnotification plugin // you can deal with your payload }); notificationextension.addlistener('pushnotificationreceived', (notification: yourpayloadtype) => { // same as pushnotification plugin // only works when the app is on foreground }); notificationextension.register(); notificationextension.addfilters({ filters: ['anystring', 'youpromised', 'withbackend'] }); // any data notification that contains key named 'filter' with value matched above will be suppressed by plugin. notificationextension.removefilters({ filters: ['youpromised'] }); // filtering 'youpromised' stop working notificationextension.getfilters().then((result) => { // result will be { value: ['anystring', 'withbackend'] } }); notificationextension.addtimefilter({ startfrom: endat: }); // every notification that received between to will be suppressed ``` ## localnotificationextension `localnotification.addlistener('localnotificationreceived')` does not work in android if you use capacitor this class just a bug fix that only overrides a receiver to notify a message received event to listener. (this will be solved in capacitor merged commit link) use this plugin for android only. (this class has not implemented for ios) ### usage ```typescript import { localnotification, plugins } from '@capacitor/core'; const { localnotifications, localnotificationextension } = plugins; class yourserviceorcomponent { constructor() {} get localnotificationplugin() { return this.platform.is('android') ? localnotificationextension : localnotifications; } yourmethod() { this.localnotificationplugin.addlistener('localnotificationreceived', (localnotification: localnotification) => { // do what you want }); } } ``` # issue & questionnaire feel free to ask anything on project issues. any kind of contributions and bug reports are also welcomed."
0,ORS,the online reporting system (ors) is a tool that allows users to generate multiple questionnaires easily. this tool aims at making it easier for meas to collect data for their reporting cycles.,"# online reporting tool ## user guide a user guide for the application is available from the repository's doc folder. ## development ### installing locally install necessary software this branch uses the following software: * ruby via rbenv there may be an issue when performing a local `rbenv install` of older versions of ruby (older than where the openssl version required is no longer hosted resulting in a in which case it is worth trying to install ###### macos tbc ###### ubuntu for ubuntu you will need the library: `sudo apt install if you have rbenv installed, you can setup ruby with: `rbenv install based on the `.ruby-version` file in the root of the project, it should then be using within the project. * postgresql * redis: ""redis is an open source, bsd licensed, advanced key-value store"", and is used in this application to store background jobs * imagemagick used by paperclip to scale image attachments * rails installed as a gem via bundler (see point clone github repository into your desired directory ```` git clone https://github.com/unepwcmc/ors ```` go into the application folder and switch to ruby branch ```` cd ors git checkout master ```` copy config/database.yml.example to config/database.yml and update with your local details install necessary gems using bundle (you will need to have the bundler gem installed) ```` bundle install ```` note: one of the gems that this command installs is **capybara-webkit**. this gem depends on if the bundle command fails because of this gem please refer to this page for help addressing this. after installing this software run ""bundle install"" again. set up your postgres database, user roles and one admin user to get you started ```` rake db:create rake db:migrate rake db:seed ```` fire up your server ```` rails server ```` and visit the home page in: ```` ```` database backups can be found on wcmc dropbox (ask for a sample if you need one), and can be imported using: psql -you postgres ort_development -f backup.sql #### background jobs use the sidekiq gem which requires redis sidekiq workers can be started using: bundle exec sidekiq -c config/sidekiq.yml sidekiq-status is installed and available at /sidekiq. ### testing integration tests are powered by capybara and can be run with: rake test:integration ## other notes ### uploaded files locations #### user added files * questionnaire header: `project_path/public/system/headers/:questionnaire_id` * answer document: `project_path/private/answer_docs/:questionnaire_id/answer_documents/:user_id/:answer_id/` * loopsource source `file: project_path/public/system/sources/:source_file_id` #### system generated files * questionnaire pdf for a user: `project_path/private/questionnaires/:questionnaire_id/users/:user_id/` * questionnaire csv: `project_path/private/questionnaires/:questionnaire_id/` ## deployment ### storing sensitive configuration parameters we store instance-specific configuration parameters (such as secret token, mailer details) in .env files loaded via dotenv gem. those values are then made available to the application via rails-secret gem and can beaccessed in a rails fashion. ### exception notifications exception_notification gem is configured to send emails & slack messages in staging & production environments. ### capistrano we are using a gem called capistrano-multiconfig which includes the ability to have different deploy/production.rb and deploy/staging.rb files for different applications with the same deploy. for example: ``` . bern-ort production.rb staging.rb cites-ort production.rb staging.rb cms-ort production.rb staging.rb icca-ort production.rb staging.rb ``` so we can then do something like `cap bern-ort:staging deploy` `cap cms-ort:staging deploy` ### mail since :smtp has some issues with ruby mail delivery method has been changed to :sendmail in config/environments/production.rb and staging.rb"
1,effort-log,a cross-platform tool for collecting metrics about programming efforts of software developers.,"# effortlog a cross-platform tool for collecting metrics about programming efforts of software developers. effortlog is developed at it center, rwth aachen university. ## introduction effortlog is mainly developed for research purposes on development efforts of software developers in the high performance computing (hpc) domain and can be used to capture the complete development life-cycle of a hpc project. moreover, effortlog can be used to log personal and team development efforts as well. effortlog captures various metrics about programming efforts through interval-based questionnaires. a popup window guides the user in pre-defined intervals through the questionnaire. additionally, the user can specify information on a project milestone which may have been reached during the last interval. milestones denote goals along the life-time such as a first-parallel version. the user can specify the achieved performance of the current milestone and how it was obtained. to gather fine-grained performance increments over the life time of an hpc project, milestones can be reached repeatedly. ## binaries you can download the binaries from github releases. there are currently four different binaries distributed: * effortlog_`<version>`_osx.dmg: for mac os x and higher * effortlog_`<version>`_osx_encrypted.dmg: for mac os x and higher with enabled encryption of log files * version for windows * version for windows with enabled encryption of log files ## build from source you can download the sources from github releases. ### effortlog >= effortlog >= supports qt and os specific requirements: * on windows: mingw with g++ or later, install qt * on mac os x: latest xcode, `brew install qt` * on linux: qt for latest openssl if encryption is required: * on windows: install openssl for windows * on mac os x: `brew install openssl` * on ubuntu/debian: `sudo apt install libssl-dev` * on opensuse: `sudo zypper install libopenssl-devel` * on fedora: `sudo yum install openssl-devel` * on arch linux: `sudo pacman -s openssl` you can build effortlog with cd $effortlog_directory cmake -s . -b build cmake --build build --config release (or --config debug for development) make (or on windows) the encrypted version can be build with cmake -dcrypt=on -dopenssl_root_dir=\<path to openssl root directory\> -s . -b build cmake --build build --config release (or --config debug for development) make (or on windows) to create the *doxygen* documentation use make doxygen ### effortlog < effortlog < provides compatibility with older versions of down to version os specific requirements: * on windows: mingw with g++ or later, install qt * on mac os x: latest xcode, `brew install * on ubuntu/debian: `sudo apt install build-essential * on opensuse: `sudo zypper install * on fedora: `sudo yum install * on arch linux: `sudo pacman -s qt` latest openssl if encryption is required: * on windows: install openssl for windows * on mac os x: `brew install openssl` * on ubuntu/debian: `sudo apt install libssl-dev` * on opensuse: `sudo zypper install libopenssl-devel` * on fedora: `sudo yum install openssl-devel` * on arch linux: `sudo pacman -s openssl` you can build effortlog with cd $effortlog_directory qmake (or make (or on windows) installation (""make install"") is not needed. to specify the installation directory use qmake prefix=$install_directory to compile the release version use qmake -config release to compile the debug version use qmake -config debug to compile the release version with encryption of use qmake -config release -config crypt to compile the debug version with encryption of use qmake -config debug -config crypt to create the *doxygen* documentation use make doxygen ## information gathered by effortlog ### project file \*.pro (json format) | information | collected through | |---|---| | title of the project | user-provided during program startup | | username (may contain multiple entries if users share project files) | user-provided during program startup | | output directory of the project file | user-provided during program startup | | output directory of the log file | user-provided during program startup | | logging interval in minutes | user-provided during program startup | ### log file \*.json (json format) | information | collected through | |---|---| | title of the project | user-provided during program startup | | username | user-provided during program startup | | logging interval specified at program startup | user-provided during program startup | | initial stage of the project | user-provided during project initialization | | comment on the initial stage of the project if provided | user-provided during project initialization | | type of the activity | user-provided during questionnaires | | id of the logging event | starting at counting forwards | | time of the logging event | system time | | time of the last logging event | system time | | actual logging interval | current time - time of last event | | comment on the activity if provided | user-provided during questionnaires | | number of events in the current logging session | starting at counting forwards | | scheduler denotes an interval-based event , an appeneded event, a manual event executed through the gui, and an event on the program) | inserted by the tool | | title of the milestone | user-provided during questionnaires | | id of the milestone (starting at | user-provided during questionnaires | | comment on the milestone if provided | user-provided during questionnaires | | used performance metric | user-provided during questionnaires | | reached performance | user-provided during questionnaires | | used architecture for the performance measurements | user-provided during questionnaires | | number of threads, nodes, etc. for the performance measurements | user-provided during questionnaires | | used compiler | user-provided during questionnaires | | used programming model | user-provided during questionnaires | notes on anonymity: * effortlog does not store any information on its users except of the project file (\*.pro) and the log file (\*.json). these files contain only user-provided input obtained from the questionnaires. * use random usernames. * the project file (\*.pro) may contain the username of the system you are currently logged in. please check this file before sharing it. * the times of each event and milestone are logged by default. they can be removed by deleting the keys `curloggingtime`, `lastloggingtime` and `time` from the json files. ## encryption effortlog can be configured to encrypt all user related files to ensure the safety and privacy of its users. all project files and log files are then encrypted with a strong aes encryption. the user sets a password for each project on project-setup. to manually decrypt the log files a current version of openssl is required. decryption can be done via command-line with the following command: openssl enc -d -in <encrypted log file>.json -out <decrypted log file> notes: * encryption is disabled by default. add `-config crypt` to your qmake flags to enable encryption. * choosing a complex and unique password for each project is crucial to ensure privacy! * as of january changing passwords for a project is not possible once the password is set. ## developing and contributing to effortlog ### submit a bug report * bugs are tracked through github issues. * please describe the bug as detailed as possible including steps which reproduce the problem. ### request a feature * feature requests are tracked through github issues. * please describe the feature as detailed as possible including the changes you like to see compared to the current behavior. ### make a pull request * open a new github pull request with the patch. * please use detailed descriptions on the purpose of the patch. * include the according issue number if present. for more information on how to develop and contribute to effortlog, please contact julian miller ## change log * (july * chore: update to qt * (october * chore: update to qt * chore: update documentation for version * (may * added feature: support for qt * chore: switch to cmake * (march * chore: updated to qt * chore: removed some deprecated code * bug fix: add ctrl key to hotkeys to prevent interference with user input * bug fix: negative time in the header when logging across date borders * (january * bug fix: missing visual updates to project settings * bug fix: wrong type when importing project files * bug fix: segfault when pressing ""log current efforts"" * (june * added feature: questionnaires remember characteristics of last performance measurement * bug fix: improved scaling on high-dpi displays * (april * added feature: added a tray icon and desktop notifications * added feature: the view on the questionnaire is now scrollable * bug fix: improved cross-platform window displaying * (march * added feature: simplified set-up * (march * added feature: added auto-completion to most of the questionnaire forms * bug fix: consistent scheduler ids for the diary entries * (february * added feature: major reorganization of the questionnaires towards a single-page layout * (may * bug fix: deployment reverted to due to packaging issues with * (may * added feature: support for changes to file directories for existing projects * bug fix: skip read of log file on newly created projects * bug fix: support for blanks in directory names * (january * added feature: added a viewer of the current log file during the questionnaire * (september * added feature: added a convenient view of the current log file sorted by dates * added feature: can now handle development sessions spanning multiple days * (february * added feature: encryption is disabled by default. add \`-config crypt\` to your qmake flags to enable encryption * bug fix: empty time stamps in the log files * (january * added feature: support for full aes encryption of all project and log files * bug fix: appending an event fails due to encryption * bug fix: wrong interval length of the first logging event * (december * added feature: added milestones to projects * added feature: added ids to each logging event * bug fix: fixed us locale to unify data format of log files * bug fix: milestones have mismatching ids between the logging event and the current milestone * (december * added feature: configuration unified in one dialog * added feature: added appendix to log file at program startup * bug fix: general fixes * (november * added feature: new configuration window * added feature: main window simplified * bug fix: errors with the generated json files * (october * bug fix: improved json handling * (september initial release ## related publications s. wienke, j. miller, m. schulz, m.s. mller: development effort estimation in hpc. international acm/ieee international conference for high performance computing, networking, storage and analysis november salt lake city, ut, usa. j. miller: software cost estimation for the development effort applied to multi-node gpu aeroacoustics simulations. master thesis, rwth aachen university, germany. j. miller, s. wienke, m. schlottke-lakemper, m. meinke, and m. s. mller: applicability of the software cost model cocomo ii to hpc projects. international journal of computational science and engineering ## contact us julian miller sandra wienke it center group: high performance computing division: computational science and engineering rwth aachen university seffenter weg d aachen (germany) ## license copyright it center, rwth aachen university this project is licensed under version of the gnu general public license."
0,CovidTracker,here is the software developed for team for tsa software development event,"# covidtracker here is the software developed for team for tsa software development event on a general hierarchy, this app will allow people to stay safe and be notified of a threat in the area they are in. it can inform them about places that are at high risk and low risk. this can educate the public on where it is and is not safe to travel. it can also give recommendations on possible quarantine periods based on contact with infected personnel depending upon the area and usage of the application. [education/social value]: currently, we hope to have luck on our side so that we do not contract covid when travelling. this app eliminates luck from the equation and provides the user with ease of mind as they now know what they are putting themselves into when commuting. as nelson mandela once said, education is the most powerful weapon which you can use to change the world. you cannot help mitigate covid or be safe without being educated and thus the news page is vital to the purpose of the app . [easy access]: at the bottom, there are tabs that allow for easy navigation. by simply clicking on a tab the user is directed to the appropriate page. also, we have navigation links and a slide feature so users can navigate within that tab. [demo] [app logo]: the apps logo has a shade of red with a design so it looks aesthetically pleasing. the design also has meaning because the overlapping squares represent the measures taken by us to help stop the spread and help society. [home page]: when opening the app, it will prompt you to our home page which has designed buttons. one is to scan a qr and another is to make a qr. for example, if they are at a walmart and want to check the covid status there, they simply take out their phone, scan the qr generated from our app, and then see all the data which makes possible conclusions about risk assessments and more. our qr in our app is different from others. this is done so through customizing the qr scanner from our code. it recognizes qrs and we have a label on the screen that shows the location of the qr in order to ensure accuracy and conformity for the user. another option is to make a qr. if a user wants to create a qr to a place that does not already have one, they simply click on the make qr button and then, they enter the location of the current place which in result, generates a random qr that can store data. [news page]: for our news page, news is pulled from the back-end database where admins can add featured news relating to admins are made through security rules in firebase. this information will be directly pulled from credible government agencies. this will be updated on a regular basis. this has social value because it reminds all the people about the coronavirus and people have access to the latest updates right from their phones. [questionnaire]: our questionnaire is designed for people who are feeling sick and can be accessible through the button on the updates tab. it asks a few questions regarding your current health status and covid history. these questions are answerable through a custom made checklist. based on the status of the circle our code differentiates yes and no and then our algorithm comes with conclusions and notifies other users if applicable under the notifications section. this algorithm is like a scoring system and each question has a different value. based on the selections of the user, you get categorized in one category and those personalized alerts and conclusions come. this happens when other people are in the same location of sick users at estimated times and the times are done through a rounded feature. [location details]: in the location details page, there are statistics for the location the user is in right now. this shows how many people visited that day, number of infections of people this week, and risk assessment so it can educate the user about that place. [settings page]: in order to comply with proper privacy rules, in settings on iphone, the user will find access to whether they want the app to access their camera and location. based on the users input the qr feature will be used or omitted. they will also find permissions & contracts our app has with a terms & conditions to ensure their privacy & safety with possibly sensitive information. [database]: our app uses firebase to call queries and have security rules to distinguish between people/admin and for customized apis. we created our entire database architecture first with all variable storage places and image storage. we used anonymous authentication, real time updates, and store features of firebase as talked before. we integrated swiftui with firebase through pod files and this allowed all the actions taken on the app to be stored in the database respectively based on our architecture. [real time updating]: since we chose firebase, we had access to real-time updates. through coding a listener that connects with observable objects, we were able to update statuses and news pages without needing the user to refresh. if a user tests positive and you were near that person, the updates tab automatically shows notification and updates risk assessment/status. [show demo on phone] [risk assessment+chain length]: based on the number of reports in a certain location and the questionnaire if they are feeling sick, we make an educated prediction about their status with the infection through an algorithm with points and percentage systems. we also have zones, red, yellow, and green for the assessment of the infection within a certain location and we developed an algorithm that calculates which zone the user is in. they should always get a covid test to ensure the accuracy of the algorithm we developed but this allows for them to make educated actions going forward based on their status and surrounding risk assessment. each zone comes with different alerts. examples include after the questionnaire or location statistics. our algorithm uses possible contact instances and the chain length to determine the risk of the user. this allows us to warn users that are indirectly in contact with an infected user. the scenario can be visualised in the form of a computer science graph. our warning system uses a breadth-first traversal to make sure that users are warned of the smallest chain through the graph to get the most accurate results. [storing time period]: in our updates page, we have a button where you can exit the location and this sends the data to the database for further use and more accurate conclusions. for enter, this happens after you scan qr, see stats, and click the enter button. it calculates the time you were there and sends it to the database. [notifications for entering + exiting]: our app records user interaction in app locations to track and break transmission chains. users have the ease to scan a qr code to bring up our data and risk assessments for that specific location. this gives the user the knowledge to choose to enter that location. if they enter, a new entry is made into our database. once they leave the location, the users can easily end their visit in the updates tab with the click of a button. in the case that users may forget, they will be asked to end their visit when trying to enter another location. our database stores all user locations visited and end location requests so we can provide our user with more accurate results. in the case that a user is evaluated to be positive, the user receives realtime updates if they were in-contact with the infected user within the past days. this allows for us to warn other users to quarantine themselves in order to break transmission chains. if the user is already positive in our app and enters a place, everyone else in that place on the rounded time will be notified immediately with a warning. these notifications of being within positive user will be there for days. the realtime updates come within the notifications section in the updates tab where the user can constantly check. [status updates]: if a user is deemed positive within our app, the status will change to negative within days. [time picker]: what if you forget to exit a location and it is been a while since you were there. our app has a solution to that. click on the exit button and then, an alert will show asking if you just left and if you hit no, a time picker page will load where you choose the estimated time of when you left and if it was a day, you can pick a previous date too. after you hit the submit button, the rounded time is stored in the database and if applicable, it will warn other users through notifications at the time entered. also, before entering a new location through the enter button, it will give a popup alert to exit the previous location and then, it will take you to the time picker page to choose the approximate time of when you left. we have constraints within the date/time picker by disabling all dates before the date you entered the place. also, if the time selected for exit was before you entered, it will choose the current time still. [how to create qr]: what if you were in a place that does not have a qr code to scan by our app. our app has a solution to that too. you can easily make a qr. click on the make qr button in tracer page, enter name of place and address, and then it will generate a qr that will hold all data for each user and the place itself per usage. you can use this generated qr by simply clicking on the copy qr button and then, you can use it in whatever way is best and efficient for you. [double check]: our app has a double check feature which checks that the qr is existent in our database and if not, it will not scan the qr while continuing to say scan for qr. there is also a flash capability button at the bottom that seamlessly switches on and off with a touch if needed when it is dark and the phone camera itself cannot scan it. [alerts]: our app has many alerts in order to guide the user. for example, if a user is positive and enters the store, we give an alert and there are many other use cases too. alerts are used when trying to enter without exiting the previous location, risk assessments customized notifications, questionnaire alerts dependent upon answers, and double checking for entering before exiting location, etc. they come with content, title, an ok button or a yes or no with different logic. [confidentiality]: in our app, all our users will be anonymous through digit anonymous ids and each has customized apis for their usage and surroundings. [how a user is defined]: since we do not have sign in functionality, a new user is created and defined within our database architecture when a new phone is used. basically, the users device differentiates multiple users. [light & dark mode]: the app is also adjustable to light and dark mode options, which can be changed by the user. [design process]: first, in order for our entire group to understand the concept, we designed a figma (mockups tool) which allows everyone to see the wireframing of the app. then, we set up the firebase and connected it with our project while adding security rules and completed the architecture of the backend. then, we created all the methods necessary so the ui can display the backend stuff (getallnews, customized apis). after, we worked on it page by page while formatting the ui too."
1,Questionnaire-Maker,web project done as part of a module during my second year at edge hill university,"# questionnaire maker questionnaire maker is a website where you can build, edit and send questionnaires and collect responses. responses can be viewed using graphs (chartjs) or as raw data in a table format. questionnaire maker supports questions types split into categories. ### frameworks used * mysql * laravel * laravel-cors * angular * chartjs * scss ## features ### account and settings the account page allows the user to edit account details (email, name, password). the account page also holds the users settings: * enable in app notifications * this enables notifications to be displayed within the website * enable email notifications * this enables notifications to be emailed to the user * notification before questionnaire expiration * this specifics the time period of when to notify the user/you when one of your questionnaires is about to expire * none - never notify you that one of your questionnaires is about to expire * day - notify you one day before one of your questionnaires is about to expire * week - notify you one week before one of your questionnaires is about to expire * month - notify you one month before one of your questionnaires is about to expire for more on notifications check out the notifications section. ### notifications this application has main notifications in which you will receive. * new response * you will receive a notification each time a new response comes on for one of your questionnaires * upcoming expiry * notifies you the specified time ahead of when one of your questionnaires is about to expire * for more on expiry times check the account and settings section. * expiry * notifies you that one of your questionnaires has expired. ### questionnaire you can create questionnaires. each questionnaire has a title, category an option description and an optional expiry date after which the questionnaire cannot be answered anymore. __once a questionnaire has expired you can no longer collect responses__ each questionnaire has main options: * complete/incomplete * this helps to tell is questionnaires are complete. this means they are ready to be answered by users. * public/private * __public__ questionnaires are displays within the websites public questionnaire page where anyone can answer a questionnaire. * __private__ questionnaires can still be answered but are not displayed to the public. ### questions each question as the choice of being required (must be submitted) or not required where the user gets to decide. #### open opens questions allow the user to answer with text in any way they want. both questions are the same programmatically with the only different being in how they are presented ot the user. ##### single line input single line input displays a text input with one line to enter text. ##### paragraph a paragraph input shows a text area with allows for large amount of text to be displayed. #### closed closed questions give the user various options in which they can pick. ##### multiple choice multiple choice questions give the user a bunch of options from which they can submit one option. ##### check boxes check box questions give the user a bunch of options from which they can pick one or more options. ##### drop down works in the same way as the multiple choice but the appearances is as a drop down (select box). #### scaled ##### star this shows the user a star rating area in which they pick how many stars they wish. this question supports between and stars as the max. ##### slider this questions displays a slider in which the user picks a number. this question supports a range between any numbers with a interval of the creators choosing. ### responses each question type responses are viewed in different ways with different graphs available. #### open both open question types are views in a table format. (this is the only option). #### closed/ scaled star closed questions are viewable in different ways: * pie chart * bar chart * horizontal bar chart * table (raw data) * there is also a toggle switch with this option to only display options that have responses. #### scaled slider slider scaled questions are viewable in different ways: * line graph * table (raw data) * there is also a toggle switch with this option to only display options that have responses."
0,fr_covidata,a redcap module to facilitate the scheduling and data management of testing for first responders,"# redcap first responder a redcap module to facilitate the scheduling and data management of testing for first responders. this project was created by a multidisciplinary team at the university of florida to support the testing of first responders in alachua county, florida and the surrounding counties. ## caution this module was created with numerous abstractions to allow it to be reused in other sites and projects, yet there remain some hard-coded project features. we advise you to use the included project xml as a starting point to minimize your challenges in running this module. also, be aware the data entry fields for site data do not carefully test the values keyed in. we recommend you start with the included example sites file, then make modifications. ## prerequisites - redcap >= - redcap entity >= ## manual installation - clone this repo into - clone the redcap_entity repo into - go to **control center > external modules**, enable redcap entity, and then this module. redcap entity will be enabled globally, but `fr_covidata` has to be enabled on a per-project basis after *global configuration* is completed. ## configuration to configure and use this module, follow these steps: create a redcap project from the file update the `appointments` field on the `appointments form`, changing it to a dynamic sql field and configuring it to auto-complete. paste the appropriate code from `example/dynamic_sql_*.sql` enable the fr covidata module as described above. configure the fr covidata module identify to set `which location id is this project for? this will reduce the risk of errors if one lab is processing specimens from different redcap projects. start with and work your way up if you have to deploy multiple production instances of this module. configure the fr covidata module identify to set `which instrument is used for appointments?` in the included redcap xml files, the form is named ""appointments"". configure the fr covidata module to indicate which repeat type is used for repeats: _repeating instances_ or _individual events_. in the included redcap xml files, _events_ are used. ![](images/module_configuration_for_fr_covid_module.png) use a mysql client to load sites data from `redcap_entity_test_site_data.sql`. alternatively, use the `define sites` page of this module to enter the data. be cautious as some portions of the interface of this module have very few guard rails. i.e., your data entry will not be checked. e.g., tiems must be entered in a clock format such that a.m. is the leading zero is critical. the development schedule has not allowed the addition of these tests, nor does it allow for much documentation. as such, the authors advise you to _use the example configuration_ as a starting point. adjust the project_ids referenced on those just-loaded sites by editing and running a copy of `redcap_entity_test_site_update.sql` access `define sites` to make any needed changes to the site definitions. generate the initial appointment blocks by accessing `define sites` and selecting the sites of interest and clicking `manually generate new appointments` ![](images/define_sites.png) ## appointment scheduling features this module adds an appointment scheduling feature to redcap. this feature is built on top of redcap entity and a dynamic sql field. it allows appointment blocks to be selected from a dynamic sql field using the built-in auto-completion feature of dynamic sql fields. the sql query queries a table of appointments to generate a list of available appointment blocks. on form save, redcap writes the `appointment_id` into the value of the dynamic sql field. the module uses the `redcap_save_record` hook to write the `record_id` and `event_id` into the appointment record. the `redcap_save_record` hook will also update appointment-related fields on the record to provide easy lookups of the site details and date and time of the appointment block. once assigned to a person, an appointment block is no longer available. this feature is used in a redcap survey to allow the first responders to select their appointments. if the research participant needs to cancel or change an appointment, they must call the study team. the study team will access the redcap project, locate the participant's record, and cancel or replace the existing appointment. redcap entity manages the table of appointments. ## site management features a _site_ is a testing site. a study coordinator or redcap admin must define each site before appointment blocks for that site can be created. redcap entity manages the site data. a study coordinator or redcap admin can populate the site table by accessing the define sites page. it allows for crud operations on sites for this project. each site allows the configuration of a long name, short name, appointment duration, address, open time, close time, closed days of the week, and the number of appointment days to build out in advance. the open and close times are bounds on the generation of appointments. ## appointment block management features _note: all cron management features have been disable as of this is to allow us (cts-it) to more easily manage manual appointment block creation until we can add a per-site, per-weekday, start and stop times. sorry for the inconvenience. the docs will be over-hauled when that feature is completed._ an _appointment block_ is a fixed block of time at a single site. appointment blocks must be created for a site before a research participant can schedule an appointment at that site. this module manages appointment block creation. the script that makes the appointment blocks can be run manually or automatically. the appointment blocks are generated when a study coordinator presses the `manually generate new appointments` button of the define sites page or automatically by a cron job that runs each day. appointment block creation uses the _appointment horizon_, _site id_, _open_, _close_, _closed\_days_, _start\_date_, and _appointment duration_ attributes for each site to generate records in the appointments table. it will create _appointment horizon_ days of appointment blocks for each site if those blocks do not already exist. the module will define a cron job that runs daily to assure _appointment\_horizon_ days of appointment blocks exist at all times. whether you let the cron job make the appointments or use the `manually generate new appointments` button to make them, the underlying code will create appointment blocks starting on the _next day_. for example, if you configure a site to have three days of appointments, then click the button on monday, the script will create appointments on tuesday, wednesday, and thursday. if the same site were closed on wednesday, the script would create appointments only on tuesday and thursday. as of release the most precise way to make appointment blocks is to set _appointment\_horizon_ days to zero and set _start\_date_ to the precise date for which you want to make appointments. select the sites that need new appointment blocks and click `manually generate new appointments`. repeat this process for each site date that needs new appointment blocks. ## using test data the `test_data` folder includes rscript to generate test datasets for the icf, questionnaire and mini questionnaire. together, these import files can speed the process of testing the custom code used in these project. to make test data. open the r project in the `test_data` folder and run `make_test_data.r`. if you provide a file called `replacement_demographics.csv` and it has the columns first_name, last_name, email, and the rscript will replace the first_name, email, and phone on each demographic record. to load test data, erase all data in the project, then load these three files from `./test_data/output/`: ``` all_baseline_data.csv ``` there are additional files, but they might not be useful for typical testing. they fill in the mini-question with diminishing frequency, but they do it out of sync with the appointment and result forms. that is probably not helpful, but they are provided here should they prove useful. ## clone a project into production to clone a development project into a production project, follow the steps below. note: this procedure assumes you are copying a project within a redcap host. locate your development project and copy it using `project setup`, `other functionality`, `copy the project`. set the details on the new project 'first responder testing - production'. also copy the following project attributes: - [ ] all records/responses (nnn records total) - [x] all users and user rights - [x] all users roles - [x] all reports - [x] all report folders - [x] all data quality rules - [x] all project folders - [x] all settings for survey queue and automated survey invitations - [x] all project bookmarks - [x] all custom record status dashboards - [x] all settings for external modules (modules will be disabled by default) - [x] all alerts & notifications enable project overlay banner module. set text to `this is the real, production project. it is under construction and not ready for live data`. set the css to something like this to change the bg color to yellow ``` #project-overlay-banner { /* position and z-index because the banner to appear to float over the page */ position: fixed; z-index: opacity: --bg-color: background-color: var(--bg-color); padding: width: text-align: center; } ``` enable the fr covidata module. configure the fr covidata module identify to set `which location id is this project for? change this to _not_ match the location in the development project. configure the fr covidata module identify to set `which instrument is used for appointments?` in the included redcap xml files, the form is named ""appointments"". configure the fr covidata module to indicate which repeat type is used for repeats: _repeating instances_ or _individual events_. in the included redcap xml files, _events_ are used. use a mysql client to load the site data from `redcap_entity_test_site_data.sql`. adjust the project_ids referenced on those just-loaded sites by editing and running a copy of `redcap_entity_test_site_update.sql` access `define sites` to make any needed changes to the site definitions. generate the initial appointment blocks by accessing `define sites`, selecting the appropriate sites, and clicking `manually generate new appointments`. add an api token for the data manager and send the token to be integrated into rscript-based tools that need it. assign user rights privileges to the study team lead so they can make roles and adjust user rights for their team. delete reports that are only relevant in the development. edit alerts to remove testing email addresses in the to: field, set from addresses to something reasonable, ""test"" banner at the top of the emails, and ""testing:"" from the subject lines. switch the project to production mode. disable the project overlay banner module. add the public survey url to the public-facing landing page. you have now completed the project deployment."
1,experience_sampling,"a mobile application for sending notifications to users at random select time; then asking users to do questionnaires which contain multiple question types, skip logic, and conditional branching.","# experience sampling ## claims this app is just for research purpose, so that it is not available for someone who does not participant in the research. but i can show it on my cellphone in interview. (or i can provide a link on google drive to download apk (android version) through email) ## introduction the purpose of this application is to collect data from users' mental state through psychological questionnaires without internet. this app will send local notifications to users. when users receive notifications, they need to do questionnaires right away. it seems like an easy application, but it is not. because one of the requirements is to send notifications exactly at set time, which means we need to overcome the restriction of local notifications. (e.g. the battery policy of ios/android, doze mode of android, local notification limit counts in ios ...) ## use case ### homepage homepage would change the introduction when research state is switched. it also contains brief instructions. as for the precise instructions: in answer_intro page. !image ### settings users will get the subjectid and password from researcher. they need to set their basic information and preference here. if you are not a subject in this research, you will not be able to use this app. (if you really like to test this app, please send me an email (menghueigao@gmail.com). i will provide a set of subjectid & password just for testing.) !image ### history users can get their answering history and upload the passed questionnaires in this page. !image ### questionnaire there are some types of questions in this questionnaire. !image !image !image ## questionnaire format ## design icons all from https://www.flaticon.com/search?word=questionnaire"
1,AUCO,"auco is a gamified online tool made with react that focuses on helping primary and middle school teachers to fight against bullying, in terms of detection and mitigation, and offering an open space where the students can communicate their worries to their teachers.","# auco ## what is auco? auco is a gamified online tool made with react that focuses on helping primary and middle school teachers to fight against bullying, in terms of detection and mitigation, and offering an open space where the students can communicate their worries to their teachers. the back-end of this proyect is hosted in auco-server. ## how does it work? in the platform, the students are asked to answer specific questionnaires, that are validated in their use to detect bullying cases. gamification is used to motivate students to use the online tool, and the teacher receives notifications regarding the possible bullying-cases. ## quick start auco ```bash cd auco npm start ```"
1,Team16_Capstone,design of a smartphone app for personalized cancer symptom management,"# this is a smartphone app design for personalized cancer symptom management. this application alerts users when it is time for their light therapy sessions, helping them more easily stick to a routine that works for them. patient light therapy data, which includes therapy frequency and duration, is written from the app to a database that researchers from michigan state university's college of nursing can access. !visor design the goal of this project is to design a smartphone application to help monitor and enhance observation of the prescribed light therapy. the application will be programmed for the time of the day the individual is advised to receive the light therapy. a text reminder will be sent through the app at the advised time of the day to notify the user. real-time data will be provided by a timer that records start and end times of each light therapy session. if the user does not respond within minutes of the advised time, a second text reminder will be sent, and if the user does not respond within minutes of the second reminder, an alert message will be sent. this smartphone app will be programmed to notify and allow the user to record sleep/wake times, naptimes, and levels of fatigue each night for a pre-set timeframe. all the data collected by the application will be sent and stored in a server for future reference. this smartphone application will replace the previously used paper-pencil daily log. *development software used:* the operating system used for the app is android and was designed using android studio. the backend was written using mostly java and the front end will be written using xml. information gathered by the app will be stored in a database hosted by the michigan state university department of computer science. ## program classes: !class diagram ### main activity this is the screen of the app when lauched. each of the icons and the text below them serve as buttons that redirect to other pages. ### database tool this class is responsible for all internet-based activities in the app. it contains methods for writing to the various database tables and verifying the legitimacy of the user. anytime responses are detected from the other question pages in the app, a databasetool will be created and the appropriate write method is called. the methods generate the correct http link to store the data and then performs the http request. the tool is constructed around the preferences of the user, since instances of the class need to know the user_id and birthday of the user to verify whether the user is legitimate. ### help activity this class represents the screen that is visible after selecting the ""help"" icon on the home screen. once you click on the help button off the home screen, you will be prompted three buttons. one button labeled ""introduction video"" will lead you to an introduction video provided by the college of nursing. the second button labeled ""how to video"" will lead you to a how to video provided by the college of nursing. lastly, there is a ""back to home"" button that will take you back to the home screen. **help button video replacement** first download and name the video you would like to implement into the app. place that video into the raw folder under app/src/main/res/ in your directory. depending on if you are changing the how to video or the introduction video, you will go to howtovideoactivity or introvideoactivity. you will see a line of code like this: ``` uri uri = uri.parse(""android.resource://"" + getpackagename() + ""/"" + you will change the to what the name of the new video is. then you will go to activity_help.xml you will click on the design tab then you will go to text you will erase what was there before, and put in a new label for the initial help screen button. you will then see a yellow triangle warning sign click on the warning and look down to where it says hardcoded text. open that warning message and click fix, then ok. ### my info activity this class represents the screen that is visible after selecting the ""my info"" icon on the home screen. this page will show the user his or her unique id number, and have a button to enter a new id number, if his or her current one is incorrect. ### bedtime questions activity this class holds the questions that the user must complete before going to sleep at night. upon clicking submit, the class will create a databasetool and store the responses in the database. ### nap questions activity this class holds the questions that the user must complete regarding his or her naps. upon clicking submit, the class will create a databasetool and store the responses in the database. ### wake up questions activity this class holds the questions that the user must complete upon waking up in the morning. upon clicking submit, the class will create a databasetool and store the responses in the database. ### notification receiver this class creates the notification that shows on the user's device at the time specified by the user. ### reenter activity this class contains the screen that informs users that they must re-enter their id and birthday, as the current entry is invalid. ### reminder activity the reminder alert function is reliable and effectively notifies the user for when light therapy should be administered. the reminder function must reliably send a second notification if the app user does not respond to the first notification within minutes. the graphical user interface (gui) is easy to navigate and understand. the app should allow the patient to record sleep/wake times, naptimes, and levels of fatigue each night for a pre-set timeframe. the user input data should be stored on a database that is easy to access by the user/care provider !reminder activity framework ### repeating activity this screen is the screen shown when the notification is interacted with ### setid activity this screen is the screen in which the user enters his or her id and birthday. ### start timer activity this screen has the timer. it contains options for the user to pause the timer and end the session early if desired. ### thank you activity this screen is shown after a submission has been successfully logged. it has a button to return to the home screen of the app. ## user interface the user interface was designed with the target user in mind. typical users of this app will most often be cancer patients, who will be suffering from fatigue, nausea, and other cancer-related symptoms. for this, ease of use was our top priority. the application's graphical user interface (gui) incorporates large buttons, simple navigation paths, and limited input options, specific to the user entry fields. !user interface description ## data extraction for healthcare providers the app writes to the database using a php script run through a student cse webdev account. none of the database information will need to be stored on the app or local storage, it will all be stored in the cloud. this is done to enhance security to mitigate source code being stored on apps across devices. the medical professionals will have a python script that retrieves the data from the database and writes it to a csv. this is also done by accessing the database through php. ### python script for pulling data from a cloud-based .csv file into ms excel the python script **patient_data_getter.py** will be stored in a file location which is convenient to the healthcare provider. as long as the healthcare provider has the required software installed, they can generate excel files with the necessary patient data. the excel files will be created in the same file location that the **patient_data_getter.py** is saved in. ### extracted database file format a seperate excel file is automatically generated for each database table that exists within the application. for example, a seperate excel file will be generated for the bedtime questionnaire, the nap time questionnaire, the wake-up questionnaire, and timer usage. ### required software: - .csv - python - mysql workspace - mysql python connector ### install python python can easily be installed by visiting the link: choose from the following installer files that best suits your operating system and click through the easy to follow steps in the installation wizard: !python ### installing software from powershell terminal open windows powershell from the windows start menu from command line enter the following commands ``` > mkdir patient_light_therapy [enter] # this creates a folder directory named ""patient_light_therapy"" > cd .\patient_light_therapy\ [enter] # this navigates you into the folder you had just created > install mysql-connector [enter] > install [enter] > install requests [enter] # you have now installed all the required software to run the patient_data_getter.py script ``` ### download the script open the following link: https://github.com/mahucs/patientdatagetter download script by selecting the green ""code"" button in the upper right and then selecting ""download zip"" !screenshot of download zip extract the **patient_data_getter.py** from the zip and add it to the new folder you created now you may exit the windows powershell terminal and navigate to the folder you have created in the file explorer you should see the script named **patient_data_getter.py**. to run the python script and generate excel files with the patient light therapy data, double-click **patient_data_getter.py** to run. the excel files should be generated in the same file location. !patient data getter ### how to install app **download android studio** first you need to make sure you have android studio installed on your computer. android studio can be downloaded from the following link: !android studio download **download light therapy smartphone application** download the app from the link using an android device: https://github.com/mahucs/lighttherapylog download the apk from the link you should then be able to see it downloading on the top bar of your device once it is downloaded, open downloads, tap on the apk file, and tap yes when prompted the app will begin installing on the device ### development **mysql** the following statements must be run on the new database: create table bedtime_questions (submit_time text, bedtime text, fatigue_level integer, sleepiness_level integer, user_id integer); create table nap_questions (submit_time text, nap_taken text, first_nap_start text, first_nap_end text, second_nap_start text, second_nap_end text, third_nap_start text, third_nap_end text, user_id integer); create table wakeup_questions (submit_time text, time text, difficulty_sleeping text, waking_up_during text, woke_up_early text, user_id integer); create table timer_usage (start_time text, end_time text, user_id integer); create table users (user_id integer, birthday text); the college of nursing must provide a list of the user ids and all of the users birthdays to be stored in the database. these must be inserted into the users table for that app to work properly. **php** change the database information in all of the .php files to match the new database information"
1,formidable,"formidable, git-ified. synced manual! this repository is just a mirror of the formidable. please do not send pull requests and issues.","=== contact forms, surveys & quiz forms plugin by formidable forms builder for wordpress === contributors: formidableforms, sswells, srwells, jamie.wahlin tags: forms, contact form, form builder, survey, form maker, form, form creator requires at least: tested up to: requires php: stable tag: the most advanced wordpress forms plugin. go beyond contact forms with our drag & drop form builder for surveys, quiz forms, and more. == description == = the most powerful wordpress form builder plugin on the market = we built <a href=""https://formidableforms.com/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">formidable forms</a> to offer the ""first-ever"" solutions-focused wordpress form plugin on the market. you can use our drag & drop wordpress form builder plugin to create contact forms, surveys, quiz forms, registration forms, payment forms, purchase forms, email marketing forms, and just about any other form you can imagine. at formidable forms, creating the most extendable form builder plugin is our priority, so you save time when building even the most advanced forms. unlike other wordpress form maker plugins that focus solely on building contact forms, we believe in allowing our users to push the limits and create complex forms quickly! before we take a deep-dive into the features of the powerful formidable form builder plugin, you should know that formidable forms is mobile responsive so your contact forms and all other types of forms will always look great on all devices (desktop, laptop, tablets, and smartphones). on top of that, we have optimized formidable contact forms and advanced forms for speed and maximum server performance. whether you use formidable forms to build a contact form on your own site or an advanced form for your client, you can confidently say that it is one of the fastest wordpress form builders on the market. > <strong>formidable forms pro</strong><br /> > this form builder plugin is the lite version of the formidable forms pro plugin that comes with all the contact form and advanced form features you will ever need. our premium form features include repeater fields, email subscription forms, multi-page contact forms, file upload forms, smart forms with conditional logic, payment integrations, form templates, form relationships, cascading dropdown fields, front-end form editing, powerful formidable views to display data in web applications, and far more than just contact forms. <a href=""https://formidableforms.com/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"" rel=""friend"" title=""formidable forms"">click here to purchase the most advanced premium wordpress form builder plugin now!</a> you can start with our pre-built contact form template or create totally custom forms from scratch all with an easy-to-use drag & drop form builder interface. let us take a look at all the powerful form builder features that you get with formidable forms for making amazing contact forms, lead forms, subscription forms, request a quote forms, donation forms, payment order forms and more. = drag & drop contact form maker and advanced form builder = the formidable forms drag & drop form builder allows you to quickly create unlimited contact forms, surveys, quizzes, registration forms, and just about any other type of form that you want. our form builder plugin comes with all the powerful form fields that you need to create a solution-focused form, fast! * single line text (for names, phone numbers, addresses, and more) * email * website/url * paragraph text * radio buttons * checkboxes * dropdown select boxes * number * phone number * hidden fields * user id * html block = complete entry management for contact forms and surveys = formidable forms allows you to view all your contact form and survey entries right from your wordpress dashboard. once a user submits a contact form, their response is automatically stored in your wordpress database. formidable forms is gdpr-friendly**. you can turn off ip tracking or stop saving contact form submissions entirely. alternatively, you can add a gdpr checkbox field to your contact forms and payment forms to collect consent. need to import your contact form leads to another service like mailchimp? no problem. **export contact form leads to a csv**, open it in excel, and import anywhere. you can also configure unlimited form email notifications and autoresponders triggered by contact form submissions. on top of that, you can easily customize the contact form success message the user sees after they submit the form, or redirect them to another page for your more advanced form needs. = the only form maker plugin with an advanced form styler = with our built-in form styler, you can instantly customize the look and feel of your contact forms. with just a few clicks, your contact form, email form, and advanced forms can be transformed to match your website design. by default, formidable forms applies a single styling template to all formidable contact forms and advanced forms on your site. but if you want a custom form style for each individual contact form, sidebar form, and registration form, you can upgrade to formidable forms pro. = build smart surveys with beautiful reports = aside from simple contact forms, formidable forms comes with a built-in survey feature, so you can quickly create powerful surveys and see beautiful reports. the best part is that you can do this all within formidable forms without any third-party tools. = quickly create advanced registration forms for any use case = whether you need to create a youth sport team registration form, event registration form, or church retreat registration form, formidable forms has got you covered. unlike other contact form plugins, formidable forms comes with a repeater field that allows you to create the most powerful registration forms. then, our marketing integrations and apis can send the contact form and registration form data anywhere you want. = accept credit cards and easily collect payments = by now, you probably already realize the theme that formidable forms is more than just a contact form plugin. you can use formidable forms to create payment forms and accept credit card payments right from your website. we offer seamless integration with paypal, stripe, and authorize.net, so you can create order forms and purchase forms with our drag & drop form builder. you can even use formidable forms to create woocommerce forms with custom fields (more on that later). = grow your business with marketing integrations = we know that marketing is the key to grow your business. that is why formidable forms allows you to connect contact forms, payment forms, and advanced forms with a marketing platform of your choice. we integrate with popular email marketing services like: * mailchimp * aweber * constant contact * getresponse * mailpoet * active campaign * salesforce * hubspot on top of these native integrations, we also integrate with zapier, so you can quickly route your contact form data to over more services with just a few clicks. = create data-driven web applications with formidable views = formidable views are by far the most powerful feature that makes formidable far more than just a form builder plugin. views allow you to flexibly display any submitted form data on the front-end of your website. our customers use formidable views to create data-driven web applications like real estate listings, employment listings, event calendars, business or member directories, job boards, and other searchable databases. as you can see, formidable forms is not your average contact form plugin. it is a true all-in-one wordpress form solution. = increase your sales with woocommerce product forms = formidable forms is the only wordpress form builder plugin that offers extensive integration with woocommerce. our goal is to empower you to build powerful woocommerce product forms, so you can increase your store sales. you can use formidable forms to add a woocommerce product configurator with custom calculation fields, and automatically send the data to the woocommerce cart with variable pricing options. need your customers to upload a file when they purchase a product? no problem. simply drag & drop a file upload field into your woocommerce form and you are done. you can even show submitted form values in the woocommerce purchase receipt emails as well as trigger sms text messages or marketing integrations when an order is completed. and of course, you can use formidable forms to add a simple contact form on your woocommerce store. = build powerful quiz forms & calculators = along with a contact form, you can also use the formidable form builder plugin to create quiz forms and calculator forms. here are some example web calculators you can quickly add to your site: * advanced mortgage calculator * car payment calculator * bmi calculator * user age calculator * online quote calculator * net promoter score (nps) survey calculator ... and our powerful form calculations allow you to build just about any other type of calculator form. if that was not enough, you can also use our formidable form builder to create quizzes on your site and display results. this is great for membership sites, lms, or just for viral quizzes to grow your email list. our goal is to go beyond simple contact forms and allow users to create form-based solutions without any code :) = create wordpress user registration forms, profile forms, and more = if you run a wordpress membership site, then you need more advanced forms along with your contact form. the formidable form builder plugin allows you to customize your wordpress user registration forms, so you can collect additional data when the user profile is created. with our front-end form editing, you can also build custom profile forms and allow users to keep their profile updated, or even progressively add to the profile from a set of forms, from the first contact form to the last payment form. our front-end form editing feature is unique to us, and you will not find any other wordpress contact form plugin offering such a solution with the level of extendability that we do. = beautiful graphs and reports to help you analyze and showcase data = we believe that data alone does no good if you cannot analyze it. that is why we make it easy for you to analyze your contact form, survey, quiz, calculator, and other form data with beautiful graphs and reports. you can even showcase form data on the front-end of your website by embedding graphs in your wordpress posts or pages. = all the advanced form fields and features you need to grow your business = formidable forms goes far above and beyond contact forms to offer all the advanced form fields and features you need to grow your business. this includes things like multi-page forms, save and continue forms, cascading form fields, powerful conditional logic, partial form submissions, invisible spam protection, front-end user post submission, calculators, user-tracking, and so much more. we are on a mission to offer an all-in-one solution-focused wordpress form plugin, so you do not have to install plugins alongside your contact form maker plugin to do everything you want. = extend and customize your forms - developer's dream come true = formidable forms is the form plugin of choice for smart developers, freelancers, and agencies because it helps them build complex form solutions and basic contact forms quickly and defy the limits imposed by time and knowledge. our goal is to help you build complex websites with low overhead. we believe big projects do not always need big resources. that is why we made formidable forms the most extendable wordpress form builder plugin on the market. you can easily route your data from contact forms and advanced forms with our powerful api. formidable views allow you to display form data anywhere on the front-end, so you can quickly create data-driven web applications. on top of that, our hooks and filters allow you to completely extend formidable forms to meet your needs. we even include hundreds of code examples in our docs to give you the confidence to get started. = full formidable forms feature list = since formidable forms is not your average wordpress contact form plugin, this feature list is going to be very long. grab a cup of coffee and read through, or just install the most powerful wordpress form maker plugin, your choice :) * <a href=""https://formidableforms.com/features/drag-drop-form-builder/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">online drag and drop form builder</a>. build everything from contact forms and email forms to calculators, registration forms, and complex online forms. make amazing forms the easy way with a simple wordpress drag and drop form builder. no code required. * <a href=""https://formidableforms.com/features/display-form-data-views/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">display form data with views</a>. other wordpress form builder plugins only let you collect data. formidable forms let us you format, filter, and display form submissions in custom formidable views on the front-end of your site. views turn forms into solutions. job boards, event calendars, business directories, ratings systems, and management solutions. if you can come up with it, most likely formidable can handle it. * <a href=""https://formidableforms.com/features/dynamically-add-form-fields/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">repeating field groups (repeaters)</a>. allow your users to add sets of fields to registration forms, application forms, email forms, calculator forms, and other advanced forms on the fly. * <a href=""https://formidableforms.com/features/wordpress-multiple-file-upload-form/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">drag and drop multiple file upload forms</a>. easily upload documents, files, photos, and music, with any number of files in contact forms, job application forms (resumes), wordpress user profile forms (avatars), registration forms, get a quote forms, and other advanced forms. * <a href=""https://formidableforms.com/features/wordpress-multi-step-form/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">multi-step forms with progress bars</a>. want to increase conversion rates and collect more leads with smart contact forms? create beautiful paged forms with rootline and progress indicators. add conditional logic to page breaks for smart branching forms. * <a href=""https://formidableforms.com/features/cascading-dropdown-lookup-field/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">cascading lookup fields</a>. change values in other form fields or drill down through options to reveal a final value. designed for country/state/city fields in contact forms and registration forms and year/make/model fields in auto forms, or to get a price from a separate product form. * datepicker fields with advanced <a href=""https://formidableforms.com/downloads/datepicker-options/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">datepicker options</a> including blackout dates, dynamic minimum and maximum dates, and inline calendars. our datepickers are great for basic online booking forms, event registration forms, and specialized contact forms. * create relationships with dynamic fields. populate form fields from other forms and link data between two forms without duplication. form relationships are helpful in a huge number of cases including linking employment application forms to a job, quiz forms to a class, event registration forms to an event, sports registration forms to a team, and contact forms to a department. * add password fields with a password strength meter in wordpress user registration forms, profile forms, and change password forms. * collect reviews with star ratings in feedback forms, recipe ratings forms, product review forms, event rating forms, customer testimonial forms, and yes, even contact forms. then display and share the ratings in formidable views. * add more field types with our form creator including rich text fields, time fields, scale fields, slider fields, toggle fields, tags fields, address fields, and section headings. * <a href=""https://formidableforms.com/features/confirm-email-address-password-wordpress-form/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">confirmation fields</a>. double check email addresses or passwords and prevent typos from cannibalizing your contact form leads. * <a href=""https://formidableforms.com/features/conditional-logic-wordpress-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">conditional logic for smart forms</a>. show or hide fields in contact forms and advanced forms based on user selections or user roles. make complex forms simple and increase form conversion rates. * <a href=""https://formidableforms.com/features/email-autoresponders-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">send email notifications & autoresponders</a>. automatically let clients know you received their contact form message. then create customized email notifications for multiple recipients and get info from a contact form or email form to those who need it. * email routing: conditionally send multiple autoresponder emails and notifications based on values in contact forms, email forms, payment forms, and registration forms. * <a href=""https://formidableforms.com/features/wordpress-calculated-fields-form/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">calculator forms</a>. create basic and complex calculations, and even combine text from multiple fields for a mortgage calculator, auto loan calculator, or many other calculator forms. even a contact form could benefit from calculations for easy quotes and price estimates. * <a href=""https://formidableforms.com/features/wordpress-visual-form-styler/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">visual form style creator</a>. our form creator for contact forms, calculators, and other online forms not only allows you to build forms, but also create branded forms that match your site. change colors, borders, padding and much more without any code. * <a href=""https://formidableforms.com/features/flexible-layouts-responsive-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">flexible form layout design</a>. build mobile responsive contact forms and advanced form layouts with multiple fields in a row by using our css layout classes. * <a href=""https://formidableforms.com/features/wordpress-mobile-friendly-responsive-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">mobile-friendly, responsive forms</a>. all of our forms are sized automatically for every screen size. ensure that everyone can see and submit your contact forms and other online forms from any device. * <a href=""https://formidableforms.com/features/user-submitted-posts-wordpress-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">user submitted front-end posts and pages</a>. create and edit wordpress posts, pages, and even custom post types from your front-end online forms. send user-generated content quickly from a post creation form to a page. * <a href=""https://formidableforms.com/features/form-entry-management-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">simple entry management</a>. flexibly and powerfully display, edit, and delete form entries from anywhere on your site, and specify who has permission to do so. your logged-in users can fully manage their personal journal entries, weight tracking, guest blog posts, rsvp status, and whatever else you need, far and above just contact forms. * <a href=""https://formidableforms.com/features/front-end-editing-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">wordpress front-end editing</a>. allow users to edit their form entries and posts from the front-end of your site. create an online journaling platform, member directory, classified ads, community recipes, and more. * logged-in users can <a href=""https://formidableforms.com/features/save-and-continue-partial-submissions/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">save and continue partial form submissions</a>. whether it is a contact form or a long multi-paged form, users can save form progress and pick up right where they left off. * <a href=""https://formidableforms.com/features/create-a-graph-wordpress-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">graphs and charts for data visualization</a>. display statistics from surveys, polls, quiz forms, questionnaires, and advanced forms. or graph the data in a variety of ways that automatically update as new form data is submitted (great for weight tracking over time). * form permission settings. limit visibility of specialized contact forms and advanced forms based on user role. * form entry limits. limit a contact form, registration form, survey, quiz, or directory submissions to only allow one entry per user, ip, or cookie. * form scheduling. open and close event registration forms and signup forms on a specific date. or close registration forms when the seat limit or team size has been reached. want a contact form for questions about a planned event that auto closes when the event starts? no problem. * conditionally redirect to a custom page after a contact form, custom search form, quiz form, calculator form, payment form, support ticket form, or other online form is submitted. help clients get the answers they are looking for, or show a tailored result based on their form selections. * we believe that not only contact forms, but also advanced forms should be extendable to meet your needs. so we give you access to <a href=""https://formidableforms.com/features/customize-form-html-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">customize the form html</a> (like contact form but still keep the ease and speed of a drag & drop form builder plugin. our team labors for simplicity without sacrificing flexibility. * <a href=""https://formidableforms.com/features/importing-exporting-wordpress-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">import and export forms, form submissions, styles, and views</a>. quickly move forms, entries, views and styles to another site. need to export leads from a contact form to another service? check. * <a href=""https://formidableforms.com/features/wordpress-form-templates/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">form templates for instant form building</a>. get started quickly with the most advanced form creator that includes form templates, style templates, and formidable view templates. our wordpress form generator makes it fast to build contact forms, job application forms, and other online forms. * import our <a href=""https://formidableforms.com/downloads/category/form-templates/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">pre-built form/view templates</a> as a shortcut to a final product. our growing form template library includes contact forms, payment forms, calculators, a woocommerce product creator, and more. * <a href=""https://formidableforms.com/features/wcag-accessible-forms/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">wcag accessible forms with compliance</a>. do not alienate your audience. ensure your contact forms, surveys, quiz forms, lead capture forms, and other online forms are compliant and available to anyone. * <a href=""https://formidableforms.com/features/invisible-spam-protection/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">invisible spam protection</a>. do not waste time sorting through spam from your contact form. get instant and powerful anti-spam features from honeypot, invisible recaptcha, akismet, and the wordpress comment blacklist. * <a href=""https://formidableforms.com/features/fill-out-forms-automatically/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">fill out forms automatically</a> with values from the user profile or posts (i.e. custom fields). when a user is logged in, prefill known values like first name, last name, and email address in a contact form. * <a href=""https://formidableforms.com/features/white-label-form-builder-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">white label form builder</a>. replace the formidable forms branding with your own in the admin area. plus, we never show ""powered by"" links in your free contact forms or online forms. * <a href=""https://formidableforms.com/downloads/user-registration/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">wordpress user registration forms</a>. register wordpress users, edit profiles, reset passwords, and add a login form. when using wordpress multisite forms, you can even allow logged in and logged out users to create new subdomains. * <a href=""https://formidableforms.com/downloads/signature/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">digital signature forms</a>. eliminate paper forms with a digital signature field in contact forms, application forms, registration forms, or advanced forms. * <a href=""https://formidableforms.com/downloads/autoresponder/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">form action automation</a>. schedule form email notifications, sms messages, and webhooks to trigger at a later time. you can automatically delete guest posts after days, send weekly digest emails, trigger happy birthday text messages from a contact form or lead form and much more. * <a href=""https://formidableforms.com/downloads/formidable-api/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">formidable forms api</a>. send form entries to other rest apis and add a set of form webhooks. this includes the option to send form entries from one formidable site to another. * <a href=""https://formidableforms.com/downloads/quiz-maker/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">quiz maker forms</a>. write your quiz form questions, submit an entry as the quiz key, and publish the quiz on a page. then all the quiz form grading is automatically done for you. * <a href=""https://formidableforms.com/support/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">world class support</a>. have questions or need guidance on how to use our contact form builder or set up your web application? we are happy to help. our passion with formidable forms is to help you <strong>defy the limits</strong> so you can take on bigger projects, earn more clients, and grow your business. = payment forms, form apis, and marketing integrations = in addition to all the form builder features listed above, power up contact forms, registration forms, and calculator forms with these integrations. * <a href=""https://formidableforms.com/downloads/paypal-standard/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">paypal payment forms</a>. automate your business by collecting instant payments and recurring payments from clients. collect information, calculate a total, and send clients to paypal from your payment forms. * <a href=""https://formidableforms.com/downloads/stripe/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">stripe payment forms</a>. keep users on your site while collecting payments from a credit card form. select from one time and recurring charges in order forms, donation forms, and contact forms. * <a href=""https://formidableforms.com/downloads/authorize-net-aim/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">authorize.net aim payment forms</a>. process one-time payments in order forms, registration forms, and calculator forms with authorize.net aim. * <a href=""https://formidableforms.com/downloads/woocommerce/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">woocommerce product configurator</a>. add custom fields to a woocommerce product form and collect extra data when a product is added to the cart. use form calculations for variable pricing, upload a file with the purchase, and send custom emails when a purchase is completed. * <a href=""https://formidableforms.com/downloads/mailchimp/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">mailchimp forms</a>. add and update leads in a mailchimp email marketing list from lead forms, contact forms, order forms, and email forms. * <a href=""https://formidableforms.com/downloads/constant-contact/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">constant contact forms</a>. create leads automatically in constant contact with newsletter signup forms and contact forms. * <a href=""https://formidableforms.com/downloads/getresponse-wordpress-plugin/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">getresponse forms</a>. collect leads in contact forms, add them to getresponse, and trigger getresponse marketing automations. * <a href=""https://formidableforms.com/downloads/aweber/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">aweber forms</a>. subscribe users to an aweber mailing list when a newsletter signup form or contact form is submitted. * <a href=""https://formidableforms.com/downloads/mailpoet-newsletters/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">mailpoet newsletter forms</a>. fill your email marketing lists from newsletter signup forms and contact forms. then send wordpress newsletters from your own site using mailpoet. * <a href=""https://formidableforms.com/downloads/highrise/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">highrise forms</a>. add leads to your highrise crm account any time a wordpress contact form, registration form, or payment form is submitted. * <a href=""https://formidableforms.com/downloads/salesforce/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">salesforce forms</a>. create leads, contacts, and any other salesforce objects directly from your contact page and advanced forms. * <a href=""https://formidableforms.com/downloads/activecampaign-wordpress-plugin/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">activecampaign forms</a>. let your contact form pull double duty as a payment form, post creation form, user registration form, and an activecampaign integration. * <a href=""https://formidableforms.com/downloads/hubspot-wordpress/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">hubspot forms</a>. route contact form and lead form data from your wordpress forms to hubspot crm. * <a href=""https://formidableforms.com/downloads/twilio/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">twilio for sms forms</a>. collect votes and poll responses via sms text or send sms notifications when form entries are submitted. get notified instantly when an important contact form or payment form is completed, and let your form leads know you received their message. * <a href=""https://formidableforms.com/downloads/wp-multilingual/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">wpml forms</a>. translate contact forms, registration forms, and advanced forms into multiple languages using our integrated multilingual forms plugin. * <a href=""https://formidableforms.com/downloads/polylang/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">polylang forms</a>. get the form creator with polylang bilingual or multilingual contact forms. use the form builder to make your form, then translate it without duplicate forms. * <a href=""https://formidableforms.com/downloads/zapier/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">zapier forms</a>. connect with hundreds of different applications through zapier. insert a new row in a google docs spreadsheet, post on twitter, or upload a dropbox file from a contact form, calculator form, payment form, and more. with zapier, you have the option to trigger thousands of actions from a lead form, quote form, quiz form, and other online forms. * <a href=""https://formidableforms.com/downloads/bootstrap/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">bootstrap form styles</a>. instantly add bootstrap form styling to contact forms, registration forms, survey forms, and advanced forms. * <a href=""https://formidableforms.com/downloads/bootstrap-modal/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">bootstrap modal form</a>. open contact forms, login forms, formidable views, shortcodes, and other content in a bootstrap modal popup. after reading this feature list, you can probably imagine why formidable forms is the most advanced wordpress form plugin on the market, designed for far more than just contact forms. give formidable forms a try. want to unlock the full power? <a href=""https://formidableforms.com/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">upgrade to our pro forms</a> to get all the features for smart contact forms and full web applications. = form plugin credits = this form builder plugin is created by steve and steph wells and the amazing formidable forms team. formidable forms is part of the <a href=""https://www.wpbeginner.com/"">wpbeginner</a> accelerator with <a href=""https://syedbalkhi.com/"">syed balkhi</a> as an advisor to our company. == installation == go to the plugins -> 'add new' page in your wp admin area search for 'formidable' click the 'install now' button activate the plugin through the 'plugins' menu go to the formidable forms menu click the 'add new' button to go to the form generator page and create a new contact form, email form, registration form, or advanced form insert your newly created contact form, quiz, survey form, registration form, or advanced form on a contact us page, post, or widget using a shortcode [formidable id=x], alternatively use `<?php echo $key = '', $title=true, $description=true); ?>` to add a contact form in a contact page template == screenshots == build professional wp contact forms without any code. form builder plugin page for creating a contact form, survey, registration form, quote form, payment form, calculator form, quiz form, and many more. field options and css layout classes on the form creator page field options for checkbox fields in the form maker view, create, edit, and delete entries on the back end from a contact form, employment application form, to do list, order form, and more. add a wordpress contact form into your sidebar with a widget == frequently asked questions == = how do i get started with the best wordpress contact form plugin? = the fastest way to build a contact form is to use the contact form template we built for you. after you activate formidable forms, insert [formidable id=contact-form] on the wordpress page of your choice. that is it! want to make a new contact form? go to the formidable -> forms page and click ""add new"". choose the contact us form template on the form buider page and click ""load template"". save your new contact form. next, edit or create a wordpress contact page for the contact form. click the ""formidable"" button to open the form shortcode builder. choose your contact form and insert it into the wordpress page. save the contact page for a beautiful wp contact form, ready to collect and store your leads. learn more about <a href=""https://formidableforms.com/wordpress-contact-form-template-to-unique/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">using the contact form template</a>. = my contact forms are not sending emails. why not? = when you do not receive emails from your contact forms, try the following steps: double check that your email address is present and correct in your email form action on the form settings page of the form builder. the [admin_email] shortcode uses the email address from your wordpress settings -> general page. are receiving other emails from your site (ie comment notifications, forgot password...)? if not, form emails will not work either. check your spam box. try a different email address in your contact form settings in the form builder. install wp mail smpt or another similar emailing plugin and configure the smtp settings. if none of these steps fix the contact form email problem and no other wp emails are going out, please contact your web host. <a href=""https://formidableforms.com/wordpress-not-sending-emails-smtp/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">read more about wordpress emails not sending from contact forms</a> in our blog. = how do i edit the field names in the form maker? = the contact form field labels and descriptions are changed with in-place edit in the form builder. click on the label you would like to change and it will turn into a text field. <a href=""https://formidableforms.com/formidable-faqs/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">see more faqs</a> for making an amazing contact form or advanced online form. = what types of wordpress forms can i build with formidable forms? = formidable forms drag & drop form builder combined with our add-ons is the most powerful contact form plugin and advanced form builder plugin on the market. here are some types of wordpress forms you can create: * simple contact forms * advanced contact forms * custom contact forms * multi-page contact forms with progress bar * dynamic contact forms (where fields change based on users answers) * request a quote contact form * job application contact form * feedback survey contact form * make a suggestion contact form * testimonials contact form * change request forms * online booking forms * event booking form * online rsvp forms * custom wordpress user registration forms (great for membership sites) * wordpress login forms * custom wordpress user profile forms * wordpress post submission forms (great for guest posts) * credit card payment forms * paypal payment form * stripe payment form * make a donation forms * t-shirt order forms * product purchase forms * lead capture forms * newsletter signup forms * mailchimp signup forms * aweber contact forms * constant contact forms * getresponse signup forms * mailpoet newsletter signup forms * active campaign forms * salesforce crm forms * hubspot crm forms * multilingual wpml contact forms * multilingual polylang contact forms * auto forms with car make and model * video release forms * partnership agreement forms * pto request contact form * online petition form * contact forms that require a signature * custom signature forms * maintenance request contact form * scholarship application forms * file download forms * employment verification forms * make a referral contact form * volunteer registration contact form * membership registration forms * event registration forms * custom survey forms * poll forms * quiz forms * members only contact form * advanced mortgage calculator * car payment calculator * bmi calculator * user age calculator * online quote calculator * recipe reviews form = i would like access to all advanced form, view, and reporting features. how can i get them? = to get access to more features, integrations, and support, <a href=""https://formidableforms.com/?utm_source=wprepo&utm_medium=link&utm_campaign=liteversion"">upgrade to formidable forms pro</a>. a pro license gives you access to the full version of formidable forms for more advanced contact forms, formidable views, graphs and stats, priority support, and formidable forms add-ons! == changelog == = = * new: add a new forms block for use with the new wp editor * fix: a false number was showing for number of plugin updates available when add-ons were not installed = = * new: improved autoupdating and installation for form add-ons * tweak: only show the form add-ons page to those who can activate plugins * fix: radio button shadows had a box around them in some browsers * fix: do not mark an entry as a duplicate when the second entry includes more fields than the first * code: move deprecated code to its own folder <a changelog for all versions</a>"
1,FitnessApp,group project at ruhr-university bochum. an android-based app developed in java for recording user mood and sports activity. designed for research purposes.,"# fit mood - a healthy tracking app !fit mood logo ## overview fit mood is a healthy lifestyle app designed to help users stay active and improve their mood through various sports and activities. the app provides a range of features, including a mood questionnaire, sports recording, diy sports goals setting, sport archive display, gps and sensor data collection, and notifications setting. ## how to use fit mood ### mood questionnaire - upon launching the app, users can fill out a mood questionnaire to assess their current mood. - if the mood score is low, fit mood may suggest a random sport or activity to help uplift the user's mood. - !ques - !ques - !ques - !ques ### sports recording - to record different kinds of sports and activities, navigate to the ""sports tracking"" section in the app. - select the type of sport from the provided options (e.g., jogging, yoga, etc.). - tap on the ""start"" button to start a sport activity. - save the entry to database and keep track of your sports history(you can find this in archive section). !sport_tracking !sport_tracking ### diy sports goals - users can set their own sports and fitness goals. - select the type of sport from the provided options (e.g., jogging, yoga, etc.) and create a new goal. - save the goal to track your progress and stay motivated. !sport_goal ### sport archive - the ""sport archive"" section displays a list of all the recorded sports and activities in chronological order. - users can view their activity history and see details such as date, sport type, duration and mood. - additionally, a chart may visualize the duration of sports over time. !sport_archive ### gps and sensor data collection - fit mood can collect gps and sensor data during sports activities (e.g., running) to track your pace, and other metrics. - ensure that the gps and sensor permissions are granted for accurate data collection. !sport_sensor ### notifications setting - users can set notifications for reminders . - navigate to the ""setting"" section to manage notification settings. - adjust the time and frequency of notifications according to your preferences. ## conclusion fit mood is your all-in-one companion to stay active, track your sports, and improve your mood. start using fit mood today and experience the positive impact it can have on your well-being!"
0,FitMood,"reposting: the originals is my group work at ruhr-university bochum. an user mood & sport recoding app for further research purpose. written in java, avaliable on android devices.","# fit mood - a healthy tracking app !fit mood logo ## overview fit mood is a healthy lifestyle app designed to help users stay active and improve their mood through various sports and activities. the app provides a range of features, including a mood questionnaire, sports recording, diy sports goals setting, sport archive display, gps and sensor data collection, and notifications setting. ## how to use fit mood ### mood questionnaire - upon launching the app, users can fill out a mood questionnaire to assess their current mood. - if the mood score is low, fit mood may suggest a random sport or activity to help uplift the user's mood. - !ques - !ques - !ques - !ques ### sports recording - to record different kinds of sports and activities, navigate to the ""sports tracking"" section in the app. - select the type of sport from the provided options (e.g., jogging, yoga, etc.). - tap on the ""start"" button to start a sport activity. - save the entry to database and keep track of your sports history(you can find this in archive section). !sport_tracking !sport_tracking ### diy sports goals - users can set their own sports and fitness goals. - select the type of sport from the provided options (e.g., jogging, yoga, etc.) and create a new goal. - save the goal to track your progress and stay motivated. !sport_goal ### sport archive - the ""sport archive"" section displays a list of all the recorded sports and activities in chronological order. - users can view their activity history and see details such as date, sport type, duration and mood. - additionally, a chart may visualize the duration of sports over time. !sport_archive ### gps and sensor data collection - fit mood can collect gps and sensor data during sports activities (e.g., running) to track your pace, and other metrics. - ensure that the gps and sensor permissions are granted for accurate data collection. !sport_sensor ### notifications setting - users can set notifications for reminders . - navigate to the ""setting"" section to manage notification settings. - adjust the time and frequency of notifications according to your preferences. ## conclusion fit mood is your all-in-one companion to stay active, track your sports, and improve your mood. start using fit mood today and experience the positive impact it can have on your well-being!"
1,FitnessApp,fitness app using android studio,"# fit mood - a healthy tracking app !fit mood logo ## overview fit mood is a healthy lifestyle app designed to help users stay active and improve their mood through various sports and activities. the app provides a range of features, including a mood questionnaire, sports recording, diy sports goals setting, sport archive display, gps and sensor data collection, and notifications setting. ## how to use fit mood ### mood questionnaire - upon launching the app, users can fill out a mood questionnaire to assess their current mood. - if the mood score is low, fit mood may suggest a random sport or activity to help uplift the user's mood. - !ques - !ques - !ques - !ques ### sports recording - to record different kinds of sports and activities, navigate to the ""sports tracking"" section in the app. - select the type of sport from the provided options (e.g., jogging, yoga, etc.). - tap on the ""start"" button to start a sport activity. - save the entry to database and keep track of your sports history(you can find this in archive section). !sport_tracking !sport_tracking ### diy sports goals - users can set their own sports and fitness goals. - select the type of sport from the provided options (e.g., jogging, yoga, etc.) and create a new goal. - save the goal to track your progress and stay motivated. !sport_goal ### sport archive - the ""sport archive"" section displays a list of all the recorded sports and activities in chronological order. - users can view their activity history and see details such as date, sport type, duration and mood. - additionally, a chart may visualize the duration of sports over time. !sport_archive ### gps and sensor data collection - fit mood can collect gps and sensor data during sports activities (e.g., running) to track your pace, and other metrics. - ensure that the gps and sensor permissions are granted for accurate data collection. !sport_sensor ### notifications setting - users can set notifications for reminders . - navigate to the ""setting"" section to manage notification settings. - adjust the time and frequency of notifications according to your preferences. ## conclusion fit mood is your all-in-one companion to stay active, track your sports, and improve your mood. start using fit mood today and experience the positive impact it can have on your well-being!"
1,flowlix,flowlix - a smartwatch application to measure flow in real-time.,"# flowlix - a smartwatch application to measure flow in real-time. <div style=""margin: auto; width: <img alt=""flowlix_logo"" /> </div> \ this repo contributes to the seminar ""seminar digital platforms, markets & work"" of kit in the winter semester in this project, a smartwatch app is to be developed, which should enable the effortless recording of the flow state. flowlix is a smartwatch application developed to measure the user's experience of flow, a state of mind that leads to a higher level of engagement and productivity. the project was implemented using the android studio development environment and consists of the following main components: ## structure of the project the project consists of several packages, each serving a specific purpose in the overall functionality of the application. it is build using the model-view-viewmodel pattern. here is a rundown of the major packages and their contents. * model package \ the model package contains the implementation of the flowlix class, which serves as the main model for the application. * data package \ this package contains all the data classes required by the application, such as the activity, flowuistate, question, and mytime classes. * schedule package \ the schedule package includes the implementation of the scheduler and schedule classes, which serve as the components responsible for scheduling the notifications to be sent to the user. * resources package \ this package includes all the resources used by the application, such as io and the implementation of the questionprovider class, which serves as the data provider for the questions used in the experiment. \ currently the questions consinst of the flow short scale. to adapt the questions to another study, please use the questionprovider file. the ui will then adapt dynamically. * notification package \ the notification package includes the implementation of the actionreceiver and sendnotificationworker classes, which serve as the components responsible for sending notifications to the user. * viewmodel package \ this package includes the implementation of the flowviewmodel class, which serves as the primary view model for the application. * view packacke \ this package includes the implementation of the various screens that make up the user interface of the application, such as the mainactivity, presentation, and theme classes. ### purpose of the application the purpose of the flowlix application is to provide a simple and intuitive way to measure a user's flow experience while using a smartwatch. the application sends periodic notifications to the user throughout the day, asking them to complete a quick questionnaire about their current flow state. the results of the questionnaire are then analyzed to gain insights into the user's flow experience. ### using the application to use the flowlix application, simply load it on to your watch using android studio and follow the instructions provided by the application. you will be asked to complete a short questionnaire several times throughout the day, and your responses will be used to determine your flow state at any given moment. the results of the questionnaire can be analyzed to gain insights into your flow experience, helping you to better understand how to improve your level of engagement and productivity."
1,PsychApp_Portal,the webstite / portal for the 'psychapp' project,"# psychapp_portal a portal hosted by the ucy that allows for psychology students to conduct studies with a 'digital questionnaire'. with the portal the project information, project details as well as the actual questionnaire can be changed. a version of this portal is hosted at: http://psychappportal.cs.ucy.ac.cy test user credentials: email: test_user@test.mail password: password the android application 'psychapp' that works as a digital questionnaire useful for any psychology research. description: answer questions in specific times throughout the day. the user can set theese times. the questions are specific to each project. settings regarding the study or user are retrieved from the database. the answers given by the user are also sent to this database. the app also works in offline mode by storing the answers project settings localy, in this case the answers are sent when a login/authentication attempt occurs (with an established internet connection). an authentication code is needed to access the application, this code should be generated and given by the project owner. project - a research project owned/run by a researcher. the app is used to gather information by multiple users. the information gathered is in the form of a questionnaire. the project contains some defining information, like: the researchers, a description, the number of days and times per day an answer should be requested, a set of questions, and a user list. researcher - is an owner of a project or works for one. he/she can view the answers of any user in his project while creating new user accounts. he can alter the project settings and/or information. (super researchers can also create/delete projects and add/remove researchers from projects) user - he uses this mobile application to answer the set of questions the required amount of times per day until a required amount of days passes. question - questions can have multiple types/formats. simple text format: requires the user to write an answer multiple choice: the user must provide an answer from the existing options. (these questions may allow the user to write his own answer if set to do so). multiple choice questions can either be displayed in vertical or horizontal order slider questions: the answer is given in the form of a slider, or rather, a percentage represented by a slider. answers - it is important that for each answer the question it answers, tne time it was issued, and (obviously) the actual answer is known. each answer belongs to a specific user. app features: notifies user when its time to answer the digital questionnaire shows the user a set of questions which the user should answer. these answers are sent to a designated server. the application can store the answers if connection to the internet is not established so that these aswers can later be sent to the database. present some useful research information regarding researcher and study simple settings interface that allows the change of the initial notification time (or all notificaiton times depending on the type of study), log out or even stop contributing to the study. -an introduction sequence on first start that shows a project logo, a small description, some project details and a consent page in which the consent is required to continue using the app. -as previously mentioned the application stores some information locally that allows for: questions and answers are stored locally to allow use even without an internet connection synchronization occurs when the application first launches during the authentication (if internet connection is established). if a connection to the internet is not available then the application uses the stored credentials and user information to launch. notifications times are set when the user changes or sets the notification time, and are set daily. the notifications are local."
1,amber,data collection server,"# amber > electronic data capture system ## about amber is an electronic data capture system with a rest api, an administration interface amber studio and a user interface amber collect. functionalities: * data collection * data collection using online questionnaires * multiple data types: text, numeric, logical, image, video, file etc. * questionnaire builder * extensible question types * questionnaires grouped by study * questions with skip conditions * questionnaires with pages * self-reported data collection * participants * walk-in patients * users * user roles: administrator, manager, interviewer, guest * user/group permissions * user signup * user management * multi-lang * documentation * themes technical features: * scalable * offline-first design, with auto sync * multiple clients: web, mobile, desktop, script * auth with local credentials * docker * mailer * configurable ## getting started (developers) this project uses feathers. an open source web framework for building modern real-time applications. make sure you have nodejs and npm installed. install your dependencies ``` cd path/to/amber npm install ``` start your app ``` npm start # or rmp run dev ``` ## environment variables amber uses dotenv for environment variables discovery from a `.env` file. * `cluster_count`, node cluster count, defaults to all available cpu cores * `app_name`, jwt issuer * `app_secret_key`, encryption key * `app_secret_iv`, secret string for the encryption's initial vector, * `app_url`, jwt audience * `app_api_keys`, the allowed api keys (comma separated values) for triggering backround tasks execution, * `client_urls`, comma separated client urls, for the cors policy * `amber_studio_url`, amber studio app url, to be included in the notification emails * `amber_collect_url`, amber collect app url, to be included in the notification emails * `amber_visit_url`, amber visit app url, to be included in the notification emails * `mongodb_url`, the mongodb connection string * `encrypt_data`, whether the patient/participant data should be encrypted in the database * `otp_timeout`, is the number of minutes during which the onetime password (otp) sent by email is valid. default is when set to the email-based onetime password is deactivated. this does not apply to the time-based onetime password (totp) procedure, which can be activated per user. * `recaptcha_secret_key`, the recaptcha secret key. * `signup_whitelist`, the list of email domains that are allowed to signup. use '*' for wild card. default is all. * `signup_blacklist`, the list of email domains that are not allowed to signup. use '*' for wild card. default is none. * `gmail`, the gmail user name for the notification service * `gmail_password`, the gmail user password for the notification service * `sendinblue_api_key`, the sendinblue api key for the notification service * `smtp_host`, the smtp server host * `smtp_port`, the smtp server port (defaults to if is secure is false or if true) * `smtp_name`, the smtp server name * `smtp_secure`, whether the smtp connection should use ssl (default is true) * `smtp_require_tls`, whether the smtp connection should use tls (when secure is false) * `smtp_logger`, enable smtp logging * `smtp_debug`, enable smtp debug by sending log events * `smtp_user`, the smtp server user * `smtp_password`, the smtp server user's password * `from_email`, the automated sender email address, * `github_key`, oauth key for github * `github_secret`, oauth secret for github * `google_key`, oauth key for google * `google_secret`, oauth secret for google * `administrator_email`, user seeding when there is no administrator in the database * `administrator_pwd`, user seeding when there is no administrator in the database * `log_level`, logger level (`error`, `warn`, `info`, `verbose`, `debug`, `silly`, etc. (see winstonjs)), default is `info` * `log_file`, file logger path * `log_file_level`, file logger level when `log_file` is specified, default is `log_level` * `node_env`, name of the config file to be merged with the default one (e.g. `production`) ## testing simply run `npm test` and all your tests in the `test/` directory will be run. ## scaffolding feathers has a powerful command line interface. here are a few things it can do: ``` $ npm install -g @feathersjs/cli # install feathers cli $ feathers generate service # generate a new service $ feathers generate hook # generate a new hook $ feathers help # show all commands ``` ## help for more information on all the things you can do with feathers visit docs.feathersjs.com."
1,PsychApp_App-Android-,the android application for the 'psychapp' project,"# psychapp the android application 'psychapp' that works as a digital questionnaire useful for any psychology research. description: answer questions in specific times throughout the day. the user can set theese times. the questions are specific to each project. settings regarding the study or user are retrieved from the database. the answers given by the user are also sent to this database. the app also works in offline mode by storing the answers project settings localy, in this case the answers are sent when a login/authentication attempt occurs (with an established internet connection). an authentication code is needed to access the application, this code should be generated and given by the project owner. project - a research project owned/run by a researcher. the app is used to gather information by multiple users. the information gathered is in the form of a questionnaire. the project contains some defining information, like: the researchers, a description, the number of days and times per day an answer should be requested, a set of questions, and a user list. researcher - is an owner of a project or works for one. he/she can view the answers of any user in his project while creating new user accounts. he can alter the project settings and/or information. (super researchers can also create/delete projects and add/remove researchers from projects) user - he uses this mobile application to answer the set of questions the required amount of times per day until a required amount of days passes. question - questions can have multiple types/formats. > simple text format: requires the user to write an answer > multiple choice: the user must provide an answer from the existing options. (these questions may allow the user to write his own answer if set to do so). multiple choice questions can either be displayed in vertical or horizontal order > slider questions: the answer is given in the form of a slider, or rather, a percentage represented by a slider. answers - it is important that for each answer the question it answers, tne time it was issued, and (obviously) the actual answer is known. each answer belongs to a specific user. app features: - notifies user when its time to answer the digital questionnaire - shows the user a set of questions which the user should answer. these answers are sent to a designated server. the application can store the answers if connection to the internet is not established so that these aswers can later be sent to the database. - present some useful research information regarding researcher and study - simple settings interface that allows the change of the initial notification time (or all notificaiton times depending on the type of study), log out or even stop contributing to the study. -an introduction sequence on first start that shows a project logo, a small description, some project details and a consent page in which the consent is required to continue using the app. -as previously mentioned the application stores some information locally that allows for: > questions and answers are stored locally to allow use even without an internet connection > synchronization occurs when the application first launches during the authentication (if internet connection is established). if a connection to the internet is not available then the application uses the stored credentials and user information to launch. > notifications times are set when the user changes or sets the notification time, and are set daily. the notifications are local."
0,Web_Technologies_Chat,"stack overflow service, questionnaire, forum with comments and likes on django","# terms of reference for creating a chat as a task, it is proposed to complete the project ""questions and answers"". this service will allow internet users to ask questions and receive answers to them. commenting and voting capabilities build a community and allow users to actively help others. the recommended implementation is stack overflow. ## technologies used - application code is written in **python + django**. - the application runs under the control of the **gunicorn** server. - database - **postresql**. - **nginx** is used to return statics. - to deliver real-time messages **nginx + mod_push**. - for data caching - **memcached**. - layout is done using **twitter bootstrap**. - interface interaction with the user is provided by **javascript/jquery**. - you can use the **django.contrib.auth** application to authorize and store users. ## main entities - user - email, nickname, password, avatar, date of registration, rating. - question - title, content, author, creation date, tags, rating. - answer - content, author, date of writing, flag of the correct answer, rating. - tag - tag word. ## basic pages and forms **listing questions** with pagination of questions per page. it is necessary to implement sorting by date added and rating types of sorting). the site header contains: a logo, a search bar (for quick search by the title and content of the question), a button to ask a question (only available to authorized users). on the right side of the header is a user block. for an authorized user, the user block contains his nickname, avatar, links to the exit and to the page with his profile. for unauthorized - links ""login"" and ""registration"". in the right column - information blocks ""popular tags"" and ""top users"" (description below). all listings have like/dislike buttons that allow you to change the rating of a question. **page for adding a question** (can be done as an overlay). available only to authorized users. the title, question text and tags are entered into the form, separated by commas. a question can have no more than tags associated with it. for a hint when choosing a tag, you can use a ready-made jquery plugin. ready-made django applications for tags are not allowed. when processing the form, it is necessary to check the validity of the data. if the question is successfully added, the user is redirected to the question page, if there are errors, they must be displayed in the form. **question page with a list of answers**. you can add an answer on the question page. answers are sorted by rating and date of addition if the rating is equal. answers are divided into pieces per page. the form for adding an answer is on the question page. displayed only for authorized users. after adding an answer, the questioner should receive an email notification of the new answer. this letter should contain a link to go to the question page. the author of the question can mark one of the answers as correct. users can vote for questions and answers with likes ""+"" or ""-"". one user can vote for question and answer only time, but can cancel his choice or re-vote an unlimited number of times. **listing questions by tag**. this page displays all questions containing some tag. sort by question rating. pagination of questions. users get to this page by clicking on one of the tags in the question description. **user's page** contains his settings - email, nick and profile picture. each user can only view their own page. the user should be able to change email, nick and profile picture. **authorization form**. consists of the username and password fields. additionally, there is a link to the registration form. if authorization is successful, the user is redirected to the original page; if authorization is unsuccessful, form error messages are displayed in the form. for authorized users, instead of this form, the logout button should be shown. **registration page**. any user can register on the site by filling out the form with e-mail, nickname, avatar and password. the avatar is uploaded to the server and displayed next to the user's questions and answers. if the registration in the form fails, you should display error messages. **block of popular tags**. in the right column of the site is a cloud of the most popular tags. the most popular tags are those that have been used in the most questions. the generation of this block takes a long time, so this block must be generated in the background using a cron script. **block of top users** (weeks). the top users block includes authors who have asked the most popular questions or answers over the past week. those. questions and answers created in the last week are sorted by rating. we choose the top n, their authors will be the best. ## project requirements the structure of the project should be clear to users. pages are navigated through links. form processing should be done with a redirect. the project code should be neat and without duplication. the presence of large repetitive code snippets or patterns may be the reason for the deduction of points. the layout of the project must be done using css framework twitter bootstrap. the application code should be sensitive to the input data and issue appropriate error codes and texts. message to users ""question added"", ""the question was not added because"" is displayed in the overlay. a server response with a code may be the reason for the deduction. page generation time should not depend on the amount of data in the database. project pages should not be given more than second. ## data volume requirements - users > - questions > - answers > - tags > - user ratings >"
1,questionnaire,"questionnaire is not just a survey app, it has advanced functionality, including an administrative section for easy survey management, analysis of results, and flexible customization of survey design. support for google authentication, email sending, and a user-friendly interface panel will make your experience with the app even more productive.","# questionnaire !image ## simplify the process of creating and conducting surveys with clients, employees, and other participants using questionnaire. this application provides full functionality for creating surveys, managing results, and offers a user-friendly interface for both administrators and users ## *current version (improved email messages)* ### functionality ***general:*** - fully responsive design. ***admin area:*** - authentication (using google sign-in); - authorization (using internal roles); - notification of the user's completion of the survey (by receiving an email); - results manager: - viewing the list of previously conducted surveys; - receiving the results of any of the available surveys in xlsx format; - delete a survey you no longer need; - control panel: - create a new survey; - add a question to the survey: - selecting a question type; - selecting whether the answer is required; - add answer options if necessary; - delete an answer option; - delete a question using the appropriate interface element; - change the order of the questions using the appropriate interface elements; - select and add an image for the survey topic; - add a survey title; - sort the questions added to the survey as needed; - filter the questions added to the survey as needed; - search for a question by its content; - choose a color for the survey design using the color palette or color picker; - adding an email address to receive notifications (the default email address from your google account is used); - exit with saving the results; - copy the link to the created survey to the clipboard; - notification of creating a new survey; - exit without saving the results; - applying temporary storage of intermediate data in case of atypical situations. ***user area:*** - completing the survey by answering questions one by one; - validation of answers: - by data compliance; - by mandatory data entry; - visual display of the survey progress; - textual display of the survey progress; - visual design and sequence of questions in accordance with the administrator's preferences; - notification of completion of the survey; - prevent multiple surveys from being conducted from a single device (five-minute limit). **the version with the ukrainian interface is currently available. the development of an english-language interface is planned.** --- **this application was developed using react.** **this project was bootstrapped with create react app.** **to develop the application, the following additional libraries were used:** | library | version | purpose | |-------------------------|-------------|------------------------------------------------------------| | clipboard-polyfill | | polyfill for working with the clipboard | | emailjs-com | | library for sending emails | | firebase | | infrastructure for developing web applications | | firebase/firestore | | component for storing and retrieving data | | firebase/auth | | component for user authentication | | firebase/app-check | | component for protecting web applications | | react-google-recaptcha | | component for interacting with recaptcha | | xlsx | | library for working with electronic spreadsheets | --- ### application structure !image --- ### appearance | | | | |---------------------------|---------|---------| | application | !image | !image | | admin area | !image | !image | | admin area | !image | !image | | user area | !image | !image | | rwd mobile | !image | | --- ( )"
1,AUCO-server,"this is the back-end of auco, made with nodejs, mongodb and express. auco is a gamified online tool made with react that focuses on helping primary and middle school teachers to fight against bullying, in terms of detection and mitigation, and offering an open space where the students can communicate their worries to their teachers.","# auco ## what is auco? auco is a gamified online tool made with react that focuses on helping primary and middle school teachers to fight against bullying, in terms of detection and mitigation, and offering an open space where the students can communicate their worries to their teachers. the front-end of this proyect is hosted in auco. ## how does it work? in the platform, the students are asked to answer specific questionnaires, that are validated in their use to detect bullying cases. gamification is used to motivate students to use the online tool, and the teacher receives notifications regarding the possible bullying-cases. ## quick start auco server ```bash npm start ```"
1,PsychApp_Back_End,the back-end for the 'psychapp' project,"# psychapp_be the back-end for the psyhcapp project description: answer questions in specific times throughout the day. the user can set theese times. the questions are specific to each project. settings regarding the study or user are retrieved from the database. the answers given by the user are also sent to this database. the app also works in offline mode by storing the answers project settings localy, in this case the answers are sent when a login/authentication attempt occurs (with an established internet connection). an authentication code is needed to access the application, this code should be generated and given by the project owner. project - a research project owned/run by a researcher. the app is used to gather information by multiple users. the information gathered is in the form of a questionnaire. the project contains some defining information, like: the researchers, a description, the number of days and times per day an answer should be requested, a set of questions, and a user list. researcher - is an owner of a project or works for one. he/she can view the answers of any user in his project while creating new user accounts. he can alter the project settings and/or information. (super researchers can also create/delete projects and add/remove researchers from projects) user - he uses this mobile application to answer the set of questions the required amount of times per day until a required amount of days passes. question - questions can have multiple types/formats. simple text format: requires the user to write an answer multiple choice: the user must provide an answer from the existing options. (these questions may allow the user to write his own answer if set to do so). multiple choice questions can either be displayed in vertical or horizontal order slider questions: the answer is given in the form of a slider, or rather, a percentage represented by a slider. answers - it is important that for each answer the question it answers, tne time it was issued, and (obviously) the actual answer is known. each answer belongs to a specific user. app features: notifies user when its time to answer the digital questionnaire shows the user a set of questions which the user should answer. these answers are sent to a designated server. the application can store the answers if connection to the internet is not established so that these aswers can later be sent to the database. present some useful research information regarding researcher and study simple settings interface that allows the change of the initial notification time (or all notificaiton times depending on the type of study), log out or even stop contributing to the study. -an introduction sequence on first start that shows a project logo, a small description, some project details and a consent page in which the consent is required to continue using the app. -as previously mentioned the application stores some information locally that allows for: questions and answers are stored locally to allow use even without an internet connection synchronization occurs when the application first launches during the authentication (if internet connection is established). if a connection to the internet is not available then the application uses the stored credentials and user information to launch. notifications times are set when the user changes or sets the notification time, and are set daily. the notifications are local."
0,ccsm-cds-with-tests,this repository contains clinical decision support (cds) which provides recommendations for cervical cancer screening and management (ccsm).,"# cervical cancer screening and management (ccsm) clinical decision support (cds) with tests this repository contains clinical decision support (cds) which provides recommendations for cervical cancer screening and management (ccsm). the ccsm cds is expressed in a computer-interpretable format using health information technology (it) interoperability standards. when used with health it systems that support the underlying interoperability standards, the ccsm cds is capable of providing patient-specific recommendations for cervical cancer screening and management decisions. the burden of implementing the ccsm cds on such health it systems can be less than what would be needed to develop similar capabilities ""from scratch."" to verify the correctness of the ccsm cds, a set of automated tests have been included which use synthetic patient data. ## cautions and limitations this repository contains cds definitions which are under *active development*. the ccsm cds has not been tested in a clinical environment and should be considered a *work-in-progress*. per the license under which the ccsm cds is released, *no warranty is made* and *no liability is assumed*. ## cds overview the ccsm cds provides recommendations for cervical cancer screening and management based upon the following primary and secondary evidence bases. ### primary evidence-based guidelines - you.s. preventive service task force recommendation statement: screening for cervical cancer - asccp risk based management consensus guidelines for abnormal cervical cancer screening tests and cancer precursors - risk estimates supporting the asccp risk-based management consensus guidelines ### additional supporting guidelines and evidence - asccp clinical practice statement: evaluation of the cervix in patients with abnormal vaginal bleeding - cervical cancer screening and prevention practice bulletin - antenatal exposure to des: lessons learned...future concerns - guidelines for prevention and treatment of opportunistic infections in adults and adolescents with human immunodeficiency virus (hiv) - guidelines for screening of immunosuppressed women without hiv infection ## utlized standards multiple health it interoperability standards are used to define the ccsm cds. these standards are used to define both the structure of the ccsm cds as well as the logic needed to provide customized recommendations for each patient. ### fast healthcare interoperability resources (fhir) fast healthcare interoperability resources (fhir) is an international it standard for exchanging healthcare information electronically. fhir provides general data structures or resources for representing a variety of clinical and healthcare-related data. example resource types include condition and observation, which can respectively be used to represent clinical diagnoses and laboratory test results. fhir resources are, by design, general in nature so that they can support the majority of real-world use cases. but fhir also allows each resource to be customized for specific applications; these customizations can themselves be standardized through the use of fhir extensions, profiles, and implementation guides. this customizability and flexibility are some of the reasons why fhir has been growing in popularity despite being a relatively new standard. the use of fhir in the united states is expected to continue to grow because it is the basis for the application programming interface (api) required by the century cures act interoperability final rule. it is for these reasons, flexibility and eventual availability, that fhir has been selected for use in the ccsm cds definition. several fhir resources are used to define the *structure* of the ccsm cds: - plandefinition - used to define and describe groups of actions that occur under certain circumstances; these groups of actions represent the overall structure of the ccsm cds. each action may reference fhir resources including other plandefinition resources. - activitydefinition - used to define and describe a single activity, such as a request for a laboratory test or for a communication to be sent to a provider. - questionnaire - used to define forms that can be presented to the cds user to obtain additional information when necessary. - library - used to package the cds logic, which is referenced by the other fhir resources and expressed using cql. #### clinical reasoning module the clinical reasoning module (crm) is a subset of the base fhir standard. the crm provides the fhir resources and operations needed for representing and distributing clinical knowledge tools such as cds. the structure of the ccsm cds is based upon the guidance provided by the crm for designing and building cds. #### fhir clinical guidelines implementation guide the fhir clinical guidelines implementation guide (ig), also known as clinical practice guidelines (cpg) on fhir, provides an approach and methodology for representing the intent of clinical guidelines as computable cds. the ccsm cds was developed by following the best practices outline in the cpg on fhir ig. these best practices include testing and verification of the ccsm cds. in addition, several extensions and profiles defined in the cpg on fhir ig have been used in the ccsm cds representation. ### clinical quality language (cql) the clinical quality language (cql) is a domain-specific computer programming language focused on the expression of clinical quality concepts. it can be used to author cds logic and is designed to interface with fhir. that latter fact constitutes one of cqls advantages over other more general-purpose programming languages when it comes to authoring cds logic. an additional advantage is that logical expressions written in cql tend to read more like natural language than as a computer program, making cql more accessible to audiences outside the realm of software development.n computer code written in cql is human readable but can be translated into a more structured format that is interpretable by computers. this computer-friendly format is called the expression logical model (elm) javascript object notation (json), and it is this format of the logic that is interpreted when the cds logic is executed against patient data. while fhir allows the structure of the ccsm cds to be described, it can only enumerate the set of all actions that could apply to a patient. the cql standard allows the cds logic to be expressed so that it can be determined which actions apply to a specific patient. the follow are example ccsm cds capabilties which have been implemented using cql: - query patient electronic health record (ehr) for pertinent medical history - aggregate and sort pertinent medical history for presentation to the clinician on a dashboard - apply inclusion and exclusion logic to determine what actions of the cds should apply to a particular patient - generate recommendations for a particular patient when appropriate - identify errors and generate meaningful notifications to be communicated to the clinician ## underlying technologies this section describes the underlying technologies used in this repository. ### node.js javascript runtime node.js is a back-end javascript runtime environment. although the ccsm cds itself does not directly require use of node.js, this repository uses it to run a number of supporting javascript tools for verification and testing (see below). ### python the asccp risk based management consensus guidelines for abnormal cervical cancer screening tests and cancer precursors leverages risk estimates provided by the national cancer institute. to make these risk estimates usable by the ccsm cds logic, the risk tables must be converted into a cql library. a python script has been provided for automating this converstion. it requires python pandas, and openpyxl. ### sushi all fhir resources in this repository have been defined using fhir shorthand (fsh). using fsh simplifies the development and maintenance of the ccsm cds fhir resources while still maintaining the necessary fidelity. to convert the fsh definitions to full fhir resources, a javascript tool called sushi is used which requires the node.js runtime. in addition to converting fsh definitions into fhir, sushi also performs basic verification of resources to ensure they align with the fhir specification. ### cql execution engine once cds logic written in cql has been translated into the computer friendly elm json format, software is needed to execute or run the logic in the context of a patients electronic health record. executing cql in this way is necessary in order to support verification and testing of the ccsm cds. multiple open-source cql execution engines exist; the ccsm cds has been tested using the cql execution framework reference implementation, a software library written in the javascript programming language. additional javascript libraries are used to help interface with fhir data and to help handle clinical codes and value sets. ### cql testing framework the cql testing framework is a javascript software library that facilitates testing of logic written in cql. while leveraging the cql execution framework reference implementation, it provides a convenient short-hand notation for defining test cases. the cql testing framework also automates the process of running the test cases, which greatly increases the efficiency of testing cds. all tests included in this repository were developed through the use of the cql testing framework. ## usage this section describes how this repository can be installed and used for testing and verification purposes. ### installation this repository must downloaded or cloned to a local file system. a recent version of the node.js runtime should be downloaded and installed. installation of this repository is accomplished by typing `npm install` into a command prompt from within the same directory as this readme file. this should download all necessary dependencies including sushi and the cql testing framework. if the risk tables need to be regenerated, then python should also be downloaded and installed. ### generate fhir resources the fsh definitions located in the `./fsh-tank/input` folder can be converted into full fhir resources by typing `npm run sushi` into a command prompt from within the same directory as this readme file. the resulting fhir resources will be written to the `./fsh-tank/fsh-generated` folder. ### convert risk tables to cql the cql library containing the risk estimates can be regenerated by running risk-tables/generate-cql-risk-tables.py` into a command prompt from within the same directory as this readme file. ### translate cql into elm json before the cql can be tested, it must first be converted to the computer-interpretable elm json representation. this is only necessary if the cql source is modified and can be accomplished using the cql-to-elm translator reference implementation. the cql testing framework provides a command for invoking the cql-to-elm translator: ``` npx cql-to-elm cql ``` but note that this requires installing java se development kit on your system. see documentation from the cql testing framework for more information. ### package elm json into fhir library resources in order to execute cds logic, the fhir clinical guidelines implementation guide requires elm json logic to be converted into and embedded into a corresponding fhir library resource. `npm run packager` runs the script in `util/packager.js`, encoding elm json files in `cql/` as strings, and overwritting the content strings in the corresponding library resources in `fsh-tank/`. the script also saves the unencoded elm json off into .js files so it is easier for the dashboard to import them. ### run cql tests to run the tests to verify functionality of the ccsm cds, type `npm run test-cql` into a command prompt from within the same directory as this readme file. note that this will require a umls account and vsac api key; please see documentation for the cql testing framework for further instructions. the results from running the tests against the current cql definitions can be found in test-results.txt. ## feedback feedback on this draft work is welcomed and encouraged. prospective users can either open an issue on github or reach out to the maintainers directly. ## licenses (c) the mitre corporation. all rights reserved. approved for public release: distribution unlimited. unless otherwise noted, the ccsm cds is available under an apache license. it was produced by the mitre corporation for the division of cancer prevention and control, centers for disease control and prevention in accordance with the statement of work, contract number task order number the ccsm cds reproduces in electronic form the risk estimates supporting the asccp risk-based management consensus guidelines. these risk estimates were supported by the intramural research program of the national cancer institute. the risk estimates are in the public domain in the united states of america and are made freely available elsewhere. any loinc (http://loinc.org) content is copyright &copy; regenstrief institute, inc. and the logical observation identifiers names and codes (loinc) committee and is available at no cost under the license at http://loinc.org/license. loinc<sup>&reg;</sup> is a registered united states trademark of regenstrief institute, inc. the ccsm cds makes reference to several clinical terminology systems and value sets available through the unified medical language system (umls) and the value set authority center (vsac), both operated by the united states national library of medicine. these resources require an account and license through umls terminology services (uts)."
0,WP-Form-Builder,highly configurable and easy to use wordpress drag and drop form builder plugin,"# wp form builder author: james collings version: homepage: https://www.wpformbuilder.com/ documentation: https://www.wpformbuilder.com/documentation/ demo: https://www.wpformbuilder.com/demo/ created: updated: ## about create your next form with ease using our new drag and drop form builder, with multiple field types, each with validation helping to capture the data you require, whether its a simple contact form or even a complex questionnaire we can build it. setup email notifications to alert administrators about new form submissions, or even just thank users for completing the form, or do nothing, the choice is yours with our configurable form notifications and confirmations. simply change colours of the form to match your websites theme via our style editor and preview the form, when ready to display the form use our new wysiwyg button to output and configure the form shortcode. ## features * __saved submissions__ - form submissions are automatically stored and can be viewed from within the wordpress admin area. * __email notifications__ - easily setup email notifications when forms are submitted, and customise it with template tags to display for entry data. * __form validation__ - fields can make use of multiple validation functions, each allowing for custom validation messages. * __field types__ - currently supports (text, text area, file, select, checkbox, radio) * __spam protection__ - recaptcha integration to help stop unwanted spam ## documentation * installation * managing forms * creating a form * managing fields * add a field * field validation * remove a field * form settings * general settings * form confirmations * display settings * recaptcha settings * form styles * form notifications * form submissions * adding form to page ### installation download the latest version of the plugin from github here. extract the download to your websites wp-content/plugins folder. activate the plugin from the wordpress admin plugins section. ### managing forms all features of the plugin can be found under the left hand menu item called forms, when this section loads up you will be show a list of all previously created forms. !form archive to interact with any form hover over the form form, you should see a list of actions should appear under the form name. !form hover actions > throughout the interface if you do not know what to do, hover over the ? to show a brief message about what that feature does. #### creating a form to create a form click on the menu item forms > add form, or when you are on the form archive a link to create a new form should be visible next to the title of the page. when this page loads up you have to enter the name of the form, this name will be displayed at the top of the form, this can be edited at a later date under the form settings tab. !create form click the create form button to create the empty form. #### managing fields !edit form on the left hand side of the screen you will see a dashed box that says drop field here to add to the form , this is the field dropzone, to the right of that is a list of fields under the title available fields. ##### add a field click and drag the field that you want to add to the form from the right hand column into the field dropzone on the left hand size, if there are fields already added you can hover above or below to insert the field in the correct order you require. once you have dropped the field in the dropzone, a field panel should appear allowing you (as shown in the next image) to set attributes such as the field label, depending on the type of dropped field different options will be available. !add field once a field has been dropped, you can easily reorder the list of fields by click and dragging on the top bar of the field panel, to make this easier you can toggle the display of the field panel by clicking on the up/down arrows at the top right corner of the field (highlighted below). !field toggle ###### general field options !field toggle all fields have the following fields: * label - text displayed before the field. * placeholder - text displayed on the field before any data is inserted. * css classes - used when styling the form via css ###### text field options !field toggle text fields have the following fields: * default value - text entered here will populate the field when the form is loaded. ###### textarea field options !field toggle textarea fields have the following fields: * rows - how many rows of text will be visible (alters the height of the textbox) * default value - text entered here will populate the field when the form is loaded. ###### select field options !field toggle select fields have the following fields: * empty text - this text will appear as an empty option * select type - allow the field to accept single or multiple options. * values - values can be add/removed via the plus and minus icons on the right hand side, each row makes up an choosable option. * label - text visible to the user * value - value of option, not visible to the user * default - check this to make to make the field pre populate with this selection. ###### checkbox field options !field toggle checkbox fields have the following fields: * values - values can be add/removed via the plus and minus icons on the right hand side, each row makes up an choosable option. * label - text visible to the user * value - value of option, not visible to the user * default - check this to make to make the field pre populate with this selection. ###### radio field options !field toggle radio fields have the following fields: * values - values can be add/removed via the plus and minus icons on the right hand side, each row makes up an choosable option. * label - text visible to the user * value - value of option, not visible to the user * default - check this to make to make the field pre populate with this selection. ###### file field options !field toggle file fields have the following fields: * maximum files size - set this to the size limit of files you want to allow users to upload, enter this in megabytes as an integer (check that your php server settings post_max_size and upload_max_filesize are greater than the value you enter, otherwise this can because problems. * allowed extensions - type all the file extensions you want to allow users to upload each separated by a comma ,. ##### field validation adding field validation rules is as easy as clicking on the add validation rule on the field panel, once clicked a dropdown will appear allowing you to choose the type of validation you want to add. once selected extra options will appear depending on the chosen value, by default all validation rules allow you to customise the message displayed when the field is invalid, leave the message blank to use the default validation message. !field validation rules ##### remove a field fields can be deleted by clicking on the delete text at the top right of each field. #### form settings > if you are unclear about any fields when editing the form settings page, hover over a ? to show a brief description about that section. ##### general settings * form name - name of the form, displayed at the top of the form when viewed * form content - text content displayed after the title on the form. * submit button text - set the text displayed on the forms submit button ##### form confirmation * confirmation type - what happens when the form is complete show message or redirect to page * confirmation location - where the confirmation message appears. * confirmation message - text to display one successful submission * confirmation redirect - location to redirect too on successful submission. ##### display settings * style editor - enable display the user of the style editor ##### recaptcha settings add a recaptcha spam field to the form, you will need to generate an api key on the recaptcha website and follow there instructions on how to get a site key and public key. ##### form styles if you have enabled the style editor in the display settings, on form save a style tab will appear at the top in the header, click this to view all the style choices, each field has a ? explaining what section it styles, click on the text input box to show a colour picker, once you have the ideal colour, click anywhere on the page to hide. you can disable each style individually by checking the checkbox labelled disable. #### form notifications notifications are triggered on a successful form submission, you can have multiple form notifications, notification messages can contain data from the submitted form. !form notifications when a form is first created you will have a default notification setup, this will send an email to the website administrator with the subject line new form submission and in the email body a list of all the fields followed by the data submitted. to display form data in your notification there are merge tags, these are based on the fields in your form. you can display the data from any field in the form with ""{{field_field_name}}"" a list of all merge tags will appear to the right hand side of the notification message box. #### form submissions by default all form submissions are stored and can be accessed from within the forms section of the website, from the list of forms hover and click on the submissions action, or when on the edit screen click on the submissions menu item. > you can manage the columns displayed in the submission table by adding a plugin filter to your themes functions file, a way to do this visually will be coming soon. !manage entries you should see a paginated list of form submissions, which is searchable via the search entries input above. all new entries are highlighted with an unread label next to the entry id. to view an entry in more detail click on the entry id, or hover over it and click on the view action. !view entry on the left hand side is a list of all the information submitted, and on the right hand side is information about the submission such as the date/time and the user account / guest who submitted it. #### adding form to page we have added a button to your wysiwyg editor to make it simple to insert a form into a page, click the form icon highlighted in the image below to start the insert process. !tinymce button a modal window will open up allowing you to choose from a list of forms previously created, once chosen click on the insert button at the bottom, this will insert the form shortcode into the current page. !tinymce button ## changelog ### * add: scaffold addon class for extending form * add: shortcode parameters title and ajax * add: option to submit form via ajax (iframe support for old browsers) ### * add: number input, number slider, and number range slider field ### * fix: sanitize data when editing the form * fix: move form settings from post_content to meta field * fix: display status messages when editing and saving data * add: make field label required * add: click and add field to form ### * add: form preview link * add: edit form general error, toggle display of field errors below message * fix: increase security with file upload, randomly generate folder and file prefix ### * plugin released"
1,Android_COVID_Monitor,mini project for senior design. by sara hamdy and jonathan hall,"# android covid monitor ## **mini project for senior design by jonathan hall and sara hamdy.** this project was designed and created over days, as an intro to senior design. the application, built using java in android studio, features both sso(signal sign on) through google and email login through account creation. both authentication processes are enabled and stored through google firebase. <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_login.png"" /> once logged in, the user is able to take self administered health surveys, present their health badge to university administrators, and check live local covid statistics through the helpful api provided by https://corona.lmao.ninja/. ### home screen <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_homescreen.png"" /> the health survey is a series of questions that ask the user if they are experiencing various covid symptoms. the questions are presented in a neat manner, with one question at a time to avoid scrolling. this allows users who feel well to breeze through their questionnaire and be incentivized to complete it regularly. the surveys are taken daily, and if the user misses theirs, a notification will be send via banner to remind the user. there is also a helpful display in the app that outputs the last time a survey was taken. the data is stored via firebase's cloud firestore. ### survey screen <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_survey.png"" /> <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_alert.png"" /> if the user answers ""yes"" to any survey questions, their banner will turn orange to signify to university administrators that the student should be home. if the student answers ""no"" to all survey questions, the banner will display green signifying **all good to go!** ### badge screen <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_cleared.png"" /> <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_quarantine.png"" /> additionally, the user is able to quickly check the real time covid reports in massachusetts. ### api screen <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_api.png"" /> to view the data, you have to be an administrator. the administrator logs in via the same log in screen, but they are taken to the admin panel. it is important to note that you cannot create an admin account through registration (important for data safety). **note, our default admin was (user: admin@gmail.com, password: but it will vary by implementation**. using the admin panel, you can view covid survey statistics, such as the number of surveys taken in the past day and recent positive symptom surveys. for the safety of the user however, names are never displayed. ### admin panel <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/covidapp_admin.png"" /> ## dependencies we used google firebase for all our storage, including user (authentication) and survey data. here is a snapshot of our databases. ### firebase authentication and firebase cloud firestore <img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/firebase_authentication.png"" /><img src=""https://github.com/jon-s-hall/android_covid_monitor/blob/master/images/firebase_surveys.png"" /> we also used https://corona.lmao.ninja/ for our covid api, and https://unsplash.com/ for our free login screen background."
1,radisa,survey app,"welcome to platform that empowers users to create and edit surveys effortlessly while automatically aggregating results. with the ability to add and modify user profiles, as well as receive valuable suggestions, our application is designed for exploring the thoughts and opinions of students on various subjects. dive into a seamless experience of survey management, user engagement, and data analysis all in one place. start understanding and capturing diverse perspectives with our intuitive survey platform. specs of project key features: email notification on survey activation background email sending with rate limiting react ui with rodal, tostify, framer motion laravel api with validations mysql database with automatic survey lockdown pdf export using jspdf and chart.js integration for data visualization responsive design automatic logout after hour student search functionality tailwind css for styling fontawesome for icons grade system without registration material-tailwind/react ui responsive design additional project features queue worker toggle: purpose: send emails upon survey activation. implementation: uncomment the code in the surveycontroller.php file. enable the queue worker by running ""php artisan queue:work"" and setting queue_connection=database in the .env file. scheduled task toggle: purpose: automatically lock surveys after one week. implementation: start the scheduler by running ""php artisan schedule:run"" important notes: make sure to configure the environment variables accordingly. for the queue worker to send emails, the queue_connection in the .env file should be set to database. adjust the delay in the code snippet to control the time between emails. this way, you can easily toggle the queue worker for sending emails and the scheduled task for survey lockdown by following the provided instructions. to start it! clone the repository git clone cd radisa if you encounter problems with cloning, try the following: git remote add origin git pull origin main install dependencies composer install npm install cd react npm install create environment file cp envstarterpack .env generate application key php artisan key:generate configure database make sure to set up your database configuration in the .env file. run migrations php artisan migrate start laravel server php artisan serve build and run react cd react npm run dev additional notes ensure that xampp server is installed and running for local usage. important users are added from within the application. on the landing page, go to the login section, and upon the first opening, you will have the option to create an admin account. upon doing so, you will receive administrative credentials and permissions. use these credentials to access the administrator profile, from where you can create user accounts. these users can then fill out the survey questionnaires that you, as the administrator, create."
1,Mental-health-care,health app,"# course - capstone project ## group - ## group members- name - sameer shaligram student id - name - shiwantha viraj student id - name - kavin ranawella student id - name - ghanashyam shingate student id - name - pushpraj rajan student id - # app name - ## app description - ### ""discover a better you with introducing our mobile app for improving mental healtha thorough resource for anyone wishing to do so. our app offers daily mood tracking, self-evaluation, and individualised treatment recommendations for mental illnesses. utilise our app to take charge of your mental health right now. ## list of features- users can use our simple game gui which can offer user to take control on his anger like starting count from to while after every count he will see some tips to get his anger in control. users will be able to find medical centres nearby for mental health needs. users can see a splash screen while opening the app. users can easily navigate the app using bottom tabs. users can indicate their mood by choosing emojis as a means of expression. users can change to dark theme for better viewing and relaxation. users can track their mood day by day. users can store emergency contacts for immediate mental health assessment. users can read daily inspirational quotes for motivation. adding favourites list if something is preferred. users can keep track of water intake. if users are in stressful condition, they can check steps to get out of that condition. users can delete all activity history users can read in-built pdf books in the app. calendar feature can be added to set appointment by user. users can track self-satisfaction and mental wellness progress. remove all in-app notifications at once. users can check quick health by answering a questionnaire. users can record their day-by-day mood and show the progress record. users can set and analyze your mental health goals. users can track sleep. users will get notified from mental health app. users can keep track of medicine intake. ## getting started to run the app on your device, follow these steps: * clone the repository: git clone https://github.com/s-shaligram/mental-health-care * install dependencies: npm install * start the development server: npm start * use expo go app or an emulator to test the app on your device. ## contributing we welcome contributions to improve the app. if you find any bugs or have suggestions for new features, please feel free to raise an issue or submit a pull request. ## acknowledgments special thanks to all the team members for their dedication and hard work in developing the app, making a positive impact on mental health."
0,SurveySolutionsAPIv2,a comprehensive set of r functions to access the survey solutions rest/graphql api based version),"--- output: github_document --- <!-- readme.md is generated from readme.rmd. please edit that file --> ```{r, include = false} knitr::opts_chunk$set( collapse = true, comment = ""#>"", fig.path = ""man/figures/readme-"", out.width = ) ``` # <!-- badges: start --> [!lifecycle: experimental](https://lifecycle.r-lib.org/articles/stages.html#experimental) <!-- badges: end --> <p float=""center""> <img src=""warning.svg"" /> </p <div align=""justify""> this is a (beta - new edition of the survey solutions r api package, based on the recently (as stable) released package. most of the syntax is the same as in the existing httr based surveysolutionsapi package, and therefore it should be easy to integrate it in your existing workflow, if you have used the previous edition so far. but besides a few syntax changes as well as several other updates like more meaningful error messages using the cli and the rlang packages there are also quite a bunch of new features. therefore, i decided to release this package as a completely new one, such that users who do not want to switch to the new package or make use of the new features, can still work with the old package as usual. nevertheless, a transition to the new package is recommended. additionally, the package also seeks a deeper integration with the updated susographql package, which now also is purely based on the package. #### new features in this package specific to one or several functions are: - **suso_get_stats_interview, suso_get_assignments, suso_createuser, suso_createass, suso_getsv** and **suso_getint** with potentially long running queries now use parallel request feature, which reduces processing time substantially. for example, assignments (*suso_createass*) can now be created in about minutes, a list of all interviewers (*suso_getint*) in a workspace for interviewers and supervisors now only takes around minutes. in particular in large scale surveys and censuses, this feature may facilitate working with the api considerably. - **suso_set_key:** workspace can now be set as an environment variable, like it was already the case for server, user, and password. - **suso_export:** now has the option to merge all the data export files into a single data table and also add survey weights, for analysis-ready data sets. - **suso_export:** of spatial (survey solutions geography questions) data (i.e. polygons, point locations, lines) can be processed into sf (simple feature) objects directly, by setting *process_mapquestions = true*. for example a type polygons question, collected manually or automatic, will result in an sf polygon, which can be stored directly as a shape file with st_write. - **suso_export:** now also processes available value labels and applies them to categorical variables, as well as variable labels without using the stata export (and therefore the package are not required any longer). in case you have one or several translations for your questionnaire, these can be applied as well, such that the labels appear are in the desired language. the (exportclass) specific methods, subsequently make use of these additional attributes, resulting in publication-ready tables and graphs. - **suso_export_paradata:** now uses milliseconds for all time based calculations, and also adds comprehensive questionnaire information to the data, like i.e. question type. - **suso_export_paradata:** now also identifies gps variable in your questionnaire, and uses it, to add gps location data to the paradata, which facilitates spatial analysis of paradata considerably. - **suso_mapupload, suso_mapassign, suso_mapinfo, suso_mapreport** and **suso_deletemap** now also integrates complete map management into a single package using a harmonized syntax and returning the same output - **suso_assignworkspace:** now also supports workspace assignment of multiple supervisors and interviewers in one go. in addition it has the argument *keep_old_workspace*. if *true*, then the existing workspaces the user is already assigned to are automatically added. with this new feature, all users from one workspace can be assigned to a new workspace with a single function #### new general features in this package are: - new classes and methods, i.e.: assignmentclass, exportclass, userclass, and methods like summarytable.exportclass (dt based) or boxplot_summary.exportclass based). - http error messages are translated into r errors and use the error codes (and messages) as provided by the survey solutions api response), which makes debugging easier. - several options, which allows the user to customize processing to their environment, like: *suso.maxpar.req* for the maximum number of parallel requests, *suso.para.break* for customizing breaks when calculating paradata response times, *suso.para.tz* for setting the time zone or *suso.para.maxcore* for the number of cores used in parallel processing. - several functions also includes notifications and progress bars when running in a shiny app, text content of these messages can be modified through several global options, such that the ui can be customized to the user language. in case you do not need any of these notifications, you can also deactivate them globally. - handling of transient http errors which are sometimes returned by the survey solutions api, through an automatic retry after a short delay, and a maximum number of retry attempts. this is just a very rough overview of the most prominent features, for details please see the individual functions' documentation. an extensive documentation is still in preparation and will follow over the next weeks, as well as some more class specific methods. for now, until the new documentation (i.e vignettes, gihub.io website) is released please use the original surveysolutionsapi package documentation, which is still valid for most of the functions. ##### further details on the package philospy again, and even more than the previous httr based api package, this package is more than just a simple wrapper around the survey solutions rest api (or graphql) endpoints. the main intention of this package though, is to be integrated into your own data collection workflow, either through a shiny application or just through a simple script without a lot of additional data wrangling and adjustments. as such, the package allows you to build your own workflows with your own customized user interfaces for your survey solutions data collection operations, no matter if you are dealing with a small scale impact evaluation or a large scale census. for this reason, the api calls return easy to process data tables, and in some cases, like paradata, even add additional variables useful for further processing. for example the outputs of the newly added *summarytable.exportclass* and *boxplot_summary.exportclass* can be used in a shiny application right away, by either using *renderdt* from the r dt package, or *renderplotly.* from the r plotly package. important to note here is, that the package also makes extensive use of the **data.table** package, which allows for fast (multi-core) processing of large data sets. the individual functions either return a data.table, or a specific extension of data.table, with individual methods defined. in case you are not familiar with it yet, you should probably have a look a this introduction. nevertheless, in case you do not require the capacities offered by data.table, you can still treat the return objects like a data frame or even continue with it in the tidyverse. a package which combines both worlds is the dtplyr package, and for a comparison between the dplyr package and the data.table package see here. ## installation the package is not on cran yet, so you have to install it by using ``` r build_vignettes = t) ``` the included vignettes also contain different examples and further explanations. bellow you can find a few examples. ## examples ### credentials management to use the api you first need to set-up the api user on your survey solutions server. see here for details. after this done, you can use the *suso_set_key()* function, to provide your credentials. ```r suso_clear_keys() suso_set_key(""https://xxx.mysurvey.solutions"", ""xxxxxx"", ""xxxxxxx"", ""test"") suso_keys() #> $suso #> $suso$susoserver #> ""https://xxx.mysurvey.solutions"" #> #> $suso$susouser #> ""xxxxxx"" #> #> $suso$susopass #> ""xxxxxxx"" #> #> $suso$workspace #> ""test"" #> #> #> attr(,""class"") #> ""suso_api"" ``` ### workspace management you can also manage your workspaces through the api. in particular, you can - request a list of all workspaces the api user has access to, as well as - create new workspaces - and assign users to a particular workspace. however for the latter two operations you require admin credentials. standard api user credentials would not work. to receive a list of workspaces to which the current api user has access to, you can just run: ```r ws <- suso_getworkspace() print(head(ws)) #> name displayname disabledatutc #> primary default workspace na #> test test na #> na ``` ### user management these functions are particularly useful for survey management, and more details can be found in the corresponding vignette on survey management. let us start with getting a list of all supervisors on the server. ```r sv <- suso_getsv() print(head(sv)) #> islocked creationdate userid username #> false somesvuser #> false #> false #> false #> false #> false ``` ### questionnaire management the basic questionnaire api calls are handled through the *suso_getquestdetails* function. if no input is provided, the function returns a list of all questionnaires on the server: ```r questlist <- suso_getquestdetails() # print(questlist) ``` specifying *operation.type = status*, you receive a list of statuses. ```r statlist <- suso_getquestdetails(operation.type = ""statuses"") print(statlist) #> ""restored"" ""created"" ""supervisorassigned"" ""interviewerassigned"" ""rejectedbysupervisor"" ""readyforinterview"" ""senttocapi"" #> ""restarted"" ""completed"" ""approvedbysupervisor"" ""rejectedbyheadquarters"" ""approvedbyheadquarters"" ""deleted"" ``` by taking a particular *questionnaireid* and specifying the *operation.type *you can execute further requests. for example, ### data export to export the data collected in survey solutions, you use *suso_export*. ``` #> the last file has been created hours ago. #> filename: assignment__actions #> nesting level: #> **** #> #> filename: households #> nesting level: #> **** #> #> filename: interview__actions #> nesting level: #> **** #> #> filename: interview__diagnostics #> nesting level: #> **** #> #> filename: interview__errors #> nesting level: #> **** ``` its return value is a list with the following elements: main, with - **main** containing the files: interview__comments, - containing all rosters at the first level - containing all rosters at the second level - containing all rosters at the third level through the harmonized id, main and roster files can easily be put together. more on this in the specific vignette. ## paradata export to retrieve the paradata for a particular interview you use *suso_export_paradata* ```r <- suso_export_paradata(questid = questionnaireid], version = version], reloadtimediff = onlyactiveevents = f, allresponses = t)) #> #> the last file has been created hours ago. #> #> starting download & file extraction. #> #> #> calculating response timings. #> #> extracting gps variable. #> processing: #> answerset #> #> answerremoved #> #> approvebyheadquarter #> #> restarted #> #> reject #> #> questiondeclaredinvalid #> #> questiondeclaredvalid #> #> export & transformation finished. #> user system elapsed #> ``` ### map management since recently, it is now also possible, to handle maps through the api. this is implemented through the lately introduced graphql api. to upload a map, you can just use the **suso_mapupload** function like this: ```r suso_mapupload(path_to_zip = mappath) #> xmaxval ymaxval xminval yminval wkid filename size maxscale minscale shapetype importdateutc uploadedby users #> checkshapesimple.shp polygon ``` to assign a map you can use the **suso_mapassign** function: ```r suso_mapassign(filename = ""checkshapesimple.shp"", username = #> filename user shapetype importdateutc #> checkshapesimple.shp polygon ``` ## further information to find information on the world bank's survey solutions cass have a look on these pages: - survey solutions support page: https://support.mysurvey.solutions/ - survey solutions server request: https://mysurvey.solutions/ to find information on the api syntax, visit your own servers api documentation or got to: - https://demo.mysurvey.solutions/primary/apidocs/index.html# and to find more information on the package, check out the package vignettes. ## feature requests and bug reports since this is a beta release, feedback, bug reports and feature requests are very welcome. you can either use the standard github approach by filing a bug report/feature request here or you use the survey solutions user forum here. the package is still under testing and also development of some features, therefore it is only recommended for experienced users. all functions use the susographql functions, but are adjusted to the syntax of this package. be aware, that workspace assignment requires admin credentials. regular api user credentials would not work. </div>"
0,Covid_Information_App,"the main function of this application is to help users to know the latest information on based on their location. the application provides different guidelines for covid in different provinces and countries. it clears the confusion for the people to properly follow the guidelines for the particular area in which they live, sometimes the guidelines keep changing so this app sends push notifications to the device accordingly. if the person is a traveler then the app provides quarantine guidelines and travel restrictions to and from the region there will be no need to download different applications for this purpose and also it gives updated information about covid vaccination and live statistics of covid cases by country and provinces in the form of pie chart and map view.","in these desperate times, coronavirus disease is flowing through the people very quickly and brought the human race to the pandemic situation. this software requirement document refers to covid information application. this document will be used by developers, testers, designers, and project managers so that they can build a mobile application that will be used by people who are not aware of the latest regional guidelines and want to know the latest information about the the main purpose of this covid information application is to provide the latest covid information like provincial guidelines, news about coronavirus, covid statistics for the people who are facing difficulties in finding the precise information. the main function of this application is to help users to know the latest information on based on their location. the application provides different guidelines for covid in different provinces and countries. it clears the confusion for the people to properly follow the guidelines for the particular area in which they live, sometimes the guidelines keep changing so this app sends push notifications to the device accordingly. if the person is a traveler then the app provides quarantine guidelines and travel restrictions to and from the region there will be no need to download different applications for this purpose and also it gives updated information about covid vaccination and live statistics of covid cases by country and provinces in the form of pie chart and map view and also update their profiles for contact information. this mobile application is mainly used by people facing difficulties in finding the official information about the guidelines and the covid news. requirements | **requirement id** | **requirement statement** | **comments** | | ------------------ | ------------------------------------------------ | -------------------------------------------------------------------------------------------------- | | | login page | the system must have a login screen so that the registered user can log in. | | | sign up | the application must have a sign-up page where the new user can register using email and password. | | | forgot password | follow the secure procedure to recover the password in case a registered user forgets. | | | search location | the user can search for the location by using google map api | | | notification | the system must always send a push notification when guidelines changes | | | log out | users must have an option to log out. | | | users can get their provincial and country data. | current data must provide to the user. | | | email verification | users must get the email verification at the time of registration | | | pie chart | provincial and country data is displayed in the form of pie charts. | | | map-view | provincial and country data is displayed on the map view. | | | map_animation | it shows how spread over the years | | | self_assessment | users can check if they have covid symptoms | | | newsfeed | users can see the latest news about covid | functional requirements | **requirement id** | **requirement statement** | **comments** | | ------------------ | ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | | performance | when the user logs in how the application executes various tasks and how instantaneously the next page opens(in | | | capacity | capacity is delivering enough functionality required by the end-users. | | | portability | this application runs on android devices. | | | security | only allows the authorized users to get access to the app either admin or user. | | | usability | this app design is simple to understand and easy to use even for the person who does not have good knowledge of phones. | | | efficiency | all the activities work smoothly one after another. | | | consistency | like-items should always be displayed and act the same way across the entire application (and even between applications). | | | scalability | it is a non-functional property of a system that describes the ability to appropriately handle increasing (and decreasing) workloads. can use this application at a time. | case diagrams !use case diagram diagram !class diagram diagram user:- !user admin:- !admin case scenario > register --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | authors | team | | use case name | register | | pre-conditions | the user is not registered and does not have an account. | | post-conditions | the user is redirected to the log in page after registration. | | triggering event | the user has clicked on the sign up button. | | description | new customers can register in the application using sign up page. | | flow of events | users first need to fill the details before login. user must have his full name, password, gender and email.users can easily login after this. | | alternate flow | none | | exceptional flow(s) | exception: only unregistered user emails should be used to register. the system will prompt the message &quot;email has already been registered, enter new email&quot;. the password should be a minimum characters. the system will prompt the message &quot;email and password required&quot; | | actor(s) | primary-non-registered-user | > login --- | **use case id** | | | ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | authors | team | | use case name | login | | pre-conditions | the user is registered and has an account. | | post-conditions | the user is redirected to the home page after logging in | | triggering event | user clicks on the login button. | | description | user need to login to get the features of the application user will provide credentials in order to login screen. | | flow of events | user clicks on the login button user enters the email and the password in the login credentials. user is directed to the homepage specific to the user. | | alternate flow | user clicks on &quot;forget password. user enters the email used for registration. email to change password is sent to the given email address. user changes the password and confirms the changes. user is directed to the login page. user enters the user name and the password in the form. user is directed to the homepage specific to the user | | exceptional flow(s) | users must be registered to login. the password should be a minimum characters. the system will prompt the message &quot;email and password required&quot; | | actor(s) | primary-registered-user | > reset password --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | | authors | team | | use case name | reset password | | pre-conditions | the user is registered and has an account. | | post-conditions | the password of the user will be updated in the database. | | triggering event | the user has clicked on the forgot password button. | | description | user has forgotten the password and wants to reset it, so this feature helps the user to reset the password. | | flow of events | user clicks on the forgot password link.. user enters the email used for registration. user clicks on a forgotten password. users will change passwords using links received by email. user is redirected to the login page. | | alternate flow | none | | exceptional flow(s) | exception: password should be a minimum character. the system will prompt the message &quot;password is too short, it should be at least characters&quot;. the system will prompt the message &quot;email is not registered with application&quot;. | | actor(s) | primary-registered-user | > notification --- | **use case id** | | | ------------------- | ------------------------------------------ | | authors | team | | use case name | notification | | pre-conditions | user must login | | post-conditions | users can view the notifications. | | triggering event | if there is update regarding the instance | | description | users can get notification about covid | | flow of events | user pulls the notification bar. | | alternate flow | none | | exceptional flow(s) | user must be a registered user | | actor(s) | primary-registered-user | > edit profile --- | **use case id** | | | ------------------- | --------------------------------------------------------- | | authors | team | | use case name | edit profile | | pre-conditions | user must have successfully logged in the application. | | post-conditions | user have updated their profiles successfully. | | triggering event | user can successfully edit their detail. | | description | logged in user can update their data and manage profile.. | | flow of events | change name | | | change email | | | change password | | | change country | | | change province | | | mobile number | | | click on update profile button | | alternate flow | none | | exceptional flow(s) | failed authentication not allowed to edit the profile | | actor(s) | primary-registered-user | > covid information --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------------------------ | | authors | team | | use case name | covid information | | pre-conditions | users must have successfully logged in the application. | | post-conditions | users can view the latest information. | | triggering event | users after successfully logging in can view the updated covid information. | | description | users can get information about etc.). | | flow of events | when the user reaches the home screen of the application, the user can get information about | | alternate flow | none | | exceptional flow(s) | failed authentication not allowed to create the profile | | actor(s) | primary-registered-user | > graphical data --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | | authors | team | | use case name | graphical data | | pre-conditions | users must have successfully logged in the application. | | post-conditions | users can view the information about in the form of graphical data representation. | | triggering event | user in the feed section click on the graphical data (like pie chart, animated map and map) to view the covid information | | description | users can view the variety of data regarding spread of in different representations such as pie charts or maps. | | flow of events | latest information according to province and country has been shown to the user in the form of graphical data representation.user clicks on the different pie charts and maps. | | alternate flow | none | | exceptional flow(s) | user must verify to gain access to the application | | actor(s) | primary-registered-user | > self assessment --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | | authors | team | | use case name | self assessment | | pre-conditions | users must have successfully logged in the application. | | post-conditions | users can perform self assessment through the application. | | triggering event | users can go through the questions related to covid and get the results at the end behalf of his/her answers. | | description | by using this, the people can come to conclusion that if they need to take covid test or have any symptoms of coronavirus | | flow of events | users continuously follow the questionnaire which has yes/no questions until they come to the conclusion. | | alternate flow | none | | exceptional flow(s) | user must verify to gain access to the application | | actor(s) | primary-registered-user | > news feed --- | **use case id** | | | ------------------- | ---------------------------------------------------------------------------------- | | authors | team | | use case name | news feed | | pre-conditions | users must have successfully logged in the application. | | post-conditions | user can able to view the latest covid information | | triggering event | user can able to view the news feed | | description | news feed can provide the news of covid cases and centres and updated information. | | flow of events | users can click on the news feed button to get the updated news about | | alternate flow | none | | exceptional flow(s) | user must verify to gain access to the application | | actor(s) | primary-registered-user | > logout --- | **use case id** | | | ------------------- | ------------------------------------------------------------------------------------- | | authors | team | | use case name | logout | | pre-conditions | users must have successfully logged in the application. | | post-conditions | users can able to logout the application. | | triggering event | users can successfully logout the application. | | description | registered users can logout the application after getting the status regarding covid. | | flow of events | users click on the logout button to close the application. | | alternate flow | none | | exceptional flow(s) | user must verify to gain access to the application | | actor(s) | primary-registered-user | > admin login --- | **use case id** | | | ------------------- | ---------------------------------------------------------------------- | | authors | team | | use case name | admin login | | pre-conditions | admin must have credentials assigned. | | post-conditions | admin will successfully access to the application | | triggering event | admin can sign in | | description | admin can push the information to the covid user application. | | flow of events | admin clicks on the sign in button and gets access to the admin panel. | | alternate flow | none | | exceptional flow(s) | admin must verify to gain access to the application | | actor(s) | admin | > admin crud --- | **use case id** | | | ------------------- | --------------------------------------------------------------------------------- | | authors | team | | use case name | admin crud | | pre-conditions | admin must have an email id. | | post-conditions | admin can able to register | | triggering event | admin will successfully access to the application and can perform crud operations | | description | admin can perform the crud operation in the application. | | flow of events | admin can login the application and perform crud operations. | | alternate flow | none | | exceptional flow(s) | admin must verify to gain access to the application | | actor(s) | admin | stories --- | **sr_no** | **as a** | **i want to** | **so that** | | --------- | -------- | --------------------- | ------------------------------------------------------------------------------ | | | user | login | i can get information and keep myself safe in this pandemic. | | | user | reset my password | i can change my password easily in case i forget. | | | user | update profile | i can change my personal information. | | | user | vaccine centers | i can search and get the location of vaccine centers at any place any time. | | | user | get notifications | i can keep myself aware about new updates about | | | user | graphical data | i can get data in the form of graphical representation and animation. | | | user | news feed | i can see all the latest covid related news at one place. | | | user | travel guidelines | i can check the travel guidelines according to my need. | | | user | self assessment | i can check if i have any symptoms of covid by myself. | | | user | quarantine guidelines | i will have an idea how to quarantine and be safe. | | | user | covid centers | i can search and get the location of centers at any place any time. | | | user | logout | i can safely log out and keep my information safe. | | | admin | login | i can gain access to the covid information admin app. | | | admin | crud | i can create, read, update and delete data about | | | admin | logout | i can logout once done using the application. | diagram !admin diagram !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin !admin"
0,NYP-Journey,nyp journey is built using c# asp.net webform + mysql +bootstrap its purpose is to increase the opportunities of interaction between all teachers and students and make in-campus works become much convenient.,"# nyp-journey ## index - about - getting started - build using - features - database model - copyright - author ## about due to consistent increment of polytechnic students, more requirements will be needed by campus community. many individuals are now not fulfilled by the limited knowledge on paper and are struggled in finding a platform to guide them to study further in their interested aspects as well as find someone that can help you. in order to increase the opportunities of interaction between all teachers and students, make it much convenient, a new web-based application need to be developed. therefore, we came up with an web-based platform to solve these inconveniences. nyp journey eases the users within campus by establishing a communication platform for users to investigate their academic concerns and share their learning experience. this idea is derived from question and answers sites like stack overflow and quora which users can ask questions in different aspects and professionals can solve their problems. furthermore, we would like a system that can encourage the users to interact with the platform more actively just like grab. we hope that the platform can combine the advantages of the pure question & answer site and well-known service site to build a unique platform and bring convenient service to the users. > the web app has been deployed on azure: https://eadpproj.azurewebsites.net/ ## getting started these instructions will get you a copy of the project up and running on your local machine for development and testing purposes. #### prerequisites to be able to run the application, **.net framework sdk** is required.(recommended version: .net framework sdk before running this application, please seed the database with following command in package manager console to ensure the running of application ```c# update-database ``` ## build using - c# - language - asp.net webform - framework - .net framework sdk - runtime environment - bootstrap keen theme & material-kit pro - ui framework - mysql ## features nyp journey summary functions and features are user identification system, user profile, wallet, question forum, management tools, notification menu, shop, ranking, invitation system, reporting pages and credit system. - ##### user identification system user register and login the account by key in correct credentials with their corresponding admin number(for student)/nric(for teacher). user can find back their password by receiving systems email. - registration - otp the email will be sent to validate user's email. - form wizard the form will be shown step-by-step to guide the users more friendly. - login by using users' own identity numbers, they will be able to sign in to the system. - forgot password system will send password to users emails if they forget their passwords. - ##### user profile user can customize their own head icon and leave comment under other users profile. the profile contains users posted blogposts and brief data statistics about what have user done in nyp journey. user can also add their favorite blogposts to favorite section. - customization modifications in users' own profile icon and information are available. - comment users can leave comment under other users profile page. - blog user can share their learning experience in blog system. user can tip the author with credit and can add the blogpost to favorite. administrator can highlight the blogpost to make it more obvious on blog list page. - ##### wallet user can check their own transaction history about their credits and shop purchase history which generate as invoice. user can also top up their credit balance using paypal. - paypal if users need credits, they can purchase through paypal api using real-life currency. - transaction history user can view their credit transaction histories in my wallet. - ##### question forum user posts question with a credit reward, after being approved by management system, other users can answer the question and one of them will be picked as the best solution and claim the credit reward. - ask question all users can ask question in the forum, the posting of the question will cost credit as a reward to the best solution made. all user can answer the question and the best solution for the question poster will claimed the reward. user can also leave reply under the answer. - manager review system before the question publishes to the public users, it will be reviewed by administrator, if the question is approved, it can be seen by all users, else, it will be deleted. - ##### management tools in order to manage the massive data more effectively, nyp journey has a system that can only be accessed by admin account. the system can let the admin check the statistics of the website by data visualization. it is also able to edit all users information, posts and check the credit transaction record. - user management admin is authorized to delete or modify any users' information. - question management admin can delete any question in the forum. - blog management admin can highlight the blog if the blog has quality content, the blog that has been highlighted will be more obvious for the viewers in the blog list. - ##### notification menu users check their own action record in nyp journey and can redirect to the corresponding page. - action notify every action user does, including of creation of question in the forum, posting blog and redeeming any book from the shop. - ##### shop users redeem the credit for learning resources and the purchase invoice will be saved inside wallet>invoice. - book shop the books can be redeemed by credit from wallet system. - ##### ranking user can see the overall ranking about users, blogposts and question forum in nyp journey. - ##### invitation system users invite their friends who have not yet get into nyp journey with a invitation code. both the new user who key in the code and the invitation code owner will be rewarded extra credit. - invitation code every user has their own unique invitation code, once the code has been key in by other new user that has not yet applied invitation code. both users will be awarded credit that can redeem books in bookshop. - ##### reporting pages user can feedback in the questionnaire page and can type in if any issue occur in contact page. ## database model !database model ## copyright - ownership of copyright - copyright license - data mining - permissions - enforcement of copyright - infringing material #### ownership of copyright i own the copyright in: this website; and the material on this website (including, without limitation, the text, computer code, images, artworks on this website). #### copyright license we grant to you a worldwide non-exclusive royalty-free revocable license to: view this website and the material on this website on a computer via a web browser; copy and store this website and the material on this website in your web browser cache memory; and print pages from this website for your own [personal and non-commercial] use. we do not grant you any other rights in relation to this website or the material on this website. in other words, all other rights are reserved. for the avoidance of doubt, you must not adapt, edit, change, transform, publish, republish, distribute, redistribute, broadcast, rebroadcast or show or play in public this website or the material on this website (in any form or media) without our prior written permission. #### data mining the automated and/or systematic collection of data from this website is prohibited. #### permissions you may request permission to use copyright materials on this website by writing to #### enforcement of copyright we take the protection of its copyright very seriously. if we discover that you have used our copyright materials in contravention of the license above, we may bring legal proceedings against you seeking monetary damages and an injunction to stop you using those materials. you could also be ordered to pay legal costs. if you become aware of any use of our copyright materials that contravenes or may contravene the license above, please report this by email to #### infringing material if you become aware of any material on the website that you believe infringes your or any other person's copyright, please report this by email to ## author - wang yang"
1,pie-form,developed drag and drop wordpress form plugin,"=== drag & drop builder, human face detector, pre-built templates, spam protection, user email notifications & more! === contributors: genetech, pieforms tags: contact form, form builder, custom form, email form, contact form plugin requires at least: tested up to: requires php: stable tag: license: or later license uri: the intelligent and easy form plugin. drag & drop form builder to help create simple to complex forms for any purpose with just a few clicks. == description == the intelligent and easy form builder plugin **pie forms** are fast, flexible, and responsive. with the most efficient drag and drop form builder and extensivity, it offers you can take your form building experience to the next level. it let us you create multiple interactive types of wordpress forms with no coding knowledge required. shortcodes can embed your forms anywhere on your website without any hassle. pie forms are lightweight fully optimized for page speed to maximize your websites efficiency. they offer conversion optimization features such as the smart form logic that let us you create dynamic forms where fields change based on the users input, multi-page forms with a progress bar, and other advanced forms. == what makes pie forms unique? == *the human face detection feature detects and accepts only a human face and restricts others.* == free features: == * unlimited forms- no restrictions * drag and drop form builder * responsive and beginner-friendly * entry/submission management * rtl support * multi-column layout * html email template * admin/user email notification * multiple email recipients * quick form preview option * google recaptcha and * honeypot * editable successful form submission message * editable email settings and form validation messages * ajax form submission * custom/server-side validation * smart tags * gdpr compliance * auto-filled name and email fields when the user is logged in * import contact form forms * search filter in select field * prebuilt form templates * shortcode support * page builder support (wpbakery page builder, gutenberg block editor, classic editor, elementor, & divi builder) == extensions for free: == * **paypal donation add-on** collect payments for supporting causes with paypal donation add-on == premium features: == * advanced fields * block users * limit form entries by device * limit form entries by numbers * schedule forms * conditional logic * user/admin email notification * form visibility based on roles, logged-in & guest users * redirect option after submission * autofill logged-in users details * file upload * image upload * date and time picker * digital signature * rating field * human face detection (ai) through image field * csv export for form entries * ticket-based support- lifetime == paid extensions: == * **stripe add-on** easily collect payments and donations online with our stripe addon * **authorize.net add-on** take recurring payments and set payment lengths with the authorize.net addon using pie forms. * **paypal payment add-on** collect payments and donations easily for your website with pie forms paypal payment addon. * **activecampaign add-on** automate your email campaigns and build an engaging customer experience with the activecampaing add-on. * **mailchimp add-on** connect your mailchimp account with pie forms and add users to your mailchimp list directly on form submissions. * **broadcast add-on** send emails to an entire list of registered users simultaneously, using pie forms' broadcast add-on. * **drip add-on** design and schedule email campaigns to send automated response to your users with pie forms' drip add-on. * **quiz/survey add-on** easily create questionnaires, surveys, and tests to enhance your data collection process with weighted scores and percentages. * **pabbly connect add-on** automate your work process and save time with pabbly connect by pie forms. * **zapier add-on** automate your work in minutes with pie form's zapier addon * **smart translator add-on** translate user response with google translate or deepl using smart translation add-on. * **multipage add-on** break your form into multiple pages to create clutter-free forms with the multipage add-on * **password protected add-on** create password protected forms there is so much more to explore! == pre-built form templates == pie forms comes with pre-built templates to save time and boost your form-building experience. all the templates available are editable, and you can easily add, remove, or rearrange the fields anywhere on the form as per your requirements. == gdpr compliant forms and data entry management == our forms are fully gdpr compliant. you only need to enable gdpr and add the gdpr compliance field to your form for taking the user consent. all user entries will be stored in the tab entries for quick access and efficient data entry management. == page speed optimized == we know the importance of user experience. therefore, pie forms are highly optimized to load your pages fast, and the page speed is not compromised. == full spam protection == spam can be annoying and very dangerous for your website. pie forms has powerful captcha support: recaptcha and hcaptcha, and honeypot to protect your website data. admin can also limit the number of form entries from a device to avoid spam. you can validate your forms for secure submissions with client-side validation (jquery). to add an extra layer of security, pie forms has server-side validation (php) if the client-side validation is blocked on the users browser. == compatibility with famous wordpress builders == pie forms is compatible with the famous wordpress page builders and can be integrated seamlessly with **wpbakery page builder**, **gutenberg block editor**, **classic editor**, **elementor**, and **divi builder**. select the pie forms module and add forms directly to your page or create new forms right inside its builder. == integrations with third-party applications == * paypal * mailchimp * google translate * deepl * stripe * authorize.net * zapier * pabbly connect * wpbakery page builder * gutenberg block editor * classic editor * elementor * divi builder * activecampaign == translations == want to add a new language to pie forms? great! you can contribute via **translate.wordpress.org** == useful resources == blog: learn more about wordpress through our community blog contact us: have a query? feel free to reach out to us! demo: make yourself familiarized with all our features. get started: extensive documentation to make pie forms a breeze **try it to believe in it!** *unlock more features? upgrade to our pro version* == what is next? == liked pie forms? do check out our other projects. **pie register**: pie register is a **user registration plugin** to help you create custom login and registration forms in minutes, with no coding skills required. you can customize the registration process and build advance registration flows using the various form fields. the plugin comes with some additional security features to keep your website spam-free. **pb addons for wpbakery**: build your website with premium quality web and woocommerce elements for wpbakery page builder. == pie forms is all that you need for your website == with pie forms, everything is easy! we want to ensure that your experience with pie forms is the best. you can help us do that. how? * do not see a feature you need for pie forms? * have any questions for our form builder? * or want to help us with your feedback? let us know if you think we are missing out on some essential features! we are ready to hear and open to all. feel free to contact us us and let us help you! == frequently asked questions == = who should use pie forms? = pie forms is basically for everyone. if you are a blogger, designer, developer, or a small business owner searching for an easy way to connect with your audience, pie forms is meant for you. = do i need to have coding skills to use pie forms? = you can create and manage forms with no coding skills through an intuitive drag and drop form builder. = what type of wordpress forms can i build with pie forms? = with pie forms, you can create multiple types of wordpress forms in no time. some examples of forms are the job application form, feedback survey form, request a call back form, make a suggestion form, product survey form, quote request form, online booking forms, medical appointment form, and a lot more. = do pie forms include spam protection? = pie forms is fully compatible with all versions of google recaptcha: * recaptcha * recaptcha * it has honeypot * hcaptcha = is there any way i can block the unwanted users? = yes, with pie forms, you can block unwanted users and bots to keep your website spam-free. you can block the users by their username, email address, or ip address. = how to add styles to your pie forms? = to make your forms more interactive, you can simply add css class in the particular field or form and add custom css in the stylesheet of your current theme. = how can i accept payments with pie forms? = pie forms allows you to accept payments and donations via paypal by simply adding a payment field to your forms and synchronizing the details of the payment gateway with it. = what are smart tags in pie forms? = a smart tag is a code used to add relevant information to the email settings and transform the static emails by replacing them with dynamic user data. = is image upload and file upload the same? = no, you can upload all types of files through the file upload feature, whereas image upload is specifically for images. == screenshots == form form settings block users html template global settings entries smart translator == changelog == ### * fixed: payment redirection issue in php ### * fixed: payment field issue. * added: enable multiple payment methods on single form. ### * fixed: ui fixes. ### * fixed: some ui fixes. ### * added: authorize.net addon. * added: checkout payment field. ### * added: activecampaign addon. ### * added: quiz/survey addon. * added: stripe addon advance payments ( google pay , apple pay ) . * fixed: stripe addon amount issue. ### * added: action in zapier addon. * fixed: checkbox data in entries table. * added: section title. ### * fixed: form settings icons. * fixed: css for pie forms gutenberg block * fixed: allow to edit fields on form field selection. * fixed: order of fields in add fields settings. ### * added: pabbly connect addon ### * added: zapier addon * added: pie forms module added in beaver builder ### * added: stripe addon * fixed: escaping and sanitization issues. * updated: compatibility wordpress ### * fixed: cross-site scripting attacks. * fixed: escaping and sanitization issues. ### * fixed: show form data in email ### * added: print entries pdf (premium) * added: search in entries * added: show icons in submit and processing button in general setting * fixed: code cleanup * fixed: single and multiple field in export csv (premium) ### * added: show success message in popup in general setting * added: image upload field (premium) * added: human face detection in image upload field (premium) ### * added: custom phone regex in phone field * added: export csv in entries (premium) * fixed: drip reports on entry view (premium) * updated: compatibility wordpress * updated: visual editor added to email and user notifications settings ### * added: server side validation for limit length of text area filed. * fixed: show detected city according to site region in advance settings of address field (premium) * fixed: database errors * fixed: gdpr field to be added once in a form. * fixed: removed fields to be used once in the form from the search filter * fixed: detect country according to site region (premium) * updated: download url option in general settings for redirect to. ### * fixed: form submission time when viewing entries (premium) * fixed: entries not being saved * fixed: form disappears from the list of forms when enabled after disabling * fixed: paypal addon * fixed: license key (all addons) * updated: add license key link removed from plugin action links (all addons) * updated: currency tab added in builder form settings and removed from the global settings menu (paypal addon) * updated: unsubscribe url tag (drip and broadcast addon) * updated: removed data of removed fields from entries' view (premium) ### * added: separate js file for import contact form (premium) * added: user report for broadcast email (broadcast addon) * added: user report for drip campaign (drip addon) * added: file upload classic field * added: paypal addon * added: smart translator addon * fixed: compatibility issues broadcast email / drip campaign with pie forms ### * updated: file upload store in media library added (premium) * updated: file upload modern and classic style's added (premium) * updated: uploaded file links include in email and entries (premium) * updated: set entries time according to server times * fixed: plugin speed optimization ### * added: disabling of html template for email notifications in global settings * added: disable user entry in general form settings * added: option to add header image in email notifications in global settings * added: option to add footer content in email notifications in global settings * added: option to add background color to the email notifications in global settings * added: from name and from address in user email settings * updated: gdpr field always required * updated: user entries enabled by default. admin can disable it from form settings * updated: unique submission and limit form submission settings moved into ""limit and schedule"" in form settings (premium) * fixed: missing smiley icon in rating field (premium) * fixed: missing data in entry view (premium) * fixed: plugin speed optimization ### * added: rating field (premium) * added: add dynamic text section (multipage form addon) * fixed: warning undefined index count ### * added: visible forms dropdown in general settings to show forms based on roles, logged-in and guest users (premium) * added: custom message before the form starting date in limit and schedule (premium) * added: rtl support on form * added: search field in builder form fields > add fields * fixed: plugin speed optimization ### * added: save user entries * added: import form further settings. placeholder, class, cc, bcc, reply to * added: field description position dropdown in form settings > general settings * added: fixed date calender in schedule form ( show / expiry date) (premium) * fixed: import email setting message body * fixed: import user email consistency * fixed: code cleanup * fixed: removed unused libraries and images ### * added: license tab in general settings for activation an addons. * fixed: wordpress compatibility issues. ### * added: import your contact form forms! (pie forms > tools > import) ### * fixed: plugin speed ### * added: pie forms element in wpbakery page builder * fixed: date field empty on backspace and delete key * fixed: show label as placeholder on email template * fixed: detech country issue fix with placeholder on country field (premium) * fixed: search field on country dropdown (premium) * fixed: signature field when hiding label (premium) * fixed: remove gray color on start & end date on form setting tab in limit and schedule section (premium) ### * added: hcaptcha support (premium) * added: limit form submissions from a device (premium) * added: pie forms module added in divi builder * fixed: user_email tag in user email setting ### * added: native integration with elementor: add to the page and create new forms right inside its builder * fixed: scroll issue on setting tab * fixed: link button popup visibility on user email message in user email setting tab * update: email template alignment center to left ### * added: added user email notification settings * added: success message filter after form submission * fixed: scroll to error/success message on form empty submission * fixed: remove extra items on the template file * fixed: visible captcha on the focus of any field * fixed: form field setting radio uncheck on multiple items. * fixed: remove disable attribute on the dropdown field place holder * fixed: separate js / css file according to field visible (code optimization) * fixed: collapse issue on smart tag dropdown * fixed: address field placeholder text * fixed: remove negative values from number filed ### * added: custom validation message in name field * fixed: php compatibility issues ### * fixed: minor bug fixes ### * added: name and email fields auto filled when user is logged in * fixed: several bug fixes ### * fixed: wordpress compatibility issues. ### * added: marketing menu for addons * fixed: several bug fixes. ### * fixed: several bug fixes. ### * added: view entries in dashboard. * added: created grid where all users entries are showing : name, email address, form (filter) , action. * added: gdpr agreement fields enable if admin checked it from global settings. * added: gdpr agreement checkbox in global settings. ### * added: pieforms gutenberg block. * added: filter hook to change form action. * added: filter hook to change footer text of email. * added: filter hook to add classes on form submit button container. * added: search filter in select field. * updated: load google recatpcha assets when form focus so that it will help in increase page speed. * added: show labels as placeholders. * fixed: several bug fixes. ### * added: custom validation * added: server side validation * added: smart tags * added: multiselect field * added: data delete on uninstalling plugin * fixed: pagination on all forms menu * bug fixes ### * added: ajax form submission * added: email settings * fixed: form grid sorting * fixed: word count and character limit of textarea field * bug fixes ### * ui changes * added environment and system information tab in tools menu * bug fixes"
0,IntelliClinic,ai-based healthcare app for improved diagnostics and treatment using advanced ml models,"# intelliclinic <p align=""center""> <img alt=""intelliclinic banner""> </p> intelliclinic is an ai-powered healthcare platform (ahp) is a cutting-edge solution designed to revolutionize the healthcare industry by integrating artificial intelligence into patient care workflows. ahp streamlines patient intake, automates the creation of focused hpis, and provides support for differential diagnosis, significantly enhancing the efficiency of medical documentation and patient management. with its advanced nlp capabilities, the platform translates complex medical notes into actionable data, thereby improving the quality of care and facilitating better health outcomes. emphasizing security and compliance, ahp ensures the protection and confidentiality of sensitive health information throughout the patient care process. # technical software specification document ## table of contents introduction - purpose - scope - definitions, acronyms, and abbreviations - references - overview overall description - product perspective - product functions - user classes and characteristics - operating environment - design and implementation constraints - user documentation - assumptions and dependencies system features - ai-driven dynamic intake - focused hpi generation - nlp for note management external interface requirements - user interfaces - hardware interfaces - software interfaces - communications interfaces system features - security requirements - software quality attributes other nonfunctional requirements - performance requirements - safety requirements - security requirements - software quality attributes - business rules other requirements appendix a: glossary appendix b: analysis models appendix c: to be determined list --- ## introduction ### purpose this document specifies the technical requirements and architectural design for the development of an ai-powered healthcare platform, hereinafter referred to as ""ahp"". ahp is designed to enhance the efficiency and effectiveness of healthcare services through the application of artificial intelligence. ### scope the ahp will be a comprehensive solution capable of optimizing patient intake, generating focused hpi, aiding in differential assessment and planning, and automating patient note creation. ### definitions, acronyms, and abbreviations - **hpi**: history of present illness - **mvp**: minimum viable product - **ehr**: electronic health record - **nlp**: natural language processing - **api**: application programming interface - **ssl**: secure sockets layer ### references - hipaa compliance documentation - fhir (fast healthcare interoperability resources) specification - python documentation ### overview the document details the product functions, user interfaces, system features, and security requirements. ``` ai-healthcare-platform-mvp/ app/ # application code __init__.py # initializes the python app as a module views.py # handles the routing and views for the web application models.py # defines data models for the application forms.py # defines web-forms to interact with user input utils/ # utility scripts and helper functions __init__.py ai_helpers.py # helper functions for ai operations db_helpers.py # helper functions for database interactions templates/ # html templates for the web interface layout.html # base layout for the web pages index.html # main page template report.html # template for displaying the patient report ai/ # ai model code __init__.py intake_model.py # ai model for patient intake note_generation_model.py# ai model for generating patient notes static/ # static files for the web interface css/ # css stylesheets main.css # main stylesheet for the application js/ # javascript files main.js # main javascript file for dynamic behaviors img/ # image files logo.png # logo image tests/ # automated tests __init__.py test_views.py # tests for view functions test_models.py # tests for data models config/ # configuration files __init__.py settings.py # contains settings for the django project scripts/ # deployment and utility scripts init_db.py # script to initialize the database start_server.sh # script to start the web server .gitignore # specifies intentionally untracked files to ignore requirements.txt # lists all python dependencies for the project manage.py # command-line utility for administrative tasks dockerfile # instructions for docker to build the application docker-compose.yml # defines and runs multi-container docker applications readme.md # project overview and instructions ``` - **app/**: this directory contains the core application logic, including view functions, data models, and form definitions. the `templates/` sub-directory contains html templates to render the web pages. - **ai/**: this directory is dedicated to the ai aspects of the project, including the machine learning models that handle patient intake and note generation. - **static/**: contains all the static assets used by the web application like css, javascript, and images. these files contribute to the frontend part of the application. - **tests/**: includes tests for different parts of the application ensuring code reliability and ease of maintenance. - **config/**: holds configuration files for the application, such as django settings. - **scripts/**: contains utility scripts that help in setting up the database or starting the server, which are especially useful for deployment. - **.gitignore**: a git configuration file that tells git which files or directories to ignore in a project. - **requirements.txt**: a plaintext file listing all the dependencies which can be installed using `pip install -r requirements.txt`. - **manage.py**: a command-line utility that let us you interact with this django project in various ways. - **dockerfile** and **docker-compose.yml**: used for containerizing the application and defining multi-container docker applications, respectively. - **readme.md**: the markdown file providing a description of the project, how to set it up, and how to use it. ## overall description ### product perspective ahp will function as a standalone module capable of seamless integration with existing healthcare it ecosystems, enhancing their capabilities through ai-driven solutions. ### product functions - ai-driven patient intake - generation of focused hpi - differential diagnosis support - automated patient note creation - integration with ehr systems ### user classes and characteristics - **physicians**: require efficiency in documentation and patient management. - **patients**: seek medical advice and use ahp for preliminary assessments. - **administrators**: manage ahp operation and oversee system settings. ### operating environment ahp will be a cloud-based saas solution, accessible via web browsers on desktop and mobile devices. ### design and implementation constraints - ahp will be developed using the django web framework. - compliance with hipaa is mandatory. - the initial release will support english language only. ### user documentation - online help within the application. - user manual for end-users and administrators. - api documentation for integrators. ### assumptions and dependencies - access to cloud services provided by aws. - the initial ai model will be trained on a dataset provided by a partnering healthcare institution. ## system features ### ai-driven dynamic intake this feature will include an intelligent questionnaire that adapts to the patient's inputs in real-time. the ai will analyze responses to prioritize follow-up questions, minimize patient fatigue, and maximize the collection of relevant health data. the system will utilize a decision tree algorithm which will be trained on initial datasets to recognize patterns in symptom presentation and medical history. ### focused hpi generation the ai model will process the intake information to produce a concise hpi document. the model will be trained using supervised learning techniques on anonymized patient histories to identify and summarize key health information, which will be crucial for the differential diagnosis phase. ### nlp for note management the nlp module will convert free-text patient notes into structured data. it will employ text analysis to extract and categorize medical entities, such as symptoms, diagnoses, and treatments, facilitating easy search and retrieval. this module will be essential for generating summaries and reports for both healthcare providers and patients. ## external interface requirements ### user interfaces - the system will have a responsive web interface. - dashboards for real-time data presentation. the web interface will be built using a mobile-first design approach ensuring compatibility with a wide range of devices. the user interface will be clean and minimalistic, with an emphasis on usability and accessibility standards. it will include interactive elements such as modals, tooltips, and dropdown menus to provide a dynamic user experience without overwhelming the user with medical jargon. ### hardware interfaces no specific hardware interface is required. ### software interfaces - aws for cloud hosting. - fhir api for ehr integration. - python libraries for nlp. ### communications interfaces - https for secure data transmission. the platform will use restful apis for communication between the frontend and backend services. these apis will be secured using jwt (json web tokens) to ensure that only authenticated and authorized users can access sensitive endpoints. ## system features ### security requirements - oauth for authentication. - ssl encryption for data in transit. ### software quality attributes - reliability: cloud-hosting for high availability. - usability: intuitive interface design. - maintainability: well-documented codebase with unit tests. ## other nonfunctional requirements ### performance requirements - the system will support a minimum of concurrent users. - response times will not exceed seconds for any transaction. the platform will be optimized for quick load times, with an aim for initial contentful paint to occur within second, and interactive readiness within seconds over a standard broadband connection. to achieve this, backend services will be stateless to enable horizontal scaling, and front-end assets will be minimized and served from a content delivery network (cdn). ### safety requirements - error handling mechanisms to prevent system crashes. - data validation to prevent incorrect data entry. the platform will feature robust input validation to prevent common security threats such as sql injection, cross-site scripting (xss), and cross-site request forgery (csrf). it will also implement rate limiting to protect against denial-of-service attacks. ### security requirements - all data will be encrypted at rest using - regular security audits and compliance checks. ### software quality attributes - scalability: designed to easily add more resources. - flexibility: modular design for easy updates and changes. ### business rules - the system will prioritize data privacy in accordance with hipaa. ## other requirements - data backups will be performed daily. - a disaster recovery plan will be established and tested quarterly. ### data retention and archiving data retention policies will comply with medical data retention requirements, which typically dictate that patient records be preserved for a minimum number of years post-treatment. archiving solutions will be implemented to ensure data is securely stored long-term and can be retrieved when necessary. ### legal and regulatory compliance the platform will comply with all relevant healthcare regulations, including but not limited to hipaa in the united states, gdpr in the european union, and pipeda in canada. regular audits will be conducted to ensure ongoing compliance. ## appendix a: glossary refer to definitions, acronyms, and abbreviations. ## appendix b: analysis models - included are er diagrams, uml models, and data flow diagrams for the ahp. this appendix will include uml diagrams to outline the system architecture, er diagrams to map out the database schema, and sequence diagrams to describe the flow of operations within the platform. these models will provide a visual representation of the system's components and their interactions, facilitating a better understanding of the system's functionality. ## appendix c: to be determined list - selection of third-party services for email and sms notifications. - choice of ai model training platforms. - finalize the choice of machine learning and data analytics tools. - determine the third-party service providers for auxiliary functionalities such as two-factor authentication and push notifications."
0,mentalhealth_status_classification,this project focuses on classifying a childs wellbeing status during the pandemic period using a customized survey.. this will allow the government to make informed decisions/new policies that reduce the risk of a child having behavioral or emotional difficulties or both.,"# mental health status classification project ## background --- <img ever since the start of the pandemic back in the government expects more lockdowns through the winter to slow down the spread of the virus. one of the concerns raised by the government is the wellbeing of young primary school children since they are removed from their friends and play environments. for this project, the main goal is to deploy initial classification models that help to monitor a childs wellbeing status during the pandemic period. by identifying factors that influence the status of a childs wellbeing through a customized survey, the government will be able to make more informed decisions/new policies that reduce the risk of a child having behavioral or emotional difficulties or both. dataset is provided in .json format by client under training_batch_files folder for model training. (not included in this repository due to data confidentiality reasons) for model prediction, a web api is used (created using streamlit) for user input. note that results generated from model prediction along with user inputs can be stored in various formats (i.e. in csv file format or another database). ## contents - code and resources used - model training setting - project findings - eda - best classification model and pipeline configuration - summary of model evaluation metrics from best classification model - hyperparameter importances from optuna (final model) - hyperparameter tuning optimization history from optuna - overall confusion matrix and classification report from final model trained - precision recall curve from best classification model - learning curve analysis - feature importance based on shap values for every class - crisp-dm methodology - project architecture summary - project folder structure - mongodb atlas setup - project instructions (local environment) - project instructions (docker) - project instructions (heroku with docker) - initial data cleaning and feature engineering - machine learning pipelines configuration - handling imbalanced data - feature engineering - encoding ""interval"" features - encoding ""binary"" features - encoding ""ordinal"" features with different magnitudes ""for certain"" - encoding features with rare categories - encoding ""nominal"" and ""ordinal"" features with uncertainty in magnitude difference - encoding ""time-related"" features - feature scaling - feature selection - cluster feature representation - legality ## code and resources used --- - **python version** : - **packages** : borutashap, feature-engine, featurewiz, imbalanced-learn, joblib, catboost, lightgbm, matplotlib, pymongo, numpy, optuna, pandas, plotly, scikit-learn, scipy, seaborn, shap, streamlit, tqdm, xgboost, yellowbrick - **dataset source** : from (for confidentiality reasons, dataset is not included here) - **database**: mongodb atlas - **mongodb documentation**: https://www.mongodb.com/docs/ - **optuna documentation** : https://optuna.readthedocs.io/en/stable/ - **feature engine documentation** : https://feature-engine.readthedocs.io/en/latest/ - **imbalanced learn documentation** : https://imbalanced-learn.org/stable/index.html - **scikit learn documentation** : https://scikit-learn.org/stable/modules/classes.html - **shap documentation**: https://shap.readthedocs.io/en/latest/index.html - **xgboost documentation**: https://xgboost.readthedocs.io/en/stable/ - **lightgbm documentation**: https://lightgbm.readthedocs.io/en/latest/index.html - **catboost documentation**: https://catboost.ai/en/docs/ - **numpy documentation**: https://numpy.org/doc/stable/ - **pandas documentation**: https://pandas.pydata.org/docs/ - **plotly documentation**: https://plotly.com/python/ - **matplotlib documentation**: https://matplotlib.org/stable/index.html - **seaborn documentation**: https://seaborn.pydata.org/ - **yellowbrick documentation**: https://www.scikit-yb.org/en/latest/ - **scipy documentation**: https://docs.scipy.org/doc/scipy/ - **streamlit documentation**: https://docs.streamlit.io/ - **blueprint for encoding categorical variables**: ## model training setting --- for this project, nested cross validation with stratification is used for identifying the best model class to use for model deployment. the inner loop of nested cross validation consists of fold cross validation using optuna (tpe multivariate sampler with trials on optimizing average macro score) for hyperparameter tuning on different training and validation sets, while the outer loop of nested cross validation consists of fold cross validation for model evaluation on different test sets. the diagram below shows how nested cross validation works: <img src=""https://mlr.mlr-org.com/articles/pdf/img/nested_resampling.png"" given the dataset for this project is small (less than samples), nested cross validation is the most suitable cross validation method to use for model algorithm selection to provide a more realistic generalization error of machine learning models. the following list of classification models are tested in this project: - logistic regression - linear svc - k neighbors classifier - gaussian naive bayes - decision tree classifier - random forest classifier - extra trees classifier - ada boost classifier - gradient boosting classifier - xgboost classifier - lightgbm classifier - catboost classifier for model evaluation on multiclass classification, the following metrics are used in this project: - balanced accuracy - precision (macro) - recall (macro) - score (macro) - (main metric for optuna hyperparameter tuning) - matthew's correlation coefficient ## project findings --- #### eda (exploratory data analysis) all plots generated from this section can be found in intermediate_train_results/eda folder. ##### i. basic metadata of dataset on initial inspection, the current dataset used in this project has a total of features. both ""_id"" and features represent unique identifier of a given record and the remaining features have mix of ""float"", ""int"" and ""object"" data types. upon closer inspection on data dictionary, there are several date-time related features where further information can be extracted and remaining features are considered as categorical variables. ##### ii. target variable distribution given that there is no target variable, this project requires creating target variable manually (wellbeing_category_wms - mainly based on variables related to me and my feelings questionnaire. more details can be found in the coding file labeled ""train preprocessing.py"") !target_class_distribution from the diagram above, there is a very clear indication of target imbalance between all classes for multiclass classification. this indicates that target imbalancing needs to be addressed during model training. ##### iii. missing values !proportion of null values from the diagram above, most features with missing values identified have missing proportions approximately less than except for ""method_of_keepintouch"" feature with approximately containing missing values. ##### iv. categorical features the following sets of plots are created for every feature of the dataset that contains less than unique values: count plot (number of unique values per category) count plot (number of unique values per category by target class) bar plot (number of missing values by target class) - for features with missing values for features with more than unique values, a csv file is generated which represents the distribution of categories. in addition, it was observed that features like ""breakfast_ytd"", 'method_of_keepintouch' and 'type_of_play_places' can contain multiple values (seperated by "";"" symbol). those features are split into its individual categories first before generating a csv file for representing distribution of categories. the set of figures below shows an example of the following plots mentioned above for method_of_keepintouch feature: <p float=""left""> <img <img <img </p> --- #### best classification model and pipeline configuration the following information below summarizes the configuration of the best model identified in this project: - <b>best model class identified</b>: linear support vector classifier - <b>method of handling imbalanced data</b>: none - <b>contrast encoding method for ordinal data</b>: sum encoder - <b>method of feature scaling</b>: minmaxscaler - <b>feature selection method</b>: featurewiz - <b>number of features selected</b>: - <b>list of features selected</b>: 'method_of_keepintouch_i live near them so i can see them (at a social distance);by phone (texting, calling or video calling);on social media;on games consoles', 'method_of_keepintouch_i live near them so i can see them (at a social distance);by phone (texting, calling or video calling)', 'method_of_keepintouch_by phone (texting, calling or video calling);on social media', 'method_of_keepintouch_by phone (texting, calling or video calling);on social media;on games consoles', 'method_of_keepintouch_by phone (texting, calling or video calling)', 'garden', 'play_near_water', 'play_in_grass_area', 'play_in_house','hours_slept', 'contact_by_visit', 'contact_by_phone', 'snacks_brk', 'yogurt_brk', 'healthy_cereal_brk', 'easywalk_topark', 'read_info_sheet', 'school_health_records', 'gender_girl', 'life_scale', 'school_scale', 'going_school_no, i am at home', 'friends_scale', 'safety_toplay_scale', 'type_of_play_places_in my house;in my garden', 'breakfast_ytd_sugary cereal e.g. cocopops, frosties, sugar puffs, chocolate cereals', 'homespace_relax_sometimes but not all the time', 'study_year', 'sleeptime_ytd_sin', 'sleeptime_ytd_hour_cos', 'birth_date_day_of_year_sin', 'birth_date_day_of_year_cos', 'birth_date_quarter_sin', 'birth_date_quarter_cos', 'awaketime_today_hour_cos', 'awaketime_today_hour_sin', 'timestamp_day_of_week_sin', 'timestamp_month_cos', 'timestamp_month_sin'] - <b>clustering as additional feature</b>: yes - <b>best model hyperparameters</b>: {'c': 'class_weight': 'balanced', 'dual': false, 'fit_intercept': true, 'intercept_scaling': 'loss': 'squared_hinge', 'max_iter': 'multi_class': 'ovr', 'penalty': 'random_state': 'tol': note that the results above may differ by changing search space of hyperparameter tuning or increasing number of trials used in hyperparameter tuning or changing number of folds within nested cross validation. for every type of classification model tested in this project, a folder is created for every model class within intermediate_train_results folder with the following artifacts: - confusion matrix from fold cross validation (.png format) - classification report from fold cross validation (.png format) - hp_importances for every fold (.png format - in total) - hyperparameter tuning results for every fold (.csv format - in total) - optimization history plot for every fold (.png format - in total) - optuna study object for every fold (.pkl format - in total) - precision-recall curve (.png format) in addition, the following artifacts are also created for the best model class identified after final hyperparameter tuning on the entire dataset: - confusion matrix (.png format) - classification report (.png format) - hp_importances (.png format) - hyperparameter tuning results (.csv format) - optimization history plot (.png format) - optuna study object (.pkl format) - learning curve plot (.png format) - shap plots for feature importance from every class (.png format - in total) - precision recall curve (.png format) <b>warning: the following artifacts mentioned above for the best model class identified will not be generated for certain model classes under the following scenarios: - shap plots for kneighborsclassifier and gaussiannb: for generating shap values for these model classes, kernel explainer from shap module can be used but with large computational time. - shap plots for xgbclassifier with dart booster: tree explainer from shap module currently does not support xgbclassifier with dart booster.</b> --- #### summary of model evaluation metrics from best classification model the following information below summarizes the evaluation metrics *(average (standard deviation)) from the best model identified in this project along with the confusion matrix from nested cross validation outer fold with inner fold): <p float=""left""> <img <img </p> - <b>balanced accuracy (training set - fold)</b>: - <b>balanced accuracy (validation set - fold)</b>: - <b>balanced accuracy (test set - fold)</b>: - <b>precision (training set - fold)</b>: - <b>precision (validation set - fold)</b>: - <b>precision (test set - fold)</b>: - <b>recall (training set - fold)</b>: - <b>recall (validation set - fold)</b>: - <b>recall (test set - fold)</b>: - score (training set - fold)</b>: - score (validation set - fold)</b>: - score (test set - fold)</b>: - <b>matthews correlation coefficient (training set - fold)</b>: - <b>matthews correlation coefficient (validation set - fold)</b>: - <b>matthews correlation coefficient (test set - fold)</b>: note that the results above may differ by changing search space of hyperparameter tuning or increasing number of trials used in hyperparameter tuning or changing number of folds within nested cross validation --- #### hyperparameter importances from optuna (final model) !hp_importances_linearsvc_fold_overall from the image above, determining the contrast method for encoding ordinal data and method for handling imbalanced data as part of preprocessing pipeline for linear svc model provides the highest influence followed by selecting hyperparameter value of ""c"", ""class_weight"" and feature selection method. setting hyperparameter value of penalty and use of clustering as additional feature for linear svc model provides little to zero influence on results of hyperparameter tuning. this may suggest that both penalty hyperparameters of linear svc model and use of clustering as additional feature can be excluded from hyperparameter tuning in the future during model retraining to reduce complexity of hyperparameter tuning process. --- #### hyperparameter tuning optimization history from optuna !optimization_history_linearsvc_fold_overall from the image above, the best objective value (average of macro scores from fold cross validation) is identified after trials. --- #### overall confusion matrix and classification report from final model trained <p float=""left""> <img <img </p> from the image above, the classification model performs better for cases where a child's wellbeing is either normal or emotional and behaviour significant with more samples being classified correctly. given that the model evaluation criteria emphasize the costly impact of having both false positives and false negatives equally for all classes, the current classification model is optimized to improve macro score. --- #### precision recall curve from best classification model !precisionrecall_curve_linearsvc_cv from the diagram above, precision-recall curve from best model class identified shows that the model performs best on identify wellbeing status of children that are normal followed by emotional_significant behaviour_significant and emotional_and_behaviour_significant --- #### learning curve analysis !learningcurve_linearsvc from the diagram above, the gap between train and test macro scores (from cross validation) gradually decreases as number of training sample size increases. however, the gap between both scores remain large, which indicates that adding more training data may help to improve generalization of model. --- #### feature importance based on shap values for every class <b> emotional and behaviour significant class</b> <p float=""left""> <img <img </p> from both diagrams above, gender of child is the most influential variable from the top variables identified from feature selection using featurewiz for predicting whether a child's wellbeing is both emotional and behaviour significant. shap's summary plot provides indication of how values of different features may impact the result of model prediction. for example, gender of child not being identified as female have higher probability of being emotional and behaviour significant, while a child who is very unhappy with school or life (lower value of scale close to has higher probabiliy of being identified as emotional and behaviour significant. the following plots below represents feature importance based on shap values for other classes for reference: <b> emotional significant class</b> <p float=""left""> <img <img </p> <b> behaviour significant class</b> <p float=""left""> <img <img </p> <b> normal class</b> <p float=""left""> <img <img </p> ## crisp-dm methodology --- for any given machine learning projects, crisp-dm (cross industry standard practice for data mining) methodology is the most commonly adapted methodology used. the following diagram below represents a simple summary of the crisp-dm methodology for this project: <img note that an alternative version of this methodology, known as crisp-ml(q) (cross industry standard practice for machine learning and quality assurance) can also be used in this project. however, the model monitoring aspect is not used in this project, which can be considered for future use. ## project architecture summary --- the following diagram below summarizes the structure for this project: !image note that all steps mentioned above have been logged accordingly for future reference and easy maintenance, which are stored in <b>training_logs</b> folder. ## project folder structure --- the following points below summarizes the use of every file/folder available for this project: application_logger: helper module for logging model training and prediction process intermediate_train_results: stores results from eda, data preprocessing and model training process model_training_modules: helper modules for model training saved_models: stores best models identified from model training process for model prediction training_batch_files: stores csv batch files to be used for model training training_data_fromdb: stores compiled data from mongodb database for model training training_logs: stores logging information from model training for future debugging and maintenance dockerfile: additional file for docker project deployment readme.md: details summary of project for presentation requirements.txt: list of python packages to install for project deployment setup.py : script for installing relevant python packages for project deployment docker_env: folder that contains files that are required for model deployment without logging files or results. borutashap.py: modified python script with some changes to coding for performing feature selection based on shap values on test set _tree.py: modified python script to include adaboost classifier as part of the set of models that support shap library. pipeline_api.py: main python file for running training pipeline process and performing model prediction. ## mongodb atlas setup --- !image for this project, data provided by the client in json format will be stored in mongodb atlas, which is a cloud database platform specially for mongodb. the following steps below shows the setup of mongodb atlas: register for a new mongodb atlas account for free using the following link: https://www.mongodb.com/cloud/atlas/register after login, create a new database cluster (shared option) and select the cloud provider and region of your choice: <img src = go to database access tab under security section and add a new database user as follows: <img src = - keep a record of username and password created for future use. go to database tab under deployment section and click on connect button: !image select ""connect your application"" option: <img src = <b>important: make a note of the connection string and replace username and password by its values from step !image - note that this connection string is required for connecting our api with mongodb atlas. the following sections below explains the three main approaches that can be used for deployment in this project after setting up mongodb atlas: <b>docker</b> <b>cloud platform (heroku with docker)</b> <b>local environment</b> ## project instructions (docker) --- <img deploying this project on docker allows for portability between different environments and running instances without relying on host operating system. <b>note that docker image is created under windows operating system for this project, therefore these instructions will only work on other windows instances.</b> <b> for deploying this project onto docker, the following additional files are essential</b>: - dockerfile - requirements.txt - setup.py docker desktop needs to be installed into your local system (https://www.docker.com/products/docker-desktop/), before proceeding with the following steps: download and extract the zip file from this github repository into your local machine system. <img copy docker_env folder into a separate directory, before proceeding with subsequent steps which will use docker_env folder as root directory. on line inside dockerfile, set the environment variable mongo_db_url as the connection string defined in the last step of mongodb atlas setup section. !image build a new docker image on the project directory with the following command: ``` docker build -t api-name . ``` run the docker image on the project directory with the following command: ``` docker run -e -p api-name ``` a new browser will open after successfully running the streamlit app with the following interface: <img src = browser for the application can be opened from docker desktop by clicking on the specific button shown below: !image from the image above, click on training data validation first for initializing data ingestion into mongodb atlas, followed by subsequent steps from top to bottom in order to avoid potential errors with the model training/model prediction process. the image below shows an example of notification after the process is completed for training data validation process: <img src = after running all steps of the training pipeline, run the following command to extract files from a specific directory within the docker container to host machine for viewing: ``` docker cp <container-id>:<source-dir> <destination-dir> ``` after performing model training, clicking on the model prediction section expands the following section that allows user input for model prediction: <img src = the image below shows an example of output from model prediction after successfully completed all of the above steps: <img src = ## project instructions (heroku with docker) --- <img src = a suitable alternative for deploying this project is to use docker images with cloud platforms like heroku. <b> for deploying models onto heroku platform, the following additional files are essential</b>: - dockerfile - requirements.txt - setup.py <b>note that deploying this project onto other cloud platforms like gcp, aws or azure may have different additionnal files required.</b> for replicating the steps required for running this project on your own heroku account, the following steps are required: clone this github repository into your local machine system or your own github account if available. <img copy docker_env folder into a separate directory, before proceeding with subsequent steps which will use docker_env folder as root directory. go to your own heroku account and create a new app with your own customized name. <img on line inside dockerfile, set the environment variable mongo_db_url as the connection string defined in the last step of mongodb atlas setup section. !image from a new command prompt window, login to heroku account and container registry by running the following commands: ``` heroku login heroku container:login ``` note that docker needs to be installed on your local system before login to heroku's container registry. using the dockerfile, push the docker image onto heroku's container registry using the following command: ``` heroku container:push web -a app-name ``` release the newly pushed docker images to deploy app using the following command: ``` heroku container:release web -a app-name ``` after successfully deploying docker image onto heroku, open the app from the heroku platform and you will see the following interface designed using streamlit: <img src = from the image above, click on training data validation first for initializing data ingestion into mongodb atlas, followed by subsequent steps from top to bottom in order to avoid potential errors with the model training/model prediction process. the image below shows an example of notification after the process is completed for training data validation process: <img src = after performing model training, clicking on the model prediction section expands the following section that allows user input for model prediction: <img src = the image below shows an example of output from model prediction after successfully completed all of the above steps: <img src = <b>important note</b>: - using ""free"" dynos on heroku app only allows the app to run for a maximum of minutes. since the model training and prediction process takes a long time, consider changing the dynos type to ""hobby"" for unlimited time, which cost about per month per dyno. you may also consider changing the dynos type to standard for enhanced app performance. - unlike stand-alone docker containers, heroku uses an ephemeral hard drive, meaning that files stored locally from running apps on heroku will not persist when apps are restarted (once every hours). any files stored on disk will not be visible from one-off dynos such as a heroku run bash instance or a scheduler task because these commands use new dynos. best practice for having persistent object storage is to leverage a cloud file storage service such as amazons (not part of project scope but can be considered) ## project instructions (local environment) --- if you prefer to deploy this project on your local machine system, the steps for deploying this project has been simplified down to the following: download and extract the zip file from this github repository into your local machine system. <img copy docker_env folder into a separate directory, before proceeding with subsequent steps which will use docker_env folder as root directory. add environment variable ""mongo_db_url"" with connection string defined from last step of mongodb atlas setup section as value on your local system. the following link provides an excellent guide for setting up environment variables on your local system: https://chlee.co/how-to-setup-environment-variables-for-windows-mac-and-linux/ open anaconda prompt and create a new environment with the following syntax: ``` conda create -n myenv ``` - note that you will need to install anaconda if not available in your local system: https://www.anaconda.com/ after creating a new anaconda environment, activate the environment using the following command: ``` conda activate myenv ``` go to the local directory in command prompt where docker_env folder is located and run the following command to install all the python libraries : ``` pip install -r requirements.txt ``` overwrite both borutashap.py and _tree.py scripts in relevant directories (<b>env/env-name/lib/site-packages and env/env-name/lib/site-packages/shap/explainers</b>) where the original files are located. after installing all the required python libraries, run the following command on your project directory: ``` streamlit run pipeline_api.py ``` a new browser will open after successfully running the streamlit app with the following interface: <img src = from the image above, click on training data validation first for initializing data ingestion into mongodb atlas, followed by subsequent steps from top to bottom in order to avoid potential errors with the model training/model prediction process. the image below shows an example of notification after the process is completed for training data validation process: <img src = after performing model training, clicking on the model prediction section expands the following section that allows user input for model prediction: <img src = the image below shows an example of output from model prediction after successfully completed all of the above steps: <img src = ## initial data cleaning and feature engineering --- after performing exploratory data analysis, the following steps are performed initially on the entire dataset before performing further data preprocessing and model training: i) filter data where respondent provides permission to use questionnaire (use_questionnaire feature) ii) derive target variable based on features related to me and my feelings questionnaire. iii) reformat time related features (i.e timestamp, birthdate, sleeptime_ytd and awaketime_today) to appropriate form iv) removing list of irrelevant colummns identified from dataset (i.e. unique identifier features, features related to target variable to prevent target leakage and lsoa related features that have direct one to one relationship with wimd related features) v) checking for duplicated rows and remove if exist vi) split dataset into features and target labels. vii) perform missing imputation on categorical variables based on highest frequency for every category. viii) save reduced set of features and target values into different csv files (x.csv and y.csv) for further data preprocessing with pipelines to reduce data leakage. for more details of which features have been initially removed from the dataset, refer to the following csv file: <b>columns_drop_from_original.csv</b> in addition, the following pickle files (with self-explanatory names) have been created inside intermediate_train_results folder during this stage which may be used later on during data preprocessing on test data: - <b>categoryimputer.pkl</b> ## machine learning pipelines configuration --- while data preprocessing steps can be done on the entire dataset before model training, it is highly recommended to perform all data preprocessing steps within cross validation using pipelines to reduce the risk of data leakage, where information from training data is leaked to validation/test data. the sections below summarizes the details of machine learning pipelines with various variations in steps: #### i. handling imbalanced data while most machine learning models have hyperparameters that allow adjustment of <b>class weights</b> for classification, an alternative solution to handle imbalanced data is to use oversampling method. for this project, the following methods of handling imbalanced data are tested: - smoten: synthetic minority over-sampling technique for nominal data. - no oversampling or undersampling required note that this dataset do not contain continuous variables, thus the only suitable methods available for handling imbalanced data is either using smoten for oversampling or using class weights hyperparameter. #### ii. feature engineering the following features are derived after handling imbalanced data if relevant: - age (difference between timestamp and birth_date) - hours slept (difference between awaketime_today and sleeptime_ytd) - datetime features (i.e. year, month, quarter, week, day_of_week, day_of_month, day_of_year, hour and minute) from timestamp, birth_date, awaketime_today and sleeptime_ytd (using datetimefeatures function from feature-engine library) - number of methods of keep in touch (based on method_of_keepintouch feature) - number of types of play places (based on type_of_play_places feature) - number of breakfast food yesterday (based on breakfast_ytd feature) #### iii. encoding ""interval"" features features that are identifed as interval data types have equal magnitudes between different values. these features can be encoded directly using custom <b>label encoding (from - study_year - safety_toplay_scale - health_scale - school_scale - family_scale - friends_scale - looks_scale - life_scale - - - - #### iv. encoding ""binary"" features features that are identified as binary data types only require simple encoding vs - read_info_sheet - school_health_records - other_children_inhouse - easywalk_topark - easywalk_somewhere - garden - keep_in_touch_family_outside_household - keep_in_touch_friends - sleeptime_ytd_minute - awaketime_today_minute in addition, these following features contain multiple values which can also be split into individual values in binary form: - method_of_keepintouch (contact_by_phone, contact_by_visit, contact_by_social_media, contact_by_game) - type_of_play_places (play_in_house, play_in_garden, play_in_grass_area, play_in_bushes, play_in_woods, play_in_field, play_in_street, play_in_playground, play_in_bike_or_park, play_near_water) * only top categories are used - breakfast_ytd (bread_brk, sugary_cereal_brk, healthy_cereal_brk, fruits_brk, yogurt_brk, nothing_brk, cooked_breakfast_brk, snacks_brk) * only top categories are used #### v. encoding ""ordinal"" features with different magnitudes ""for certain"" for features that are identified as ordinal data types with high certainty of categories having different magnitudes can be encoded using one of the following contrast methods: - backward difference encoder - polynomial encoder - sum encoder - helmert encoder these following features will be encoded using contrast methods, since these features clearly show different magnitudes: - fruitveg_ytd - number_people_household - sports_in_week - internet_in_week - tired_in_week - concentrate_in_week - softdrink_in_week - sugarsnack_in_week - takeawayfood_in_week #### vi. encoding features with rare categories for features that contain many unique categories, these features may have categories that are considered to be ""rare"" due to low frequency. to reduce the cardinality of these features, <b>rarelabelencoder</b> from feature-engine library is used. #### vii. encoding ""nominal"" and ""ordinal"" features with uncertainty in magnitude difference the following list of features are ordinal that may or may not have different magnitudes between values: - doingwell_schoolwork - lots_of_choices_important - lots_of_things_good_at - feel_partof_community - outdoorplay_freq - enoughtime_toplay - play_inall_places <b>note that the features listed above are encoded using label encoding (from in order of importance) as intermediate step before further data encoding.</b> the following list of features are identified as nominal: - gender - going_school - homespace_relax - method_of_keepintouch - breakfast_ytd - type_of_play_places <b>for all the features mentioned in this section, features are encoded using either one hot encoding (for non-tree based models) or catboost encoding (for tree-based models).</b> #### viii. encoding ""time-related"" features all time-related features that are derived from timestamp, birth_date, sleeptime_ytd and awaketime_today are encoded using either cyclicalfeatures (for non-tree based models) function from feature-engine library or catboost encoding (for tree-based models). note that while one hot encoding is the most popular approach for categorical data encoding, time-related features are usually cyclical in nature such that performing one hot encoding on time related features does not capture the cyclical component. #### x. feature scaling feature scaling is only essential in some machine learning models like logistic regression, linear svc and knn for faster convergence and to prevent misinterpretation of one feature significantly more important than other features. for this project, minmax scaler is used since this dataset only contains categorical variables. #### xi. feature selection given the current dataset has very large number of features, performing feature selection is essential for simplifying the machine learning model, reducing model training time and to reduce risk of model overfitting. for this project, the following methods of feature selection are tested: - mutual information - anova - feature importance using extra trees classifier - logistic regression with lasso penalty - borutashap (default base learner: random forest classifier) - featurewiz (sulov (searching for uncorrelated list of variables) + recursive feature elimination with xgboost classifier) #### xii. cluster feature representation after selecting the best features from feature selection, an additional step that can be tested involves representing distance between various points and identified cluster point as a feature (cluster_distance) for model training. from the following research paper written by maciej piernik and tadeusz morzy in both authors concluded the following points that will be applied to this project: - adding cluster-generated features may improve quality of classification models (linear classifiers like logistic regression and linear svc), with extra caution required for non-linear classifiers like k neighbors classifier and random forest approaches. - encoding clusters as features based on distances between points and cluster representatives with feature scaling is significantly better than solely relying on cluster membership with one hot encoding. - adding generated cluster features to existing ones is safer option than replacing them altogether, which may yield model improvements without degrading model quality - no single clustering approach (k-means vs hierarchical vs dbscan vs affinity propagation) provide significantly better results in model performance. thus, affinity propagation method is used for this project, which automatically determines the number of clusters to use. however, ""damping"" parameter requires hyperparameter tuning for using affinity propagation method. ## legality --- this is an internship project made with for non-commercial uses only. this project will not be used to generate any promotional or monetary value for me, the creator, or the user."
0,BLOSSOM-ADDON,let us fight against digital pollution it is an free extension that will track your browsing habits and data consumption.,"# blossom-addon let us fight against digital pollution it is an free extension that will track your browsing habits and data consumption. ---------------------------------------------------------------------------------------------------------------------------- !alt text blossom addon is our solution to digital pollution. it is an free extension that will track your browsing habits and data consumption. our goal is to aware people on their ecological impact. while supporting you in a more responsible use of the internet. !alt text # download https://addons.mozilla.org/firefox/addon/blossom-addon/ # presentation ## introduction digital devices create more pollution than we imagine: in fact, during all its lifespan digital objects pollute, and these devices create times more than the whole of france. first because they require rare metals to be manufactured. then between elevated levels of electricity consumption caused by datacentres and users' homes but also by growing internet traffic. and finally digital objects are hard to recycle and most of the time they end up polluting less developed countries. so now you understand that nothing is genuinely immaterial, and internet traffic is in constant growth, that is unless we restrict it. hence, we took it upon ourselves to develop a tool to limit users data usage. on this graph, we can observe a dramatically increase of the data traffic since as mentioned above, we chose as a group to develop an internet extension to educate and limit our data traffic. we named it blossom addon, after the tree that characterises it. how does it work? you are wondering. to give a short answer, it measures the data flow generated by loaded web pages and gives a conversion into rejected we will delve into more detail shortly. as a bonus, it is personalised to each user, and as a result it accompanies you on your journey to being eco responsible and conscious on the web. !alt text ## a brief review of what we know now nowadays, the consequences of digital pollution are increasingly significant. because of this, some solutions exist to limit its impact. first, from a users point of view, we must buy sensibly and moderately. besides, second-hand resale is becoming increasingly popular. also, some companies recycle electronic items, enabling a decrease in pollution, which often accumulates in natural places. in addition, while using our electronics items such as laptops or phones, we can significantly reduce our energetic consumption daily through simple actions. it is a common misconception that using phones or laptops rather than paper means that we are not polluting. nevertheless, the electronic industry needs a vast number of servers to stock all our data that consume tremendous amounts of power to cool theses centres down. unfortunately, all these solutions are limited one way or another. we cannot force people to cut back on their habits neither in personal nor professional settings. in this modern era, people are accustomed to high quality data, and it is exceedingly difficult to return to a more restricted or measured consumption. additionally, despite the huge amount of time spent on the internet by the general population, people are uninformed of their actions, especially of the effects of said actions. finally, it is important to warn people of this problem. we think that many people could adopt better practices if they knew how to. our principal aim while developing blossom addon was to cut data consumption in a more user-friendly way. we had two main objectives: make it easier for users to curb their data consumption inspired us is the site/app cleanfox. we all receive unwanted spam in our inboxes. what this app does is allow you to delete unwanted emails and cancel subscriptions to newsletters that easily invade our mailboxes, thus cutting emissions caused by sending these emails. the second one is to educate users about good habits to take we had to find a way to motivate people to act better, and we found that applications that allow you to focus on your current task like focus-to-do or focus plant were the best instigators. in our case, every week if the user does not exceed a certain amount of data traffic, he will earn points and his tree will grow. ## technical details a - first use quiz and option page when our users first open the app, they will be greeted with an entry quiz to find out their preferences. we have not added this feature to the extension yet, by lack of time. therefore, we have only coded an options page, which will resemble it a lot. this page is made up of checkboxes to change the choices made at the beginning. this customisation allows you to choose between different parameters, such as the number of limitations the app will impose on you: you can ask it to reduce streaming quality, to receive notifications the page is up and running, and the options can be saved, but for now they do not do anything functional. b-javascript programming to obtain the amount of loaded data in the background, a lot is happening within this app. we created a database with javascript to save the amount of data consumed by communicating with the site visited; when a page is loaded, it is sent as a package or a whole; and by reading the size of this package we could determine the amount of data received. this does not create lot of data because it is saved within the users pc, and not in cloud. as a matter of fact, the data counter resets itself every sunday, to make the weekly report easier to code. most of the functions of our programs have been created from scratch, such as the getweek() function, which allows us to retrieve the number of the current week to associate it with the user's data consumption. to display our graphs, the use of asynchronous functions was also necessary to optimize the response time and reduce the waiting time. for example, when we load the weekly report, the advice section is displayed first because its faster to load, then the graphs when all the calculations are done. c- creation of a database to categorise sites a second database was needed to categorise the different websites for the weekly report. to do this, we created a short questionnaire that we all shared on our social media accounts. it included questions such as what sites do you use the most?, what email services do you use?, to help us build a database full of websites that the public uses but that we did not necessarily think of. in total, we got just under responses, that helped us categorise around websites. to resume, two databases were coded, a first for storing what is happening on the extension and a second including all the sites that we have listed associated with the category to which they belong. d- system for evaluating data consumption to define what tree corresponds with which score, a rating system was needed. we did some research about average consumption per hour by category and average time spent by the population in these categories. this helped us to determine the users virtuosity limit in each category (mails, streaming, searches, social medias, downloads, and others). in the case of emails, we considered that we send emails per day on average, and we had to consider the fact that an email will generate more data traffic than the weight displayed. thus, it gives us an average of kb per email, but we also needed to take into consideration the email page loading data consumption. to calculate that we used our own extension, by scrolled and checked our mail box during minutes, to have a data consumption by minutes and we added it. at the end, the virtuosity limit per week in the email category is around mb. the scoring system is based on a score out of and the user starts with points. if the user exceeds the defined consumption limit, he will lose one point for every over the limit of the category. for example, in the email category the limit of virtuosity is around mb, and of that is mb, and if the users go passed the limit, every he lose one point. in addition, the calculation of points is updated each gliding week, which means it considers the previous days, and not monday to sunday like a conventional week. ex: if it is wednesday, we will consider the points accumulated since last wednesday. also, the first week of usage will be an observational phase for our extension, as our extension does not have enough days to calculate and attribute a tree. in the future, we would like to attribute badges to users. the purpose is to reward people who already have the maximal score to continue their efforts and to encourage people who have a very bad score. an example of badge is you reduced your consumption since two consecutive weeks. e - evolution of the tree to encourage users to improve their habits on the internet, and as a reward system, we attributed a different state to the tree, according to his or her ecoscore. as the points system is out of we decided to give the tree different appearances, from almost dying to a blooming tree. so, if our user has a score of say then they will be shown this tree (show on the board), the one corresponding to a score between and and so forth. f - weekly report as we explained to you, every user will have a weekly report, and now i am going to give you more technical details about it. to make this we used html to display everything at its own place on the page. then obviously we knew we needed graphs to have an understandable visual for the user. for that we used morris.js, which is a library, in other words, it gives us the structure already coded, so we just needed to understand how to use it and implement our data. of course, we also created a function to convert bytes into this conversion was made thanks to the model created by the shift project, which works towards creating an economy free of carbon emissions. these calculations take into consideration the energy consumption made by servers and networks, and how many grams of are emitted per country to create this energy. finally, to make it more recognizable, the page required personalization, we did it thanks to a css page that allowed us to define the background, the font, and the font colour. ## conclusion overall, we reached the main objectives that we set ourselves during these last few months. nevertheless, we would like to continue to work on this project during our free time to enhance the add-on. first, we intend to adapt the score mode thanks to the recommendations of our beta-testers. we also want to add an entry quiz to personalize the users experience. another idea is to propose one article per week about digital pollution, that enables to inform the users more about this type of pollution. finally, after some weeks of usage by different users, we will have some unknown websites in the other category, and we will add these into the adequate category and certainly add extra categories. to conclude, digital pollution should be more communicated to people because as traffic data keep increasing, pollution does too. to fight this, the first step is to inform populations, everybody must be aware of how much pollution is created through the digital industry. thanks to blossom addon, people will be aware of their own consumption every day and every week. in addition to that they will be able to reduce it thank to our advice and our motivational tree. blossom addon is now available on the firfox addon store thus help up to save the planet and download our extension! !alt text"
0,CoronaTracker,an android app for tracking the cases all over the world and self-assessing one's status,"# tracker the link for the project video ## abstract we all know that the world is dealing with an unprecedented challenge of the coronavirus which has infected millions across the globe. the virus very contagious and has spread to almost all the countries except a few. in these tough times we ought to know the situation around us and in order to stay safe. this was the primary idea behind development of the covid tracker app which provides information on our android device. the app provides a platform to the user where he can track the total number of cases all over the world. this app provides the details like total cases, recovered cases, demised cases, active and critical cases which is enough to know that whether travelling is safe or not. the app also includes a search bar for the users to navigate through the list of countries affected by the covid and look at the statistics of a particular country. it also has an additional feature which allows you to report your symptoms which might enable the authorities to take an early and informed decision. it also let us users assess and report his symptoms or any travel history which is stored on the cloud and help in identifying hotspot and cluster zones. the app we have developed makes use of cloud firestore, rest api and volley library to achieve its purpose. ## motivation with humanitys on-going fight with the pandemic of disease, we have developed a tracker app. although some of the medical institutions have made progress regarding the vaccine development, there is no surety about the vaccine reaching to the masses in the immediate future. the app can help authorities to do regressive contact tracing, identify hotspots that can help slow the spread and flatten the curve. the stored data on the cloud can be visualized and studied by the epidemiologists to forecast future trends and aid authorities in taking necessary actions ## design the simple arc loader is used in the app which is a sign of data being fetched from the server. pie chart along with the legends are present on the home screen. global stats are displayed below the pie chart. the track countries will direct to the list of affected countries. all of the items in this list view have an onclick listener which will direct to the details of that particular country. the data received was in the json format. the check status button on the main activity opens a new activity where the user can choose from two options. one option being to assess and report himself and the other one is to view info in the area around him. the assess yourself option asks the user questions about his travel history and if he has any symptoms and stores this information on the firebase cloud. each users information is stored in different documents. in the view info activity, the java code fetches the data from the cloud and displays the total number of suspected cases in the region the user is located, and it tells how safe the area is for the user. **app screenshots** # technologies used **android studio:** we have developed the android app using android studio. it is the official ide for googles android development platform. its extended features enable easy development of an android app as compared to the eclipse. its template-based design structures facilitate easy design of the layout by adding and adjusting the standard components like buttons, views, texts and other aesthetics. it has built-in support for the google cloud platform which allows to integrate firebase cloud messaging and google app engine. the gradle based app building and android-specific refactoring provides a very conducive and user-friendly platform. **firebase:** firebase is a mobile and web application development platform developed by google. it can be integrated with the android studio and can be used to store data entered by the user on the app to the cloud. this data can be accessed by the owner of the app and can be used for multiple purposes. this includes things like analytics, authentication, databases, configuration, file storage, push messaging, and the list goes on. the services are hosted in the cloud, and scale with little to no effort on the part of the developer. client sdks provided by firebase interact with these backend services directly, with no need to establish any middleware between your app and the service. **cloud firestore:** it is a flexible, scalable database for mobile, web, and server development from firebase and google cloud platform. it also offers seamless integration with other firebase and google cloud platform products, including cloud functions. the cloud firestore data model offers flexibility by allowing the use of hierarchical data structures. it uses data synchronization to update data on any connected device. cloud firestore also offers offline support. when an offline device is back in the network, the cloud firestore will update the database and make the necessary changes. **pixel we are using google mobile phone pixel it has a octa-core cpu with android operating system version installed in it. **rest api:** rest is the acronym for representational state transfer. it is an architectural style for distributed hypermedia systems. by separating the user interface concerns from data storage concerns, the user interfaces portability across multiple platforms improves. this also improves scalability by simplifying the server components. each request from client to server must contain all the information necessary to understand the request. therefore, the session state is maintained solely on the network. when a response is cacheable then a database cache is entitled to reuse the response data for later, similar requests. by applying the generality software engineering principle to the component interface, the overall system architecture is simplified, and interaction visibility is improved. to get a uniform interface, multiple architectural constraints are required to guide component behaviour. rest is characterized by four interface constraints: resource identification; resource manipulation by representations; self-descriptive messages; and hypermedia as an application state engine. rest enables client functionality to be expanded by downloading and executing applet or script code. **volley library:** volley is an http library which facilitates faster and easier networking for android apps. it has numerous desirable features. the network requests are automatically scheduled on multiple concurrent network connections. transparent disk and memory response caching with standard http cache coherence is present. there are debugging and tracing tools which are an added advantage. strong ordering that makes it easy to correctly populate your ui with data fetched asynchronously from the network. ## technical challenges we faced a conundrum while trying to display the data in the graphical manner. we finally decided to move on with the pie chart. we were unaware of the json format and the technicalities related to the received data. we had trouble connecting to the cloud and integrating it with android studio. the querying system for the cloud database is relatively slower, therefore it is taking a little longer duration to fetch the data from the cloud. the application uses all the modern technologies with its updated version. when we tried to run the app in the older version of the android, it was not working properly, and some activities were not behaving properly. therefore, we assume that the user uses the updated version of the android and a relatively new mobile phone. ## implementation the screen in figure is the home screen for the application. it gets displayed every time we open the application. the numbers are updated every minutes and initially there is a simple arc loader while the data is being received. this is a relative layout and the under that, we have a constraint layout having two card views. the legends and the pie chart are a present in the card view. under that there is a scroll view just in case all the above-mentioned data is not visible on the screen at a time. below that we have two buttons each having a unique functionality and directs us to the corresponding window. the track countries button allows us to get country wise statistics. the check status button enables us to access a short questionnaire which reports the data to the cloud and sends a response according to the statistics. the track countries button directs you to the activity mentioned above. this activity has a search window and a list of all the affected countries in alphabetical manner. the search window filters the search and displays the corresponding countries. all the countries are a part of the list view. and we can click on any country to get its details. clicking on any country will direct us to the window shown in figure it has all the details and these details are updated every minutes. next on the home page is the check status button which is shown in figure when we will click on that a new activity page will open which is there in figure in this activity there are two buttons namely assess yourself and view info. the assess yourself activity will ask the user to enter his name, his travel history and if he possesses any symptoms. this data entered by the user is stored in the google cloud firebase database. the view info button will tell the user about the suspected cases in his location and also whether his location is safe or not depending upon the number of suspected cases we are able to give this information by fetching the data which is stored in the cloud database. ## evaluation we tried to run our application for various cases. the cases also included a number of negative scenarios like can we do not enter any information in the asked questions. all these scenarios are now covered in the application. since our application has a lot of cloud and api interaction, the performance of our application solely depends on the response times of the cloud apis. we tried to find the average time of response but as said before since we are using free trial services the service is very slow and response time is unpredictable. we also evaluated the performance of each of the threads these again depend on services. also, the amount of on mobile device memory for storing data is minimal in our application since all the data is stored inside the cloud ## future work a notification feature can be added to the app such that whenever a new corona positive tested person enters your area you will get an alert notification in your mobile phone. we can integrate the app with the hospital official. so, if a person persists any symptoms, he can be connected with the nearest testing centre and for health check-up with the nearest hospital based on the location of the mobile. we can also add the bluetooth activity in the app. this activity will help the user to find if he has been in contact with any positive case person so that he can take the precautionary measures priorly. ## refernces https://developer.android.com/training/volley [volley library] https://restfulapi.net/ [ rest api] https://github.com/blackfizz/eazegraph [pie chart] https://github.com/generic-leo/simplearcloader [simple arc loader] https://cloud.google.com/firestore/docs/client/get-firebase [firebase] https://cloud.google.com/solutions/mobile/mobile-firebase-app-engine-flexible [integration of app with firebase] https://firebase.google.com/docs/firestore/query-data/queries [cloud database]"
1,FitnessApp,university project on knowledge representation and management. we combine gamification (minus the pressure and competition) with self-quantification and put it into an app.,"*last updated on may, written by & palebdue* # science based fitness tracker app | | | | | | -------------------- | ----------------- | -------------- |-- | |<img src=""md_images/app_picture.png"" | <img src=""md_images/add_activity.png"" width = | <img src=""md_images/chat_pic.png"" width = | <img src=""md_images/acutal_chat.png"" width = | keeping track of things can be quite hard and keeping track of yourself even harder. maybe you have already tried some of the wide variety of self-quantification apps out there but found them just a bit overwhelming, with daily goals, reminders to just squeeze in a few more steps or dramatic up- and downward graphs. finding a tool that is not pestering you for constant improvement while also being more fun than just a sheet of paper or your phone's note app can be quite the task. that is the niche this app is trying to fill. log your workouts at your own pace, without any requirements attached to them. you will get positive feedback from your digital workout buddy along the way and can chat with them about your activities or whatever is at their mind at the moment. here is how it works: you can input any activity type you want (whether it be swimming, jogging, quidditch or jousting) and choose a workout buddy to accompany you. whenever you log a new workout of that type, your buddy will remember this. you can later chat with them about your workouts this week and your overall performance. your buddy will also grow closer to you the more you two work out together and you will have more topics to talk about. they will not judge you whenever you decide to skip a week or just go for a five minute stroll instead of hiking up and down the nearest mountain. they will just be your personal hype person - cheering you on when you keep up the pace and being understanding whenever you need a little rest. the whole application is still very much a work in progress. the version you will find here is functional, but of course we are happy about everyone who contributes. please feel invited to join us and add any features, lines of dialogue or whole buddies. following you will find a description of the development journey, including the scientific background to the overall design and individual elements. you will also find a simple guide on how to use the app and ways to add new buddies or dialogue without having to comb through the existing code first. thank you for your time and we very much hope that you all will enjoy this little application we put together - whether it be from a user or developer side :) # theoretical background ## call to adventure for our knowledge management course, we were on a mission to find a fun project that tackles the curriculum of our course and our personal interests. so we fell into a research rabbit hole and found self-quantification and gamification - data and games, magical words to our ears. we made a plan for the big adventure ahead of us: creating an app on a scientific foundation that combines those two topics. the outcome is a tool for personal/individual knowledge and information management for your fitness data, but there is more. you are not alone in your workouts. in our app you can add new activities to the collection according to your own favourite activities and choose a buddy that works out with you. whenever you workout, your buddy will as well and the connection between the both of you grows stronger. you can have conversations with your buddies, like a quick chat or an overview about one of your activities. through this, your buddy will accompany you through encouragement and insights, or just as a neat little distraction while you rest after your workout session. if you want to learn more about our journey to the outcome, there is more from our adventure: ## table of content meeting the mentor(s) & crossing the threshold self-quantification gamification why do we think this is a good idea? a few things to keep in mind tests, allies, and enemies the ultimate boon how it works master of two worlds why no visualisation? sequel bait what else could be added to this concept? evaluation code improvements implementation requirements functions <a name=""mentors""></a> ## meeting the mentor(s) & crossing the threshold ### self-quantification self-quantification is described by the quantified self movement as self-knowledge through numbers (quantifiedself.com). users collect data about themselves and use them to gain insights into their behaviours and habits. the process of collecting data is often called self-tracking, which becomes self-quantification only after this data is put into a quantitative or qualitative context. > you might self-track your sleeping schedule by writing down the times you go to bed and wake up each night. if you compare these data points to each other, to see whether going to bed early means you also wake up earlier or how your sleeping schedule differs on weekends, that is self-quantification. self-quantification itself can also be split up into sub-activities (almalki, gray & sanchez, first the collected data is managed, which includes digital or analog storage as well as organising it in a manner that makes it understandable for the user (and/or any self-quantification systems that interact with it). then, users can reflect on data, by which they derive meaning from it. > for sake of convenience, you may write down your sleeping schedule on a notepad next to your bed. since these notes are very cluttered, you decide to copy them into a table in a separate notepad, in chronological order. this is managing your data. once you have collected a sufficient amount of data points, you sit down with your notes, think of any questions you have, and see how your notes can answer them. by this you are reflecting on your data. this breakdown of self-quantification fitted our idea of what our app should do really well. it furthermore gave us an in through being less focused on the psychology of physical health and exercising itself, but on the handling of the resulting data and information. with this perspective, we could relate the subject to other fields of study. as many of you will likely already have experienced, finding a path from the knowledge you already have to what you are trying to learn can be a huge boost, and we felt the same. in particular we looked at the study of knowledge management. probst defined the building blocks of knowledge management, which consist of an inner and outer cycle of activities. self-quantification can assist in two activities of the outer cycle: knowledge measurement becoming data management and knowledge goals becoming reflection on data. <details> <summary markdown=""span"">why go into so much detail?</summary> splitting self-quantification (and later topics that will be brought up) into all these sub-tasks might seem nitpicky at first. it is however very useful when trying to incorporate it into another service, such as we will be doing shortly. by looking at the process in detail, we can ensure that we do not miss any important components and really understand how the whole concept is supposed to function. </details> self-quantification can be applied to many aspects of life, such as nutrition, health, or exercise. apps can be quite helpful with this, as they organise and sometimes track relevant data for the user. some examples that you might already be using are fitbit or google fit, which both track various exercise related data, organise them into daily, weekly, and monthly overviews, and assist in self-reflection, by pointing out increases and decreases. overall, self-quantification is meant to increase awareness, curiosity, and consciousness (orji, it can show problematic behaviour that users may not have noticed otherwise and inspire to improve oneself by comparing data to others or the former selfs. but of course it also has some disadvantages and weaknesses. continuously striving to best one self or others can turn into unhealthy behaviour, if it disregards other needs. when using tools such as apps, these apps often assume that users are already motivated to quantify themselves and offer little motivational affordances outside of self-quantification. this is a weak point especially since people can perceive feedback quite differently, based on how control or autonomy oriented they are (mekler, brhlmann, tuch & opwis, control oriented users may feel controlled by receiving feedback, while autonomy oriented users will see it as informational and feel more competent. these last two points (lack of motivational affordances and differences in perception) made us look for another motivational factor, which might mitigate these effects. | **sources** | |-------------| |quantified self. what is quantified self? retrieved from https://quantifiedself.com/about/what-is-quantified-self/ <br/><br/> almalki, m., gray, k., & sanchez, f. m. the use of self-quantification systems for personal health information: big data management activities and prospects. health information science and systems, <br/><br/> orji, r. the costs and benefits of self-monitoring for health and wellness. retrieved from: <br/><br/> mekler, e. d., brhlmann, f., tuch, a. n., & opwis, k. towards understanding the effects of individual gamification elements on intrinsic motivation and performance. computers in human behavior, <br/><br/> probst, g. j. practical knowledge management: a model that works. prism-cambridge massachusetts-, <a name=""gamification""></a> ### gamification gamification describes the use of game design elements in a non-game context, which are intended to motivate and engage users (deterding, dixon, khaled, & nacke, as more and more people are picking up gaming as a hobby and become more familiar with game elements, gamification is likewise being used to enhance services more often. it is related to subjects such as educational games, but differs in the way that the main activity performed is not a game, but simply incorporates gameful features. > as a child you may have studied to improve your language skills by playing learning games and helping your favourite cartoon characters sort vocabulary, fight declination monsters, or unravel past tenses. this would be an educational game, not gamification, as the main activity was still gaming (and you were merely tricked into studying). nowadays you may want to brush up on your language skills with the aid of an online learning platform such as duolingo. in this app you can collect badges for a variety of activities and build up a streak by completing daily lessons. this is gamification, as the main activity is learning, with game elements to motivate you to keep going. gamified applications most commonly feature points, badges or leader boards (hamari, koivisto & sarsa, these elements are very versatile, so they can be applied to many different contexts , such as education, health, and commerce. research on how gamification affects motivation is still ongoing. the difference between extrinsic and intrinsic motivation is something that especially interests researchers, but since these are difficult to measure directly and can only be seen in their behavioural outcomes, no definite connection can be made yet. something that has become apparent though is that different game design elements have different effects and that the context they are being deployed in and the personality of the user matter (dahlstrm, because of this they are, though efficient at times, no catch-all solution for engaging users. <a name=""why""></a> #### why do we think this is a good idea? we think gamification will be a great addition to our app design, since it can complement self-quantification in our competence-autonomy dilemma: users will feel competent through receiving feedback about their workout progress, guided by self-quantification tools. the game design elements can be chosen to satisfy a need for autonomy, for example by allowing users to make meaningful choices and seek out intentional interactions | **sources** | |-------------| |deterding, s., dixon, d., khaled, r., & nacke, l. september). from game design elements to gamefulness: defining"" gamification"". in proceedings of the international academic mindtrek conference: envisioning future media environments (pp. <br/><br/> j. hamari, j. koivisto and h. sarsa, ""does gamification work? -- a literature review of empirical studies on gamification,"" hawaii international conference on system sciences, pp. doi: <br/><br/> dahlstrm, c. impacts of gamification on intrinsic motivation. | <a name=""mind""></a> ### a few things to keep in mind our two mentors already gave us a great theoretical foundation for further research and a plethora of features to choose from. we also felt it important to include our own experiences and intuitions into the app design - maybe not as a (figurative) mentor, but more of a sidekick. so while we had previously let research guide us to which models to build upon, we now went to look for what we personally felt was still missing and check whether these were valid points supported by empirical research. something that was extremely important to both of us, was that we do not want to rush users to change their behaviour or log their workouts at a certain frequency. this should firstly be reflected in the choice of features. for example, we did not want our app to send push notifications. our intuition was that this would stress users, a claim we could not find a clear support or rebuttal for. however, a literature review (wohllebe, found that while push notifications increase engagement with an app, they are also often perceived as a disruption or interruption. valuing these benefits and disadvantages against each other, we decided to stick with not wanting any push notifications. our commitment to a relaxed approach to self-quantification should also show in more indirect ways, such as the language used in the in-app texts. going into detail and setting up criteria for how to do this would have been beyond the scope of this project. we instead focused on non-intrusive language, nudging users to keep engaging with the app, and allowing them the possibility to customise their experiences (almourad, et al., this includes the option to turn off any form of nudging and instead just receiving positive feedback for logged activities. another thing to keep in mind were the downsides that both self-quantification and gamification have. these were a reminder, not for the users, but for us to take things slow and consider what was actually useful and when we were going a bit overboard. for this, our sidekick needed to be a bit of a buzzkill and sit us down to look up the disadvantages of our shiny new mentor friends. in a collection of prevalent criticisms of self-sensoring devices (baker, tools often employed for self quantification, a lack of transparency in underlying algorithms was pointed out. by making the project code completely visible to any users, explaining our steps that led us there and presenting the logged data in a minimally processed form, we hope to counteract this. self-quantification tools may also convey to the users a feeling of needing to know data about themselves to abide to an external degree of wellness. these standards can be set by the tool, peers or other sources. instead of pushing users to change their behaviour to match any goals, whether they were set by us or themselves, we want to focus on simply managing and reflecting on data (almalki, gray & sanchez, this should hopefully also boost self-quantifications benefit of increased self-awareness, while alleviating the pressure to perform (ayobi, et al., lastly, we wanted all our elements to fit together organically (or as organically as a digital application can be at least). while we would have probably stuck to this principle just for the sake of organising the development process, there is actually a user benefit in it as well. especially with gamification, game design elements that are not tied to other elements can lead to off-task behaviour (andrade, mizoguchi & isotani, this means they are a distraction from the other functions instead of enhancing them. to avoid this we always checked how a new feature would interact with the other elements and to which end goal it would be used. for example we wanted to make sure our game elements were not just an experience bar that kept growing with no end, but that an, hypothetical, increase in experience would also unlock new ways to use the app. to summarise, our sidekick, or by now our group of sidekicks, are supposed to remind us of the following principles: take things slow and do not push users in any direction. keep your mind open for any negative sides of self-quantification and gamification. elements should lift each other up instead of distracting from each other. | **sources** | |-------------| |wohllebe, a. consumer acceptance of app push notifications: systematic review on the influence of frequency. <br/><br/>baker, d. a. four ironies of self-quantification: wearable technologies and the quantified self. science and engineering ethics, <br/><br/>andrade, f. r., mizoguchi, r., & isotani, s. june). the bright and dark sides of gamification. in international conference on intelligent tutoring systems (pp. springer, cham. <br/><br/>almalki, m., gray, k., & sanchez, f. m. the use of self-quantification systems for personal health information: big data management activities and prospects. health information science and systems, <br/><br/>ayobi, a., marshall, p., cox, a. l., & chen, y. may). quantifying the body and caring for the mind: self-tracking in multiple sclerosis. in proceedings of the chi conference on human factors in computing systems (pp. <br/><br/>almourad, m. b., alrobai, a., skinner, t., hussain, m., & ali, r. digital wellbeing tools through users lens. technology in society, | <a name=""tests""></a> ## tests, allies, and enemies now that we had decided on the two main elements or theories of how our app should work, we were ready to look into more concrete features, starting with game design elements. our first approach was to go with the classics: leaderboards or other comparative social features were ruled out as possible elements early on. they did not fit our ideal of not setting any expectations for users as they are, by nature, competitive. indeed some users of gamified trackers have found being evaluated by their peers an uncomfortable experience (barrat, leaderboards especially can negatively affect the sense of competence (andrade, mizoguchi & isotani, which may demotivate users from using a tracker or reduce their activities altogether. this left badges/achievements and points. badges could reflect a user's individual experience and choices they made along the way (by seeing badges that fit their workouts), but also provide an incentive to diversify their workout (to unlock new badges). points could show their overall progress, as the more workouts a user would logg, the more points they would collect. this would give them a feeling of competence, as well as rewarding interactions with the application (sailer, hense, mayr & mandl, <details> <summary> :framed_picture: mock-up here</summary> <img src=""md_images/professioneles mock up.jpg"" width = </details> none of these ideas are bad, indeed there is a reason why these features are upon the current top most researched and deployed elements (hamari, koivisto & sarsa, an app incorporating these may very well be an enjoyable and motivating system - however, relying on them does not take one of the current main criticisms of gamification into account (which has been withheld for dramatic tension). gamified systems overall show little variety in their utilised features (rapp, hopfgartner, hamari, linehan & cena, they thereby ignore that games are not just a collection of simple reward mechanisms, but come together to an overall meaningful experience. this is a lesson games themselves are already taking to heart, but which sadly has passed over many gamified applications. to be more frank, we were tasked with the challenge of how to see gamification as more than just slapping some exp counters and achievements on a system and calling it a day. so, to conceptualise a new idea of how to employ gamification, we needed to think about how games themselves work. obviously games are a lot of fun to a lot of people (including ourselves), but why? one paper that was immensely useful in that research was rapp who examined how wow engages players and drives their behaviour. he also derived some lessons for systems that want to support their users in reflecting on data and gaining insights, which was of course a near perfect fit for our app construct. the lesson we concentrated mostly on was to turn data into dynamic digital objects. these objects should tie into the mechanics of other features, provide information, and grow along with the players/users. now, these requirements might seem a bit vague at first glance, but will hopefully become more clear when we elaborate on our ideas of how to implement them in a bit. this approach seemed an excellent guideline to us, as it connects data visualisation and gamification in a new and fun way, while at the same time giving users the choice of how and when they want to reflect on their data. this is important to appeal to both control and autonomy oriented users. with this new knowledge we once again started searching for concrete features. the challenge here was how to interweave game elements and self-quantification/data visualisation in a meaningful way. <details> <summary markdown=""span"">option an rpg type adventure game, which required to complex background mechanics and distracted from the actual workout focus</summary> inspired by the paper we built upon, our first idea was an rpg type adventure, where you would increase your stats through working out and find random items after each completed workout. as you progressed, you would be able to choose a class, based upon which stats you had levelled up the most and therefore which type of activity you completed the most often. for example, a user could link jogging to their stamina stat, yoga to their dexterity, and some good old caber toss to their strength. if they went jogging a lot and kept raising their stamina, they would at some point get the option to choose the ranger class. now this is already kind of complex, but still manageable. it does not include a way to utilise these stats, items, and class choices in-app though. therefore we would need some sort of quest and/or combat system. for those of you familiar with the app habitica (formerly habitrpg), we were pretty much approaching a clone of their application. apart from that it was becoming more and more complex. this not only meant a huge amount of programming and planning work for us, but also that our end product would be more of a game with some self-quantification hidden in the corner somewhere, which was certainly not what we were aiming for. </details> <details> <summary markdown=""span"">option a dress up game, which lacked opportunities to implement self-quantification features</summary> for our next approach we wanted to look for some way to make the virtual object interesting all by themselves. one way to peak users' interest in objects that came to our mind was aesthetics (aka making things look pretty). we therefore scratched all the stats, classes, and quests from our previous idea and concentrated only on collecting equipable items. having an avatar that could be dressed in increasingly elaborate outfits the more you worked out would be a great visual representation of progress. users could also link specific workouts to what type of items would be dropped from it, for example swimming could give you a randomly selected top each time, while hiking could be linked to random shoe drops. this would encourage users to diversify their workout activities and give them some control about the items they receive. to show progress more efficiently, multiple copies of one item could be combined to an upgraded version, which would be more detailed than the basic one. what we liked about this idea was the focus on visuals, which immediately catches users attention and can be perceived as satisfying even without complex rules running in the background. however this would also be its downfall, as it made it difficult to implement self-quantification in a meaningful manner (asserting stats to the objects would not really make sense) and making the objects dynamic would also be a very time consuming task (especially since none of us have a graphic design background). </details> after these two failed attempts, more research was in order. the main question we wanted to look into was what makes game items appealing? for this we searched for research on why players purchase in-game items. the reasoning behind this was that users would purchase items in our app by investing time and energy, so the insights gained from monetary purchases would also apply to our context. regarding avatars and non-functional items (as in our last feature proposal) aesthetic qualities are the main gatekeeper for users to be interested in and purchase them (marder et al., this was something we already assumed, but we took from that the lesson that objects should have a graphical representation, enabling an at a glance, aesthetical impression. motivation to purchase can also be differentiated by two factors: it can either be object or payment oriented and utilitarian, socially, or hedonically motivated (marder et al., since we did not plan to include any social features, this ruled out social motivation. we also wanted to keep the underlying mechanics as simple as possible, so utilitarian motivation (in this case the influence on other features) was also determined to be less important. the payment orientation did not fit with our type of payment via time and energy, which left us with object oriented and hedonically motivated purchases to look further into. for this, aesthetic appeal is still important, but so are novelty, celebration of individual achievements, and showing devotion to in-game characters (npcs). novelty sounded like something that would be difficult to achieve, since we did not want to build an application that relied on continuously adding new items. having the objects grow alongside the user would also make them novel for each person individually, which connects well with the research on turning data into digital objects (rapp, celebration of individual achievements could likewise partially be achieved by reflecting how the object and the user had evolved together. it also shows how well game design elements and self-quantification interact, since self-quantification also includes finding achievements through looking at the collected data. as for the devotion for in-game characters, we had not considered npcs yet. since we had decided on not including any interactions with other users early on, we had not put any thought into social interactions of any kind. the idea of having npcs fill that need for social interactions seemed like the obvious choice in retrospect though, and the fact that users seemed to find npcs appealing in general reinforced that idea. we therefore took our avatar based app idea and decided to substitute the player-representing avatar for npcs. in a gacha game type manner users could unlock new items for these npcs, which would each represent a different workout type. what was lacking in this concept was a concrete way the collection of items would reward the user, besides some vague commitment to an npc, and the little control over the rewards through the random drop mechanic. this would not only thwart the need for autonomy in some users, but can also be a general source of annoyance and frustration to users of all types. to see how commitment to a character could pay off, we went to look at what made npcs appealing to users in the first place. players of different game genres stated that they especially liked uncovering hidden aspects of characters as they continued to interact with them (shibuya, okura, shoun & asou, we derived from that, that our app should reward players for collecting items, or directly logging workouts, by growing closer to a character they chose. this also solves our randomness issue, as this reveal of character aspects would of course not be randomised but predetermined. | | | | | -------------------- | ----------------- | -------------- | |<img src=""md_images/mehr pro skizzen | <img src=""md_images/incredibly pro skizze_locally sourced meme.png"" width = | <img src=""md_images/mehr pro skizzen | | **sources** | |-------------| | sailer, m., hense, j. you., mayr, s. k., & mandl, h. how gamification motivates: an experimental study of the effects of specific game design elements on psychological need satisfaction. computers in human behavior, <br/><br/> j. hamari, j. koivisto and h. sarsa, ""does gamification work? -- a literature review of empirical studies on gamification,"" hawaii international conference on system sciences, pp. doi: <br/><br/> rapp, a. from games to gamification: a classification of rewards in world of warcraft for the design of gamified systems. simulation & gaming, <br/><br/> rapp, a., hopfgartner, f., hamari, j., linehan, c., & cena, f. strengthening gamification studies: current trends and future opportunities of gamification research. international journal of human-computer studies, <br/><br/> marder, b., gattig, d., collins, e., pitt, l., kietzmann, j., & erz, a. the avatar's new clothes: understanding why players purchase non-functional items in free-to-play games. computers in human behavior, <br/><br/> shibuya, a., okura, h., shoun, a., & asou, n. male and female game players' preferences for game characters and real-world personalities in japan. in digra conference. <br/><br/>barratt, p. healthy competition: a qualitative study investigating persuasive technologies and the gamification of cycling. health & place, <br/><br/>andrade, f. r., mizoguchi, r., & isotani, s. june). the bright and dark sides of gamification. in international conference on intelligent tutoring systems (pp. springer, cham. | <a name=""boon""></a> ## the ultimate boon with this idea we developed a new idea of how the app would look like and as you can probably deduce from the section heading, it is the one we stuck with. we did not immediately have all the details figured out and still had to do a bunch of tweaking during development, but for the sake of brevity(-ish) we will simply describe the end construct here. the main feature of the app is a buddy system, where users can choose an npc to accompany them on their workouts. the more they work out together, the more dialogue options they unlock. through this users can grow closer to the characters. <a name=""how""></a> ### how it works when a user registers a new activity, they choose a buddy that will accompany them on these workouts. what this means is that whenever a new workout instance of this activity is logged, the friendship stat of this character is increased. this friendship is not directly visible to the user, but influences the conversation options for their buddy. they can talk to the npcs, either to just chat or to get a recap of the past workouts they have logged together. when just chatting random lines are selected based on the friendship level. an npcs that is still unfamiliar with the user might behave slightly awkward around them or only make very surface level small talk. as they continue working out together that buddy will become more comfortable with the player though. in their recaps buddies talk about various aspects of activities, such as when the last workout was logged, whether the user was able to work out longer than previously, and how often they have worked out together. besides this aggregated data, buddies also praise users for their commitment and determination. <img src=""md_images/flow chart.jpg"" > <a name=""master""></a> ## master of two worlds as we approach our figurative return to the shire/ train back to platform / medal ceremony with subsequent jedi training, it is only appropriate to look back at all the lessons we have learned and see how they were implemented in our final system. since you already had to read quite a lot of text, we decided to put this into a convenient table: | lesson learned: | feature added: | |-----------------|----------------| | need for competence requires feedback | buddies give feedback in workout recap & after logging a new workout | | need for autonomy needs choices and intentional interactions | users have choice of buddies and can seek out interactions (conversations) themselves as well as the degree of feedback | | need for autonomy needs meaningful experiences | conversations with buddies will (hopefully) be meaningful to some users | | data should be turned into digital objects, that | buddies are digital objects representing activitiesworkouts. | | tie into other features. | they reference logged workouts in their workout recaps directly and change conversation options when interacting. | | provide information. | they provide feedback in their workout recaps. | | grow with the user. | the growing friendship between the user and the buddy will unlock new conversation options.| | objects should have graphical representations. | buddies have avatars. | | items become more interesting through novelty,... | new conversation pieces are unlocked as more workouts are logged. | | celebration of users achievements, | buddies praise the user for committing to their fitness activities. | | and devotion to in-game characters. | users can decide which characters they want to get to know better and spend time on their corresponding activities. | | npcs become more likeable when users can uncover hidden aspects of their character. | this is utilised to motivate users to log more workouts with a buddy. | <a name=""visualisation""></a> ### why no data visualisation? as some of you might have realised, there is no graphical representation of the user data in our current app concept. we preferred a narrative recapitulation by the buddies, as a way to elevate our main feature. data visualisation is also better suited to illustrate relationships or connections between data points (azzam, evergreen & kistler, for example by showing trends in activity. this is an interpretive step that we did not feel comfortable making at this point, rather opting to only do some minimal aggregation, to make the data more comprehensible. this also reduces the possibility of information overload and visual stress in the user, which is more likely to occur in data visualisations (bresciani & eppler, | **sources** | |-------------| | azzam, t., evergreen, s., germuth, a. a., & kistler, s. j. data visualization and evaluation. new directions for evaluation, <br></br> bresciani, s., & eppler, m. j. the risks of visualization. identitt und vielfalt der kommunikations-wissenschaft | overall these are quite a lot of insights we borrowed from the papers we read and managed to incorporate into only a small selection of features. keeping our list of features brief was important to us, as we had to implement them without much experience in app-programming and also wanted to focus on doing a few things well instead of dabbling in a bit of everything. still we are aware that we have barely scratched the surface of possibilities of some topics, which leads into the last section of this theoretical background: further research, limitations or just <a name=""sequel""></a> ## sequel bait ### what else could be added to this concept? obviously, a lot! here are some ideas that we either had to drop because of time restrains or only came up a bit late: * more trackable workout data! users could, for example, mark which body region each activity is training. a wider selection of measurement units (such as distance for activities such as hiking) and the possibility to track multiple units per activity could also aid in self-quantification. <details><summary>:framed_picture: mock-up here</summary><img src=""md_images/professioneles mock width = * more research on data visualisation! the feedback via conversation is a very deliberate choice we made to fit with our gamification elements and differentiate us from other fitness apps. we also know that some users may prefer a graphical representation though, as they can provide more information at a glance. to find out how graphs or other visuals could be organically added to the current system, more research is needed. * more detailed feedback! in the recaps users get a pretty brief overview of their past workouts. it would be great if buddies could also mention special achievements, such as when a personal best has been beaten. * conversations are actually supposed to be dialogues, not monologues! right now the buddies are doing all of the talking in the conversations. giving the user answer options which lead to branching dialogues would not only make them more engaging, but also support the need for autonomy through being able to make choices. bonus points if the buddy remembers these choices later on. * even more visuals! the buddies could change their avatars after certain friendship levels. maybe they talk about some new fashion item they always wanted to buy or wanting to move into a new place, which then shows up in their new avatar. this would give users a visual reminder of memories they have made together. * more elaborate friendship algorithm! the underlying algorithm determining how the friendship with a buddy increases could be improved. aspects such as the duration/intensity of the workout could influence the amount of friendship. right now every logged workout simply increases the friendship score by one, so even calling it an algorithm is kind of an overstatement. * customisation! another aspect that can be considered in future work is more customisation options, such as choosing the colour design or integrating your own buddies for your favourite sports. this could also include a profile where further data can be stored to improve the overall experience with the buddies and the app, e.g. by being addressed with one's own name to strengthen the connection to the buddies. * being able to set own goals! currently, users can independently set whether and how often they want to experience nudging or encouragement to better support control and autonomy-oriented users according to their individual preferences. they are encouraged when starting the app with references to past workouts, as well as directly after logging a workout, and nudged on the home screen through a reminder of activities that have not been logged for a while. the specific messages and conditions are hard coded in the buddycsv. this could be enhanced by allowing users to set their own goals for which they receive praise, encouraging messages or a bit of nudging. for example, instead of being praised for logging a workout every third time, you could indicate that you would like to receive praise when you have hit a certain milestone (such as a hike). this personalisation would support users need for autonomy. * cut scenes! right now when just chatting with the buddy, dialogue is randomised to offer a variety of interactions. this does however not allow for efficient storytelling or character development. for this, whenever a certain condition is met, users could have the option to view a small scene with a buddy to elaborate their character. <a name=""evaluation""></a> ### evaluation just adding more and more elements is not the only thing to further improve this app though. getting some feedback on how the different features are perceived is key to improving in a meaningful way. there are some questions we already have and evaluation techniques that we think could really elevate the app: regarding the theoretical foundations and features, some insight into how the choices we made along the way are actually affecting users would be quite helpful to find weak points not yet covered by current research. our main question here would be, whether the deceleration of various gamification and self-quantification elements are actually perceived as such. this is one of the aspects that was especially important for us, however that does not mean that the same goes for other users. having some users test the app for a few weeks and then looking into the data they collected and interviewing them about their experiences would give valuable insights. relevant data would be, for example, the number of activities added (if users add a lot of different types of activities, comparing them to each other might be useful) or the frequency of workouts logged (logging longer workouts less frequently would impact our start screen reminders). the interviews could explore questions such as which buddies users liked and what made them like or dislike characters, when and where they normally engage with the app (directly after the workout, in the evening when recapping the day) or how their needs for autonomy and competence were thwarted or supported. the other main facet to evaluate would be the practical implementation, in this case the app itself and its interface. since this is an app, a usability test with the central question of how intuitive the design and use of the app is, is obvious. one could develop a survey questionnaire that assesses how comprehensive the design is, including the colour choices and elements used (such as buttons, icons and text input) as well as an additional supporting study to evaluate how easy it was to navigate to the functions of the app. <a name=""improvements""></a> ### code improvements there are also some more technical improvements that might not be visible when actually running the app, but are nonetheless beneficial to the overall performance, by making maintenance less complicated: currently, the two csv files (chat and workout_chat) needed for conversations have the same structure, but are separated to avoid confusion between the two types of dialogue. perhaps a better system could be developed for this and they could be merged with another column to classify them as workout_chat or chat. this way, when new texts and new columns are added, both csvs do not always have to be changed. the same applies to the csv files in relation to the different buddies. some parts of the programme had to be integrated statically. for example, when developing the overview of buddies in the mdswiper, no possibility could be found to read them in dynamically so that they are hardcoded in the kivy file. this is not desirable, because if you want to include new buddies, you have to work within the kivy code in addition to the csv files, which makes the procedure more time-consuming. \[update \: a contributor found a way to move the kivy code into the python file, so theoretically, now we can dynamically read in all buddies, thank you for that!] \[update \: it is not theoretical anymore, buddys are now actually read in and dynamically added to the swiper! jippie!] while programming, there was some confusion about object oriented programming in general. there are some code solutions regarding classes and their variables and functions that may be considered as idiosyncratic. for example, there are the classes `itemconfirm` and `buddyconfirm`, which have almost the same function, namely the handling when clicking an object in a displayed list. the same applies to all of the defintions of dialogue windows and oh boy, there is a lot of them. one usually wants to merge such similar code and only outsource the specific differences. these parts could be improved by more knowledge and experience in the field of object-oriented programming. there are places in the code that can be optimised where unnecessary memory or computing time is consumed. these places were deliberately left there to avoid bugs at all costs. for example, the csv files are re-read at every point where access to this data is needed to ensure that the latest data is available at all times. it is also possible to do it this way, as you cannot expect the csv files to ever get too big to read in this way, but it is still unnecessary computing. instead, the data could be read in once and only then read in again if something has been changed in them. --- <a name=""implementation""></a> ## implementation this app was developed using kivy and kivymd, a python based cross-platform gui toolkit for touch applications that follows google's material design system. <details> <summary markdown=""span"">my personal experience with kivy & kivymd :thought_balloon: </summary> i would describe myself, at least at the start, as a beginner in such extensive programming projects. using multiple classes and continuously running python loops, as is the case with apps, is new territory for me, let alone learning how to use kivy and kivymd. therefore, at many points it has been difficult for me to distinguish whether a problem is due to my general programming skills reaching their limits or whether it is due to kivy/kivymd itself, its docs or even my ide. nevertheless, one thing is certain: kivy gave me the courage to develop an app on my own in the first place, because i had a solid understanding of python and thus a big hurdle of a new programming language was taken away from me. kivymd then gave me hope that this app could actually have something in terms of design. overall, i can recommend kivy as an introduction to app programming if you have mainly worked with python so far. it is easy to learn how the kivy language is structured and you quickly get a sense of achievement with kivymd, as the app looks appealing straight away. however, i did reach some of the limits of kivy when, for example, i wanted to display dialog widgets in more than just a simple rectangular shape, but i was able to implement most of my ideas solidly, as you can see from this great result. so go for it! </details> <a name=""requirements""></a> ### requirements as listed in `requirements.txt` and can be automatically installed with the following after cloning this project. ``` install -r requirements.txt ``` <a name=""functions""></a> ### description of the app and its functions the app is designed to track your fitness activities by logging your own workouts. you can add your own activities like mudflat hiking, caber toss or deep breathing, decide which unit of measurement (how long took your mudflat hike? how much did your caber weigh or how many deep breaths did you take?) is relevant, and choose a buddy to work out with to build a closer friendship. talk to your buddy about your fitness progress or have a relaxed chat with them and get to know them better. **overview of the app's functions** - logging a new workout - overview of all implemented activities in the collection - adding new activity definitions to the collection - overview of your fitness buddys - conversations with buddys about corresponding activites or just checking in with them - setting your preferences about encouraging or nudging messages: - after logging a workout - when opening the app <details> <summary markdown=""span""> ##### an in-depth description of the app including it is design, which you can also watch in the video below </summary> #### start screen when the app is started, there is a navigation bar at the top of the home screen with a menu button that guides you through the subpages of the app. the picture of a buddy is displayed in the centre of the screen, along with a specific message. this message is either an encouragement or, if you activate the ""reminder on startscreen"" in the settings, a nudging message. the name of the buddies, the filenames of the pictures, as well as these specific messages are collected in a csv table named 'buddys.csv' (furthermore also the descriptions and the friendship levels, which are only mentioned later). in the case of encouragement, the system looks at the workouts logged in the last seven days and randomly selects a buddy with whom you have completed this workout. if there was no workout, a buddy is randomly selected. nudging looks for sports activities that have not been logged in the last two weeks to remind users of them. at the bottom of the screen is a button with a plus sign that takes you to a subpage where you can log your activity. the activity logger page is divided into individual lines, in each of them something can be entered or selected. - activity: in the first line you select the activity you want to log. to do this, click on the button ""choose an activity"", which opens a dialogue box showing all possible sports in a single choice list. - date: next, select the date. by default, the current day is displayed. clicking on the date opens a dialogue window with a calendar where you can change to the desired date. - duration: here you will find three small input fields next to each other, marked with an h for hours, m for minutes and s for seconds, where you can enter this information. - repetitions: again, an input field for the number of repetitions. - weight: in the last line you can enter how much weight was used for the activity. at the bottom of the screen, you can reject or confirm your entries using two buttons. each selected activity requires exactly one of the three measuring units. if this unit is not filled, an error message is displayed in the form of a dialogue box. if you have specified in the settings that you would like to receive encouragement after logging, you will first be taken to an intermediate page after confirming, where the respective buddy of the sport and a friendly message are displayed. after successfully confirming or cancelling the logging, you return to the start screen. thereby the file 'logged_activities.csv' is extended with the new data. the menu button in the upper left corner of the screen takes you to the following subpages: home, activity collection, buddys and settings. #### activity collection on the activity collection subpage there is a scrollable list of all sports and next to it an icon of the respective buddy that accompanies that activity. the list is created from the data in the 'activity_collection.csv' file and is automatically expanded when a new activity is created. this csv contains the names of the activities, the assigned buddy and a boolean value for each unit of measurement. it is extended with the previously created 'buddys.csv' to display the appropriate images. below the list there is a 'plus' button which allows you to add new activities to the collection. this takes you to the subpage ""add an activity to your collection"", which is again divided into rows like the activity logger page. in the first line you will find a plus in the center, which you can use to select a buddy for the activity. if you have selected a buddy in the dialog window, the plus sign will be replaced with the picture. in the next line you will find 'activity name' on the left and an input field on the right, where you can define the name. in the three lines below, you will find a switch on the right, that defines which of the units on the left of the lines the activity should be used to measure. as already mentioned for the logger, you can choose between duration, repetitions and weight. at the bottom of the screen you can cancel or confirm, adding the new activity to 'activity_collection.csv'. #### buddy screen if you click on 'buddys' via the menu button, large pictures of the individual buddies are displayed on the screen in a so-called swiper. in the center you always see a picture and to the right of it a fragment of the next buddy is shown, that you can swipe to. below each picture is a button with the name of the buddy. if you click on one of the buttons you will get to the subpage of that buddy. on the upper half of the screen you see the picture and also a short description and in the lower half there are two buttons on top of each other with which you can choose what kind of conversation you want to have with the buddy. if you select the upper button ""how is my workout working out?"", a drop-down window opens with all the activities you can talk about with that specific buddy. after selecting one, you will be taken to the chat page. if you just want to chat a little you can click on the button ""let us chat a little"" below. this will take you to the same chat page, which is split in two horizontally. at the top you always see the buddy and at the bottom a text field with the current chat message of the buddy. below that, there is a ""back"" and ""continue"" button that do just that during the conversation: switch to the previous or next message. the text messages that are displayed initially depend on whether you wanted to 'just chat' or talk about an activity. those messages are saved in two different csv files per buddy - one for chatting and one for workout talks. when chatting, it is important how good a friend you are with your buddy. low friendship levels mean more superficial and less personal conversations, but: more workouts logged, the higher the friendship level. when chatting about sports, the messages give you an overview of the last workout, the last seven days, and the total amount of sports. a more depth description on how the chat messages work, how to expand and fill them with content can be read below. #### settings the last menu item takes you to the settings. here you can choose via a slider how often you want to receive an encouragement after logging workouts. you can choose between 'never' on the left, 'sometimes' in the middle (you get feedback after every third log) and 'always'. finally, you can choose whether you want to receive reminders of seemingly forgotten sports on the start screen, as explained at the beginning of the description. this is a complete circle now. next you can watch a video of me clicking through our app (but you will not hear any clicking, since i had to mute the video, because i did not notice that there were copyrighted low-fi beats playing in the background while recording) </details> <a name=""buddys""></a> #### buddys to add your own buddy, you need to add a row to the csv file 'buddys.csv', add an image and two conversation csv files (which are described in the following section). the structure of the csv_files is as follows: | buddy | source | description | friendship_level | basic_logg_encouragement | startscreen_encouragement | startescreen_nudging | | ----- | ------ | --------------- | ---------------- | ------------------------ | ------------------------- | -------------------- | | bo | bo.jpg |that is the lad...| | ""whew, what a workout... | ""i am still recovering ... | i have been wondering...| * buddy, source, description & friendship_level these are the simplest columns. add a name for your buddy, that is distinct from the others. save your buddy's image in the `images` folder and add the file name in the `source` column. write down a description and add a friendship level. * basic_logg_encouragement this message is shown after you logged a workout, depending on your settings. it is a way to get a nice message from your buddy after you worked out with them. * startscreen_encouragement & startescreen_nudging when you open the app your buddy can encourage you with a simple reminder of your previuos workout or by a little nudging. add according messages in these two columns. <a name=""conversations""></a> #### conversations to have a chat with your buddy, you need a csv file for both the workout conversation and the regular conversation, but both are structured and processed the same way. the matching csv is first read in and mapped as a dataframe (i.e. a matrix/table), where each row represents a message. the algorithm selects the next message by minimizing the set of all messages using filters from the other columns and randomly selecting one from the resulting set. in doing so, it is guided through the texts using tags until the conversation is over. from the following representation of the csv, as well as the explanations the function of the algorithm becomes more clear. the structure of the csv_files is as follows: | text | tag | next-tag | friendship min | friendship max | condition | ... | condition n | other rec notes | | ---- | --- | -------- | -------------- | -------------- | ----------- | --- | ----------- | --------------- | | hi! you want to talk? | intro | last workout | | | | | | if any workout is logged with chosen buddy * text displayed message in the conversation. variables can be represented within the texts in square brackets `[]`, which are read and filled in the code to provide the conversation with data from the app. the definitions of these variables are stored in the dictionary `chat_variables_dict`. if you want to add new variables you can use the function `get_dict_chat_variables()` and the dictionary will be extended automatically. * tag & next-tag determines the tag of the current text and determines which tag must follow next. the chat always starts with the tag 'intro', first filters all messages based on this tag and takes over 'next-tag' to narrow down the next message when the message is selected. the chat ends as soon as there is no tag in next-tag. * friendship min & friendship max defines between which friendshiplevels a message is eligible. both a lower and an upper limit can be specified. * condition | ... | condition n & other rec notes any other columns can be inserted to act as new filters. the last column 'other rec notes' serves as explanation of the condition. to include the new condition, it must be implemented in the `fill_conversation_list()` function within the while loop to further delimit the `subset_buddy_convo_df`-dataframe. <details> <summary markdown=""span""> ##### a little more in-depth explanation on how to extent the chat messages of your buddys </summary> if you want to insert a new text message, you can add a line to the corresponding csv of a buddy. the most important part here is to pay attention to which tags you use, as the code will repeatedly move from tag to next tag, selecting the messages that will then be displayed in the chat. one can extend chats independently in different ways with different complexity. there are basically two options, with or without working on the code: ##### *without code : simple extensions without variables or new conditions* start by writing up the new text (piece of dialogue) you want your buddy to say. this should only contain already known variables, if any, i.e. variables that already occur in the other text messages or are already calculated in the code in the dictionary `chat_variables_dict`. mark these variables with square brackets [] so they can be substituted for the correct data when the app is running. examples for the text column are: ""hello, fellow kid"" or ""the last time we went [workout_name] was on [date_last_logged]"" next, you choose a tag. this can be new or an already known tag. if you want to start a new tag, you should make sure that another message refers to this new one in 'next-tag', otherwise the loop will never be able to find this message. if you choose an already existing tag, it means that the new message belongs to the same group of messages. so it should make sense in relation to the content of the message that comes before it. afterwards, it must be determined what kind of message follows next, i.e. set the next-tag. again, you have the option to use known or new tags, paying attention to the logic as well: is the new next-tag already a tag in another line or will you unintentionally end up with a dead end? do the messages that have the next-tag set here really fit as follow-up messages to my message? in addition, you can also leave the field empty, which means that the conversation is over after that. with the columns friendship min / max you can define how good you have to be friends with the buddy for that message. you can set from which level a message can be displayed at all or from which level you are already so good friends that the buddy does not even say a certain message anymore. you probably would not greet strangers with ""well, you old sock"" or say goodbye to friends with ""it was nice to meet you"", would you? if you have several messages (i.e. lines/rows) that match or build on each other thematically, you can set the column set_group instead of setting new tags for all of them. as soon as a message is selected that has been assigned to a group, this is adopted for all subsequent messages. as an example, bo talks about potatoes in one message and later mentions that he now feels like fries. this ensures that topics are not suddenly dropped or appear without reference. ##### *with code: new variables and complex conditions* if you want to create **new variables**, you should observe the following instructions in addition to what has been explained so far: the code automatically reads the square brackets `[variable]` with the variable, then looks for this string in the keys of the dictionary `chat_variables_dict` and replaces that with the corresponding value. to create new variables, it is mandatory to extend the code and have an understanding of where to find the information you want to put there. so the theory, now for the practice: find in `main.py` the function `get_dict_chat_variables()`. inside the function, mark with comments which variable is defined at the position. here you can add your new variable by setting it as a key in the class variable `fitnessapp.chat_variables_dict[""variable""] = value` and assigning it a value calculated by you beforehand. to access data from the logger, the table is read in at the beginning of the function and stored in `logger_df` filtered directly according to the previously selected workout. so what would the code look like if you wanted to specify when you first did the workout with your buddy? ```python # [date_first_logged] # in dataframe logger_df in column 'date', get the minimal date date_first_logged= logger_df[""date""].min() # save to key ""[date_first_logged]"" the value of the first workout calculated before fitnessapp.chat_variables_dict[""[date_first_logged]""] = date_first_logged ``` in your csv file, just write your new variable in brackets in the text (with spaces around the brackets:' [new_variable] ') and watch it get automatically replaced by your calculation. similar to new variables, the code for **new conditions** must be extended according to one's own wishes. in addition, a new column must be created in the csv file, which also must be applied for all conversation csv files for all buddies. extending the csv: if you want to display messages only on the basis of certain conditions, you should think of a logic for this. for example, a conversation about a workout is only started if the logger table for the workout is not empty. for this purpose, the column 'logged any' is used, whose entry is if no workout has ever been logged. within the code, the system checks whether more than workouts have been logged. if this is the case, all lines that have a zero in the column are filtered out. if you want to make a new conditional statement, you have to create a new column and fill new rows according to your own logic. extend the code: in the code of `main.py` a new filter must be implemented under the function `fill_conversation_list()` within the while loop. depending on the self-selected condition, the dataframe `subset_buddy_convo_df` must then be delimited, which at the end determines which sentence is to be said next. </details> <a name=""acknowledgements""></a> # acknowledgements we would especially like to thank our instructor and mentor maria, who accompanied our project from the beginning full of helpfulness, discussed every new crazy idea we had with us and gave us the assistance and support we individually needed to realise this project."
0,BaytreeMentorPortal,"mentor portal for a british charity organization named ""baytree centre""","## project introduction web application developed for the baytree centre by team mars. allows administrator and mentors more convenient engagement with the program. for mentors, the web application will simplify session report processes, quicker access to resources, and receive notifications for overdues and upcoming events/sessions. admins can create and manage mentors, and see statistics of mentors to get an overview of how they are performing. ## project structure: the frontend and backend are separated into ""client"" and ""server"" folders. the design pattern we followed here is mvc (model view controller). model and controller are in the backend, whereas frontend is the view. ### frontend frontend, built using react and typescript, is strucutured in components and pages, all in separate folders based on their needs. the reusable components are in components folder, whereas the pages folder contains subfolders, separating pages of the web app. <br>**/client/src/config/config.ts**: copy of the `config.ts.sample` file with the name `config.ts` is required in the */client/src/config/* folder to run the project. it is added to git ignore, so it is meant to be maintained locally. ### backend backend server is developed using a nodejs library named ""expressjs"". for database, we used mongodb. app.ts is the entry point of the server, rest of the code is in *src* folder. *config* folder has all the configurations (database config, authentication config etc). folder has all the api related files, such as *models*, *controllers*, *routes*, *middlewares*, *services* etc. *models* folder has all the database schemas, *routes* folder has the api endpoint methods. *middlewares* folder has the middlewares that are necessary for each of the routes. *controllers* processes response in json and return to the frontend. copy of the `config.ts.sample` file with the name `config.ts` is required in the folder to run the project. it is added to git ignore, so it is meant to be maintained locally. username and password of the views account need to filled in in that file to be able to access most part of the application. frontend: backend: ## run instructions ### frontend: #### cd client this will change directory to *client* folder, where frontend code is. #### npm install or npm install --legacy-peer-deps install all the necessary npm packages. #### npm start runs the frontend server locally at port ### backend: #### cd server this will change directory to *server* folder, where backend code is. #### npm install install all the necessary npm packages. #### npm start runs the server locally at port database starts at port you can connect through mongodb compass. ### deployment the app is deployed using nginx for server and for running `npm start` for both frontend and backend in the background. ""production"" branch has the final tested version that is deployed. for testing purposes, we created an admin with email ""admin@bt.com"" and multiple users that can found on mentors list from admin account. all of them have the same password: ## build directions ### frontend #### npm run build builds the frontend part of the project. ### backend #### npm run-script build builds the backend of the project, creates *dist* folder to create .js files after compiling .ts files. #### api documentation: - root uri: - login: - post ""/auth/login"" : - mongodb collection name: ""users"" - request body (type: raw) is json: {""email"": ""< email-address >"", ""password"": ""< password >""} - response: {email, roles, accesstoken, personid(add later)} - sign up: - post ""/auth/signup"" : - mongodb collection name: ""users"" - headers: key= x-access-token, value= < **admin**-token-from-login > - response: {email, personid, roles} - authenticate and authorize: - get ""/test/admin"" - get ""/test/mentor"" - get ""/test/mod"" - for all above: headers: key= x-access-token, value= < token-from-login > - mentors list: - get ""/auth/admin/mentorlist"" : - mongodb collection name: ""userinfos"" - headers: key= x-access-token, value= < **admin**-token-from-login > - response: {result: []} - my records: - get ""/auth/records/"" : - headers: key= x-access-token, value= < **user**-token-from-login > - body: { personid } - response: {message, sessions: [], questionnaires: []} ### licence apache license version january http://www.apache.org/licenses/ terms and conditions for use, reproduction, and distribution definitions. ""license"" shall mean the terms and conditions for use, reproduction, and distribution as defined by sections through of this document. ""licensor"" shall mean the copyright owner or entity authorized by the copyright owner that is granting the license. ""legal entity"" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. for the purposes of this definition, ""control"" means (i) the power, direct or indirect, to because the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent or more of the outstanding shares, or (iii) beneficial ownership of such entity. ""you"" (or ""your"") shall mean an individual or legal entity exercising permissions granted by this license. ""source"" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. ""object"" form shall mean any form resulting from mechanical transformation or translation of a source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. ""work"" shall mean the work of authorship, whether in source or object form, made available under the license, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the appendix below). ""derivative works"" shall mean any work, whether in source or object form, that is based on (or derived from) the work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. for the purposes of this license, derivative works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the work and derivative works thereof. ""contribution"" shall mean any work of authorship, including the original version of the work and any modifications or additions to that work or derivative works thereof, that is intentionally submitted to licensor for inclusion in the work by the copyright owner or by an individual or legal entity authorized to submit on behalf of the copyright owner. for the purposes of this definition, ""submitted"" means any form of electronic, verbal, or written communication sent to the licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the licensor for the purpose of discussing and improving the work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as ""not a contribution."" ""contributor"" shall mean licensor and any individual or legal entity on behalf of whom a contribution has been received by licensor and subsequently incorporated within the work. grant of copyright license. subject to the terms and conditions of this license, each contributor hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute the work and such derivative works in source or object form. grant of patent license. subject to the terms and conditions of this license, each contributor hereby grants to you a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the work, where such license applies only to those patent claims licensable by such contributor that are necessarily infringed by their contribution(s) alone or by combination of their contribution(s) with the work to which such contribution(s) was submitted. if you institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the work or a contribution incorporated within the work constitutes direct or contributory patent infringement, then any patent licenses granted to you under this license for that work shall terminate as of the date such litigation is filed. redistribution. you may reproduce and distribute copies of the work or derivative works thereof in any medium, with or without modifications, and in source or object form, provided that you meet the following conditions: (a) you must give any other recipients of the work or derivative works a copy of this license; and (b) you must because any modified files to carry prominent notices stating that you changed the files; and (c) you must retain, in the source form of any derivative works that you distribute, all copyright, patent, trademark, and attribution notices from the source form of the work, excluding those notices that do not pertain to any part of the derivative works; and (d) if the work includes a ""notice"" text file as part of its distribution, then any derivative works that you distribute must include a readable copy of the attribution notices contained within such notice file, excluding those notices that do not pertain to any part of the derivative works, in at least one of the following places: within a notice text file distributed as part of the derivative works; within the source form or documentation, if provided along with the derivative works; or, within a display generated by the derivative works, if and wherever such third-party notices normally appear. the contents of the notice file are for informational purposes only and do not modify the license. you may add your own attribution notices within derivative works that you distribute, alongside or as an addendum to the notice text from the work, provided that such additional attribution notices cannot be construed as modifying the license. you may add your own copyright statement to your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of your modifications, or for any such derivative works as a whole, provided your use, reproduction, and distribution of the work otherwise complies with the conditions stated in this license. submission of contributions. unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you to the licensor shall be under the terms and conditions of this license, without any additional terms or conditions. notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with licensor regarding such contributions. trademarks. this license does not grant permission to use the trade names, trademarks, service marks, or product names of the licensor, except as required for reasonable and customary use in describing the origin of the work and reproducing the content of the notice file. disclaimer of warranty. unless required by applicable law or agreed to in writing, licensor provides the work (and each contributor provides its contributions) on an ""as is"" basis, without warranties or conditions of any kind, either express or implied, including, without limitation, any warranties or conditions of title, non-infringement, merchantability, or fitness for a particular purpose. you are solely responsible for determining the appropriateness of using or redistributing the work and assume any risks associated with your exercise of permissions under this license. limitation of liability. in no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any contributor be liable to you for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this license or out of the use or inability to use the work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such contributor has been advised of the possibility of such damages. accepting warranty or additional liability. while redistributing the work or derivative works thereof, you may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this license. however, in accepting such obligations, you may act only on your own behalf and on your sole responsibility, not on behalf of any other contributor, and only if you agree to indemnify, defend, and hold each contributor harmless for any liability incurred by, or claims asserted against, such contributor by reason of your accepting any such warranty or additional liability. end of terms and conditions appendix: how to apply the apache license to your work. to apply the apache license to your work, attach the following boilerplate notice, with the fields enclosed by brackets ""[]"" replaced with your own identifying information. (do not include the brackets!) the text should be enclosed in the appropriate comment syntax for the file format. we also recommend that a file or class name and description of purpose be included on the same ""printed page"" as the copyright notice for easier identification within third-party archives. copyright licensed under the apache license, version (the ""license""); you may not use this file except in compliance with the license. you may obtain a copy of the license at unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an ""as is"" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license."
1,opinionstage-wordpress-plugin,"poll, survey & quiz maker plugin by opinion stage","=== poll, survey & quiz maker plugin by opinion stage === contributors: opinionstage, yoffegil, kucaahbe donate link: https://www.opinionstage.com tags: poll, quiz, survey, poll plugin, quiz plugin, survey plugin requires at least: tested up to: stable tag: requires php: add a poll, survey, or quiz plugin to your wordpress site. create a poll, quiz, or survey from scratch or based on templates. == description == = live demos: = * personality quiz * trivia quiz * lead quiz * competition quiz * list poll * image poll * thumbnail poll * head to head poll * feedback survey * satisfaction survey * user experience survey * website design survey opinion stage is a poll, survey and quiz maker plugin for wordpress. it is the easiest way to create anything from opinion polls, feedback surveys, buzzfeed-syle quizzes to contact forms. you can create the items from scratch or using hundreds of optimized templates. == main poll, survey & quiz wordpress plugin features: == * easy and fast to create polls, surveys and quizzes either from scratch or using one of the hundreds of free templates. * integrate images & videos into the polls, quizzes and surveys. * customize the look & feel by selecting the color theme, fonts and size. use the css override feature to fully match design to your site and brand. * white label the widgets and add your own logo. * display poll & survey results in real-time. * advanced analtyics dashboard for quizzes and surveys with both results and performance tables and graphs. * export all the details to a csv/xls file. * integrates with social networks (e.g. facebook, twitter, etc) to promote sharing and viral distribution of polls & quizzes. * notify with email on quiz & survey submissions. * add call to actions at the end of quizzes & surveys. * use survey and quiz branch logic that let us you determine which question is asked next based on the answer to the previous question. * integrate with your marketing automation using native integrations (e.g. mailchip, hubspot, etc), zapier.com or webhooks. * embed in a single post/page or display in a sidebar or section placement. * popup the items automatically when users enters/exits the page. * responsive design that optimizes display of polls, quizzes and surveys in desktops, tablets and mobile devices. https://www.youtube.com/watch?v=dmcosycbfds == templates & examples == start from scratch or use one of the hundreds of templates to get up and going super fast with an optimized item. == integrations == opinion stage offers dozens of integrations with all the top email and marketing services. opinion stage native integrations (e.g. hubspot, mailchimp, etc), zapier integration, webhook integration and an api. == polls your visitors == create polls in seconds to engage your users and learn what they think on any topic. the polls are full of features that let you customize every aspect of the poll functionality. use the report dashboard to get detailed real-time analytics on the votes. == quizzes for engagement & gathering leads == create buzzfeed-style and facebook-stlye quizzes that engage your users and get viral on social networks. integrate a lead form in your quiz to gather qualified leads. the quiz questions will be associated with the contact information you gather to help you qualify which leads bring value to your business. == surveys for getting insights and feedback == survey your users to get feedback and to conduct research that will help you improve your site or produce/service offering. opinion stage supports many different question types and many different features that will help you create unbiased surveys that produce quality data. == why use opinion stage? == * boost engagement & traffic - add a poll, survey or quiz to your posts/pages to increases participation, time-on-site & page views. increase social sharing and viral distribution. * gather more qualified leads - integrate a lead form inside the poll, quiz or survey. * drive sales/revenue - take advantage of the high engagement rates to increase revenue from ads inside and outside of the polls and quizzes. * extract insights - get more insights using interactive polls & surveys designed to maximize participation. extract actionable insights with an intuitive analytics dashboard. == best practices for creating an effective quiz == * start by setting the objective before starting to plan the quiz, determine what you want to achieve. are you looking to generate engagement, to gather leads, to drive social sharing, or do you have a different motivation? for example, if you are looking to generate leads, it is usually better to keep it shorter. if you are looking to generate engagement you will prefer to make it longer. if you are looking to get social shares, your focus should be on designing an outcome that will get shared. * select a topic based on your audience in the planning phase, keep your audience in mind. what topic will they find interesting or appealing? a quiz that works great for one audience, might not perform as well for another audience. select a great title the title is the single most important part of a quiz. select a title that appeals to your audience, makes them interested or curious to discover something about themselves or about others. try to keep the title clear and short as possible. add humor when relevant. * keep it short, but not too short if the quiz is too short, users tend to regard it as not serious enough or as content that will not bring much value. however, if it is too long, users will get tired and drop-off. at some point, adding another question will get you fewer responses. we recommend including questions depending on the context. * make it visual opinion stage let us you add images and videos in the quiz. you can add an image to the cover, and an intro image to each question. you can also add an image to each answer. visuals will both get you more responses and will also improve the context of the questions and answers. * get shared in social networks start by creating outcomes that are shareable. examples can include sharing your results in a trivia quiz or sharing the personality you got in a personality test. it is recommended to keep the outcome text as positive as possible regardless of the results. place in a prominent location to verify your item is noticed, place it in a central place in your site. a few options we recommend above the fold in posts/pages, in the sidebar, enter/exit popup, or in a quiz section in your site. * brand and customize opinion stage let us you change every aspect of the visual. customize the quiz so it matches your site and brand. you can set the font, sizes, and colors of the quiz. if you have some css knowledge you can customize almost every aspect of the quiz using the css override feature. * track and optimize opinion stage let us you track every aspect of the performance, including how many users viewed, started, and completed the quiz. track these parameters and use the drop-off report to optimize the length and to find questions that need to be replaced or improved. for more advanced usage scenarios you can also a/b test. == language support == opinion stage supports over languages, missing a language? let us know! == about opinion stage: == opinion stage is a powerful & easy-to-use interactive content (e.g. poll, quiz, survey, forms, etc) creation service. opinion stages' highly engaging content formats are used to boost engagement, gather leads, generate revenue and to extract actionable insights. opinion stage works with creators, including world-leading publishers, brands & agencies. for more details, visit <a target=""_blank"">the opinion stage site.</a> == installation == upload the plugin to your blog (or search for it) and then install the plugin on your plugins page active it and start creating polls, quizzes, surveys and forms == frequently asked questions == = are opinion stage items responsive? = yes, all item formats (poll, quiz, survey & form) created with opinion stage are fully responsive, and designed to optimally display on mobile, tablet and desktop = what interactive item formats does opinion stage support? = with opinion stage you can create the following item formats: poll, poll sets, personality quiz, trivia quiz, survey, form & story. = what is the difference between a poll and a survey = polls include one question and are used for getting a quick answer on a question. polls are often used for gathering opinions, getting feedback, running contents & competitions and generating engagement. surveys include multiple questions of different types. surveys are often used to gather feedback and insights. if you are still unsure whether to use a poll or a survey, contact our support team and we will be happy to help. = what customization options do you offer for the polls, surveys and quizzes? = opinion stage offers many built-in customization options such as selecting the color theme, font and sizes. use the css override feature to fully match the items to your brand. you can also white label the items and add your own logo. = is opinion stage gdpr ready? = opinion stage makes it easy for you to comply with the gdpr regulation. for more info on that, read our gdpr and privacy policy documentation on the site == other notes == == screenshots == poll example survey example trivia quiz example personality quiz example gather leads with polls and quizzes example quiz layouts templates example quiz analytics example poll for boosting engagement example quiz cover example == upgrade notice == n/a == changelog == = = * the ""standard form"" block was deprecated * minor text updates * minor style changes * internal code improvements = = * internal code improvements * tested up to wordpress = = * internal code improvements * tested up to wordpress * design update = = * tested up to wordpress * fix deprecated 'block_categories' filter * internal code improvements = = * tested up to wordpress = = * tested up to wordpress = = * tested up to wordpress * readme update = = * internal code improvements * tiny ui update = = * new tutorials & help experience * new getting started experience * internal code improvements = = * internal code improvements = = * internal code improvements = = * new getting started experience * internal code improvements * readme update = = * internal code improvements = = * ui update for not connected users = = * readme update = = * internal code improvements * tested up to wordpress = = * new getting started experience * content popup shows widget status and update date * updated plugin name * renamed classic form block to standard form * internal code improvements = = * fix: remove style that affects on other gutenberg blocks = = * readme update = = * ui update = = * internal code improvements * fix not loading widget popup on add post page = = * internal code improvements * my items page ui update * removed placements page * modified sidebar widget management ui = = * internal code improvements * tested up to wordpress = = * ui update * internal code improvements = = * fixed html render issue on create items page = = * updated plugin name * added poll on disabling plugin * renamed form block to classic form * internal code improvements = = * updated signup functional * internal code improvements = = * signup callback - higher priority added = = * fix templates links = = * deprecate set, slideshow & list * content popup ui/ux fixes * gutenberg ui/ux fixes = = * remove excessive logging = = * gutenberg integration rework * various internal code improvements = = * fix wordpress compatibility issues = = * readme update = = * ui update * readme update = = * tested up to wordpress = = * fix for missing php files = = * misc ui fixes and improvements * fix for rtl languages = = * icon issue fix * gutenberg duplicate resources fix * ui changes (images issue, and some other tweaks) = = * fix gutenberg integration = = * fix login issue * add disconnect button to ""getting started"" screen = = * fix sidebar on/off checkbox = = * fix placements links = = * fix message display = = * remove external curl dependency = = * security fixes = = * security fixes = = * readme update = = * readme update = = * added support wordpress * removed support for php versions lower than = = * bugfixes = = * readme update = = * bugfixes = = * ui looks & feel revamp = = * support and readme updates = = * gutenberg fixes and improvements = = * gutenberg fix = = * my items page * updated content popup * design update = = * readme update = = * readme update * analytics setup = = * navigation links update = = * add support for new editor gutenberg = = * readme changes * add admin loader = = * new getting started experience = = * wordpress compatibility * readme update = = * assets loading fix * readme update = = * permission fix on sub pages = = * icon set fix = = * double page bug fix * plugin renamed = = * plugin rename: improved fix = = * plugin filename fix * backward compatibility added = = * new navigation added * fixed placements issue = = * better ajax handling = = * fix deactivation issue = = * stability fixes * added deactivate screen = = * more updates to readme.txt file = = * rename plugin * update to readme.txt file * small text changes = = * small text changes = = * readme update = = * readme update = = * add story support = = * fix php installations older than = = * fix links to content = = * minor text updates = = * tested up to wordpress version * minor textual changes = = * fix content popup video placing issue = = * adds video intro = = * adds ability to sign in from content popup * various ui/ux issues fixes = = * content popup ui/ux improvements * login/logout ui/ux = = * content popup ui/ux improvements = = * minor textual changes = = * minor logging changes = = * new feature: post editor integration = = * minor changes = = * support for wp version = = * minor styling fixes * widgets embedding refactor = = * sidebar widget fix = = * prevent internal font icon leak into site area = = * minor fixes = = * fix sidebar widget settings style * add slideshow * fix contactform icon * fix video tutorials help link = = * fix menu page styling = = * add a slider content format = = * additional survey features based on client requests = = * improvements of quiz/survey reporting * various minor bug fixes = = * responses table improvements, language fixes, advanced editing in after vote notifications = = * various fixes & optimizations = = * display comment after user votes * additional advanced reports = = * add new charts to the poll, quiz & survey reports = = * display an explanation after voting in polls * fixed bug with ip blocking = = * new drop-off report * async sending of leads = = * add css override to all content types * support gtm integrations = = * improved quiz/survey reporting capabilities = = * added support for pixel tracking = = * support for wordpress = = * improve support for high volume lead configurations = = * text changes and bug fixes = = * various minor fixes & optimizations = = * added ad refresh mechanism = = * added verification for the placements ids in the connection callback function = = * various minor improvements & bug fixes = = * added chatbot tool integration = = * updated help for new features = = * rebranded quiz name to outcome, removed the section entry = = * resolved an issue with the font = = * added support for creating contact form builders, added to plugin name = = * added support for creating surveys, renamed plugin = = * support wp = = * added the option to add a content section = = * modified api path = = * various optimizations = = * security fix to limit accses to dashboard = = * various optimizations = = * added the option to embed using a fixed width = = * modified sidebar widget management ui * replaced dashboard top navigation links with more prominent 'my content' link * added 'list' to the plugin name = = * various small optimizations = = * various ui modifications - added top navigation links, dashboard ui is now more responsive. = = * renamed style to avoid css caching issues = = * complete ui revamp * removed obsolete polls insertion popup and tinymce integration * handling compatibility issues with other plugin = = * various poll, survey, quiz, slideshow, form & story article improvements = = * not showing recommendations by default when embedding trivia quiz and personality quiz via the widget shortcode = = * added support for disabling fb comments, sharing buttons and recommendations for trivia quiz and personality quiz via the widget shortcode = = * improved polls & quizzes creation help file * various small issues = = * added creation links for trivia quiz, personality quiz and lists * added a link for content discovery = = * support creating a quiz draft * added quiz tips and quiz best practices = = * better name for widget following feedback = = * added personality quizzes = = * renamed plugin to better reflect the contact form builder = = * added shortcodes for trivia and personality quizzes = = * various trivia quiz enhancements & fixes * support for iframe embeds = = * support for basque & vietnamese languages * trivia quiz beta = = * added support for quick addition of any language = = * added text domain = = * poll discovery mechanism improvements * additional tracking capabilities = = * various bug fixes = = * css modifications to better align with desired coding standards. reverted css file name change. * minor text changes * not using php style constructors any more = = * fixed broken links to dashboard * renamed css file = = * modified css structure * added an option to enable/disable sidebar widget directly via the widget box = = * added a control switch for the sidebar placement = = * added sidebar placement as a widget = = * added the option to connect the plugin to opinion stage account * added plug & play integration for fly-out placement * replaced the option of adding polls to all posts with plug & play article section placement = = * additional fix for supporting ssl = = * support for ssl when voting with social profiles * revamp of content recommendation mechanism = = * poll placement improvements = = * plugin minor changes = = * image cropping = = * new poll recommendation design = = * resolve conflicts = = * fixed compatibility issues = = * first trivia poll poll, survey, quiz, slideshow, form & story article version = = * various functionality & usability improvements = = * head-to-head poll - new revamped ui (first poll, survey, quiz, slideshow, form & story article version) = = * new look & feel settings = = * allow disabling global poll section for specific posts = = * texts changes = = * new options for adding polls or sets to all posts = = * poll sets and poll placements - improved interface = = * ad integrations (optional) - revamped interface = = * added ui support for social logins = = * new ui for multiple choice polls = = * various stability fixes = = * post vote actions = = * contact form builder improvements = = * various fixes = = * poll discovery first poll, survey, quiz, slideshow, form & story article version = = * placements first poll, survey, quiz, slideshow, form & story article version = = * various fixes = = * smart containers first poll, survey, quiz, slideshow, form & story article version = = * allow users to add their own answers * polls - mobile optimizations = = * support adding custom texts to the interface * solve minor ui issues = = * support displaying ads before showing the results * support reordering the sides of the poll = = * added the option to add facebook comments to the polls * improvements to poll creation flow = = * new poll head-to-head themes * poll ui optimizations = = * various additions and improvements to the poll style studio * support for wide pages = = * improved poll built-in ui styles * new capabilities to poll style studio = = * improved poll reports * various minor improvements = = * poll percontact form builderance improvements for peek scenarios * new banner type ad unit = = * improve process of adding polls to site * improve returning traffic tracking mechanism = = * add first of poll discovery feature * resolve issue with image addition = = * add the option to integrate advertisement into the polls for generating revenue * optimizations for poll display in mobile environments = = * enhancements on contact generation feature * mobile polls improvements * additions to default poll settings = = * poll discovery - first poll, survey, quiz, slideshow, form & story article version * poll sets improvements * poll percontact form builderance improvements = = * added an account report dashboard = = * resolved paypal integration issues * resolved facebook page integration issues = = * renamed plugin to better reflect the contact form builder = = * fixed poll display issues = = * added the ability to insert a shortcode of a set of polls * added a widget for a container and for a set of polls = = * created a widget for easily adding polls to site = = * poll contact form builder optimizations = = * resolved issues with polls on mobile = = * add external integration with parties via api/xml mechanism = = * support collecting emails from poll voters = = * fixed potential collisions with other plugins = = * first of poll sets * first of redirect after poll vote * fix related to languages in poll display = = * fix issue with mobile voting * fix for iframe embed of poll * fix for uploading images from computer = = * added czech language & fix for polish * add poll images via url = = * improve poll login screen in mobile * fixes for poll container = = * fix issues with voting on iphone/ipad = = * new poll container * improvements to the poll optimization dashboard = = * new graphs for the new reports page * new languages - romanian, polish, indonesian, danish = = * new poll navigation bar * new languages - dutch, albanian, lithuanian = = * new dashboard and site header * poll was translated to the following languages - swedish, turkish, chinese, japanese, korean = = * added the option to login to opinion stage with a email/user-name and password combination = = * added geographic location filter to poll results dashboard = = * added time filter to poll results dashboard * new design for on site poll page * various improvements & fixes on poll results dashboard = = * added the option to block repeat voting in polls by ip = = * improvements & fixes on poll studio = = * improvements & fixes on poll reporting statistics * improvements & fixes on poll core flows = = * added to the poll results screen the following poll stats: poll engagement stats, poll social stats & poll traffic stats = = * add a clone function that allows to easily create multiple polls from the same template * add the option to schedule when the poll will be closed = = * revamp of the poll social sharing settings * revamp of add poll to website screen = = * add facebook comments to polls added to facebook pages * add the option to preview the poll in different widths = = * improvements to poll style studio * added option to configure head to head polls not to show results before voting * added the option to configure all types of polls not to show results to voters * extended width support of head to head polls to pxls = = * additional social filters added to the poll interface & poll report * optimize poll sharing scenarios = = * improvements on poll sharing scenarios = = * add polls to facebook pages in feature added * enhanced poll reporting that includes poll result filters * brightcove video now supported in the polls = = * added support for google+ poll login * fixed a presentation issue with polls and https sites * fixed issue with poll display on facebook pages = = * localize polls for russian and french * new design for poll social login dialogue * polls now auto-detect https environments * various minor fixes and improvements to poll functionality = = * polls are now localized for portuguese * various minor bug fixes = = * multiple sided polls are supported for widths and above * head-to-head polls are supported for widths and above * poll style studio was improved to included many more poll style options * new improved poll dashboard * poll showcase was improved to include more poll examples and detailed explanations = = * multi-sided polls support addition of multimedia (video and image) * both head-to-head and multi-sided polls - multimedia support auto-fit for different width (e.g mobile environment) = = * multi-sided polls support addition of multimedia (video and image) * both head-to-head and multi-sided polls - multimedia support auto-fit for different width (e.g mobile environment) = = * ui improvements for the polls (filters, border etc) = = * poll creator can select number of allowed poll answers * fb poll sharing flow optimizations * poll results can be shown from the opinion-stage poll dashboard = = * new hybrid voting method added to the polls, allowing users to vote either via a social profile or completely anonymously = = * added support for anonymous poll voting = = * improved editing process of polls by adding a preview to the poll editing screen * additional layout customisations for polls - hide top bars, add bottom padding * polls can now be reset = = * additional poll languages support (german, italian, serbian) * additional poll customisations for the vote sharing process = = * additional customisations options to the poll: define which poll filters to show, poll social sharing bar removal * hiding vote option can be enabled / disabled by poll creator = = * added support for multiple selection polls = = * better support for hiding user votes in the poll * improved embed options to support both dynamic and constant width for the polls * polls can now be closed from the opinion-stage dashboard = = * improved creation flow of polls * added basic report per poll in the opinion stage polls dashboard * added account report in opinion-stage poll dashboard = = * polls are now localized for arabic * better support for sidebar polls * supporting longer side texts in polls = = * polls are now displayed properly in mobile environments * additional built-in poll themes * when clicking on poll participants, the user is now redirected to their social network profile * polls are now localized for spanish * you can now set whether you would like to display the number of votes in the poll * support for election polls (e.g. poll results displayed in points, add a minimum cliff, etc) = = * support for multiple sided polls * added the option to configure the url in which the poll will be hosted. this will allow to direct additional traffic from social network shares and emails back to the location where the poll is hosted * added the option to set the order in which the poll results are displayed. you can either set it so that the poll sides are located in the order they were configured or set them so that the side with the most votes is displayed on top = = * poll width can now be set, supported poll widths are pxl * poll widget contact form builder optimizations for high traffic polling deployments * support customized color themes for the polls = = * added an optional gender filter to the poll, so that poll results can be viewed by gender * added a central dashboard for managing all polls * added the option to display a detailed text description of the poll question to the poll widget * added the ability to configure which image is shared when sharing the poll or the poll vote on facebook = = * improvements in the poll embed flow to ease insertion of polls = = * first social poll version"
0,bluetooth-p6,"white paper describing a potential approach for using bluetooth for privacy preserving proximity matching, in the context of contact tracing apps for","# **privacy preserving proven prior proximity protocol the authors of this paper may be contacted at at `approov.io`. # problem statement in the fight against the technique of contact tracing is used to determine prior contacts, so that these people may be warned that they have been placed at risk and should take preventative measures in case there has been transmission, such as self isolating. this is highly relevant to where there is a long infectious incubation period without symptoms. the contact tracing process can be done manually but is unreliable and cannot be scaled. contact tracing is proven to flatten the all important of infection propagation value whilst minimizing societal disruption. thus there is a need to automate this process using technology. modern smartphones provide an ideal way to do this. they are ubiquitous and always carried throughout a large percentage of the population and have relatively accurate location tracking capabilities. cloud side analysis allows location tracks of individuals to be analyzed to find intersection points and identify risks of transmission between individuals. at risk individuals can then be alerted early to allow behaviour modification as their infection risk has been elevated. there has also been some past research on using bluetooth as a way of communicating between devices in close proximity to perform this tracking. bluetooth is a low energy radio protocol that is ubiquitous on modern smartphones. the challenge is to make this work at scale in a way that is compatible with existing devices in the field that does not require significant changes to the use model of apps or the oses that run on them. we also discuss how a variant of this approach might also be used to evaluate the effectiveness of social distancing measures. # concurrent efforts given the situation there is a burgeoning interest in this area, in the hope it can be rolled out quickly to fight the current outbreak. a highly relevant article was published while this document was in preparation (sunday march). this page mentions the coepi project that plans to use bluetooth scanning technology to identify devices. this seems to be in somewhat active development. on tuesday march oxford university published this release. it includes models showing how a contact tracing app could have a significant benefit in reducing the rate of infection. it has more data with a policy piece and presentation that has very similar concepts to the plan laid out in this document. there are no specific technology ideas around the app itself other than its use of location data tracking. a news article from thurs march describes states coronavirus: mobile app that can trace and warn individuals of exposure to infected people is need of the hour. another news story from march indicates that the uk is about to roll out location tracking, although it appears that individual data is still anonymized at this stage and the primary intent is to examine aggregated flows. on friday march singapore launched the tracetogether app. this is an opt-in bluetooth tracing app as explained here. another news article covers the development. it appears the app works by assigning each user with a randomized id that is advertised over bluetooth, and detected over scanning. the relationship between a users phone number and random bluetooth id is made known to the authorities but nobody else. the app needs to run in foreground on ios due to the known restrictions of bluetooth use imposed by apple. this article states that the mobile number and its corresponding permanent id are stored in a secure server. as an added layer of protection, tracetogether creates temporary ids that change regularly. only these temporary ids are exchanged between phones so it would appear that a reasonable degree of privacy is maintained. a more detailed faq deals with some of the concerns that users might have. on monday march a commitment was made to open source the code and the underlying bluetooth protocol here. there are also reports that india is developing an app that is partly based on bluetooth proximity, although the privacy aspects of this app are very unclear at present. a good overview of the stance of various countries to digital tracking for is provided in countries are now tracking phone data as the coronavirus pandemic heralds a massive increase in surveillance. in the uk where nhsx is developing some kind of yet undefined, contact tracing app there is concern over the implications for privacy. this article provides a good overview of approaches and methods to maximise privacy. there are also suggestions that the functionality could be built directly into the operating systems. # general challenges as prior articles point at there are some general challenges with the approach: * the effectiveness of measuring proximity and how well this actually correlates to the chances of transmission * whether the behavioural impacts of making the app available actually lead to societal level improved outcomes - e.g. would people tend to mix more given some sense of security of the app than they otherwise would * the app cannot track transmission through the environment itself, such as dirty surfaces, and if this accounts for some high percentage of actual transmissions then the proximity aspect is less valuable * the percentage of the population using smartphones that have the requisite capabilities. in particular these are much less prevalent in older age groups. * the impact on privacy, and how that impacts take up * getting the population to use the app. a more difficult challenge in less authoritarian or communitarian societies. * even if the use of the app is supposedly voluntary, there is a distinct danger that private actors will ask to see the status of a user in the app and might restrict access to locations for those who refuse to do this, or do not use the app. the design of the app should account for this possibility, perhaps by making it impossible to view the status more frequently than once a day (for instance) so that a user cannot be reasonably discriminated against for being unable to show their status. # known approaches ## cloud proximity matching with pre-existing data sources many apps already collect large amounts of data on our movements. telecom companies are also tracking the cell towers being used all the time. in china there is a large network of cctv with automatic face recognition in place already. thus there is a plethora of relatively coarse grain tracking information already available. normally there are significant concerns about the use of this data, but in the current circumstances it may be co-opted for proximity measurement. this seems to be the approach that south korea has taken and has demonstrated success. there are obviously massive privacy concerns around this approach. ## cloud proximity matching with dedicated app in this case a specific app is launched and makes individuals movements available in the cloud. if a user becomes infected then it becomes possible to retrace their movements and correlate them with others that can then be informed. again, this comes with significant privacy concerns. see iran launched an app that claimed to diagnose coronavirus. instead, it collected location data on millions of people. similar moves in the us have also been met with significant concern around the privacy aspects. ## app local proximity matching in this case a specific app is launched that collects location data, but this is not transmitted to the cloud but remains only on the users device. the location traces of infected persons are then downloaded to the app and it locally checks the traces for proximity. it highlights any match, but this does not necessarily have to be communicated back to the cloud. if a person becomes infected in the future then they will need to publish their prior location trace for others to match against, so a privacy loss does occur in this case but only in the case of infection. mechanisms could be put in place to redact areas around an individuals home (or place of work), to minimise the privacy loss - although of course depending on the size of the redacted area this risks losing real proximity matches close to home. on march israel launched an open source app based on this model called the shield. this particular app is read-only, in that a map of potential infection areas and times are downloaded from the cloud for local comparison against a user's movements. the app itself does not seem to have an ability to upload information if the user is found to be infected. it is unclear how this information is extracted. perhaps it is only done using a manual process. an mit group is also working on a similar concept, albeit at an earlier stage, called safe paths. this may become part of an effort to build an official who app, that may include a contact tracing element in the future. a similar concept called diary is also being developed, referenced from this relevant medium article. # approach this discusses the new approach described in this document, a form of app proximity matching with excellent privacy characteristics meaning that even the person disclosing an infection does not have to reveal their full location history. ## problems with the alternatives alternative approaches might provide some of the basic capabilities for contact tracing, but have significant limitations: * the most significant is the coarse nature of the location information that can be collected. gps traces are notoriously poor despite the theoretical accuracy when outside. furthermore, gps tracking is not possible indoors and location services need to fall back on other approaches such as wifi ranging which have even lower accuracy. thus the contact trace cannot be focused particularly accurately, requiring many more people to be asked to self-isolate and/or take additional measures than is necessary. this severely blunts the effectiveness of the approach. * adoption of the apps may be limited by privacy concerns. this may be impacted by the actual approach taken (as discussed previously) and the level of compulsion and/or sense of civic duty associated with using the app. even given the severity of the situation we face and the purported temporary nature of location tracking, there is a distinct danger that adoption now may lead to increased usage of such privacy invading techniques in the near future. an approach preserving privacy in an understandable and believable manner, as proposed here, should enable more widespread adoption. ## description the approach uses bluetooth to exchange randomized codes between devices that are both running the required contact tracing smartphone app. installation of the app does not require any signup or personal information to be revealed. the exchanged codes are fully anonymized and do not provide any information about the identity of the devices. codes are not repeated for more than one minute so no tracking of individual devices is possible. the app records a trace of the codes that have been received and their timings. this information is never transmitted to the cloud so full privacy is maintained. at some later point if a user has a confirmed case of they are able to make an anonymous disclosure and reveal the random codes that the app will have been transmitting at precise times on the prior days where there is a chance of cross-infection. where the app was unable to transmit at those times the trace of other surrounding devices is provided to allow other devices to determine if they were in the same proximity and also receiving those codes. all users of the app will receive the disclosure and the app will privately check for proximity. if so then they will be alerted to the fact that they may have been in contact with an infectious person, and the time(s) of that occurrence. this information is itself private unless they share this information with authorities (which may be possible in an anonymised way for infection tracking purposes). note that although we discuss the functionality of the contact tracing app in this document, we believe that the real contribution here would be made via an software development kit (sdk) that could be used in a contact tracing app and implement the underlying proposed protocol. ## advantages * the approach offers a provably private anonymized approach to tracing. * its operation and inherent privacy properties are actually quite easy to explain and to be widely understood. of course there may be some level of cynicism about the claims. this can be further disarmed by making the code open source. * since proximity is based on actual close physical distance for some small, but sustained period, it should represent a good proxy of actual cross infection risk. * control of bluetooth transmission energy should allow the proximity range to be kept relatively low and provide enhanced accuracy over gps location tracking approaches that are quite coarse grain and very poor inside (where infection rates are actually higher due to poorer ventilation) * it works without the need for cellular, wifi or gps contact - so ideal for many public transport scenarios ## challenges * this only works if a very large percentage of the population uses it. in order for that to happen it really needs the support of a very large tech company and/or governments. * it is not clear if it is possible to transmit continuously if the app requesting the transmission is in background mode. this is certainly not possible on ios currently. thus it may be necessary to get a large number of major app vendors to integrate the sdk so that the transmit request is coming from their app which remains in foreground. * although it appears reception for background apps when the phone is locked can be achieved, transmission when the phone is locked is less clear. this may require some changed user behaviour to have apps active (even more than usual) in public places to maximise effectiveness. * it may only be possible to measure proximity that is sustained for several minutes - although this will be correlated with chances of transmission. * it is only possible to measure actual proximity, not overlaps in location tracks that may have occurred some minutes after. * there are wide variations in the bluetooth transmission and reception power for different phones, and this may make any accurate approximation of distance very challenging. some calibration across different phone types is likely to be required. * it will have some, as yet unknown, detrimental impact on device battery life. ## approov contribution we are publishing these ideas in the hope that at least some of this will prove useful for the various groups now building bluetooth based apps that aspire to preserve privacy. we do have expertise in the development of sdks for ios and android, as well as the building of backend services to support apps at scale. moreover, we also specialize in securing apis against malicious actors, which may be highly relevant to a widespread deployment of such apps. thus we are interested in working with partners to help build apps along the principles outlined, so they can be deployed at scale as quickly as possible. if you are interested in getting in contact to discuss this then please email at `approov.io`. # bluetooth ibeacon technology ## bluetooth advertising the bluetooth protocol includes the ability for devices to advertise their existence to other nearby devices. this is the mechanism that allows nearby devices to be seen and then connected to. adverts are generated by devices on three different channels in the allocated spectrum for bluetooth as shown below. !bluetooth advertising channels image from: https://www.argenox.com/library/bluetooth-low-energy/ble-advertising-primer/ the use of three different channels offers resilience if an individual channel is blocked due to interference, a device advertises on each channel, one after the other. the rate of broadcast is dictated by the advertising interval on the device. since there is no synchronization between different devices, if the number of devices is too high and the advertising interval too low then there will be significant radio level collisions that because data loss. the advertising channels may also be used for beacons (such as ibeacons) that simply broadcast information on a periodic basis and are never connected to. ## device identification approach note that a possible way to identify individual devices might be to simply advertise the device as a peripheral and provide some unique automatically generated id as part of its name. sufficient entropy may be available for global uniqueness, or at least sufficient uniqueness in combination with some geographic filter. this id could be assigned (anonymously) once and then held statically. this would of course undo the desired privacy preserving characteristics, since individual devices could then be tracked once acquired. alternatively, the id could be reassigned in some deterministic manner after a short period of time. these ids could then be subsequently revealed if a disclosure for the device is made. in order for a smartphone to be discoverable in this way, it would need to enable peripheral advertising. this requires bluetooth low energy peripheral support, and can only occur in foreground. in order to observe other devices which are advertising, it is necessary for a bluetooth scan to be initiated. again, it appears this can only be done in foreground mode (certainly on ios, but should be possible to do it in background on android as discussed here). instead of using a directly identifying id in the advertising packet, the approach described here leverages the ibeacon standard. this has a number of advantages, not least that it is designed to allow beacon detection when the app is in background and even when the phone is locked. this allows continuous proximity scanning, even for a locked iphone, which does not appear to be achievable by an attempt to do continuous scanning of nearby bluetooth devices. moreover, the background monitoring of ibeacons appears to have some hardware support which makes it considerably more power efficient. the downside of the ibeacons is that they are not designed to broadcast variable data so the protocol has to be somewhat abused to allow this, and the maximum potential data rates are limited. ## ibeacon format an ibeacon is a special form of a ble advertisement that does bluetooth connections. it uses a very specific format which is a subset of the overall bluetooth advertisement format. the format is as follows: !ibeacon packet format image from: https://www.argenox.com/library/bluetooth-low-energy/ble-advertising-primer/ many of the bytes are fixed in the format and, to be able to leverage existing support, it is not possible to modify those in any way. in particular there is a proximity uuid associated with the beacon. this would appear to offer plenty of entropy to represent an individual device, with some rotation function over time implementing privacy requirements. unfortunately, however, the searching of ibeacons requires an app to look for particular proximity uuids known beforehand. thus it is not possible, at least using high level ibeacon support, to use the proximity uuid as a way of communicating data directly. the idea is that a particular app is only interested in seeing beacons from a particular organization with a particular proximity uuid allocated and is notified when they come into range. on ios there is a limit of proximity uuids that can be tracked per app (with some underlying hardware limit of about proximity uuids). beyond that notifications are extremely slow and unreliable. the protocol also includes a major and minor field, however. each of these are in length, giving a total of bits. these are meant to be used for having multiple beacons (with the same proximity uuid) in the same area. this allows app use cases where different events may occur when a beacon with a particular major/minor value is encountered. the use case envisaged is that the beacon locations are fixed, and as the mobile device moves around it will get closer to particular beacons with certain major/minor values and this is notified to the running app. the fundamental insight of this protocol proposal is that this capability can be abused to transmit data between devices, by creating beacons with particular major/minor values that are only enabled for short periods of time (such as minute). this will be detected as if the mobile device is moving between fixed beacons whereas in fact the beacons themselves are being modulated in a fixed position with different major/minor values. the hope is that this protocol will enable around of data to be transmitted per minute between devices in close proximity. this is an astoundingly low data rate, but should be sufficient for post facto identification of specific devices. a tx power is also transmitted. given this information and the received signal strength this allows an assessment to be made of the distance of the beacon. this is a notoriously unreliable measurement, however, since it is impacted by so many environmental conditions. transmit power will be kept very low so that only devices in very close proximity can receive the codes. this also helps reduce contention in a crowded environment. all bluetooth messages include a mac address. this identifies the physical device to allow it to be addressed for a connection. the size of the value makes the likelihood of a collision extremely low. ironically, in earlier versions of the bluetooth standard no mac randomization was performed, allowing individual devices to be easily tracked. this is of course exactly the use case we are now trying to implement. most systems have now been updated with a new mac randomization scheme. there does not appear to be a way to easily disable this temporarily or even to ascertain the randomized mac being used at any given point. note this randomization itself has some flaws as pointed out in this disclosure. however, despite this flaw not being fixed as yet it is not useful since it requires continuous monitoring to spot the continuation of message data and associate a device with a new mac. ## device support the ibeacon format was devised by apple and has been available on all ios devices since ios so it is a relatively mature technology. android support is less mature and requires ble peripheral mode to be supported in order to transmit. a list from shows support to be a little patchy, but things have improved a lot since then. more work is needed on understanding what percentage of android population support would be provided in different geographic territories. # protocol ## concepts the basic ibeacon protocol is not designed to allow any transmission of data from the beacon, there are various other beacon protocols that do allow this but these are not as widely supported so are not considered here. an ibeacon is designed to just transmit a globally unique uuid. a given app, listening for specific beacons, can then determine when one is in range and take specific action, perhaps looking up the unique uuid in a backend service. beacons have a unique proximity uuid assigned to them. a specific uuid may be assigned to a particular company using ibeacons. the device may listen for signals being broadcast by a small number of beacons with specific proximity uuids. ## inter-device communication the following shows the communication between two different devices. in reality the protocol allows a given device to be receiving information which is being broadcast by an arbitrary number of devices. at least some of the time a given device will also be transmitting. as shown on the diagram below, the reception and transmission paths are somewhat independent. !inter-device communication firstly considering reception, the device will be set up to listen for beacons on different proximity uuids. the ibeacon protocol requires reception to be filtered on specific uuids so that the information can be filtered at a low (likely hardware) level before being sent to a listening app. monitoring of beacons can occur in the background, even when the phone is locked. the events are passed to the app that records them in the rx trace. information includes the uuid channel and especially the major and minor values which enable the code transmission. the timestamp of receipt is also important since the protocol relies on knowing when matching devices should be sending a specific code. the transmission side uses a tx state that holds the codes to be transmitted. a tx scheduler determines which codes should be being transmitted at a given time slot. transmission will typically require the app to be in foreground (especially on ios) so the likely percentage time transmitting will be lower than that of reception. the implications of this are discussed in a later section. information about what could be transmitted at certain times is stored in the tx trace. this is designed to be very compact, likely of the order of bytes per day. if the app needs to make a subsequent disclosure then this means that the amount of information to be published and passed to all other instances of the app is suitably low. ## randomized code generation random codes are transmitted by a device using an ibeacon. the transmission of these codes is loosely synchronized (to a tolerance of a second or so) between all devices. the codes may be received and traced by other devices. at the time of reception these codes are random and cannot be associated with any particular device. however, if the keys for those codes are subsequently disclosed it is possible for other devices to determine (with high probability) if they encountered that device at some prior point in time. in order to minimize the amount of information that needs to be published in a disclosure, an algorithm is used to generate codes in a progressive manner throughout a day (called an epoch). two random values are generated securely on the device as follows, for each individual day of usage: * _iec (initial epoch code):_ random code generated at the start of each epoch. * _epk (epoch progression key):_ random key generated at the start of each epoch to evolve the random codes being transmitted through the epoch. a key characteristic of the protocol is that individual codes are only transmitted for a short (approximately minute) period, before the device moves onto a new code that is unrelated. codes then evolve using the secret epk. this means that it is not possible to track any individual device. it is generating a sequence of unrelated random codes that can only be matched later if the codes for that device are disclosed. even when such codes are disclosed they cannot be associated with a particular user or device. it is proposed that the secrets are evolved between frames using an hmac with the epk. this should generate sufficiently random results for the relatively small number of iterations required. if hmac results do not have sufficiently random properties then a pseudo-random generating scheme could be used instead, where the iec is effectively a random chosen seed value for the epoch. the generator would need a sufficiently long repeat sequence to avoid attacks whereby the position in the sequence could be determined by an attacker at low computational cost, since that would reveal the future sequence in the epoch and allow an individual user to be tracked. ## transmission time ordering the following provides visualisation of the order of code transmissions that can be made by a transmitting device throughout the day. there are three levels in this timing: * **slice:** a period of time during which the device will be transmitting a single slice code (sc). it is envisaged that the sc transmission period will be of the order of minute, but may be fine tuned later. multiple broadcasts of the sc will occur during this period, depending on the advertising interval, to allow for poor reception and transmission contention. * **frame:** a sequence of slices makes a frame. each of the slices transmits a code, meaning that a full code is transmitted during a frame. the frame code is set at the start of the epoch and then gradually progressed from frame to frame. * **epoch:** an epoch is composed of many frames. normally an epoch will be a period, but in some cases it may be necessary to use shorter epochs (e.g. on initial app use to align with day synchronisation and after a disclosure event when the current epoch must end immediately). an epoch represents the shortest time period possible for a disclosure. !transmission time ordering typically a device will not be continually transmitting throughout the epoch. however, the order of transmission must remain time synchronized as this is fundamental to the way in which the matching algorithm works, it must know the code that the disclosing device would have been transmitted at a specific time. whenever the app is given the opportunity to transmit it will use the current time (based in utc) to determine the current position in the transmission sequence. note that this requires to have a reasonable time synchronization. app updates to get disclosure events will also provide server time, from which a skew can be calculated for the actual time on the device. note that this means large time adjustments on the time may because temporary time synchronization loss. note that the broadcasting of an individual code will be repeated multiple times during the allotted slice time period, depending on the bluetooth advertising interval chosen. this helps counteract poor reception or collisions between different devices broadcasting. repeated codes received in the same slice period will be discarded. ## proximity uuid allocation codes may be transmitted on one of different proximity uuids used by the protocol. by using different uuids we increase the chances that the monitoring capabilities of the devices can report simultaneous codes being received from different devices. moreover, we can use the uuid as an additional source of data as it selects the particular slice within the overall word that is actually being provided. note that there is still underlying radio space contention as the advertising channels are shared amongst all broadcast messages on any proximity uuid, but use of different uuids ensures that they are reported independently if only the strongest beacon is reported during the monitoring feedback. it seems to be the case that initiating ranging allows multiple beacons with the same proximity uuid to be reported in order of signal strength, but it is not desirable to have to depend on ranging rather than the simpler monitoring process. there is a direct correlation between the proximity uuid being used and the particular slice within the overall code that is being transmitted. in order to reduce uuid contention between different devices the order of the use of the uuid channels within a frame is randomized. this means that the order that the slice codes are sent is different for each frame. this increases the chances that at least some of the codes will be received. the randomized order must be known deterministically so that the expected time slot within the overall frame is known when performing a matching operation. we do this by using bits within the overall frame code itself. the first three bits are used to select the slice number for the first slice to be transmitted. the second selects the second slice as a count ignoring the slice already transmitted and so on. the effective number of bits of selection reduces for each slice, until there is no choice remaining for the final slice (hence why only bits rather than bits are needed, selecting x bits). ## correlated reception one of the key technical challenges is that on ios it is not possible to transmit ibeacons unless the app is in foreground (which also implies the phone is not locked). android seems to have more relaxed policies around this, although it is not clear how long ibeacons can be transmitted for when an android device is locked or the contact tracing app is no longer in foreground. moreover, not all android devices have full bluetooth peripheral support which would allow them to transmit in any case. a couple of measures are proposed to help reduce the impact of these concerns: * it may be possible for apple to relax their constraints about only foreground apps being able to transmit ibeacons, perhaps as some additional permission that may be provided to contact tracing apps that are shown to demonstrate sufficient care in handling privacy. * the concept of affiliate apps is discussed in this document. these are apps that are responsible for a significant proportion of foreground time on a device (e.g. facebook, twitter, tiktok, instagram, snapchat, youtube, browsers and other messaging apps). the idea is that these apps must be updated to also have the sdk, operating in affiliate mode, whereby the transmission is initiated in those apps. however, notwithstanding the above, we must assume that the proportion of time that apps transmit will be much lower than the time receiving. thus during the disclosure process, as well as disclosing the tx state for the codes that may be transmitted by the app, the app should also disclose the slice codes it received in its rx trace during periods when it was not transmitting. this allows an assessment of co-proximity to be made. in other words, if a disclosing device was not itself transmitting then at least it can disclose what it was receiving. any other device that received matching codes (to some level of confidence) during the same periods must itself have been co-located and in proximity. thus, as long as there is one device transmitting in a particular area at the relevant time, it is possible to demonstrate proximity. disclosure of the rx traces does not meaningfully impinge on the privacy of those other users, since their tx state that generated those codes remains private and it is not possible to identify who those co-located users were, unless they subsequently disclose their tx state (remember this disclosure only only occurs if that app user is subsequently infected). note that the size of this disclosed rx trace may be problematic for scaling, since it needs to be downloaded and checked by all participating apps. a compression scheme may be used to minimize the size when no data is being received. moreover, some sub-sampling might be employed during especially busy periods. furthermore, other methods could be employed to remove information from other householders which do not need to be matched using the app: * the user may be able to set a home physical location (known only to the app) so that traces received while at home, where the number of contacts is presumably lower and better controlled, do not need to be transmitted on a disclosure. * at the time of a disclosure a capability could be provided to remove all the rx trace records that are likely to be associated with household members who are also using the contact tracing app. this could be done using a peer-to-peer sharing option over bluetooth. this would allow other householders to choose to disclose their prior tx information to the disclosing app user. this would allow local removal of those rx records, before the disclosure to the cloud. thus householder tx information would not itself be transmitted any further and would be erased once the operation is completed. ## disclosure proximity matching a disclosure consists of the tx trace for various epochs, along with a subset of the rx trace for those epochs. a match must be performed against both: * _tx matching:_ the matching process must look at each disclosed epoch tx state and compare it against the rx trace to determine if there has been a match. a progression is made through the codes that would have been transmitted by the device, and therefore potentially received had the transmitter been in proximity. the algorithm allows the code progression, and the exact timing thereof, to be known throughout the epoch. a match occurs if there are more than a certain number of matching slice codes within a clustered time period. the tx matching might be restricted to those times when there is no corresponding rx trace (since the rx trace is only supplied for periods when there is no transmission). * _rx matching:_ this matches the rx trace against the slice codes received on the device at the same time. a clustering of slice code matches indicates that the device must have been in the same proximity as the disclosing device, receiving data from some set of unknown transmitting devices. ## false positive suppression as discussed, a proximity match requires several slice code matches in a short time window. the number of matches and the size of the window must be carefully assessed. incorrectly setting parameters could lead to a high rate of false positives, which we obviously must avoid. false positives must be rendered very low probability events even in the face of the sort of scale of deployment that might occur. as a back of envelope calculation, consider that the app is receiving a new slice code every minute. this assumes the app is active all day, and is always receiving codes from one other device. in reality a device will likely only be active for part of the day, but may experience a higher number of slice code receptions per minute from surrounding devices when it is active. for the slice code, the chance of a collision is only but in a day there will be minutes of such slice codes being received. any of these could result in a collision. thus the chance of there being no collisions in the day is - however, there are other factors to consider such as the fact that multiple days and disclosures are being matched. moreover, we need to be able to cope with millions of users of the system and we do not want any of them, ideally, to experience a false disclosure proximity match on their data. note that we are also assuming that received slice codes can be delivered quickly enough when the app is running in background, and the time stamp of reception is sufficient to reliably allocate it to a particular slice period. if not, and the delays make the timing much more approximate, then this would substantially increase collision probabilities in our matching algorithm. for now, we assume that slice period time synchronization for reception is guaranteed in our approach. we have to assume that a cluster event will be required to announce an actual match. multiple matches need to occur as a tightly clustered event in time during the day. let us consider a matching period of minutes. let us conservatively assume we wish to see three different matches in that period, from the disclosed epoch information. we have a probability of - - </sup>) of a collision for each slice code, which is x thus the probability of seeing such independent collisions within the minute time window is x this is for the calculation representing five minutes periods in a day, this gives this appears to give almost certainty that for a given epoch disclosure we will not achieve a random collision of different slice codes within a minute period. thus we can be sure that such a match is real. as discussed, in reality we will be matching multiple epochs, and many different disclosed epochs per day. moreover, we may wish to use a sliding window period of minutes rather than strict minute slots and this increases the chances of collisions. overall the collision probability seems suitably low, assuming a proximity of three slice codes is sufficient. this implies a real actual proximity of several minutes and reasonable levels of signal transmission. a small simulation for this has been performed. the code is available in this repo in the `collison-simulator` directory. the size of the simulation is somewhat limited by memory and cpu time for the basic implementation that exists. it tests randomized disclosures against a cohort of receiver traces for a single epoch (i.e. a days worth of data) the number of disclosures tested was again, each is an epoch. so disclosure epochs against reception epochs. this is small scale compared with a real implementation but should reveal any fundamental shortcomings. the reception uses a profile where of the time nothing is being received, but the rest of the time there are various receptions per slice, up to at a time (but this is only reached about of the time). a full match requires matching individual slices in a slice period moving window. the results showed approximately individual slice code matches, but no full matches in the run of the simulation. a further run indicated that on this smallish sample there were not even any matches of two slice codes within a slice period moving window. # sdk operation ## architecture the internal architecture of the sdk may be viewed as follows. beacon reception and transmission are relatively independent and, as far as can be ascertained, both can occur simultaneously. each component is described at a high level in the following sections. !sdk architecture the sdk can be operated in one of two modes: * _primary mode:_ normal operation of the sdk, recording rx and tx traces. used inside a contact tracing app. * _affiliate mode:_ this is the mode used if the sdk is embedded inside some affiliate app. in this case the sdk does not do any tracing, but only transmits over bluetooth to enable continued transmission while the affiliate app is in the foreground (where transmission is restricted to foreground apps only). ## rx recorder this is responsible for performing ibeacon monitoring operations. the app will be monitoring a total of different uuids that have been allocated for the purposes of the proximity tracking. the app will receive callback events when entry to and exit from a particular region occurs. this will have an associated uuid for the ibeacon, along with the major and minor values which are the primary mechanism for transmitting code data. when a region entry event occurs, a ranging operation may be initiated that can provide more details of the beacons currently transmitted, including estimates of their distance. events are recorded in the rxtrace with all the associated metadata, including time of receipt. beacon events that may have been transmitted by the device itself need to be filtered out, presuming the hw or os does not do that already. this monitoring process will continue in the background, even when the phone is locked, and significant care must be taken to minimize power usage to avoid excessive battery drain. if bluetooth is not enabled then this module must prompt the user to enable it. ## rx trace this trace provides a record of all of the ibeacon events observed by the device. this is later analyzed against disclosure information to determine if there is a sufficient match, and therefore a notifiable event to the user. a compressed form of the rx trace may also have to be disclosed for the periods when no transmission could be made, to help co-locate with other app users. information to be stored includes: * timeslice of the event (this is based on timestamp provided, and all codes will be allocated to a particular slice of approximately minute in duration) * major and minor values for the ibeacon as this is the primary code transmission mechanism. together they form the sc (slice code). * the slice selection derived from the received uuid (to determine which slice to be matched) * potentially, the distance estimation to be used in a calculation of the match strength. alternatively, the approach could simply impose a maximum limit on the distance estimation and ignore all slice codes exceeding some fixed threshold. the rxtrace only needs to be kept for a fixed maximum period, greater than the maximum prior proximity period that may be disclosed. in practice, this would be something like three weeks, some effort should be made to protect this data at rest to ensure complete privacy, perhaps encrypting using a key stored in the hardware trust layer. as discussed above, the rx trace may also include an overall location trace of the app user for analytics purposes. ## proximity matcher the matching engine requests the disclosure stream(s) that the app is subscribed to. each stream represents the data for one particular region. the requests will be done on some periodic basis when connectivity is available. the timestamp or position of the last disclosure received will be remembered, so only the updates need to be transmitted each time. the new disclosures are received as a sequence of data for epochs being disclosed. the algorithm is discussed in the disclosure proximity matching section above. if there is a match (or matches) then the proximity matcher will provide the information about the time and duration of the match and the physical location of the match if that is also being tracked by the sdk. the unique disclosure ids will also be provided. this can be used to lookup other metadata associated with the disclosure by the contact tracing app using the sdk. ## tx state this represents the current state which is being transmitted by the app. it is composed of the following data: * _iec (initial epoch code)_: a random code that is generated as a secure random number at the start of each epoch. the individual codes are derived from this. * _epk (epoch progression key)_: a key value used in an hmac to determine the next code value in each frame. since this key is secret an observer cannot determine the relationship from one frame to the next, and is thus unable to track a device unless this code is later disclosed. * _fc (frame code)_: the current frame code that is to be transmitted. these are sent as a sequence of slice codes (sc) during the frame. this fc is initially the same as the iec in the first frame, and is transformed in each frame using the epk. ## tx scheduler the tx scheduler is responsible for determining the sequence of beacon codes to be transmitted and how long each should last in duration. it advances the tx state as required, from frame to frame. it also writes data to the tx trace at the start of each epoch. ## tx trace this records information about prior codes that may have been transmitted by the device. some of this information may be published by the app if a future disclosure is required. a trace is provided for each epoch as follows: * start time of the epoch (in utc linux time) * duration of the epoch (normally hours, but may be shorter) * slice duration (individual slice durations may be configured server side for the app in order to fine tune the efficiency of the transmission in the protocol) * iec (initial epoch code) that was used * epk (epoch progression key) that was used given this information it is possible to determine the codes that may have been transmitted by the device at any point during the epoch, using the base time as the epoch start (in utc) and replaying the deterministic code derivation algorithm. a record must also be made of whether the sdk was able to transmit in any given time period. this provides an extremely compact representation of the information that may have been transmitted during a day. the iec and epk codes are each), and the other information could be likely to be represented in or less. so epoch information only needs about bytes, i.e. the data for a single day. if we consider that the number of epochs (assuming an epoch normally being one day) typically disclosed will be of the order of then that means that an individual tx disclosure is only of the order of bytes. unfortunately the rx trace that may need to be disclosed is significantly larger than this. the tx trace should ideally be encrypted at rest for maximum security. ## disclosure submitter the submission process is provided with some metadata to be sent and the start time from which the disclosure is being made. this time is used to determine the epochs that need to be included in the disclosure. the iec and epk secrets for the appropriate epochs, along with their time ranges, are provided. furthermore, the rx trace for the periods when the sdk was not transmitting are also disclosed, allowing co-located users seeing the same codes to be matched. this information is included in the request to the disclosure api and it then becomes public domain. the disclosure api backend allocates a unique disclosure id for the disclosure that is included in the record. the contact tracking app itself may then associate further metadata with the disclosure using its own backend resources. this is outside of the scope of this document and may be determined during the development of the contact tracking app itself. note that in general the disclosure will only be made for a particular country (or larger region thereof for larger countries). logic in the contact tracing app may allow multiple disclosures to be made across different countries if the user states that they have visited them during the prior disclosure period. a significant security risk of the disclosure process is that there is no user authorization component due to the privacy design of the system. this means that malicious spoofed disclosures could be made against the endpoint, with the intention of increasing data sizes and causing random matches. this attack vector must be controlled. it is thus proposed that approov is used to protect this endpoint, so that only valid instances of the contact tracking app can make requests to the endpoint. note that when the disclosure is completed the current epoch must be ended immediately. this is because the information will then be in the public domain, allowing any device to spoof the identity of the disclosing app instance. this is of course also why proximity matching must stop at the exact time of the disclosure since any data after that point cannot be trusted. # sdk backend ## architecture the sdk is set up to communicate with some backend resources. we envisage that each geographic region will have an associated stream of disclosure events that can be submitted by valid instances of the contact tracing app(s). this needs to be designed to allow very significant scalability, both in terms of the reading and writing sides of the disclosure database. the size of the region will depend on the practical scalability of the solution and, in particular, the size of the disclosure information that each app must download every day. we would hope that an individual region can be very large, however, encompassing many millions of individual users if not entire smaller countries. !backend architecture ## disclosure data access each of the mobile devices running the contact tracing app must update periodically for recent disclosures for matching against. we envisage that only data from the relevant region(s) is to be read. the contact tracking app itself could provide facilities to do matches over multiple regions if required. scalability of the reading of this data is fundamental, and would need to be fronted by some kind of cdn capability. fortunately the data being transmitted to all app instances is identical so this is easy to achieve. one possibility is simply to put the disclosure data in files in buckets in aws, with one new file written each hour with all new disclosures. this bucket can then be made readable via aws cloudfront. the sdk just needs to download and process the disclosures files which have become newly available since its last update. ## disclosure submission api a disclosure consists of tx data for several epochs and with a time range around them. the disclosure must also include the rx trace for all periods when the sdk was not transmitting. a compression scheme will be applied to this, but in general this rx data will be significantly larger than the tx data. when a new disclosure is received it is added to the queue to be included in the next update for the region. disclosures should only be accepted from valid instances of official contact tracing apps. one approach to doing this is by restricting access using approov tokens, which prove the authenticity of the app. this prevents spoofed or scripted disclosures being made maliciously. other authorization mechanisms may also need to be in place on this api depending on the contact tracing app and its stance on self-disclosure or whether some official authorization (perhaps based on a positive test) is required. # contact tracing app ## overview the contact tracing app provides a user interface and general business logic over the top of the sdk itself. the exact nature of the steps in the app and how things are presented are beyond the scope of this document, but some basic requirements and ideas are presented here. in general a user should only install a single contact tracing app, should there be a choice in the future. this is because the contact tracing app will hold the rx and tx traces (managed by the sdk) and will be responsible for their secure storage. we only wish one app to be monitoring for beacons in the background and recording the traces, and we only want one app performing the transmission. thus there is only a single app that the user needs to go to check for matches or to make a disclosure. as discussed later, there is the option for affiliate apps to interact with the single chosen contact tracing app as required. ## installation a key attribute over the contact tracing system is that it remains anonymous. thus it should be possible to install the app and start receiving and transmitting with absolutely no need to sign up or enter any personal information. this is a key aspect of overall design philosophy and individual contact tracing apps should not deviate from this approach. since the app will require access to bluetooth and location services, requests for these rights should be made on first installation and startup of the app. ## optional location tracking there may be an option to determine if the user wishes to track their physical location or not while tracing. this is not done by the sdk itself, but the overall contact tracing app may implement this. the primary purpose of this would be to inform the user where a proximity event with a disclosed user occurred. the sdk provides the timestamp of the event from which the location can be looked up inside the app. there is no need to disclose the full trace of locations, but a user agreeing to provide the specific locations of proximity may be useful to authorities to determine where significant numbers of events are occurring and inform other users. note that this disclosure of location may then form the basis of a secondary level of disclosure, outside of the scope of the sdk itself. this secondary disclosure would show the time and location of a proximity event that has occurred with a disclosed, infected, user. the apps are then able to determine if they were at that location at that time, or shortly afterwards, where there may be some, albeit reduced, risk of infection. the app could simply inform the user of this in case they wish to take some remedial action. note that the location intersection checking can be done locally in the app and does not require location information to be published to the cloud so privacy is assured. ## normal operation the app should be able to record beacons while running in the background and while locked. some sort of indication should be made to the user that the app is running. operations may also be initiated via affiliate apps. the app could provide some kind of feedback about the amount of time it has been tracing and/or transmitting. perhaps with some kind of timeline of the days, but this is really not essential functionality. it could display the number of slice codes that have been received, but this is not a proxy for the number of physical constants since the privacy preserving aspects of the protocol mean that it is not possible to determine this. note that a count of the number of bluetooth macs seen may be a better approximation, assuming a constant rotation rate for different devices, but mobile oss prevent this information from being extracted. ## proximity match request when initiated by the user, or perhaps on an hourly timer, the contact tracing app should fetch the latest disclosure information from the cloud. it is then able to compare this against the latest disclosure information. this may result in one or more matches, each being assigned with some level of confidence and duration based on the number of matching slice codes. the time of the matches is also provided along with the disclosure ids that matched. this information can then be presented to the user so that they are able to take appropriate actions, such as self isolation for a period. the disclosure id may be used to lookup additional information (outside of the scope of regarding the disclosure, such as symptoms and the authority of the disclosure and whether there was an actual positive test or not. the app should of course provide sufficient and locally appropriate advice and support around this. an option may also be presented for the user to submit their match information (including, optionally, some resolution reduced physical location) to some other backend system for tracking the spread of infection. ## disclosure the key functionality of the app is to be able to make a disclosure. this discloses that the user has now been diagnosed with and wishes to disclose this to proximity contacts made for n days previously that this is the case. the actual identity of the user is never disclosed. medical advice will be used to help choose n, which is the period during which the user may have been infectious. typically the user will also fill in some kind of questionnaire to determine with a high degree of confidence that they have really contracted in general it cannot be assumed that tests will always be available. the approach and advice on this will obviously vary from time to time and by country, and this needs to be adhered to by the contact tracing app. in some cases an official authorization identifier (which will be checked by the disclosure api backend) may be required. when the disclosure is made via the sdk, a unique disclosure id is returned. this may be used as a key for storing other metadata associated with the disclosure. this can then be stored in the cloud to be accessed by contact tracing apps which subsequently show a proximity match for the disclosure. the app may allow the disclosure to be made in several different regions if the user has been travelling. disclosures must account for the different advice in place for a disclosure in different countries. ## affiliated apps on some platforms, such as ios, it is not clear if beacon transmission can occur for background apps. this seems to be more of an issue on ios than android, but may vary depending on model and particular os version. thus we need to have the sdk integrated into apps that are associated with a high percentage of foreground time in different markets (facebook, instagram, twitter, snapchat, messaging, tiktok, etc. etc.). each affiliate app will be linked to a particular contact tracing app which will communicate with the affiliate. ideally some common app will emerge for each country, but this is really a discussion between the contact tracing app and affiliate app partners and is outside the scope of this document. when the sdk is run in affiliate mode it simply sends slice codes with timings as dictated by the contact tracing app itself. this is simply to make sure the bluetooth start advertising calls are in the context of the affiliate app which will be used in the foreground. this mechanism requires some communication between the contact tracing app and the affiliate app, as discussed below for ios and android. ### android affiliated app communication note that the requirement for this in android appears to be much lower than for ios, since it is possible to transmit when the app is in background. however, this is included for the sake of completeness. the contact tracing app can send custom intents on a periodic basis (say minute), with the latest bluetooth codes to be transmitted. affiliate apps can register for the custom intent broadcast and, if they are in foreground, use the sdk in affiliate mode to initiate the beacon transmission for the prescribed short period. !android app affiliate ### ios affiliated app communication the affiliated app can make requests to the contact tracing app on a regular basis. this accesses an app extension that has the rights to access the data for the contact tracing app, and call the code in the sdk. this will obtain the latest transmission requirements to be returned to the affiliate app for transmission by the sdk in affiliate mode. !ios app affiliate ## revocation the app may wish to support some mechanism for revoking prior disclosures, if they were somehow done in error or maliciously. this can be done outside of the disclosure stream by having an independent cloud database of disclosure ids that have been subsequently revoked. # security threats these are general and residual concerns about the security of the system. ## fake disclosures scripted attacks against the endpoint are protected by the use of approov tokens. limits will be placed in the minimum time the contact tracing app must have been active for (say hours) before disclosure can be made, to avoid automated app installation and disclosure attacks. ## excessively powered transmission a variant of the app could transmit on the maximum bluetooth power available, rather than the power level normally chosen for the app. alternatively custom hardware could be used to transmit at higher power levels still, beyond the maximum levels normally allowed for bluetooth. this would have the effect of jamming more local transmissions to some extent. moreover, where matches are done on rx traces to find co-located devices this would excessively widen the area of apparent proximity. ## receive only freeloaders this is not a security threat as such, just a concern about the proper usage of the approach. to be effective, the app must transmit when it can and be prepared to disclose its rx traces for periods when it cannot transmit. if the app code is open source and the disclosure stream is public, it would be possible to build an app that does not conform to this requirement and selfishly only receives and looks for proximity matches. of course a similar effect can be achieved by using the official contact tracing app, but then not disclosing any subsequent infection. ## scaled replay in principle an app could be developed that synchronized codes across a large number of devices in many different locations. if a disclosure were then to be made against those replicated codes it could then match a very large number of users, causing significant disruption. this can be mitigated against by the reports submitted by users that believe they have a match. if there are too many for an individual disclosure to be believable then a revocation could be issued. note that another advantage of using approov is that the disclosing app itself could not perform this bad behaviour. it requires a relay via bluetooth app to be built that adds complexity into the attack. ## scaled cloud tracing an elegant aspect of the approach is that the codes transmitted by the app over bluetooth are ephemeral. if no recording of them is made then they are lost. codes are changing in a sequence that can only be determined if a future disclosure is made. only those users that actually collected the codes can know the location of the contact. however, it is possible that if there were a large number of mobile receivers (or fixed recording beacons) then the data could be pooled after a disclosure to determine a more detailed path of the disclosing user during the disclosure period. a large network of collaborating receivers would be required, however, to significantly undermine privacy in this way. # social distance measurement ## overview we also believe that bluetooth could play a key role in measuring the adherence to recommended social distancing guidelines. this will be one of the major challenges society will face in an exit strategy from the lockdown that much of the world is currently in. these measures will no doubt have a massive impact in flattening the curve of the infection rate. however, assuming that no widespread vaccination programme is available within the coming months, then we need to plan a gradual controlled exit from a household level isolation strategy. it is expected that social distancing measures will be in place for some considerable time to come and enhanced ways of measuring this, and providing behavioural nudges to everyone to help maintain them, would be highly beneficial. mapping of social distancing is already occurring, using anonymized phone cell data from the telecom companies and data from apps already collecting location data at scale. this is not even a new use case, google has been using such aggregated data to show how busy locations are on maps at different times of the day for years, or for showing live traffic congestion data. however, the current data (primarily from gps tracking) is relatively coarse grain, especially for indoor locations and on public transport where social distancing is even more important. it appears that what is needed are technologies that allow much more personalised feedback and advice on achieving good social distancing, as well as finer grain aggregated information to measure progress and problematic locations. such measures are in direct conflict with widespread acceptability of privacy invasive tracking. by its nature, personalised measurement of social distancing requires that location data will have to be uploaded from individual apps to allow comparison with other users. it is very difficult to fully anonymise such data, since the presence of certain locations such as home or work provide an almost direct means of identification. bluetooth provides an innovative alternative solution to this problem. it allows the direct estimation of the number of people within a certain distance using ubiquitously available smartphones. moreover, the collection of such data does not reveal locations or the identity of any app users. it merely provides a means to measure the numbers in close proximity over time, which is the key metric that needs to be evaluated and optimised. ## approach these are the key principles of an app that we envision that could use this technology: * users install the app but do not need to sign up or divulge any personal information during this process. use of the app is always completely anonymous. this could be the same app as a contact tracing app, or could be entirely independent. * the app will ask for permissions for access to bluetooth and also tracking of location. when the app is running the app it will collect location and bluetooth information in the background. this information is only held in the app and not shared without user consent. * the app will continuously listen, in the background, for bluetooth ibeacon broadcasts being made by other users running the same app in close proximity. whenever possible the app will also be broadcasting these beacon signals. * the app can generate bluetooth codes as described in this document (although if the application is confined to social distance measurement only, then of course the protocol can be much simpler). * the app will record the number of other devices it can receive broadcasts from that are in close proximity in a given time period, leveraging the fact that each will likely be broadcasting a different code at any given point. this provides an estimate of the number of other users of the app in close proximity at any point in the day. the app may associate this with a physical location. * the user of the app will be able to view a mapped trace of their location history overlaid with a proximity heap map. this will help users see times and locations where they have had the least social distance over the day. * data from previous days will be automatically deleted after a short period, such as a week. * with the consent of the user, an overall metric of their social distancing can be shared to a central service as part of an aggregated picture. again, this is fully anonymised and would only contain extremely coarse grain location data. * the app could highlight times and locations during the day where the level of proximity was particularly high (perhaps compared to an average for all users of the app). with the consent of the user, this information can be shared to a central service to help provide an aggregated picture of congestion. if the user chooses to share this information, it will remain anonymous and will only ever share a point location and time. * users of the app should be able to view this aggregated view, helping them to be more mindful of where they go and at what times. this can help smooth out demand in places where congestion is problematic. the app could even help with sharing location based tips on social media (making social distancing social!). * authorities can monitor the aggregated information and take appropriate action if required to remediate the situation. the overall measurements should also allow closer monitoring of social distancing over time in different areas, and help modulate public statements about behaviour patterns. ## advantages * it provides a way for individuals to contribute their data anonymously and make them feel that they are doing their bit in the efforts to contain the virus. * by allowing comparison with others, the app helps gamify the process of social distancing, give feedback and advice and helps nudge behaviours in a positive direction. * the operation and inherent privacy properties are actually quite easy to explain and to be widely understood. * since proximity is based on actual close physical distance for some small sustained it should represent a good proxy of actual cross infection risk. * control of bluetooth transmission energy should allow the proximity range to be kept relatively small and provide enhanced accuracy over gps location tracking approaches that are quite coarse grain and very poor inside (where infection rates are actually higher due to poorer ventilation). * it works without the need for cellular, wifi or gps contact, so is ideal for many public transport scenarios. ## challenges * this only works if a very large percentage of the population uses it. in order for that to happen it really needs the support and promotion of large tech companies and/or governments. * on ios in particular, there are severe restrictions on bluetooth transmission by apps that are not the main one running in the foreground, with the phone unlocked. this may lead to under counting of proximity since iphones will be less present. this challenge could be overcome by apple relaxing its bluetooth transmission rules for such apps and/or major app vendors including a transmission sdk in their apps so the signal is present if that app is active. there are also some models of android phones which are unable to transmit. * it is notoriously difficult to get accurate proximity measurements using bluetooth, although for the purposes of this app estimations may be sufficient and these are certainly higher quality than attempting to use gps indoors. * it will have some, as yet unknown, detrimental impact on device battery life. ## householder proximity exemptions if multiple members of the household are using the app, then proximity to them will also be included in the statistics collected by the app. in the approach discussed, it is not possible to exclude them from the data because the bluetooth slice codes transmitted are randomized and cannot identify a particular user. this may have the effect of biasing the data since these contacts should not be included in social distancing statistics gathered. one possible way around this issue is to make it easy for householders to do peer-to-peer sharing of their iec and epk values each day. this could perhaps be done via an onscreen qr code or via bluetooth. this will allow the apps of householders to ignore each other as far as the social distancing metrics are concerned. these values are not revealed to anyone else, nor any central authority, the privacy guarantees of the system are not undermined. note that if peer-to-peer sharing of keys is allowed, then it may be beneficial for the app to predetermine the iec and epk values for multiple days ahead to reduce the needed frequency of this sharing. a user of an app would always have the option to reset future values if they no longer wished to have the sharing enabled. # resources ## general https://en.wikipedia.org/wiki/ibeacon ## ios ibeacon support https://developer.apple.com/documentation/corelocation/ranging_for_beacons https://developer.apple.com/documentation/corelocation/determining_the_proximity_to_an_ibeacon_device https://developer.apple.com/library/archive/documentation/userexperience/conceptual/locationawarenesspg/regionmonitoring/regionmonitoring.html https://github.com/radiusnetworks/proximitykit-ios ## android ibeacon support (especially with altbeacon library) https://developer.android.com/guide/topics/connectivity/bluetooth https://os.mbed.com/blog/entry/ble-beacons-uribeacon-altbeacons-ibeacon/ https://www.pubnub.com/blog/build-android-beacon-ibeacon-detector/ https://play.google.com/store/apps/details?id=com.radiusnetworks.locate devices with ble peripheral support circa required for ibeacon transmission https://altbeacon.github.io/android-beacon-library/beacon-transmitter-devices.html distribution for smartphone types, by country: https://deviceatlas.com/blog/most-popular-smartphones another basic ibeacon library for android: https://github.com/easibeacon/ibeacon-android-library ## uuid rotation ## ios app data sharing https://dmtopolog.com/ios-app-extensions-data-sharing/ https://developer.apple.com/library/archive/documentation/general/conceptual/extensibilitypg/extensionscenarios.html ## android app data sharing https://developer.android.com/training/sharing/receive https://developer.android.com/training/sharing/send ## relevant academic papers and projects fluphone: understanding behavioural responses to infectious disease outbreaks - https://www.cl.cam.ac.uk/research/srg/netos/projects/archive/fluphone/ a study of bluetooth low energy performance for human proximity detection in the workplace extending bluetooth le protocol for mutual discovery in massive and dynamic encounters quantifying dynamics of transmission suggests that epidemic control and avoidance is feasible through instantaneous digital contact tracing sustainable containment of using smartphones in china: scientific and ethical underpinnings for implementation of similar approaches in other settings"
1,cozie,cozie fitbit smart watch clockface for quick surveys,"# project cozie - a smartwatch methodology for quick and easy experience surveys ## what is cozie? cozie is a fitit ionic, versa, versa lite and versa clock face that can ask people questions. it is useful for experience sampling research and was designed for the built environment, although there are also forks focused on symptoms tracking the foundation for this project is the buds lab efforts towards human sujective feedback in the built environment: - is your clock-face cozie? a smartwatch methodology for the in-situ collection of occupant comfort data - indoor comfort personalities: scalable occupant preference capture using micro ecological momentary assessments ## tutorials documentation found here and a shortcut to the video tutorials related to helping with the project or forking for yourself. ## download cozie clock face latest stable release for fitbit ionic, versa, versa light & versa latest stable release for fitbit versa & sense beta development version ## license the cozie clockface is open-sourced under at license copyright buds lab ## run the project on your computer ### clone repository first ensure that you have the latest nodejs installation https://nodejs.org/en/ clone the repo `git clone git@github.com:buds-lab/cozie.git` `cd cozie` `npm install` ### building and installing `npx fitbit-build` will build the project `npx fitbit` opens the browser, and logs into your fitbit account. from here you can connect to devices and install the app `bi` to building and install the application install the fitbit simulator for windows / macos ### document structure sent by cozie ```python { ""airspeed"": # can you perceive air movement around you?, ""anychange"": # any changes in clo, loc, or met past ""clothing"": # what are you wearing?, ""indooroutdoor"": # are you?, ""light"": # light preference, change"", ""location"": # where are you?, ""met"": # activity, lat ""mood"": # what mood are you in?, ""noise"": # sound preference, change"", ""thermal"": # would you prefer to be?, change"", else"", ""comfort"": # clock face question, = ""comfy"", = ""not comfy"" ""votelog"": # counter which stores information on how many times the user completed the survey, used for debugging to check that no responses where lost ""responsespeed"": # # time in seconds it took to complete the survey ""heartrate"": # heart rate [bpm] measured when the user completed the survey ""restinghr"": # resting heart rate [bpm] ""bmr"": # basal metabolic rate [cal/d] ""bodypresence"": true, # passes information whether the user is wearing the watch or not # geographical latitude [] provided by the gps of the phone # geographifcal longtiude [] provided by the gps of the phone ""userid"": # user id as per selection in settings ""experimentid"": alpha # experiment id as per selection in settings } ``` ### more information - getting started with the fitbit software development kit (sdk)"
1,ActiPro,r package used to process files created by actigraph link actilife,"--- output: github_document --- <!-- readme.md is generated from readme.rmd. please edit that file --> ```{r, echo = false} knitr::opts_chunk$set( collapse = true, comment = ""#>"", fig.path = ""readme-"" ) ``` # actipro the goal of actipro is to provide a free and easy-to-use accelerometer processing code specifically for studies using sensors in tandem with smartphone surveys (i.e., ecological momentary assessment). actipro started a side project on stata in and has since evolved to include novel paramters of physical actvitiy that show promise in energy-balance behavior research. ## installation you can install actipro from github with: ```{r gh-installation, eval = false} # install.packages(""devtools"") devtools::install_github(""eldinidle/actipro"") ``` ## example you will need your own folder with agd files to run basic sample code. as such, we currently do not have any available examples to run. the code itself, however, is straightforward. ```{r example} ## basic example code ```"
1,esmpack,r package to facilitate the preparation and management of esm/ema data,"esmpack: a package to facilitate preparation and management of esm/ema data =========================================================================== [!r build status](https://github.com/wviechtb/esmpack/actions) !cran version !devel version ## description the `esmpack` package is a collection of functions that facilitate preparation, management, visualization, and analysis of data collected via the experience sampling method (esm) and ecological momentary assessment (ema). ## documentation you can also read the documentation online at https://wviechtb.github.io/esmpack/ (where it is nicely formatted and the output from all examples is provided). ## installation the development version of the `esmpack` package can be installed with: ```r install.packages(""remotes"") remotes::install_github(""wviechtb/esmpack"") ``` ## meta the `esmpack` package is licensed under the gnu general public license version to report any issues or bugs, please go here."
1,iDialogPad,ema app for ios,"# idialogpad this is an ema (ecological momentary assessment) and general questionaire universal app for ios. it has been in use since the first ios release by many research groups and been distributed by adhoc in the past. now that provides sideloading apps i decided to put the project to github so that everybody can use it for free. runs on ios but must be compiled with and sdk (does not work witk xcode and sdk the uvariotest editor and simulator programms are also added. (mac and pc) the script ""sort_qdf"" can be used to sort unsorted idialogpad outputs offline. used external code: excel interface:"
1,VOLI-Visualization-Exploratory,the system demo of poster towards visualization of timeseries ecological momentary assessment (ema) data on standalone voicefirst virtual assistants,"# towards visualization of time-series ecological momentary assessment (ema) data on standalone voice-first virtual assistants yichen han, christopher bo han, chen chen, peng wei lee, michael hogarth, alison a. moore, nadir weibel, emilia farcas !a user's past sleep quality presented on an amazon echo show this work is a part of voli project at uc san diego human-centered extented intelligence lab. you may read the full [paper]() and watch the video presentation. ## introduction accessing and interacting with digital health information is a key challange for aging populations. ecological momentary assessments (ema) coupled with voice-based intelligent virtual assistants (ivas) can be effective to improve older adults quality of life. to explore the potential opportunities for visualizing time-series based ema data on standalone ivas, we prototyped this preliminary system. via this system, oler users are able to query and examine their time-series ema data on amazon echo show. !with touchscreen based standalone voicefirst ivas, older adults are able to query and visualize the timeseries based ema data (e.g., the quality and time of the sleep). by observing and interacting with the iva visualization, and especially older adults past data and corresponding trends, older users might be able to make in-situ decisions to address possible unhealthy lifestyle. this artifact will also help future system development with more categories of real-time data and studies on the effectiveness of their visualizations. ## system design we prototyped the system based on amazon alexa and amazon web services (aws). it consists of three parts: an amazon alexa frontend converting users utterances to queries, an aws lambda middle-tier that handles the queries and requests the graphs, and a aws server to generate the graphs. !when older adults request a graph from voice assistant alexa. aws lambda handles this request by asking to generate a graph and send it back to echo show, paired with alexa. ## quick start you may deploy the system in a simplified way with only alexa skill and aws lambda, or make a full deployment with aws server as well. ## prerequisites + an amazon developer account and its ```iam user name``` and ```access key``` (reference). + ```aws cli``` is configured with credentials. ## simple deployment with amazon alexa and aws lambda, you can test the system by showing static figures on the echo show. ### deploy alexa skill: go to alexa console and create a with a self-hosted backend. record its ```skill id```. connect its ```endpoint``` to the lambda function in the next part by entering its ```function arn```. ### deploy aws lambda: enter the ```lambda``` folder, then run these commands (replace contents in <> with your owns'): ``` $ aws lambda create-function --function-name voli-visualization-exploratory --zip-file fileb://system-demo.zip --handler index.handler --runtime --role arn:aws:iam::<id>:role/<role name> $ aws lambda update-function-code --function-name voli-visualization-exploratory --zip-file fileb://system-demo.zip ``` by this time, you are able to see a function in aws lambda named ```voli-visualization-exploratory```. open it, click ```add trigger```, select ```alexa```, and enter the ```skill id``` in part ## server deployment with the falsk server delopyed on aws you are able to display real-time figures on the echo show generated from the server. after deploying the server on just run it by ```$ start.py```. <!-- then you can change the url of ```backgroundimagesource``` in ```/lambda/documents/visualization_background_document.json``` to the url returning images in ```server/app/api.py```. --> ## citation ``` author = {han, yichen and han, christopher bo and chen, chen and lee, peng wei and hogarth, michael and moore, alison a. and weibel, nadir and farcas, emilia}, title = {towards visualization of time-series ecological momentary assessment (ema) data on standalone voice-first virtual assistants}, year = publisher = {association for computing machinery}, address = {new york, ny, usa}, url = doi = keywords = {gerontechnology, accessibility, health well-being, user experience design, older adults, voice user interfaces, ema}, location = {athens, greece}, series = {assets } ```"
0,EmotionTimeSeries,data archive of seven open emotion time series from studies using experience sampling methodology,"<!doctype html> <html> <head> <meta /> <meta name=""generator"" content=""pandoc"" /> <meta http-equiv=""x-ua-compatible"" content=""ie=edge"" /> <script>/*! jquery | (c) jquery foundation, inc. | jquery.org/license */ !function(a,b){""object""==typeof module&&""object""==typeof new error(""jquery requires a window with a document"");return b(a)}:b(a)}(""undefined""!=typeof window?window:this,function(a,b){var new d.call(this)},get:function(a){return b=m.merge(this.constructor(),a);return b.prevobject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushstack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushstack(d.apply(this,arguments))},first:function(){return this.prevobject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var g&&(j=g,g=arguments[h]||{},h++),""object""==typeof g||m.isfunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in new error(a)},noop:function(){},isfunction:function(a){return""function""===m.type(a)},isarray:array.isarray||function(a){return""array""===m.type(a)},iswindow:function(a){return b;for(b in in a)return j.call(a,b);for(b in a);return void null==a?a+"""":""object""==typeof a||""function""==typeof a?h[i.call(a)]||""object"":typeof a},globaleval:function(b){b&&m.trim(b)&&(a.execscript||function(b){a.eval.call(a,b)})(b)},camelcase:function(a){return a.replace(o,""ms-"").replace(p,q)},nodename:function(a,b){return a.nodename&&a.nodename.tolowercase()===b.tolowercase()},each:function(a,b,c){var for(e in for(e in a},trim:function(a){return null==a?"""":(a+"""").replace(n,"""")},makearray:function(a,b){var c=b||[];return null!=a&&(r(object(a))?m.merge(c,""string""==typeof a?[a]:a):f.call(c,a)),c},inarray:function(a,b,c){var d;if(b){if(g)return in b&&b[c]===a)return a.length=e,a},grep:function(a,b,c){for(var e},map:function(a,b,c){var for(f in a)d=b(a[f],f,c),null!=d&&i.push(d);return c,e,f;return""string""==typeof a.apply(b||this,c.concat(d.call(arguments)))},e.guid=a.guid=a.guid||m.guid++,e):void date},support:k}),m.each(""boolean number string function array date regexp object error"".split("" ""),function(a,b){h[""[object ""+b+""]""]=b.tolowercase()});function r(a){var b=""length""in in a}var s=function(a){var regexp(l+""+"",""g""),r=new regexp(""^""+l+""+|((?:^|[^\\\\])(?:\\\\.)*)""+l+""+$"",""g""),s=new regexp(""^""+l+""*,""+l+""*""),t=new regexp(""^""+l+""*([>+~]|""+l+"")""+l+""*""),you=new regexp(""=""+l+""*([^\\]'\""]*?)""+l+""*\\]"",""g""),v=new regexp(p),w=new regexp(""^""+n+""$""),x={id:new regexp(""^#(""+m+"")""),class:new regexp(""^\\.(""+m+"")""),tag:new regexp(""^(""+m.replace(""w"",""w*"")+"")""),attr:new regexp(""^""+o),pseudo:new regexp(""^""+p),child:new regexp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+l+""*(even|odd|(([+-]|)(\\d*)n|)""+l+""*(?:([+-]|)""+l+""*(\\d+)|))""+l+""*\\)|)"",""i""),bool:new regexp(""^(?:""+k+"")$"",""i""),needscontext:new regexp(""^""+l+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+l+""*((?:-\\d)?\\d*)""+l+""*\\)|)(?=[^-]|$)"",""i"")},y=/^(?:input|select|textarea|button)$/i,z=/^h\d$/i,$=/^[^{]+\{\s*\[native \w/,_=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,aa=/[+~]/,ba=/'|\\/g,ca=new ga(a,b,d,e){var f,h,j,k,l,o,r,s,w,x;if((b?b.ownerdocument||b:v)!==n&&m(b),b=b||n,d=d||[],k=b.nodetype,""string""!=typeof d;if(h.id===j)return d.push(h),d}else if(b.ownerdocument&&(h=b.ownerdocument.getelementbyid(j))&&t(b,h)&&h.id===j)return "",l=o.length;while(l--)o[l]=s+ra(o[l]);w=aa.test(a)&&pa(b.parentnode)||b,x=o.join("","")}if(x)try{return h.apply(d,w.queryselectorall(x)),d}catch(y){}finally{r||b.removeattribute(""id"")}}}return ha(){var a=[];function b(c,e){return a.push(c+"" "")>d.cachelength&&delete b[a.shift()],b[c+"" ""]=e}return b}function ia(a){return ja(a){var ka(a,b){var c=a.split(""|""),e=a.length;while(e--)d.attrhandle[c[e]]=b}function la(a,b){var ma(a){return function(b){var c=b.nodename.tolowercase();return""input""===c&&b.type===a}}function na(a){return function(b){var c=b.nodename.tolowercase();return(""input""===c||""button""===c)&&b.type===a}}function oa(a){return ia(function(b){return b=+b,ia(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function pa(a){return a&&""undefined""!=typeof a.getelementsbytagname&&a}c=ga.support={},f=ga.isxml=function(a){var b=a&&(a.ownerdocument||a).documentelement;return b,e,g=a?a.ownerdocument||a:v;return a.classname=""i"",!a.getattribute(""classname"")}),c.getelementsbytagname=ja(function(a){return a.appendchild(g.createcomment("""")),!a.getelementsbytagname(""*"").length}),c.getelementsbyclassname=$.test(g.getelementsbyclassname),c.getbyid=ja(function(a){return o.appendchild(a).id=you,!g.getelementsbyname||!g.getelementsbyname(you).length}),c.getbyid?(d.find.id=function(a,b){if(""undefined""!=typeof b.getelementbyid&&p){var c=b.getelementbyid(a);return c&&c.parentnode?[c]:[]}},d.filter.id=function(a){var b=a.replace(ca,da);return function(a){return a.getattribute(""id"")===b}}):(delete d.find.id,d.filter.id=function(a){var b=a.replace(ca,da);return function(a){var c=""undefined""!=typeof a.getattributenode&&a.getattributenode(""id"");return c&&c.value===b}}),d.find.tag=c.getelementsbytagname?function(a,b){return""undefined""!=typeof b.getelementsbytagname?b.getelementsbytagname(a):c.qsa?b.queryselectorall(a):void d}return f},d.find.class=c.getelementsbyclassname&&function(a,b){return p?b.getelementsbyclassname(a):void id='""+you+""'></a><select id='""+you+""-\f]' msallowcapture=''><option selected=''></option></select>"",a.queryselectorall(""[msallowcapture^='']"").length&&q.push(""[*^$]=""+l+""*(?:''|\""\"")""),a.queryselectorall(""[selected]"").length||q.push(""\\[""+l+""*(?:value|""+k+"")""),a.queryselectorall(""[id~=""+you+""-]"").length||q.push(""~=""),a.queryselectorall("":checked"").length||q.push("":checked""),a.queryselectorall(""a#""+you+""+*"").length||q.push("".#.+[+~]"")}),ja(function(a){var b=g.createelement(""input"");b.setattribute(""type"",""hidden""),a.appendchild(b).setattribute(""name"",""d""),a.queryselectorall(""[name=d]"").length&&q.push(""name""+l+""*[*^$|!~]?=""),a.queryselectorall("":enabled"").length||q.push("":enabled"","":disabled""),a.queryselectorall(""*,:x""),q.push("",.*:"")})),(c.matchesselector=$.test(s=o.matches||o.webkitmatchesselector||o.mozmatchesselector||o.omatchesselector||o.msmatchesselector))&&ja(function(a){c.disconnectedmatch=s.call(a,""div""),s.call(a,""[s!='']:x""),r.push(""!="",p)}),q=q.length&&new regexp(q.join(""|"")),r=r.length&&new regexp(r.join(""|"")),b=$.test(o.comparedocumentposition),t=b||$.test(o.contains)?function(a,b){var d=!a.comparedocumentposition-!b.comparedocumentposition;return la(a,b);c=a;while(c=c.parentnode)h.unshift(c);c=b;while(c=c.parentnode)i.unshift(c);while(h[d]===i[d])d++;return d}catch(e){}return e=d.attrhandle[b.tolowercase()],f=e&&d.call(d.attrhandle,b.tolowercase())?e(a,b,!p):void void new error(""syntax error, unrecognized expression: ""+a)},ga.uniquesort=function(a){var k=null,a},e=ga.gettext=function(a){var a.textcontent)return a.textcontent;for(a=a.firstchild;a;a=a.nextsibling)c+=e(a)}else a.nodevalue}else while(b=a[d++])c+=e(b);return a.nodename&&a.nodename.tolowercase()===b}},class:function(a){var b=y[a+"" ""];return b||(b=new regexp(""(^|""+l+"")""+a+""(""+l+""|$)""))&&y(a,function(a){return b.test(""string""==typeof a.classname&&a.classname||""undefined""!=typeof a.getattribute&&a.getattribute(""class"")||"""")})},attr:function(a,b,c){return function(d){var e=ga.attr(d,a);return ""+e.replace(q,"" "")+"" c,e=d.pseudos[a]||d.setfilters[a.tolowercase()]||ga.error(""unsupported pseudo: ""+a);return d,f=e(a,b),g=f.length;while(g--)d=j(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return d[you]?ia(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return function(b){return w.test(a||"""")||ga.error(""unsupported lang: ""+a),a=a.replace(ca,da).tolowercase(),function(b){var c;do if(c=p?b.lang:b.getattribute(""xml:lang"")||b.getattribute(""lang""))return c=a.location&&a.location.hash;return a===o},focus:function(a){return a===n.activeelement&&(!n.hasfocus||n.hasfocus())&&!!(a.type||a.href||~a.tabindex)},enabled:function(a){return b=a.nodename.tolowercase();return""input""===b&&!!a.checked||""option""===b&&!!a.selected},selected:function(a){return z.test(a.nodename)},input:function(a){return y.test(a.nodename)},button:function(a){var b=a.nodename.tolowercase();return""input""===b&&""button""===a.type||""button""===b},text:function(a){var a}),odd:oa(function(a,b){for(var a}),lt:oa(function(a,b,c){for(var a}),gt:oa(function(a,b,c){for(var a})}},d.pseudos.nth=d.pseudos.eq;for(b qa(){}qa.prototype=d.filters=d.pseudos,d.setfilters=new qa,g=ga.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+"" ""];if(k)return "")}),h=h.slice(c.length));for(g in d.filter)!(e=x[g].exec(h))||j[g]&&!(e=jg)||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return ra(a){for(var d}function sa(a,b,c){var d=b.dir,e=c&&""parentnode""===d,f=x++;return a(b,c,f)}:function(b,c,g){var ta(a){return ua(a,b,c){for(var c}function va(a,b,c,d,e){for(var g}function wa(a,b,c,d,e,f){return d&&!d[you]&&(d=wa(d)),e&&!e[you]&&(e=wa(e,f)),ia(function(f,g,h,i){var r=va(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):h.apply(g,r)})}function xa(a){for(var e=!g&&(d||c!==j)||((b=c).nodetype?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[sa(ta(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[you]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return ta(m)}function ya(a,b){var k&&(w=v,j=t),r};return c?ia(f):f}return h=ga.compile=function(a,b){var c,d=[],e=[],f=a[a+"" ""];if(!f){b||(b=g(a)),c=b.length;while(c--)f=xa(b[c]),f[you]?d.push(f):e.push(f);f=a(a,ya(e,d)),f.selector=a}return f},i=ga.select=function(a,b,e,f){var i,j,k,l,m,n=""function""==typeof h.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,aa.test(a)&&pa(b.parentnode)||b),e},c.sortstable=you.split("""").sort(b).join("""")===you,c.detectduplicates=!!l,m(),c.sortdetached=ja(function(a){return a.innerhtml=""<a href='#'></a>"",""#""===a.firstchild.getattribute(""href"")})||ka(""type|href|height|width"",function(a,b,c){return c?void a.innerhtml=""<input/>"",a.firstchild.setattribute(""value"",""""),""""===a.firstchild.getattribute(""value"")})||ka(""value"",function(a,b,c){return c||""input""!==a.nodename.tolowercase()?void null==a.getattribute(""disabled"")})||ka(k,function(a,b,c){var d;return c?void w(a,b,c){if(m.isfunction(b))return m.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodetype)return m.grep(a,function(a){return a===b!==c});if(""string""==typeof b){if(v.test(b))return m.filter(b,a,c);b=m.filter(b,a)}return m.grep(a,function(a){return b,c=[],d=this,e=d.length;if(""string""!=typeof a)return ""+a:a,c},filter:function(a){return x,y=a.document,z=/^(?:\s*(<[\w\w]+>)[^>]*|#([\w-]*))$/,a=m.fn.init=function(a,b){var c,d;if(!a)return this;if(""string""==typeof instanceof in b)m.isfunction(this[c])?thisc:this.attr(c,b[c]);return this.context=y,this.selector=a,this}return x.ready?x.ready(a):a(m):(void d},sibling:function(a,b){for(var c}}),m.fn.extend({has:function(a){var b,c=m(a,this),d=c.length;return a?""string""==typeof this.pushstack(m.unique(m.merge(this.get(),m(a,b))))},addback:function(a){return this.add(null==a?this.prevobject:this.prevobject.filter(a))}});function d(a,b){do a}m.each({parent:function(a){var b=a.parentnode;return m.dir(a,""parentnode"")},parentsuntil:function(a,b,c){return m.dir(a,""parentnode"",c)},next:function(a){return d(a,""nextsibling"")},prev:function(a){return d(a,""previoussibling"")},nextall:function(a){return m.dir(a,""nextsibling"")},prevall:function(a){return m.dir(a,""previoussibling"")},nextuntil:function(a,b,c){return m.dir(a,""nextsibling"",c)},prevuntil:function(a,b,c){return m.dir(a,""previoussibling"",c)},siblings:function(a){return m.sibling((a.parentnode||{}).firstchild,a)},children:function(a){return m.sibling(a.firstchild)},contents:function(a){return m.nodename(a,""iframe"")?a.contentdocument||a.contentwindow.document:m.merge([],a.childnodes)}},function(a,b){m.fn[a]=function(c,d){var e=/\s+/g,f={};function g(a){var b=f[a]={};return a?f[a]||g(a):m.extend({},a);var d=h.length;!function f(b){m.each(b,function(b,c){var d=m.type(c);""function""===d?a.unique&&k.has(c)||h.push(c):c&&c.length&&""string""!==d&&f(c)})}(arguments),b?e=h.length:c&&(g=d,j(c))}return this},remove:function(){return h&&m.each(arguments,function(a,c){var h=i=c=void i=void k.firewith(this,arguments),this},fired:function(){return!!d}};return k},m.extend({deferred:function(a){var b=[[""resolve"",""done"",m.callbacks(""once memory""),""resolved""],[""reject"",""fail"",m.callbacks(""once memory""),""rejected""],[""notify"",""progress"",m.callbacks(""memory"")]],c=""pending"",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return m.deferred(function(c){m.each(b,function(b,f){var null!=a?m.extend(a,d):d}},e={};return d.pipe=d.then,m.each(b,function(a,f){var array(e),j=new array(e),k=new array(e);e>b;b++)c[b]&&m.isfunction(c[b].promise)?c[b].promise().done(h(b,k,c)).fail(g.reject).progress(h(b,j,i)):--f;return f||g.resolvewith(k,c),g.promise()}});var h;m.fn.ready=function(a){return j(){(y.addeventlistener||""load""===event.type||""complete""===y.readystate)&&(i(),m.ready())}m.ready.promise=function(b){if(!h)if(h=m.deferred(),""complete""===y.readystate)settimeout(m.ready);else e(){if(!m.isready){try{c.doscroll(""left"")}catch(a){return h.promise(b)};var k=""undefined"",l;for(l in b=m.nodata[(a.nodename+"" m=/^(?:\{[\w\w]*\}|\[[\w\w]*\])$/,n=/([a-z])/g;function o(a,b,c){if(void c=void c}function p(a){var b;for(b in q(a,b,d,e){if(m.acceptdata(a)){var f,g,h=m.expando,i=a.nodetype,j=i?m.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void b)return k||(k=i?a[h]=c.pop()||m.guid++:h),j[k]||(j[k]=i?{}:{tojson:m.noop}),(""object""==typeof b||""function""==typeof b)&&(e?j[k]=m.extend(j[k],b):j[k].data=m.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void b?(f=g[b],null==f&&(f=g[m.camelcase(b)])):f=g,f}}function r(a,b,c){if(m.acceptdata(a)){var d,e,f=a.nodetype,g=f?m.cache:a,h=f?a[m.expando]:m.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){m.isarray(b)?b=b.concat(m.map(b,m.camelcase)):b in d?b=[b]:(b=m.camelcase(b),b=b in d?[b]:b.split("" "")),e=b.length;while(e--)delete d[b[e]];if(c?!p(d):!m.isemptyobject(d))return}(c||(delete g[h]:g[h]=null)}}}m.extend({cache:{},nodata:{""applet a=a.nodetype?m.cache[a[m.expando]]:a[m.expando],!!a&&!p(a)},data:function(a,b,c){return q(a,b,c)},removedata:function(a,b){return r(a,b)},_data:function(a,b,c){return e}return""object""==typeof this.each(function(){m.removedata(this,a)})}}),m.extend({queue:function(a,b,c){var d;return a?(b=(b||""fx"")+""queue"",d=m._data(a,b),c&&(!d||m.isarray(c)?d=m._data(a,b,m.makearray(c)):d.push(c)),d||[]):void c=m.queue(a,b),d=c.length,e=c.shift(),f=m._queuehooks(a,b),g=function(){m.dequeue(a,b)};""inprogress""===e&&(e=c.shift(),d--),e&&(""fx""===b&&c.unshift(""inprogress""),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queuehooks:function(a,b){var c=b+""queuehooks"";return m._data(a,c)||m._data(a,c,{empty:m.callbacks(""once memory"").add(function(){m._removedata(a,b+""queue""),m._removedata(a,c)})})}}),m.fn.extend({queue:function(a,b){var this.each(function(){m.dequeue(this,a)})},clearqueue:function(a){return this.queue(a||""fx"",[])},promise:function(a,b){var a&&(b=a,a=void h(),e.promise(b)}});var s=/[+-]?(?:\d*\.|)\d+(?:[ee][+-]?\d+|)/.source,t=[""top"",""right"",""bottom"",""left""],you=function(a,b){return a=b||a,""none""===m.css(a,""display"")||!m.contains(a.ownerdocument,a)},v=m.access=function(a,b,c,d,e,f,g){var in if(void j.call(m(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return a=y.createelement(""input""),b=y.createelement(""div""),c=y.createdocumentfragment();if(b.innerhtml="" <link/><table></table><a href='/a'>a</a><input type='radio' checked='checked' b,c,d=y.createelement(""div"");for(b in x=/^(?:input|select|textarea)$/i,y=/^key/,z=/^(?:mouse|pointer|contextmenu)|click/,$=/^(?:focusinfocus|focusoutblur)$/,_=/^([^.]*)(?:\.(.+)|)$/;function ca(){try{return y.activeelement}catch(a){}}m.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,n,o,p,q,r=m._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=m.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return typeof m===k||a&&m.event.triggered===a.type?void k[o])}else for(o in r.handle,m._removedata(a,""events""))}},trigger:function(b,c,d,e){var m.event(p,""object""==typeof regexp(""(^|\\.)""+q.join(""\\.(?:.*\\.|)"")+""(\\.|$)""):null,b.result=void b.result}},dispatch:function(a){a=m.event.fix(a);var k.postdispatch&&k.postdispatch.call(this,a),a.result}},handlers:function(a,b){var "",void h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[m.expando])return a;var b,c,d,e=a.type,f=a,g=this.fixhooks[e];g||(this.fixhooks[e]=g=z.test(e)?this.mousehooks:y.test(e)?this.keyhooks:{}),d=g.props?this.props.concat(g.props):this.props,a=new m.event(f),b=d.length;while(b--)c=d[b],a[c]=f[c];return bubbles cancelable ctrlkey currenttarget eventphase metakey relatedtarget shiftkey target timestamp view which"".split("" ""),fixhooks:{},keyhooks:{props:""char charcode key keycode"".split("" ""),filter:function(a,b){return null==a.which&&(a.which=null!=b.charcode?b.charcode:b.keycode),a}},mousehooks:{props:""button buttons clientx clienty fromelement offsetx offsety pagex pagey screenx screeny toelement"".split("" ""),filter:function(a,b){var c,d,e,f=b.button,g=b.fromelement;return m.nodename(a.target,""a"")}},beforeunload:{postdispatch:function(a){void e=m.extend(new d=""on""+b;a.detachevent&&(typeof a[d]===k&&(a[d]=null),a.detachevent(d,c))},m.event=function(a,b){return this instanceof m.event?(a&&a.type?(this.originalevent=a,this.type=a.type,this.isdefaultprevented=a.defaultprevented||void m.event(a,b)},m.event.prototype={isdefaultprevented:ba,ispropagationstopped:ba,isimmediatepropagationstopped:ba,preventdefault:function(){var a=this.originalevent;this.isimmediatepropagationstopped=aa,a&&a.stopimmediatepropagation&&a.stopimmediatepropagation(),this.stoppropagation()}},m.each({mouseenter:""mouseover"",mouseleave:""mouseout"",pointerenter:""pointerover"",pointerleave:""pointerout""},function(a,b){m.event.special[a]={delegatetype:b,bindtype:b,handle:function(a){var c,d=this,e=a.relatedtarget,f=a.handleobj;return(!e||e!==d&&!m.contains(d,e))&&(a.type=f.origtype,c=f.handler.apply(this,arguments),a.type=b),c}}}),k.submitbubbles||(m.event.special.submit={setup:function(){return m.event.add(this,""click._submit keypress._submit"",function(a){var b=a.target,c=m.nodename(b,""input"")||m.nodename(b,""button"")?b.form:void m.event.remove(this,""._submit"")}}),k.changebubbles||(m.event.special.change={setup:function(){return m.event.add(this,""beforeactivate._change"",function(a){var b=a.target;return this!==b||a.issimulated||a.istrigger||""radio""!==b.type&&""checkbox""!==b.type?a.handleobj.handler.apply(this,arguments):void m.event.remove(this,""._change""),!x.test(this.nodename)}}),k.focusinbubbles||m.each({focus:""focusin"",blur:""focusout""},function(a,b){var f,g;if(""object""==typeof a){""string""!=typeof b&&(c=c||b,b=void in a)this.on(f,b,c,a[f],e);return this}if(null==c&&null==d?(d=b,c=b=void b?(d=c,c=void if(!d)return this;return m().off(a),g.apply(this,arguments)},d.guid=g.guid||(g.guid=m.guid++)),this.each(function(){m.event.add(this,a,d,c,b)})},one:function(a,b,c,d){return d,e;if(a&&a.preventdefault&&a.handleobj)return d=a.handleobj,m(a.delegatetarget).off(d.namespace?d.origtype+"".""+d.namespace:d.origtype,d.selector,d.handler),this;if(""object""==typeof a){for(e in a)this.off(e,b,a[e]);return b)&&(c=b,b=void this.each(function(){m.event.trigger(a,b,this)})},triggerhandler:function(a,b){var da(a){var b=ea.split(""|""),c=a.createdocumentfragment();if(c.createelement)while(b.length)c.createelement(b.pop());return c}var ea=""abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video"",fa=/ jquery\d+=""(?:null|\d+)""/g,ga=new ua(a,b){var a.getelementsbytagname!==k?a.getelementsbytagname(b||""*""):typeof a.queryselectorall!==k?a.queryselectorall(b||""*""):void void va(a){w.test(a.type)&&(a.defaultchecked=a.checked)}function wa(a,b){return xa(a){return a.type=(null!==m.find.attr(a,""type""))+""/""+a.type,a}function ya(a){var b=pa.exec(a.type);return za(a,b){for(var c,d,e,f=m._data(a),g=m._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in ba(a,b){var in aa(a,f);return h=null,o},cleandata:function(a,b){for(var in g.events)n[e]?m.event.remove(d,e):m.removeevent(d,e,g.handle);j[f]&&(delete j[f],l?delete d[i]:typeof d.removeattribute!==k?d.removeattribute(i):d[i]=null,c.push(f))}}}),m.fn.extend({text:function(a){return v(this,function(a){return void b=wa(this,a);b.appendchild(a)}})},prepend:function(){return b=wa(this,a);b.insertbefore(a,b.firstchild)}})},before:function(){return this.dommanip(arguments,function(a){this.parentnode&&this.parentnode.insertbefore(a,this)})},after:function(){return this.dommanip(arguments,function(a){this.parentnode&&this.parentnode.insertbefore(a,this.nextsibling)})},remove:function(a,b){for(var this},empty:function(){for(var this},clone:function(a,b){return m.clone(this,a,b)})},html:function(a){return v(this,function(a){var this.dommanip(arguments,function(b){a=this.parentnode,m.cleandata(ua(this)),a&&a.replacechild(b,this)}),a&&(a.length||a.nodetype)?this:this.remove()},detach:function(a){return p&&!k.checkclone&&na.test(p))return this.each(function(c){var this}}),m.each({appendto:""append"",prependto:""prepend"",insertbefore:""before"",insertafter:""after"",replaceall:""replacewith""},function(a,b){m.fn[a]=function(a){for(var this.pushstack(e)}});var ca,da={};function ea(b,c){var e.detach(),f}function fa(a){var b=y,c=da[a];return c||(c=ea(a,b),""none""!==c&&c||(ca=(ca||m(""<iframe a;k.shrinkwrapblocks=function(){if(null!=a)return b,c,d;return ga=/^margin/,ha=new regexp(""^(""+s+"")(?!px)[a-z%]+$"",""i""),ia,ja,ka=/^(top|right|bottom|left)$/;a.getcomputedstyle?(ia=function(b){return b.ownerdocument.defaultview.opener?b.ownerdocument.defaultview.getcomputedstyle(b,null):a.getcomputedstyle(b,null)},ja=function(a,b,c){var d,e,f,g,h=a.style;return c=c||ia(a),g=c?c.getpropertyvalue(b)||c[b]:void a.currentstyle},ja=function(a,b,c){var d,e,f,g,h=a.style;return c=c||ia(a),g=c?c[b]:void la(a,b){return{get:function(){var c=a();if(null!=c)return c?void delete this.get:(this.get=b).apply(this,arguments)}}}!function(){var b,c,d,e,f,g,h;if(b=y.createelement(""div""),b.innerhtml="" <link/><table></table><a href='/a'>a</a><input null==g&&i(),g},boxsizingreliable:function(){return null==f&&i(),f},pixelposition:function(){return null==e&&i(),e},reliablemarginright:function(){return null==h&&i(),h}});function i(){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e};var ma=/alpha\([^)]*\)/i,na=/opacity\s*=\s*([^)]*)/,oa=/^(none|table(?!-c[ea]).+)/,pa=new regexp(""^(""+s+"")(.*)$"",""i""),qa=new ua(a,b){if(b in a)return b;var in a)return b;return d}function va(a,b){for(var a}function wa(a,b,c){var d=pa.exec(b);return xa(a,b,c,d,e){for(var g}function ya(a,b,c){var e+xa(a,b,c||(g?""border"":""content""),d,f)+""px""}m.extend({csshooks:{opacity:{get:function(a,b){if(b){var e,f,g,h=m.camelcase(b),i=a.style;if(b=m.cssprops[h]||(m.cssprops[h]=ua(i,h)),g=m.csshooks[b]||m.csshooks[h],void g&&""get""in g&&void g&&void e,f,g,h=m.camelcase(b);return b=m.cssprops[h]||(m.cssprops[h]=ua(a.style,h)),g=m.csshooks[b]||m.csshooks[h],g&&""get""in in ya(a,b,d)}):ya(a,b,d):void e=d&&ia(a);return ""+e)}}),m.csshooks.marginright=la(k.reliablemarginright,function(a,b){return b?m.swap(a,{display:""inline-block""},ja,[a,""marginright""]):void c?c.split("" e}},ga.test(a)||(m.csshooks[a+b].set=wa)}),m.fn.extend({css:function(a,b){return v(this,function(a,b,c){var f}return void va(this)},toggle:function(a){return""boolean""==typeof a?a?this.show():this.hide():this.each(function(){you(this)?m(this).show():m(this).hide()})}});function za(a,b,c,d,e){ return new za.prototype.init(a,b,c,d,e)}m.tween=za,za.prototype={constructor:za,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||""swing"",this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(m.cssnumber[c]?"""":""px"")},cur:function(){var a=za.prophooks[this.prop];return a&&a.get?a.get(this):za.prophooks._default.get(this)},run:function(a){var b,c=za.prophooks[this.prop];return this.options.duration?this.pos=b=m.easingthis.easing:this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):za.prophooks._default.set(this),this}},za.prototype.init.prototype=za.prototype,za.prophooks={_default:{get:function(a){var b;return $a,_a,ab=/^(?:toggle|show|hide)$/,bb=new regexp(""^(?:([+-])=|)(""+s+"")([a-z%]*)$"",""i""),cb=/queuehooks$/,db=[ib],eb={""*"":[function(a,b){var fb(){return settimeout(function(){$a=void gb(a,b){var b&&(d.opacity=d.width=a),d}function hb(a,b,c){for(var d}function ib(a,b,c){var b||""width""in in b)if(e=b[d],ab.exec(e)){if(delete b[d],f=f||""toggle""===e,e===(q?""hide"":""show"")){if(""show""!==e||!r||void j=void r&&(q=r.hidden):r=m._data(a,""fxshow"",{}),f&&(r.hidden=!q),q?m(a).show():n.done(function(){m(a).hide()}),n.done(function(){var b;m._removedata(a,""fxshow"");for(b in o)m.style(a,b,o[b])});for(d in in jb(a,b){var c,d,e,f,g;for(c in a[c]),g=m.csshooks[d],g&&""expand""in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function kb(a,b,c){var d=m.tween(a,j.opts,b,c,j.opts.specialeasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var b?h.resolvewith(a,[j,b]):h.rejectwith(a,[j,b]),this}}),k=j.props;for(jb(k,j.opts.specialeasing);g>f;f++)if(d=db[f].call(j,a,k,j.opts))return d;return m.map(k,hb,j),m.isfunction(j.opts.start)&&j.opts.start.call(a,j),m.fx.timer(m.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}m.animation=m.extend(kb,{tweener:function(a,b){m.isfunction(a)?(b=a,a=[""*""]):a=a.split("" "");for(var d=a&&""object""==typeof a?m.extend({},a):{complete:c||!c&&b||m.isfunction(a)&&a,duration:a,easing:c&&b||b&&!m.isfunction(b)&&b};return d.duration?d.duration:d.duration in e=m.isemptyobject(a),f=m.speed(b,c,d),g=function(){var d=function(a){var b=a.stop;delete a.stop,b(c)};return""string""!=typeof a&&(c=b,b=a,a=void for(e in c.finish})}}),m.each([""toggle"",""show"",""hide""],function(a,b){var c=m.fn[b];m.fn[b]=function(a,d,e){return null==a||""boolean""==typeof this.animate(b,a,c,d)}}),m.timers=[],m.fx.tick=function(){var a=m.fx?m.fx.speeds[a]||a:a,b=b||""fx"",this.queue(b,function(b,c){var d=settimeout(b,a);c.stop=function(){cleartimeout(d)}})},function(){var a,b,c,d,e;b=y.createelement(""div""),b.setattribute(""classname"",""t""),b.innerhtml="" <link/><table></table><a href='/a'>a</a><input lb=/\r/g;m.fn.extend({val:function(a){var d=m.isfunction(a),this.each(function(c){var e?e+="""":m.isarray(e)&&(e=m.map(e,function(a){return null==a?"""":a+""""})),b=m.valhooks[this.type]||m.valhooks[this.nodename.tolowercase()],b&&""set""in b&&void b=m.valhooks[e.type]||m.valhooks[e.nodename.tolowercase()],b&&""get""in b&&void c?c.replace(lb,""""):null==c?"""":c)}}}),m.extend({valhooks:{option:{get:function(a){var b=m.find.attr(a,""value"");return null!=b?b:m.trim(m.text(a))}},select:{get:function(a){for(var b;g.push(b)}return g},set:function(a,b){var null===a.getattribute(""value"")?""on"":a.value})});var mb,nb,ob=m.expr.attrhandle,pb=/^(?:checked|selected)$/i,qb=k.getsetattribute,rb=k.input;m.fn.extend({attr:function(a,b){return this.each(function(){m.removeattr(this,a)})}}),m.extend({attr:function(a,b,c){var typeof d&&null!==(e=d.get(a,b))?e:(e=m.find.attr(a,b),null==e?void d&&void m.removeattr(a,b))},removeattr:function(a,b){var c=a.value;return a.setattribute(""type"",b),c&&(a.value=c),b}}}}}),nb={set:function(a,b,c){return c=ob[b]||m.find.attr;ob[b]=rb&&qb||!pb.test(b)?function(a,b,d){var e,f;return d||(f=ob[b],ob[b]=e,e=null!=c(a,b,d)?b.tolowercase():null,ob[b]=f),e}:function(a,b,c){return c?void m.nodename(a,""input"")?void(a.defaultvalue=b):mb&&mb.set(a,b,c)}}),qb||(mb={set:function(a,b,c){var d=a.getattributenode(c);return d||a.setattributenode(d=a.ownerdocument.createattribute(c)),d.value=b+="""",""value""===c||b===a.getattribute(c)?b:void d;return c?void c=a.getattributenode(b);return c&&c.specified?c.value:void a.style.csstext||void a.style.csstext=b+""""}});var sb=/^(?:input|select|textarea|button|object)$/i,tb=/^(?:a|area)$/i;m.fn.extend({prop:function(a,b){return a=m.propfix[a]||a,this.each(function(){try{this[a]=void this[a]}catch(b){}})}}),m.extend({propfix:{""for"":""htmlfor"",""class"":""classname""},prop:function(a,b,c){var e&&void e&&null!==(d=e.get(a,b))?d:a[b]},prophooks:{tabindex:{get:function(a){var b=m.find.attr(a,""tabindex"");return b=a.parentnode;return b&&(b.selectedindex,b.parentnode&&b.parentnode.selectedindex),null}}),m.each([""tabindex"",""readonly"",""maxlength"",""cellspacing"",""cellpadding"",""rowspan"",""colspan"",""usemap"",""frameborder"",""contenteditable""],function(){m.propfix[this.tolowercase()]=this}),k.enctype||(m.propfix.enctype=""encoding"");var ub=/[\t\r\n\f]/g;m.fn.extend({addclass:function(a){var a&&a;if(m.isfunction(a))return ""+c.classname+"" "").replace(ub,"" ""):"" ""+e+"" "");g=m.trim(d),c.classname!==g&&(c.classname=g)}return this},removeclass:function(a){var a&&a;if(m.isfunction(a))return ""+c.classname+"" "").replace(ub,"" ""+e+"" ""+e+"" "","" "");g=a?m.trim(d):"""",c.classname!==g&&(c.classname=g)}return this},toggleclass:function(a,b){var c=typeof a;return""boolean""==typeof b&&""string""===c?b?this.addclass(a):this.removeclass(a):this.each(m.isfunction(a)?function(c){m(this).toggleclass(a.call(this,c,this.classname,b),b)}:function(){if(""string""===c){var b="" ""+a+"" ""+this[c].classname+"" "").replace(ub,"" focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu"".split("" ""),function(a,b){m.fn[b]=function(a,c){return this.mouseenter(a).mouseleave(b||a)},bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return a.json.parse(b+"""");var c,d=null,e=m.trim(b+"""");return e&&!m.trim(e.replace(xb,function(a,b,e,f){return ""+e)():m.error(""invalid json: ""+b)},m.parsexml=function(b){var c,d;if(!b||""string""!=typeof b)return null;try{a.domparser?(d=new domparser,c=d.parsefromstring(b,""text/xml"")):(c=new activexobject(""microsoft.xmldom""),c.async=""false"",c.loadxml(b))}catch(e){c=void c&&c.documentelement&&!c.getelementsbytagname(""parsererror"").length||m.error(""invalid xml: ""+b),c};var yb,zb,ab=/#.*$/,bb=/([?&])_=[^&]*/,cb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,db=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,eb=/^(?:get|head)$/,fb=/^\/\//,gb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,hb={},ib={},jb=""*/"".concat(""*"");try{zb=location.href}catch(kb){zb=y.createelement(""a""),zb.href="""",zb=zb.href}yb=gb.exec(zb.tolowercase())||[];function lb(a){return function(b,c){""string""!=typeof b&&(c=b,b=""*"");var mb(a,b,c,d){var e={},f=a===ib;function g(h){var i;return j=h(b,c,d);return""string""!=typeof j||f||e[j]?f?!(i=j):void nb(a,b){var c,d,e=m.ajaxsettings.flatoptions||{};for(d in b)void ob(a,b,c){var in in pb(a,b,c,d){var in a.converters)j[g.tolowercase()]=a.converters[g];f=k.shift();while(f)if(a.responsefields[f]&&(c[a.responsefields[f]]=b),!i&&d&&a.datafilter&&(b=a.datafilter(b,a.datatype)),i=f,f=k.shift())if(""*""===f)f=i;else if(""*""!==i&&i!==f){if(g=j[i+"" ""+f]||j[""* ""+f],!g)for(e in j)if(h=e.split("" try{b=g(b)}catch(l){return{state:""parsererror"",error:g?l:""no conversion from ""+i+"" to text/xml"",json:""application/json, text/javascript""},contents:{xml:/xml/,html:/html/,json:/json/},responsefields:{xml:""responsexml"",text:""responsetext"",json:""responsejson""},converters:{""* text"":string,""text json"":m.parsejson,""text b?nb(nb(a,m.ajaxsettings),b):nb(m.ajaxsettings,a)},ajaxprefilter:lb(hb),ajaxtransport:lb(ib),ajax:function(a,b){""object""==typeof a&&(b=a,a=void c,d,e,f,g,h,i,j,k=m.ajaxsetup({},b),l=k.context||k,n=k.context&&(l.nodetype||l.jquery)?m(l):m.event,o=m.deferred(),p=m.callbacks(""once null==b?null:b},getallresponseheaders:function(){return c=a.tolowercase();return t||(a=s[c]=s[c]||a,r[a]=b),this},overridemimetype:function(a){return t||(k.mimetype=a),this},statuscode:function(a){var in a)q[b]=[q[b],a[b]];else v.always(a[v.status]);return this},abort:function(a){var b=a||you;return ""+jb+""; in v.abort();you=""abort"";for(d transport"");function x(a,b,c,d){var v},getjson:function(a,b,c){return m.get(a,b,c,""json"")},getscript:function(a,b){return m.get(a,void m.isfunction(c)&&(e=e||d,d=c,c=void a}).append(this)}return this},wrapinner:function(a){return this.each(m.isfunction(a)?function(b){m(this).wrapinner(a.call(this,b))}:function(){var b=m(this),c=b.contents();c.length?c.wrapall(a):b.append(a)})},wrap:function(a){var b=m.isfunction(a);return this.each(function(c){m(this).wrapall(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){m.nodename(this,""body"")||m(this).replacewith(this.childnodes)}).end()}}),m.expr.filters.hidden=function(a){return vb(a,b,c,d){var e;if(m.isarray(b))m.each(b,function(b,e){c||rb.test(a)?d(a,e):vb(a+""[""+(""object""==typeof e?b:"""")+""]"",e,c,d)});else if(c||""object""!==m.type(b))d(a,b);else for(e in b)vb(a+""[""+e+""]"",b[e],c,d)}m.param=function(a,b){var c,d=[],e=function(a,b){b=m.isfunction(b)?b():null==b?"""":b,d[d.length]=encodeuricomponent(a)+""=""+encodeuricomponent(b)};if(void for(c in a)vb(c,a[c],b,e);return d.join(""&"").replace(qb,""+"")},m.fn.extend({serialize:function(){return m.param(this.serializearray())},serializearray:function(){return this.map(function(){var a=m.prop(this,""elements"");return a?m.makearray(a):this}).filter(function(){var a=this.type;return this.name&&!m(this).is("":disabled"")&&ub.test(this.nodename)&&!tb.test(a)&&(this.checked||!w.test(a))}).map(function(a,b){var c=m(this).val();return null==c?null:m.isarray(c)?m.map(c,function(a){return{name:b.name,value:a.replace(sb,""\r\n"")}}):{name:b.name,value:c.replace(sb,""\r\n"")}}).get()}}),m.ajaxsettings.xhr=void a in xb)xba}),k.cors=!!yb&&""withcredentials""in yb,yb=k.ajax=!!yb,yb&&m.ajaxtransport(function(a){if(!a.crossdomain||k.cors){var b;return{send:function(c,d){var e,f=a.xhr(),g=++wb;if(f.open(a.type,a.url,a.async,a.username,a.password),a.xhrfields)for(e in a.xhrfields)f[e]=a.xhrfields[e];a.mimetype&&f.overridemimetype&&f.overridemimetype(a.mimetype),a.crossdomain||c[""x-requested-with""]||(c[""x-requested-with""]=""xmlhttprequest"");for(e in c)void xb[g],b=void zb(){try{return new a.xmlhttprequest}catch(b){}}function $b(){try{return new a.activexobject(""microsoft.xmlhttp"")}catch(b){}}m.ajaxsetup({accepts:{script:""text/javascript, application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/(?:java|ecma)script/},converters:{""text script"":function(a){return m.globaleval(a),a}}}),m.ajaxprefilter(""script"",function(a){void _b=[],ac=/(=)\?(?=&|$)|\?\?/;m.ajaxsetup({jsonp:""callback"",jsonpcallback:function(){var a=_b.pop()||m.expando+""_""+vb++;return jsonp"",function(b,c,d){var b.data&&!(b.contenttype||"""").indexof(""application/x-www-form-urlencoded"")&&ac.test(b.data)&&""data"");return json""]=function(){return g||m.error(e+"" was not a)return null;""boolean""==typeof d=you.exec(a),e=!c&&[];return because=m.fn.load;m.fn.load=function(a,b,c){if(""string""!=typeof a&&because)return because.apply(this,arguments);var d,e,f,g=this,h=a.indexof("" "");return this.on(b,a)}}),m.expr.filters.animated=function(a){return m.grep(m.timers,function(b){return a===b.elem}).length};var cc=a.document.documentelement;function dc(a){return b?b.using.call(a,n):l.css(n)}},m.fn.extend({offset:function(a){if(arguments.length)return void b=f.documentelement,m.contains(b,e)?(typeof this.map(function(){var a=this.offsetparent||cc;while(a&&!m.nodename(a,""html"")&&""static""===m.css(a,""position""))a=a.offsetparent;return a||cc})}}),m.each({scrollleft:""pagexoffset"",scrolltop:""pageyoffset""},function(a,b){var c=/y/.test(b);m.fn[a]=function(d){return v(this,function(a,d,e){var f=dc(a);return void in f?f[b]:f.document.documentelement[d]:a[d]:void(f?f.scrollto(c?m(f).scrollleft():e,c?e:m(f).scrolltop()):a[d]=e)},a,d,arguments.length,null)}}),m.each([""top"",""left""],function(a,b){m.csshooks[b]=la(k.pixelposition,function(a,c){return c?(c=ja(a,b),ha.test(c)?m(a).position()[b]+""px"":c):void f=arguments.length&&(c||""boolean""!=typeof v(this,function(b,c,d){var e;return this.length},m.fn.andself=m.fn.addback,""function""==typeof define&&define.amd&&define(""jquery"",[],function(){return m});var ec=a.jquery,fc=a.$;return m.noconflict=function(b){return a.$===m&&(a.$=fc),b&&a.jquery===m&&(a.jquery=ec),m},typeof b===k&&(a.jquery=a.$=m),m}); </script> <meta name=""viewport"" content=""width=device-width, /> <style input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html solid ("" attr(href) "")""}abbr[title]:after{content:"" ("" attr(title) solid solid td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered solid #ddd!important}}@font-face{font-family:'glyphicons auto solid ease-in-out;-o-transition:all ease-in-out;transition:all solid solid old,old ul,ul old,ul dotted solid #eee}blockquote old:last-child,blockquote p:last-child,blockquote .small,blockquote footer,blockquote .small:before,blockquote footer:before,blockquote solid .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:''}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right solid solid solid solid #ddd}.table solid solid col[class*=col-]{position:static;display:table-column;float:none}table td[class*=col-],table screen and solid solid auto solid ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out .form-control{cursor:not-allowed}textarea.form-control{height:auto}input[type=search]{-webkit-appearance:none}@media screen and input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg label,.radio input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:not-allowed}.checkbox-inline.disabled,.radio-inline.disabled,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio-inline{cursor:not-allowed}.checkbox.disabled label,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .radio select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.form-inline .checkbox,.form-inline .checkbox label,.form-inline .radio .checkbox input[type=checkbox],.form-inline .radio .has-feedback .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .checkbox,.form-horizontal .has-feedback .form-group-lg .form-group-sm solid auto .btn-default,fieldset[disabled] .btn-default.active,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .btn-primary,fieldset[disabled] .btn-primary.active,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success.active,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info.active,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning.active,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger.active,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-link:focus,fieldset[disabled] linear;-o-transition:opacity linear;transition:opacity solid solid solid solid .caret,.navbar-fixed-bottom .dropdown .dropdown-menu,.navbar-fixed-bottom .dropdown .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn,.btn-toolbar .btn-group,.btn-toolbar .dropdown-toggle:active,.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn .btn-lg .dropdown-menu{left:auto}[data-toggle=buttons]>.btn input[type=checkbox],[data-toggle=buttons]>.btn input[type=radio],[data-toggle=buttons]>.btn-group>.btn input[type=checkbox],[data-toggle=buttons]>.btn-group>.btn .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group solid input[type=checkbox],.input-group-addon .open>a,.nav .open>a:focus,.nav solid solid #eee solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid solid transparent}@media solid transparent;-webkit-box-shadow:inset .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse,.navbar-fixed-top and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-brand,.navbar>.container-fluid solid .open .open .dropdown-menu .dropdown-header,.navbar-nav .open .open .open .dropdown-menu>li>a:focus,.navbar-nav .open .dropdown-menu>li>a:hover{background-image:none}}@media solid solid transparent;-webkit-box-shadow:inset .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.navbar-form .checkbox,.navbar-form .checkbox label,.navbar-form .radio .checkbox input[type=checkbox],.navbar-form .radio .has-feedback .navbar-brand:focus,.navbar-default .navbar-nav>li>a:focus,.navbar-default .navbar-nav>.active>a,.navbar-default .navbar-nav>.active>a:focus,.navbar-default .navbar-nav>.disabled>a,.navbar-default .navbar-nav>.disabled>a:focus,.navbar-default .navbar-nav>.disabled>a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .navbar-collapse,.navbar-default .navbar-nav>.open>a,.navbar-default .navbar-nav>.open>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.active>a,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#ccc;background-color:transparent}}.navbar-default .btn-link:focus,.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>li>a:focus,.navbar-inverse .navbar-nav>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>.active>a,.navbar-inverse .navbar-nav>.active>a:focus,.navbar-inverse .navbar-nav>.disabled>a,.navbar-inverse .navbar-nav>.disabled>a:focus,.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-nav>.open>a,.navbar-inverse .navbar-nav>.open>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-inverse .navbar-nav .open .navbar-link:hover{color:#fff}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse solid li{display:inline}.pager li>a,.pager solid li>a:focus,.pager li>a:hover{text-decoration:none;background-color:#eee}.pager .next>a,.pager .next>span{float:right}.pager .previous>a,.pager .previous>span{float:left}.pager .disabled>a,.pager .disabled>a:focus,.pager .disabled>a:hover,.pager .badge,.btn-xs .jumbotron,.container-fluid screen and .jumbotron,.container-fluid solid ease-in-out;-o-transition:border ease-in-out;transition:border ease-in-out}.thumbnail solid .close,.alert-dismissible ease;-o-transition:width ease;transition:width ease}.progress-bar-striped,.progress-striped .progress-bar{-webkit-animation:progress-bar-stripes linear infinite;-o-animation:progress-bar-stripes linear infinite;animation:progress-bar-stripes linear solid .list-group-item-heading,button.list-group-item .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-heading,.list-group-item.active .list-group-item-heading>.small,.list-group-item.active .list-group-item-heading>small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading>.small,.list-group-item.active:focus .list-group-item-heading>small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading>.small,.list-group-item.active:hover .list-group-item-heading>small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-heading,button.list-group-item-success .list-group-item-heading,button.list-group-item-info .list-group-item-heading,button.list-group-item-warning .list-group-item-heading,button.list-group-item-danger solid solid solid .list-group-item,.panel>.panel-collapse>.list-group .list-group-item:first-child,.panel>.panel-collapse>.list-group:first-child .list-group-item:last-child,.panel>.panel-collapse>.list-group:last-child caption,.panel>.table caption,.panel>.table-responsive>.table td:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child solid #ddd}.panel>.table>tbody:first-child>tr:first-child td,.panel>.table>tbody:first-child>tr:first-child .panel-heading+.panel-collapse>.list-group,.panel-group solid #ddd}.panel-group .panel-footer+.panel-collapse solid .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive solid .modal-dialog{-webkit-transition:-webkit-transform ease-out;-o-transition:-o-transform ease-out;transition:transform solid solid solid solid .btn-group solid solid solid ease-in-out ease-in-out ease-in-out all and ease-in-out;-o-transition:-o-transform ease-in-out;transition:transform top,right top,right .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control solid .btn{text-shadow:none}@media screen and .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control dd:after,.dl-horizontal dd:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before,.modal-footer:after,.modal-footer:before,.nav:after,.nav:before,.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.row:after,.row:before{display:table;content:"" ""}.btn-group-vertical>.btn-group:after,.btn-toolbar:after,.clearfix:after,.container-fluid:after,.container:after,.dl-horizontal dd:after,.form-horizontal and and and and and and and and and and print{.visible-print{display:block!important}table.visible-print{display:table!important}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}}@media print{.hidden-print{display:none!important}} </style> <script>/*! * bootstrap (http://getbootstrap.com) * copyright twitter, inc. * licensed under the mit license */ if(""undefined""==typeof jquery)throw new error(""bootstrap's javascript requires jquery"");+function(a){""use strict"";var b=a.fn.jquery.split("" new error(""bootstrap's javascript requires jquery version or higher"")}(jquery),+function(a){""use strict"";function b(){var a=document.createelement(""bootstrap""),b={webkittransition:""webkittransitionend"",moztransition:""transitionend"",otransition:""otransitionend otransitionend"",transition:""transitionend""};for(var c in b)if(void e=function(){c||a(d).trigger(a.support.transition.end)};return settimeout(e,b),this},a(function(){a.support.transition=b(),a.support.transition&&(a.event.special.bstransitionend={bindtype:a.support.transition.end,delegatetype:a.support.transition.end,handle:function(b){return a(b.target).is(this)?b.handleobj.handler.apply(this,arguments):void strict"";function b(b){return this.each(function(){var c=a(this),e=c.data(""bs.alert"");e||c.data(""bs.alert"",e=new d(this)),""string""==typeof b&&e[b].call(c)})}var c(){g.detach().trigger(""closed.bs.alert"").remove()}var e=a(this),f=e.attr(""data-target"");f||(f=e.attr(""href""),f=f&&f.replace(/.*(?=#[^\s]*$)/,""""));var g=a(f);b&&b.preventdefault(),g.length||(g=e.closest("".alert"")),g.trigger(b=a.event(""close.bs.alert"")),b.isdefaultprevented()||(g.removeclass(""in""),a.support.transition&&g.hasclass(""fade"")?g.one(""bstransitionend"",c).emulatetransitionend(d.transition_duration):c())};var e=a.fn.alert;a.fn.alert=b,a.fn.alert.constructor=d,a.fn.alert.noconflict=function(){return a.fn.alert=e,this},a(document).on(""click.bs.alert.data-api"",c,d.prototype.close)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.button""),f=""object""==typeof b&&b;e||d.data(""bs.button"",e=new c(this,f)),""toggle""==b?e.toggle():b&&e.setstate(b)})}var this.$element.attr(""aria-pressed"",!this.$element.hasclass(""active"")),this.$element.toggleclass(""active"")};var d=a.fn.button;a.fn.button=b,a.fn.button.constructor=c,a.fn.button.noconflict=function(){return a.fn.button=d,this},a(document).on(""click.bs.button.data-api"",'[data-toggle^=""button""]',function(c){var d=a(c.target);d.hasclass(""btn"")||(d=d.closest("".btn"")),b.call(d,""toggle""),a(c.target).is('input[type=""radio""]')||a(c.target).is('input[type=""checkbox""]')||c.preventdefault()}).on(""focus.bs.button.data-api blur.bs.button.data-api"",'[data-toggle^=""button""]',function(b){a(b.target).closest("".btn"").toggleclass(""focus"",/^focus(in)?$/.test(b.type))})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.carousel""),f=a.extend({},c.defaults,d.data(),""object""==typeof b&&b),g=""string""==typeof b?b:f.slide;e||d.data(""bs.carousel"",e=new c(this,f)),""number""==typeof b?e.to(b):g?e[g]():f.interval&&e.pause().cycle()})}var c=function(b,c){this.$element=a(b),this.$indicators=this.$element.find("".carousel-indicators""),this.options=c,this.paused=null,this.sliding=null,this.interval=null,this.$active=null,this.$items=null,this.options.keyboard&&this.$element.on(""keydown.bs.carousel"",a.proxy(this.keydown,this)),""hover""==this.options.pause&&!(""ontouchstart""in this.$items=a.parent().children("".item""),this.$items.index(a||this.$active)},c.prototype.getitemfordirection=function(a,b){var b;var this.$items.eq(f)},c.prototype.to=function(a){var b=this,c=this.getitemindex(this.$active=this.$element.find("".item.active""));return this.sliding?void this.sliding?void e=this.$element.find("".item.active""),f=d||this.getitemfordirection(b,e),g=this.interval,h=""next""==b?""left"":""right"",i=this;if(f.hasclass(""active""))return l=a(this.$indicators.children()[this.getitemindex(f)]);l&&l.addclass(""active"")}var m=a.event(""slid.bs.carousel"",{relatedtarget:j,direction:h});return "")).addclass(""active""),e.removeclass([""active"",h].join("" d=a.fn.carousel;a.fn.carousel=b,a.fn.carousel.constructor=c,a.fn.carousel.noconflict=function(){return a.fn.carousel=d,this};var e=function(c){var d,e=a(this),f=a(e.attr(""data-target"")||(d=e.attr(""href""))&&d.replace(/.*(?=#[^\s]+$)/,""""));if(f.hasclass(""carousel"")){var c=a(this);b.call(c,c.data())})})}(jquery),+function(a){""use strict"";function b(b){var c,d=b.attr(""data-target"")||(c=b.attr(""href""))&&c.replace(/.*(?=#[^\s]+$)/,"""");return a(d)}function c(b){return this.each(function(){var c=a(this),e=c.data(""bs.collapse""),f=a.extend({},d.defaults,c.data(),""object""==typeof d(this,f)),""string""==typeof b&&e[b]()})}var a=this.$element.hasclass(""width"");return a?""width"":""height""},d.prototype.show=function(){if(!this.transitioning&&!this.$element.hasclass(""in"")){var b,e=this.$parent&&this.$parent.children("".panel"").children("".in, .collapsing"");if(!(e&&e.length&&(b=e.data(""bs.collapse""),b&&b.transitioning))){var f=a.event(""show.bs.collapse"");if(this.$element.trigger(f),!f.isdefaultprevented()){e&&e.length&&(c.call(e,""hide""),b||e.data(""bs.collapse"",null));var h=function(){this.$element.removeclass(""collapsing"").addclass(""collapse h.call(this);var i=a.camelcase([""scroll"",g].join(""-""));this.$element.one(""bstransitionend"",a.proxy(h,this)).emulatetransitionend(d.transition_duration)g}}}},d.prototype.hide=function(){if(!this.transitioning&&this.$element.hasclass(""in"")){var b=a.event(""hide.bs.collapse"");if(this.$element.trigger(b),!b.isdefaultprevented()){var a.support.transition?void this.$elementc.one(""bstransitionend"",a.proxy(e,this)).emulatetransitionend(d.transition_duration):e.call(this)}}},d.prototype.toggle=function(){this[this.$element.hasclass(""in"")?""hide"":""show""]()},d.prototype.getparent=function(){return a(this.options.parent).find('[data-toggle=""collapse""][data-parent=""'+this.options.parent+'""]').each(a.proxy(function(c,d){var e=a(d);this.addariaandcollapsedclass(b(e),e)},this)).end()},d.prototype.addariaandcollapsedclass=function(a,b){var c=a.hasclass(""in"");a.attr(""aria-expanded"",c),b.toggleclass(""collapsed"",!c).attr(""aria-expanded"",c)};var e=a.fn.collapse;a.fn.collapse=c,a.fn.collapse.constructor=d,a.fn.collapse.noconflict=function(){return a.fn.collapse=e,this},a(document).on(""click.bs.collapse.data-api"",'[data-toggle=""collapse""]',function(d){var e=a(this);e.attr(""data-target"")||d.preventdefault();var f=b(e),g=f.data(""bs.collapse""),h=g?""toggle"":e.data();c.call(f,h)})}(jquery),+function(a){""use strict"";function b(b){var c=b.attr(""data-target"");c||(c=b.attr(""href""),c=c&&/#[a-za-z]/.test(c)&&c.replace(/.*(?=#[^\s]*$)/,""""));var d=c&&a(c);return d&&d.length?d:b.parent()}function d(b){return this.each(function(){var c=a(this),d=c.data(""bs.dropdown"");d||c.data(""bs.dropdown"",d=new g(this)),""string""==typeof b&&d[b].call(c)})}var e=a(this);if(!e.is("".disabled, :disabled"")){var f=b(e),g=f.hasclass(""open"");if(c(),!g){""ontouchstart""in document.documentelement&&!f.closest("".navbar-nav"").length&&a(document.createelement(""div"")).addclass(""dropdown-backdrop"").insertafter(a(this)).on(""click"",c);var d=a(this);if(c.preventdefault(),c.stoppropagation(),!d.is("".disabled, :disabled"")){var h="" li:not(.disabled):visible a"",i=e.find("".dropdown-menu""+h);if(i.length){var h=a.fn.dropdown;a.fn.dropdown=d,a.fn.dropdown.constructor=g,a.fn.dropdown.noconflict=function(){return a.fn.dropdown=h,this},a(document).on(""click.bs.dropdown.data-api"",c).on(""click.bs.dropdown.data-api"","".dropdown form"",function(a){a.stoppropagation()}).on(""click.bs.dropdown.data-api"",f,g.prototype.toggle).on(""keydown.bs.dropdown.data-api"",f,g.prototype.keydown).on(""keydown.bs.dropdown.data-api"","".dropdown-menu"",g.prototype.keydown)}(jquery),+function(a){""use strict"";function b(b,d){return this.each(function(){var e=a(this),f=e.data(""bs.modal""),g=a.extend({},c.defaults,e.data(),""object""==typeof b&&b);f||e.data(""bs.modal"",f=new c(this,g)),""string""==typeof b?fb:g.show&&f.show(d)})}var this.isshown?this.hide():this.show(a)},c.prototype.show=function(b){var a=this;this.$element.hide(),this.backdrop(function(){a.$body.removeclass(""modal-open""),a.resetadjustments(),a.resetscrollbar(),a.$element.trigger(""hidden.bs.modal"")})},c.prototype.removebackdrop=function(){this.$backdrop&&this.$backdrop.remove(),this.$backdrop=null},c.prototype.backdrop=function(b){var d=this,e=this.$element.hasclass(""fade"")?""fade"":"""";if(this.isshown&&this.options.backdrop){var f=a.support.transition&&e;if(this.$backdrop=a(document.createelement(""div"")).addclass(""modal-backdrop ""+e).appendto(this.$body),this.$element.on(""click.dismiss.bs.modal"",a.proxy(function(a){return if(!this.isshown&&this.$backdrop){this.$backdrop.removeclass(""in"");var g=function(){d.removebackdrop(),b&&b()};a.support.transition&&this.$element.hasclass(""fade"")?this.$backdrop.one(""bstransitionend"",g).emulatetransitionend(c.backdrop_transition_duration):g()}else b&&b()},c.prototype.handleupdate=function(){this.adjustdialog()},c.prototype.adjustdialog=function(){var a=window.innerwidth;if(!a){var b=document.documentelement.getboundingclientrect();a=b.right-math.abs(b.left)}this.bodyisoverflowing=document.body.clientwidth<a,this.scrollbarwidth=this.measurescrollbar()},c.prototype.setscrollbar=function(){var a=document.createelement(""div"");a.classname=""modal-scrollbar-measure"",this.$body.append(a);var b=a.offsetwidth-a.clientwidth;return d=a.fn.modal;a.fn.modal=b,a.fn.modal.constructor=c,a.fn.modal.noconflict=function(){return a.fn.modal=d,this},a(document).on(""click.bs.modal.data-api"",'[data-toggle=""modal""]',function(c){var d=a(this),e=d.attr(""href""),f=a(d.attr(""data-target"")||e&&e.replace(/.*(?=#[^\s]+$)/,"""")),g=f.data(""bs.modal"")?""toggle"":a.extend({remote:!/#/.test(e)&&e},f.data(),d.data());d.is(""a"")&&c.preventdefault(),f.one(""show.bs.modal"",function(a){a.isdefaultprevented()||f.one(""hidden.bs.modal"",function(){d.is("":visible"")&&d.trigger(""focus"")})}),b.call(f,g,this)})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tooltip""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.tooltip"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var class=""tooltip"" role=""tooltip""><div class=""tooltip-arrow""></div><div class=""tooltip-inner""></div></div>',trigger:""hover document.constructor&&!this.options.selector)throw new error(""`selector` option must be specified when initializing ""+this.type+"" on the window.document object!"");for(var e=this.options.trigger.split("" ""),f=e.length;f--;){var g=e[f];if(""click""==g)this.$element.on(""click.""+this.type,this.options.selector,a.proxy(this.toggle,this));else if(""manual""!=g){var h=""hover""==g?""mouseenter"":""focusin"",i=""hover""==g?""mouseleave"":""focusout"";this.$element.on(h+"".""+this.type,this.options.selector,a.proxy(this.enter,this)),this.$element.on(i+"".""+this.type,this.options.selector,a.proxy(this.leave,this))}}this.options.selector?this._options=a.extend({},this.options,{trigger:""manual"",selector:""""}):this.fixtitle()},c.prototype.getdefaults=function(){return c.defaults},c.prototype.getoptions=function(b){return b=a.extend({},this.getdefaults(),this.$element.data(),b),b.delay&&""number""==typeof b.delay&&(b.delay={show:b.delay,hide:b.delay}),b},c.prototype.getdelegateoptions=function(){var b={},c=this.getdefaults();return this._options&&a.each(this._options,function(a,d){c[a]!=d&&(b[a]=d)}),b},c.prototype.enter=function(b){var c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof a in c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof b=a.event(""show.bs.""+this.type);if(this.hascontent()&&this.enabled){this.$element.trigger(b);var e=this,f=this.tip(),g=this.getuid(this.type);this.setcontent(),f.attr(""id"",g),this.$element.attr(""aria-describedby"",g),this.options.animation&&f.addclass(""fade"");var h=""function""==typeof n=h,o=this.getposition(this.$viewport);h=""bottom""==h&&k.bottom+m>o.bottom?""top"":""top""==h&&k.top-m<o.top?""bottom"":""right""==h&&k.right+l>o.width?""left"":""left""==h&&k.left-l<o.left?""right"":h,f.removeclass(n).addclass(h)}var p=this.getcalculatedoffset(h,k,l,m);this.applyplacement(p,h);var q=function(){var a=e.hoverstate;e.$element.trigger(""shown.bs.""+e.type),e.hoverstate=null,""out""==a&&e.leave(e)};a.support.transition&&this.$tip.hasclass(""fade"")?f.one(""bstransitionend"",q).emulatetransitionend(c.transition_duration):q()}},c.prototype.applyplacement=function(b,c){var k=this.getviewportadjusteddelta(c,b,i,j);k.left?b.left+=k.left:b.top+=k.top;var a=this.tip(),b=this.gettitle();a.find("".tooltip-inner"")this.options.html?""html"":""text"",a.removeclass(""fade in top bottom left right"")},c.prototype.hide=function(b){function d(){""in""!=e.hoverstate&&f.detach(),e.$element.removeattr(""aria-describedby"").trigger(""hidden.bs.""+e.type),b&&b()}var e=this,f=a(this.$tip),g=a.event(""hide.bs.""+this.type);return this.$element.trigger(g),g.isdefaultprevented()?void a=this.$element;(a.attr(""title"")||""string""!=typeof a.attr(""data-original-title""))&&a.attr(""data-original-title"",a.attr(""title"")||"""").attr(""title"","""")},c.prototype.hascontent=function(){return this.gettitle()},c.prototype.getposition=function(b){b=b||this.$element;var e;var h=b.top-f-g.scroll,i=b.top+f-g.scroll+d;h<g.top?e.top=g.top-h:i>g.top+g.height&&(e.top=g.top+g.height-i)}else{var j=b.left-f,k=b.left+f+c;j<g.left?e.left=g.left-j:k>g.right&&(e.left=g.left+g.width-k)}return e},c.prototype.gettitle=function(){var a,b=this.$element,c=this.options;return a=b.attr(""data-original-title"")||(""function""==typeof new error(this.type+"" `template` option must consist of exactly top-level element!"");return this.$tip},c.prototype.arrow=function(){return c=this;b&&(c=a(b.currenttarget).data(""bs.""+this.type),c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c))),b?(c.instate.click=!c.instate.click,c.isinstatetrue()?c.enter(c):c.leave(c)):c.tip().hasclass(""in"")?c.leave(c):c.enter(c)},c.prototype.destroy=function(){var a=this;cleartimeout(this.timeout),this.hide(function(){a.$element.off("".""+a.type).removedata(""bs.""+a.type),a.$tip&&a.$tip.detach(),a.$tip=null,a.$arrow=null,a.$viewport=null})};var d=a.fn.tooltip;a.fn.tooltip=b,a.fn.tooltip.constructor=c,a.fn.tooltip.noconflict=function(){return a.fn.tooltip=d,this}}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.popover""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.popover"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var c=function(a,b){this.init(""popover"",a,b)};if(!a.fn.tooltip)throw new error(""popover requires class=""popover"" role=""tooltip""><div class=""popover-content""></div></div>'}),c.prototype=a.extend({},a.fn.tooltip.constructor.prototype),c.prototype.constructor=c,c.prototype.getdefaults=function(){return c.defaults},c.prototype.setcontent=function(){var a=this.tip(),b=this.gettitle(),c=this.getcontent();a.find("".popover-title"")this.options.html?""html"":""text"",a.find("".popover-content"").children().detach().end()this.options.html?""string""==typeof c?""html"":""append"":""text"",a.removeclass(""fade top bottom left right in""),a.find("".popover-title"").html()||a.find("".popover-title"").hide()},c.prototype.hascontent=function(){return this.gettitle()||this.getcontent()},c.prototype.getcontent=function(){var a=this.$element,b=this.options;return a.attr(""data-content"")||(""function""==typeof this.$arrow=this.$arrow||this.tip().find("".arrow"")};var d=a.fn.popover;a.fn.popover=b,a.fn.popover.constructor=c,a.fn.popover.noconflict=function(){return a.fn.popover=d,this}}(jquery),+function(a){""use strict"";function b(c,d){this.$body=a(document.body),this.$scrollelement=a(a(c).is(document.body)?window:c),this.options=a.extend({},b.defaults,d),this.selector=(this.options.target||"""")+"" .nav li > c(c){return this.each(function(){var d=a(this),e=d.data(""bs.scrollspy""),f=""object""==typeof c&&c;e||d.data(""bs.scrollspy"",e=new b(this,f)),""string""==typeof b=a(this),e=b.data(""target"")||b.attr(""href""),f=/^#./.test(e)&&a(e);return f&&f.length&&f.is("":visible"")&&[[f[c]().top+d,e]]||null}).sort(function(a,b){return a,b=this.$scrollelement.scrolltop()+this.options.offset,c=this.getscrollheight(),d=this.options.offset+c-this.$scrollelement.height(),e=this.offsets,f=this.targets,g=this.activetarget;if(this.scrollheight!=c&&this.refresh(),b>=d)return this.activetarget=null,this.clear();for(a=e.length;a--;)g!=f[a]&&b>=e[a]&&(void c=this.selector+'[data-target=""'+b+'""],'+this.selector+'[href=""'+b+'""]',d=a(c).parents(""li"").addclass(""active"");d.parent("".dropdown-menu"").length&&(d=d.closest(""li.dropdown"").addclass(""active"")), d.trigger(""activate.bs.scrollspy"")},b.prototype.clear=function(){a(this.selector).parentsuntil(this.options.target,"".active"").removeclass(""active"")};var d=a.fn.scrollspy;a.fn.scrollspy=c,a.fn.scrollspy.constructor=b,a.fn.scrollspy.noconflict=function(){return a.fn.scrollspy=d,this},a(window).on(""load.bs.scrollspy.data-api"",function(){a('[data-spy=""scroll""]').each(function(){var b=a(this);c.call(b,b.data())})})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tab"");e||d.data(""bs.tab"",e=new c(this)),""string""==typeof b&&e[b]()})}var b=this.element,c=b.closest(""ul:not(.dropdown-menu)""),d=b.data(""target"");if(d||(d=b.attr(""href""),d=d&&d.replace(/.*(?=#[^\s]*$)/,"""")),!b.parent(""li"").hasclass(""active"")){var e=c.find("".active:last f(){g.removeclass(""active"").find(""> .dropdown-menu > g=d.find(""> .active""),h=e&&a.support.transition&&(g.length&&g.hasclass(""fade"")||!!d.find(""> .fade"").length);g.length&&h?g.one(""bstransitionend"",f).emulatetransitionend(c.transition_duration):f(),g.removeclass(""in"")};var d=a.fn.tab;a.fn.tab=b,a.fn.tab.constructor=c,a.fn.tab.noconflict=function(){return a.fn.tab=d,this};var e=function(c){c.preventdefault(),b.call(a(this),""show"")};a(document).on(""click.bs.tab.data-api"",'[data-toggle=""tab""]',e).on(""click.bs.tab.data-api"",'[data-toggle=""pill""]',e)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.affix""),f=""object""==typeof b&&b;e||d.data(""bs.affix"",e=new c(this,f)),""string""==typeof b&&e[b]()})}var affix-top e=this.$target.scrolltop(),f=this.$element.offset(),g=this.$target.height();if(null!=c&&""top""==this.affixed)return h=null==this.affixed,i=h?e:f.top,j=h?g:b;return this.pinnedoffset;this.$element.removeclass(c.reset).addclass(""affix"");var a=this.$target.scrolltop(),b=this.$element.offset();return b=this.$element.height(),d=this.options.offset,e=d.top,f=d.bottom,g=math.max(a(document).height(),a(document.body).height());""object""!=typeof d&&(f=e=d),""function""==typeof e&&(e=d.top(this.$element)),""function""==typeof f&&(f=d.bottom(this.$element));var h=this.getstate(g,b,e,f);if(this.affixed!=h){null!=this.unpin&&this.$element.css(""top"","""");var i=""affix""+(h?""-""+h:""""),j=a.event(i+"".bs.affix"");if(this.$element.trigger(j),j.isdefaultprevented())return;this.affixed=h,this.unpin=""bottom""==h?this.getpinnedoffset():null,this.$element.removeclass(c.reset).addclass(i).trigger(i.replace(""affix"",""affixed"")+"".bs.affix"")}""bottom""==h&&this.$element.offset({top:g-b-f})}};var d=a.fn.affix;a.fn.affix=b,a.fn.affix.constructor=c,a.fn.affix.noconflict=function(){return a.fn.affix=d,this},a(window).on(""load"",function(){a('[data-spy=""affix""]').each(function(){var c=a(this),d=c.data();d.offset=d.offset||{},null!=d.offsetbottom&&(d.offset.bottom=d.offsetbottom),null!=d.offsettop&&(d.offset.top=d.offsettop),b.call(c,d)})})}(jquery);</script> <script>/** * @preserve shiv | @afarkas @jdalton @jon_neal @rem | licensed */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a,b){function c(a,b){var c.innerhtml=""x<style>""+b+""</style>"",d.insertbefore(c.lastchild,d.firstchild)}function d(){var a=t.elements;return""string""==typeof a?a.split("" ""):a}function e(a,b){var c=t.elements;""string""!=typeof c&&(c=c.join("" "")),""string""!=typeof a&&(a=a.join("" "")),t.elements=c+"" ""+a,j(b)}function f(a){var b=s[a[q]];return b||(b={},r++,a[q]=r,s[r]=b),b}function g(a,c,d){if(c||(c=b),l)return c.createelement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].clonenode():p.test(a)?(d.cache[a]=d.createelem(a)).clonenode():d.createelem(a),!e.canhavechildren||o.test(a)||e.tagurn?e:d.frag.appendchild(e)}function h(a,c){if(a||(a=b),l)return a.createdocumentfragment();c=c||f(a);for(var e}function i(a,b){b.cache||(b.cache={},b.createelem=a.createelement,b.createfrag=a.createdocumentfragment,b.frag=b.createfrag()),a.createelement=function(c){return t.shivmethods?g(c,a,b):b.createelem(c)},a.createdocumentfragment=function(""h,f"",""return function(){var n=f.clonenode(),c=n.createelement;h.shivmethods&&(""+d().join().replace(/[\w\-:]+/g,function(a){return b.createelem(a),b.frag.createelement(a),'c(""'+a+'"")'})+"");return n}"")(t,b.frag)}function j(a){a||(a=b);var a=b.createelement(""a"");a.innerhtml=""<xyz></xyz>"",k=""hidden""in a=b.createdocumentfragment();return""undefined""==typeof a.clonenode||""undefined""==typeof a.createdocumentfragment||""undefined""==typeof t={elements:n.elements||""abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time }; </script> <script>/*! respond.js min/max-width media query polyfill * copyright scott jehl * licensed under https://github.com/scottjehl/respond/blob/master/license-mit * */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a){""use strict"";a.matchmedia=a.matchmedia||function(a){var b,c=a.documentelement,d=c.firstelementchild||c.firstchild,e=a.createelement(""body""),f=a.createelement(""div"");return f.innerhtml='&shy;<style media=""'+a+'""> { width: strict"";function c={};a.respond=c,c.update=function(){};var d=[],e=function(){var a.xmlhttprequest}catch(c){b=new a.activexobject(""microsoft.xmlhttp"")}return function(){return b}}(),f=function(a,b){var all"")&&a.matchmedia(""only all"").matches,!c.mediaqueriessupported){var date).gettime();if(b&&g&&p>r-g)return a.cleartimeout(h),h=a.settimeout(you,p),void v in l)if(l.hasownproperty(v)){var c in d in f)if(f.hasownproperty(d)){var e=j.createelement(""style""),f=f[d].join(""\n"");e.type=""text/css"",e.media=d,q.insertbefore(e,o.nextsibling),e.stylesheet?e.stylesheet.csstext=f:e.appendchild(j.createtextnode(f)),n.push(e)}},v=function(a,b,d){var g=function(a){return }; </script> <script> /** * jquery plugin: sticky tabs * * @author aidan lister <aidan@php.net> * adapted by ruben arslan to activate parent tabs too * */ (function($) { ""use strict""; $.fn.rmarkdownstickytabs = function() { var context = this; // show the tab corresponding with the hash in the url, or the first tab var showstufffromhash = function() { var hash = window.location.hash; var selector = hash ? 'a[href=""' + hash + '""]' : 'li.active > a'; var $selector = $(selector, context); if($selector.data('toggle') === ""tab"") { $selector.tab('show'); // walk up the ancestors of this element, show any hidden tabs $selector.parents('.section.tabset').each(function(i, elm) { var link = $('a[href=""#' + $(elm).attr('id') + '""]'); if(link.data('toggle') === ""tab"") { link.tab(""show""); } }); } }; // set the correct tab when the page loads showstufffromhash(context); // set the correct tab when a user uses their back/forward button $(window).on('hashchange', function() { showstufffromhash(context); }); // change the url when tabs are clicked $('a', context).on('click', function(e) { history.pushstate(null, null, this.href); showstufffromhash(context); }); return this; }; }(jquery)); window.buildtabsets = function(tocid) { // build a tabset from a section div with the .tabset class function buildtabset(tabset) { // check for fade and pills options var fade = tabset.hasclass(""tabset-fade""); var pills = tabset.hasclass(""tabset-pills""); var navclass = pills ? ""nav-pills"" : ""nav-tabs""; // determine the heading level of the tabset and tabs var match = tabset.attr('class').match(/level(\d) /); if (match === null) return; var tabsetlevel = var tablevel = tabsetlevel + // find all subheadings immediately below var tabs = tabset.find(""div.section.level"" + tablevel); if (!tabs.length) return; // create tablist and tab-content elements var tablist = $('<ul class=""nav ' + navclass + '"" role=""tablist""></ul>'); var tabcontent = $('<div class=""tab-content""></div>'); // build the tabset var activetab = tabs.each(function(i) { // get the tab div var tab = $(tabs[i]); // get the id then sanitize it for use with bootstrap tabs var id = tab.attr('id'); // see if this is marked as the active tab if (tab.hasclass('active')) activetab = i; // remove any table of contents entries associated with // this id (since we will be removing the heading element) $(""div#"" + tocid + "" li a[href='#"" + id + ""']"").parent().remove(); // sanitize the id for use with bootstrap tabs id = id.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_'); tab.attr('id', id); // get the heading element within it, grab it is text, then remove it var heading = tab.find('h' + tablevel + ':first'); var headingtext = heading.html(); heading.remove(); // build and append the tab list item var a = $('<a role=""tab"" data-toggle=""tab"">' + headingtext + '</a>'); a.attr('href', '#' + id); a.attr('aria-controls', id); var li = $('<li role=""presentation""></li>'); li.append(a); tablist.append(li); // set it is attributes tab.attr('role', 'tabpanel'); tab.addclass('tab-pane'); tab.addclass('tabbed-pane'); if (fade) tab.addclass('fade'); // move it into the tab content div tab.detach().appendto(tabcontent); }); // set active tab $(tablist.children('li')[activetab]).addclass('active'); var active = $(tabcontent.children('div.section')[activetab]); active.addclass('active'); if (fade) active.addclass('in'); if (tabset.hasclass(""tabset-sticky"")) tabset.rmarkdownstickytabs(); } // convert section divs with the .tabset class to tabsets var tabsets = $(""div.section.tabset""); tabsets.each(function(i) { buildtabset($(tabsets[i])); }); }; </script> <style type=""text/css"">.hljs-literal { color: } .hljs-number { color: } .hljs-comment { color: font-style: italic; } .hljs-keyword { color: font-weight: bold; } .hljs-string { color: } </style> <script <style type=""text/css"">code{white-space: pre;}</style> <style type=""text/css""> pre:not([class]) { background-color: white; } </style> <script type=""text/javascript""> if (window.hljs) { hljs.configure({languages: []}); hljs.inithighlightingonload(); if (document.readystate && document.readystate === ""complete"") { window.settimeout(function() { hljs.inithighlighting(); }, } } </script> <style type=""text/css""> { font-size: } { font-size: } { font-size: } { font-size: } { font-size: } { font-size: } { font-size: } .table th:not([align]) { text-align: left; } </style> <style type=""text/css""> .main-container { max-width: margin-left: auto; margin-right: auto; } code { color: inherit; background-color: } img { } .tabbed-pane { padding-top: } .html-widget { margin-bottom: } button.code-folding-btn:focus { outline: none; } summary { display: list-item; } </style> <!-- tabsets --> <style type=""text/css""> .tabset-dropdown > .nav-tabs { display: inline-table; max-height: min-height: overflow-y: auto; background: white; border: solid #ddd; border-radius: } .tabset-dropdown > .nav-tabs > li.active:before { content: """"; font-family: 'glyphicons halflings'; display: inline-block; padding: border-right: solid #ddd; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before { content: """"; border: none; } .tabset-dropdown > .nav-tabs.nav-tabs-open:before { content: """"; font-family: 'glyphicons halflings'; display: inline-block; padding: border-right: solid #ddd; } .tabset-dropdown > .nav-tabs > li.active { display: block; } .tabset-dropdown > .nav-tabs > li > a, .tabset-dropdown > .nav-tabs > li > a:focus, .tabset-dropdown > .nav-tabs > li > a:hover { border: none; display: inline-block; border-radius: background-color: transparent; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li { display: block; float: none; } .tabset-dropdown > .nav-tabs > li { display: none; } </style> <!-- code folding --> </head> <body> <div class=""container-fluid main-container""> <div class=""fluid-row"" id=""header""> </div> <div id=""readme"" class=""section <p>this is an archive including the data of currently seven studies measuring emotions in daily life using the experience sampling methodology (esm).</p> <div id=""the-included-studies-are"" class=""section included studies <p>note: vrijen et. al ask for a request to reuse their data. for more info see <a <old style=""list-style-type: decimal""> <li>bringmann, l. f., vissers, n., wichers, m., geschwind, n., kuppens, p., peeters, f., &amp; tuerlinckx, f. a network approach to psychopathology: new insights into clinical longitudinal data. plos one, <li>bringmann, l. f., pe, m. l., vissers, n., ceulemans, e., borsboom, d., vanpaemel, w., &amp; kuppens, p. assessing temporal emotion dynamics using networks. assessment, <li>rowland, z., &amp; wenzel, m. mindfulness and affect-network density: does mindfulness facilitate disengagement from affective experiences in daily life?. mindfulness, <li>fried, e. i., papanikolaou, f., &amp; epskamp, s. mental health and social contact during the pandemic: an ecological momentary assessment study. clinical psychological science, <li>vrijen, c., hartman, c. a., van roekel, e., de jonge, p., &amp; oldehinkel, a. j. spread the joy: how high and low bias for happy facial emotions translate into different daily life affect dynamics. complexity, <li>fisher, a. j., reeves, j. w., lawyer, g., medaglia, j. d., &amp; rubel, j. a. exploring the idiographic dynamics of mood and anxiety via network analysis. journal of abnormal psychology, <li>wendt, l. p., wright, a. g., pilkonis, p. a., woods, w. c., denissen, j. j., khnel, a., &amp; zimmermann, j. indicators of affect dynamics: structure, reliability, and personality correlates. european journal of personality, </old> <p>we would like to thank these authors for making their data openly available.</p> </div> <div id=""organization-of-this-archive"" class=""section of this <p>the organization of this archive is as follows:</p> <ul> <li><code>datafromauthors/</code>: includes the data and associated material for each study.</li> <li><code>processingfiles/</code>: includes r files for each original data set and processes them into a standard format; these scripts are called by <code>processdata.r</code></li> <li><code>dataclean/</code>: includes the pre-processed data for each study.</li> <li><code>processdata.r</code>: runs the processing scripts for each study, generating the cleaned data.</li> <li><code>processbetween.r</code>: uses the cleaned between-person data to create a list of datasets with columns id and between person characteristic for each dataset; this script is called by <code>processdata.r</code></li> </ul> </div> </div> </div> <script> // add bootstrap table styles to pandoc tables function bootstrapstylepandoctables() { $('tr.header').parent('thead').parent('table').addclass('table table-condensed'); } $(document).ready(function () { bootstrapstylepandoctables(); }); </script> <!-- tabsets --> <script> $(document).ready(function () { window.buildtabsets(""toc""); }); $(document).ready(function () { $('.tabset-dropdown > .nav-tabs > li').click(function () { $(this).parent().toggleclass('nav-tabs-open') }); }); </script> <!-- code folding --> <!-- dynamically load mathjax for compatibility with self-contained --> <script> (function () { var script = document.createelement(""script""); script.type = ""text/javascript""; script.src = ""https://mathjax.rstudio.com/latest/mathjax.js?config=tex-ams-mml_htmlormml""; })(); </script> </body> </html>"
0,emaexplorer,shiny app to explore ecological momentary assessment (ema) data,# emaexplorer shiny app to explore ecological momentary assessment (ema) data
0,UNITI-SCED-paper,data and corresponding analysis code of the paper: pilot study of a smartphone-based tinnitus therapy using structured counseling and sound therapy: a multiple-baseline design with ecological momentary assessment,# uniti-sced-paper data and corresponding analysis code of the paper: pilot study of a smartphone-based tinnitus therapy using structured counseling and sound therapy: a multiple-baseline design with ecological momentary assessment
0,pni-ema,ecological momentary assessment for pni employees,"# pni-ema climate and inclusion ecological momentary assessment for princeton neuroscience institute employees. <p align=""center""> <img src=""img/pni-ema.png""> </p> ## prerequisites * python (and add it to top of path) * pip (and add it to path) * git (and add it to path) ## installation and updating set up a new virtual environment with python and give it any name, _e.g._, venv_name. ```bash python -m venv venv_name ``` activate the virtual environment with: ```bash source ./venv_name/bin/activate ``` or, on os windows: ```bash .\venv_name\scripts\activate ``` install the repository with command below. also, rerun the same command to check for and install updates. ```bash pip install git+https://github.com/bartulem/pni-ema ``` ## usage locate the pip installed package: ```bash pip show pni-ema ``` navigate to the directory w/ the ""send_ema_email.py"" file (example path listed below). ```bash cd /.../venv_name/lib/site-packages/pni-ema ``` make sure you define locations of the eml_file, email_config_file and ema_directory at the bottom of send_ema_email.py. run the script. ```bash python send_ema_email.py ``` developed and tested in pycharm pro on windows lts."
1,EMAeval-R-Package,this is a careless responder identification package for ecological momentary assessment (ema) data.,"--- title: ""emaeval description"" author: ""noah kraus"" date: output: rmarkdown::github_document always_allow_html: true --- ```{r setup, include=false} knitr::opts_chunk$set(echo = true) ``` # emaeval r markdown the r package emaeval contains functions created to help researchers identify careless responses as well as responders ine ema data. an example dataset is included in the package to help the user better understand the uses of each function. this dataset ""emaeval_data"" is used in the example code below. there are ""participants,"" each having assessments. each was asked questions per assessment. ```{r message=false, warning=false,echo=false} library(emaeval) library(knitr) library(kableextra) knitr::opts_chunk$set(opts.label=""kill_prefix"") emaeval_data <- emaeval::emaeval_data caption = ""emaeval_data example"", row.names = true) %>% kable_styling() ``` # functions below are the functions in the r package emaeval. the functions are: * flagging_df * flagging_plots * tpi_cutoff * sd_cutoff * perc_mode_cutoff * combined_cutoff * combined_cutoff_percent each section will be dedicated to a particular function, giving an example of the usage with the emaeval_data and showing the output. ## flagging_df *this function creates a dataframe that reports time to complete (ttc), time per item (tpi), item standard deviation (sd), and longstring. if the longstring returns na, then there was no longstring response because all item responses were different. the partial results of the flagging_df function are based from the emaeval_data example above. * ``` {r eval = false} flaggingdf <- flagging_df(emaeval_data, ttc.colnames = c(""startdate"", ""enddate""), item.colnames = ``` ```{r message=false, warning=false, echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data flaggingdf <- flagging_df(emaeval_data, ttc.colnames = c(""startdate"", ""enddate""), item.colnames = caption = ""flagging dataframe example"", row.names = true) %>% kable_styling() ``` ## flagging_plots *this function creates a histograms of each of the calculations reported in the flagging_df function. this can be used to help users identify the cutoff values for tpi and sd.* ``` {r eval = false} flagging_plots(emaeval_data, ttc.colnames = c(""startdate"", ""enddate""), item.colnames = number.items = ``` ```{r message=false, warning=false, fig.align=""center"", echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data flagging_plots(emaeval_data, ttc.colnames = c(""startdate"", ""enddate""), item.colnames = = ``` *note: the longstring histogram has a much smaller scale for the count. this is due to the lack of longstring values because many assessments do not have a longstring value because all item responses differ.* ## tpi_cutoff *this function creates a dataframe of id and data indices in which the assessment met the cutoff criterion for time per item. the user inputs their own cutoff for tpi. the user can also specify what type of comparison they would like to complete with the cutoff value using __condition =...__ if responses to all items are mandatory, then the following response should be included:* ``` mandatory.response = true ``` *below is the code for the function.* ``` {r eval = false} tpi_cutoff(emaeval_data, cutoff = condition = ""<="", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") ``` ```{r message=false, warning=false, fig.align=""center"", max.height = echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data tpi_cutoff_df <- tpi_cutoff(emaeval_data, cutoff = condition = ""<="", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") kable(tpi_cutoff_df, caption = ""assessments flagged by tpi cutoff"", row.names = false) %>% kable_styling() %>% scroll_box(width = , height = ``` ## sd_cutoff *this function creates a dataframe of id and data indices in which the assessment met the cutoff criterion for item score standard deviation. the user inputs their own cutoff for sd. the user can also specify what type of comparison they would like to complete with the cutoff value using __condition =...__* *below is the code for the function.* ``` {r eval = false} sd_cutoff(emaeval_data, cutoff = condition = ""<="", item.colnames = id.colname = ""id"") ``` ```{r message=false, warning=false, fig.align=""center"", max.height = echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data sd_cutoff_df <- sd_cutoff(emaeval_data, cutoff = condition = ""<="", item.colnames = id.colname = ""id"") kable(sd_cutoff_df, caption = ""assessments flagged by sd cutoff"", row.names = false) %>% kable_styling() %>% scroll_box(width = , height = ``` ## perc_mode_cutoff *this function creates a dataframe of id and data indices in which the assessment met the cutoff criterion for the percent of items at mode. the user inputs their own cutoff for percent of items at mode. the user can also specify what type of comparison they would like to complete with the cutoff value using __condition =...__* *below is the code for the function.* ``` {r eval = false} perc_mode_cutoff(emaeval_data, cutoff = condition = "">="", item.colnames = id.colname = ""id"") ``` ```{r message=false, warning=false, fig.align=""center"", max.height = echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data perc_mode_cutoff_df <- perc_mode_cutoff(emaeval_data, cutoff = condition = "">="", item.colnames = id.colname = ""id"") kable(perc_mode_cutoff_df, caption = ""assessments flagged by percent of items at mode cutoff"", row.names = false) %>% kable_styling() %>% scroll_box(width = , height = ``` ## combined_cutoff *this function creates a dataframe of id and data indices in which the assessment met the cutoff criteria for time per item or item score standard deviation or percent of items at mode. the user inputs their own cutoff for tpi, sd and percent of items at mode. the user can also specify what type of comparison they would like to complete with each cutoff value using either __sd.condition =...__ and __tpi.condition=...__ and __perc.mode.condition=...__ users can also specify the logical component for the criteria, specifying with __combined.logic = ...__ if responses to all items are mandatory, then the following response should be included:* ``` mandatory.response = true ``` *below is the code for the function.* ``` {r eval = false} combined_cutoff(emaeval_data, sd.cutoff = sd.condition = ""<="", tpi.cutoff = tpi.condition = ""<="", perc.mode.cutoff = perc.mode.condition = "">="", combined.logic = ""or"", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") ``` ```{r message=false, warning=false, fig.align=""center"", max.height = echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data combined_cutoff_df <- combined_cutoff(emaeval_data,sd.cutoff = sd.condition = ""<="", tpi.cutoff = tpi.condition = ""<="", perc.mode.cutoff = perc.mode.condition = "">="", combined.logic = ""or"", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") kable(combined_cutoff_df, caption = ""assessments flagged by tpi, sd or percent of items at mode cutoffs"", row.names = false) %>% kable_styling() %>% scroll_box(width = , height = ``` ## combined_cutoff_percent *this function creates a dataframe of id and percent of responses in which assessments met the cutoff criteria for time per item or item score standard deviation or percent of items at mode. the user inputs their own cutoff for tpi, sd and percent of items at mode. the user can also specify what type of comparison they would like to complete with each cutoff value using either __sd.condition =...__ and __tpi.condition=...__ and __perc.mode.condition=...__ users can also specify the logical component for the criteria, specifying with __combined.logic = ...__ if responses to all items are mandatory, then the following response should be included:* ``` mandatory.response = true ``` *below is the code for the function.* ``` {r eval = false} combined_cutoff_percent(emaeval_data, sd.cutoff = sd.condition = ""<="", tpi.cutoff = tpi.condition = ""<="", perc.mode.cutoff = perc.mode.condition = "">="", combined.logic = ""or"", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") ``` ```{r message=false, warning=false, fig.align=""center"", max.height = echo=false} library(emaeval) library(knitr) library(kableextra) emaeval_data <- emaeval::emaeval_data combined_cutoff_percent_df <- combined_cutoff_percent(emaeval_data, sd.cutoff = sd.condition = ""<="", tpi.cutoff = tpi.condition = ""<="", perc.mode.cutoff = perc.mode.condition = "">="", combined.logic = ""or"", ttc.colnames = c(""startdate"", ""enddate""), number.items = mandatory.response = true, item.colnames = id.colname = ""id"") kable(combined_cutoff_percent_df, caption = ""percentage of assessments flagged by tpi, sd or percent of items at mode cutoffs"", row.names = false) %>% kable_styling() ```"
1,JustInTimeAdaptiveIntervention,jitai using off-the-shelf wearable devices for improving physical activity among individuals with spinal cord injury using manual wheelchair,"# justintimeadaptiveintervention jitai using off-the-shelf wearable devices for improving physical activity among individuals with spinal cord injury using manual wheelchair we have developed a smartphone application (app) called the personal health informatics and rehabilitation engineering (phire) app for android-based smartphones. the phire app runs on an android-based smartphone (e.g. nexus or lg corp., englewood cliffs, nj, usa), and collects sensor data from a wrist-worn smartwatch (e.g. urbane, lg corp., englewood cliffs, nj, usa), and a bluetooth-based whee l rotation monitor (e.g. panobike, topeak inc., taichung, taiwan) to detect wheelchair-based physical activities (pas) in individuals with spinal cord injury who use manual wheelchairs for mobility purposes. the smartwatch and wheel rotation monitor stream data to the smartphone. the phire app uses a decision tree machine-learning algorithm to classify wheelchair-based pas and estimate pa levels once per minute wheelchair-based pas include resting, arm-ergometry, household activities, activities that may involve some wheelchair movement, wheelchair propulsion, caretaker pushing, and wheelchair basketball. the energy expenditure is estimated in a three-step process: wheelchair-based pas are detected in near-real-time, the metabolic equivalent of a task (met) for the wheelchair-based pa in individuals with sci (paraplegia and tetraplegia) is obtained from a compendium listing activity-metabolic estimates , and the energy expenditure is then estimated based on the mets and the weight of the individual using the phire app the distance traveled in miles is calculated based on the wheelchair-wheel diameter and sensor reading from the wheel rotation monitor. via the smartphone, the phire app also collects ecological momentary assessments about the type of pas an individual is performing during the day. these ecological momentary assessments responses allow researchers to validate whether the pa an individual self-reports to be performing is detected by the phire app. all sensor data and logs are encrypted, saved on the smartphone, and uploaded to googles firebase cloud storage on an hourly basis. data are then downloaded to a desktop computer, decrypted, and viewed using custom desktop data visualization software. the phire app can provide feedback about energy expenditure and distance traveled every minute during the day, and overall energy expenditure and distance traveled for the day and the week. individuals can view their feedback whenever they want. the phire app can also provide just-in-time adaptive intervention (jitai) which includes providing proactively-prompted, real-time feedback through the smartphone (audio and/or vibration: based on individuals choice) and smartwatch (vibration) when the individual performs a bout of moderate-intensity (or higher) pa. the default setting of the app is a minimum of three continuous minutes of pa before providing personalized feedback. personalization is based on the individuals prior patterns of conducting bouts of moderate-intensity pa, as measured by the system. individuals are also provided with congratulatory messages when they perform a moderate-intensity pa bout of at least three minutes. following this, the congratulatory messages are provided every minute until the individual stops performing the moderate-intensity pa. individuals also receive a congratulatory message when they reach and exceed their daily goal. the daily goal is personalized each subsequent day based on the individuals pattern of performing moderate-intensity pa the day before. the congratulatory message contains minutes of moderate-intensity pa performed and minutes remaining to attain their goal. references quinlan jr. programs for machine learning: morgan kaufmann publishers inc.; p. hiremath sv, intille ss, kelleher a, cooper ra, ding d. estimation of energy expenditure for wheelchair users using a physical activity monitoring system. archives of physical medicine and rehabilitation. collins eg, gater d, kiratli j, butler j, hanson k, langbein we. energy cost of physical activities in persons with spinal cord injury. medicine and science in sports and exercise."
0,AndroidSurveyFramework,android survey app for ema (ecological momentary assessment) research.,"# androidsurveyframework an android ema (ecological momentary assessment) survey app. this app relies on the node.js server project here: <img <img <img <img in order to run the app, you will need to change the *app/build.gradle* file's api_base_url variable to point to your running node.js server: buildconfigfield ""string"", ""api_base_url"", ""\""https://my.survey-rest-api.ip/\"""""
1,mindfuck,a browser extension for monitoring impulsive behaviors,# mindfuck a browser extension for monitoring impulsive behaviors ## methodology we will use [ecological momentary to understand an individual's internal sense of impulsivity while browsing. ## notes background.js runs on every page. popup.js runs on the popup page. contentscript.js relays messages to other pages. ## roadmap ensure that the extension works reliably on pages that have many auto-reloads (e.g. youtube)
1,tigersurvey,a novel experience sampling tool for social science research,"# tigersurvey a novel experience sampling/ecological momentary assessment tool for social science research! to use, create a new xcode project copy the files in this repo into the project run 'pod install' to install the necessary libraries (if using your own backend, remove the lines for firebase) change the questions in data.swift to suit your research needs you will probably also want to make significant edits to the language and interface to achieve your desired impression. an app that allows researchers to design and distribute surveys from within the app itself is upcoming--in the meantime, some familiarity with swift is required :)"
0,EMASENS_ML,repository to accompany: supervised machine learning to predict smoking lapses from ecological momentary assessments and sensor data: implications for just-in-time adaptive intervention development,"# emasens_ml repository to accompany the paper (submitted): supervised machine learning to predict smoking lapses from ecological momentary assessments and sensor data: implications for just-in-time adaptive intervention development ## included data contains observations of variables. contains observations of variables. ## included scripts all scripts for data cleaning and pre-processing have been included for transparency. for ethical reasons, however, the raw data are not included. data analysis that is reproducible starts at script which reads in prior to running this, please run"
0,NLML,nlml - machine learning tools in r,"# nlml nlml is a github repository containing scripts which make performing methodologically correct machine learning analyses more easy. the scripts in this repository were initially developed to build person-specific and pooled prediction models for binge eating, binge drinking and alcohol use with ecological momentary assessment data. however, they can be used in all kinds of contexts. ## getting started as of yet, the functions have not been included in an r package. therefore, you need to follow these steps to use the functions: download the functions you are interested in to a local folder source the functions: \ `setwd('/user/test/nlml')` \ `nlml_functions = list.files(pattern=""*.r"")` \ `sapply(nlml_functions,source,.globalenv)` ## materials looking for information on how you can use the scripts? consult the wiki! nlml wiki"
0,Models-for-Intensively-Collected-Mobile-Data,computation algorithms and statistical models for mobile health data,"# models-for-intensively-collected-mobile-data this is a repository for my master's thesis on analysis of intensively collected mobile data. the final paper and all simulation codes are provided #### abstract: ecological momentary assessment (ema) studies make use of modern technologies such as smartphones to repeatedly sample subjects behavior and state in real time. these studies produce intensively measured longitudinal data with large numbers of observations per subject, and are well suited to address research questions in psychology and public health while assuring a degree of ecological validity. this paper highlights two analytical approaches to ema data. mixed-effects location-scale jointly model the mean and variance of the response variable while accounting for individual heterogeneity. time-varying effects model on the other hand estimates dynamic, nonlinear associations between variables by estimating coecients as functions of time. theoretical and analytical properties of these methods are described alongside simulation studies and real data analysis examples to illustrate their strengths and weaknesses in practice."
1,Coremelysis,coremelysis is an app for experience sampling that uses machine learning for sentiment analysis.,"# coremelysis !platform ios coremelysis is an app for experience sampling that uses machine learning for sentiment analysis. ## installation this app was developed for ios with xcode it is not avaiable on app store. to run the app, download and open the project file on xcode. ## our motivation this is a final project for college from cs majors. our goal was to create a privacy focused and ai powered mobile solution for experience sampling (or ecological momentary assessment). ## how to use it the app has screens: ### history responsible for showing past inferences as well as provinding some basic statistics of your inference history. ### main (coremelysis) the core of the app, here you can type your entries and have then be evaluated and stored in the history. ### settings here you can change the model used for inference (see the list bellow for options) as well as see more information of the app. | model | author | source | | -------- | -------- | -------- | | natural language | apple | link | | sentiment polarity | vadym markov | link |"
0,PIDApp,pulse intervals detection app: an r shiny app to detect and process pulse intervals from pothoplethismography-based blood volume pulse,"# pidapp: pulse intervals detection app the pidapp is a graphical application made with the r shiny package to *detect and process pulse intervals* measured with pothoplethismography (ppg), based on both manual and automatic procedures. ## pidapp versions the development of a more comprehensive version of the app, and the related documentation is currently ongoing. for now, this repository includes the versions of the app used in two studies to process the bvp signal recorded with the wristband (empatica, milan): - app version used in the study menghini, l., gianfranchi, e., cellini, n., patron, e., tagliabue, m., & sarlo, m. stressing the accuracy: wristworn wearable sensor validation over different conditions. *psychophysiology, - `vmhrv-selfregulation`: app version used in the study menghini, l., fuochi, g., sarlo, m. inter- and intraindividual relationships between vagally-mediated heart rate variability and self-regulatory processes: an ecological momentary assessment (*in preparation*), whose ongoing data pre-processing and data analysis are available at https://github.com/luca-menghini/vmhrv-selfregulation # work in progress..."
1,IsolationAlert,an android app used to identify social status based on users' social activities,"# isolation alert isolation is an android app to identify **[social isolation][social isolation]** based on the users social activities on a mobile device. adviser: [dr. yuting zhang][dr. yuting zhang] and [dr. dan fulford][dr dan fulford] contributed to [metropolitan college][metropolitan college] and [sargent college][sargent college] at boston university. features -------- #### dashboard * device usage * acquire and show the counts of calls, sms, photos and videos of the day. * social app usage * acquire and show the onscreen time of common social apps. e.g. facebook, instagram. * activity (in progress) * acquire and show the total time of user's activity (e.g. in a vehicle) within the day. * location (in progress) * acquire the locations whenever a user moves (or changes the location) with a specific time-span. #### ema (ecological momentary assessment) * survey (normal) * acquire the answers chosen by the user for further mental assessment. * survey (sensor-initiated) (in progress) * pop up a notification to ask a yes-no question when microphone detects conversation within given block of time. #### conversation recognition * training session (in progress) * let the user record the voice in a short span of time. * testing session (in progress) * retrieve the accuracy of the user's voice from the microphone and keep the specific information. (e.g. location, time) screenshots -------- dashboard </br> <div align=center> <img </div> </br> ema & conversation recognition </br> <div align=center> <img </div> </br> platform -------- editor: android studio language: java library usage -------- [gson][gson] [greendao][greendao] [easypermissions][easypermissions] [social isolation]:https://en.wikipedia.org/wiki/social_isolation [dr. yuting zhang]: http://www.bu.edu/met/faculty/full-time/yuting-zhang/ [dr dan fulford]:https://www.bu.edu/sargent/profile/dan-fulford/ [sargent college]:https://www.bu.edu/sargent [metropolitan college]:http://www.bu.edu/met [gson]: https://github.com/google/gson [greendao]: https://github.com/greenrobot/greendao [easypermissions]: https://github.com/googlesamples/easypermissions"
1,CTHMMs-for-adaptive-sampling,repository for adaptive sampling in ema code,"# cthmms-for-adaptive-sampling repository for a study proposing a method for adaptive sampling in ecological momentary assessment type settings, using continuous-time hidden markov models. part of the epsrc-funded wearable clinic project. ## abstract wearable and mobile technology provides new opportunities to manage health conditions remotely and unobtrusively. for example, healthcare providers can repeatedly sample a person's condition to monitor disease progression and intervene if necessary. to ensure that this technology is deployed effectively, there is a utility-tolerability trade-off between collecting information at sufficient frequencies and quantities to be useful, and over-burdening the user or the underlying technology. selecting the next sampling time adaptively using previous responses, so that people are only sampled at high frequency when necessary, can help to manage this trade-off. we present an approach to adaptive sampling using clusters continuous-time hidden markov models. the model is used to predict, at any given sampling time, the probability of moving to a high-risk state, and the next sample time is scheduled when this probability has exceeded a given threshold. the clusters, each representing a distinct sub-model, allow heterogeneity in states and state transitions. the work is illustrated using longitudinal mental-health symptom data in people collected using clintouch, a mobile app designed to monitor patients with schizophrenia. using these data we show how the adaptive sampling scheme behaves under different model parameters and risk thresholds, and how, subject to accepting a slightly higher average detection delay, the sampling frequency can be substantially reduced on average."
1,awarns-framework,"easing the development of context-aware apps. powered by our task dispatcher and context apis plugins. modular by design, just use what you need","# @awarns framework [!build the awarns framework (reads like awareness *[werns]* framework), is a nativescript-based application development framework created to simplify the development of mobile applications that need to react to the changes in the context of the phone, even when the app is not visible. unlike other similar frameworks, this has been developed with background execution in mind. no matter if the app is not open when the change occurs, if there is a listener for the change, a reaction to the change will be triggered in the form of a developer-defined task. this means the framework is completely background-first. this is possible thanks to the well-tested nativescript task dispatcher (ntd), which is at the core of the awarns framework. indeed, this framework takes the task definition and execution model offered by the ntd and extends it with primitives to ease the development of context-aware plugins and applications. due to that the ntd only supports the android platform for now, this framework shares this same limitation (**ios is not supported**). awarns sits as a modular layer on top of the ntd. this means that it is possible to build applications with just the minimum number of dependencies required by each application use case. each individual module is available as a separate npm package. the modules can be classified in categories, depending on their purpose: common, sense, analyze and act. the following figure depicts how the categories are related: !awarns framework modules categories ## framework modules the following tables list the modules that come with the framework, grouped by the categories: common, sense, analyze and act. however, the possibilities of the framework are not limited to the modules listed here. it is perfectly fine to develop internal (domain-specific) plugins to extend what is offered by the framework in any of these categories (see our detailed usage and extension guide). similarly, contributions of new (general-purpose) plugins are welcome (see our contributing guide). ### common | module | summary | latest release | downloads | |-----------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------| | @awarns/core | **always install this plugin.** this will enable your app to configure and use the rest of the plugins. it is required to develop your own features on top of the framework. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/core) | [!npm](https://www.npmjs.com/package/@awarns/core) | | @awarns/tracing | **(optional plugin)** we suggest you to install and configure this plugin if your background execution workflow is not trivial (more than a handful of tasks). it facilitates some degree of debugging and profiling while the app is running in production. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/tracing) | [!npm](https://www.npmjs.com/package/@awarns/tracing) | ### sense | module | summary | latest release | downloads | |-------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------| | @awarns/battery | install this plugin if you want to obtain the remaining battery level of the device on a regular basis. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/battery) | [!npm](https://www.npmjs.com/package/@awarns/battery) | | @awarns/geolocation | install this plugin if you want to access the location of the phone, even in background, on a regular basis. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/geolocation) | [!npm](https://www.npmjs.com/package/@awarns/geolocation) | | @awarns/wifi | install this plugin if you want to scan for nearby wi-fi access points (aps) on a regular basis, even in background. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/wifi) | [!npm](https://www.npmjs.com/package/@awarns/wifi) | | @awarns/ble | install this plugin if you want to perform regular scans for nearby bluetooth low energy devices, even if the app is not actively running (in background). [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/ble) | [!npm](https://www.npmjs.com/package/@awarns/ble) | | @awarns/human-activity | install and configure this plugin if your app can benefit from listening to updates in the activity being performed by the user (or object) carrying the phone (including background updates). [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/human-activity) | [!npm](https://www.npmjs.com/package/@awarns/human-activity) | | @awarns/phone-sensors | install this plugin if you want to collect data from the accelerometer, gyroscope, and/or magnetometer sensors [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/phone-sensors) | [!npm](https://www.npmjs.com/package/@awarns/phone-sensors) | | @awarns/wear-os | install this plugin if you want to use a wearos smartwatch to collect data from its sensors (e.g., accelerometer, gyroscope, heart rate monitor, etc...) [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/wear-os) | [!npm](https://www.npmjs.com/package/@awarns/wear-os) | ### analyze | module | summary | latest release | downloads | |-----------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------| | @awarns/geofencing | install and configure this plugin if your app requires to be notified of changes in the position relative to an area of interest. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/geofencing) | [!npm](https://www.npmjs.com/package/@awarns/geofencing) | | @awarns/ml-kit | install this plugin if you want to execute machine learning models (tensorflow lite models) in your device. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/ml-kit) | [!npm](https://www.npmjs.com/package/@awarns/ml-kit) | ### act | module | description | latest release | downloads | |-------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------| | @awarns/persistence | install and configure this plugin if you want to locally store and remotely synchronize the information resulting of an observation or an analysis conducted by the framework. this can be used to develop your own stateful tasks and plugins within the context of the framework. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/persistence) | [!npm](https://www.npmjs.com/package/@awarns/persistence) | | @awarns/notifications | install and configure this plugin if you want to notify the user about some event detected by the framework or your own developed tasks. this contains also some basic constructs to collect information from the user, ingest it and act upon it. [docs] | [!npm (scoped)](https://www.npmjs.com/package/@awarns/notifications) | [!npm](https://www.npmjs.com/package/@awarns/notifications) | ## prerequisites this framework shares the same limitations as the nativescript task dispatcher (ntd) regarding minimum requirements. check the ntd readme for specific details on this. ## usage you can check out our tutorials, to learn how to use the framework. follow the quickstart guide to get the basics on how the framework works. if you need to go beyond the surface, you can read our detailed usage and extension guide. for more concrete usage and extension instructions, please read the core's package readme file. additionally, for specific usage instructions of each one of the plugin modules, please, refer to the corresponding module readme file (you can follow the links to their docs through the table above). ## contributing interested in contributing to the framework with your own module? please, read or contributing guide for step-by-step instructions. ## framework maintainers <a href=""https://github.com/agonper"" title=""alberto gonzlez prez""> <img alt=""alberto gonzlez prez"" </a> <a title=""miguel matey sanz""> <img alt=""miguel matey sanz"" </a> ## acknowledgements the development of this plugin has been possible thanks to the spanish government. concretely, the spanish ministry of education, culture and sports (grant references and and the spanish ministry of science and innovation's programme: ""programa estatal de i+d+i orientada a los retos de la sociedad"" (references and this project is an open-sourced excerpt coming from symptoms and symptoms-et projects at geotec. the awarns framework represents an evolution of our internal ecological momentary assessment and intervention framework (emai framework) that we use to develop mental health apps. the previous, non-modular version, has been extensively used and tested internally for many years."
0,larmexShiny,"shiny application to fit an exogenous linear autoregressive mixed-effects model, larmex, to ecological momentary assessments","<!doctype html> <html> <head> <meta /> <meta name=""generator"" content=""pandoc"" /> <meta http-equiv=""x-ua-compatible"" content=""ie=edge"" /> <title>readme</title> <script>// pandoc adds attributes on both header and div. we remove the former (to // be compatible with the behavior of pandoc < document.addeventlistener('domcontentloaded', function(e) { var hs = document.queryselectorall(""div.section[class*='level'] > :first-child""); var i, h, a; for (i = i < hs.length; i++) { h = hs[i]; if continue; // it should be a header a = h.attributes; while (a.length > } }); </script> <script>/*! jquery | (c) openjs foundation and other contributors | jquery.org/license */ !function(e,t){""use strict"";""object""==typeof module&&""object""==typeof new error(""jquery requires a window with a document"");return t(e)}:t(e)}(""undefined""!=typeof window?window:this,function(c,e){""use strict"";var t=[],r=object.getprototypeof,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},you=t.push,i=t.indexof,n={},o=n.tostring,v=n.hasownproperty,a=v.tostring,l=a.call(object),y={},m=function(e){return""function""==typeof e&&""number""!=typeof e.nodetype&&""function""!=typeof e.item},x=function(e){return b(e,t,n){var r,i,o=(n=n||e).createelement(""script"");if(o.text=e,t)for(r in c)(i=t[r]||t.getattribute&&t.getattribute(r))&&o.setattribute(r,i);n.head.appendchild(o).parentnode.removechild(o)}function w(e){return null==e?e+"""":""object""==typeof e||""function""==typeof e?n[o.call(e)]||""object"":typeof e}var new s.fn.init(e,t)};function p(e){var t=!!e&&""length""in in s.call(this)},get:function(e){return t=s.merge(this.constructor(),e);return t.prevobject=this,t},each:function(e){return s.each(this,e)},map:function(n){return this.pushstack(s.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushstack(s.apply(this,arguments))},first:function(){return this.pushstack(s.grep(this,function(e,t){return this.prevobject||this.constructor()},push:you,sort:t.sort,splice:t.splice},s.extend=s.fn.extend=function(){var a&&(l=a,a=arguments[s]||{},s++),""object""==typeof a||m(a)||(a={}),s===you&&(a=this,s--);s<you;s++)if(null!=(e=arguments[s]))for(t in new error(e)},noop:function(){},isplainobject:function(e){var t,n;return!(!e||""[object object]""!==o.call(e))&&(!(t=r(e))||""function""==typeof(n=v.call(t,""constructor"")&&t.constructor)&&a.call(n)===l)},isemptyobject:function(e){var t;for(t in for(r in e},makearray:function(e,t){var n=t||[];return null!=e&&(p(object(e))?s.merge(n,""string""==typeof e?[e]:e):you.call(n,e)),n},inarray:function(e,t,n){return e.length=i,e},grep:function(e,t,n){for(var r},map:function(e,t,n){var for(o in e)null!=(i=t(e[o],o,n))&&a.push(i);return symbol&&(s.fn[symbol.iterator]=t[symbol.iterator]),s.each(""boolean number string function array date regexp object error symbol"".split("" ""),function(e,t){n[""[object ""+t+""]""]=t.tolowercase()});var d=function(n){var regexp(m+""+"",""g""),$=new regexp(""^""+m+""+|((?:^|[^\\\\])(?:\\\\.)*)""+m+""+$"",""g""),_=new regexp(""^""+m+""*,""+m+""*""),z=new regexp(""^""+m+""*([>+~]|""+m+"")""+m+""*""),you=new regexp(m+""|>""),x=new regexp(f),v=new regexp(""^""+i+""$""),g={id:new regexp(""^#(""+i+"")""),class:new regexp(""^\\.(""+i+"")""),tag:new regexp(""^(""+i+""|[*])""),attr:new regexp(""^""+w),pseudo:new regexp(""^""+f),child:new regexp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+m+""*(even|odd|(([+-]|)(\\d*)n|)""+m+""*(?:([+-]|)""+m+""*(\\d+)|))""+m+""*\\)|)"",""i""),bool:new regexp(""^(?:""+r+"")$"",""i""),needscontext:new regexp(""^""+m+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+m+""*((?:-\\d)?\\d*)""+m+""*\\)|)(?=[^-]|$)"",""i"")},y=/html$/i,q=/^(?:input|select|textarea|button)$/i,j=/^h\d$/i,k=/^[^{]+\{\s*\[native \w/,z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ee=/[+~]/,te=new se(t,e,n,r){var n;if(a.id===i)return n.push(a),n}else if(f&&(a=f.getelementbyid(i))&&y(e,a)&&a.id===i)return h.apply(n,e.getelementsbyclassname(i)),n}if(d.qsa&&!n[t+"" ""+xe(l[o]);c=l.join("","")}try{return ue(){var r=[];return function e(t,n){return r.push(t+"" "")>b.cachelength&&delete e[r.shift()],e[t+"" ""]=n}}function le(e){return ce(e){var fe(e,t){var n=e.split(""|""),r=n.length;while(r--)b.attrhandle[n[r]]=t}function pe(e,t){var de(t){return function(e){return""input""===e.nodename.tolowercase()&&e.type===t}}function he(n){return function(e){var t=e.nodename.tolowercase();return(""input""===t||""button""===t)&&e.type===n}}function ge(t){return function(e){return""form""in e?""label""in e.parentnode?e.parentnode.disabled===t:e.disabled===t:e.isdisabled===t||e.isdisabled!==!t&&ae(e)===t:e.disabled===t:""label""in e&&e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&&(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&&""undefined""!=typeof e.getelementsbytagname&&e}for(e in d=se.support={},i=se.isxml=function(e){var t=e&&e.namespaceuri,n=e&&(e.ownerdocument||e).documentelement;return!y.test(t||n&&n.nodename||""html"")},t=se.setdocument=function(e){var t,n,r=e?e.ownerdocument||e:p;return a.appendchild(e).appendchild(c.createelement(""div"")),""undefined""!=typeof e.queryselectorall&&!e.queryselectorall("":scope fieldset div"").length}),d.attributes=ce(function(e){return e.classname=""i"",!e.getattribute(""classname"")}),d.getelementsbytagname=ce(function(e){return e.appendchild(c.createcomment("""")),!e.getelementsbytagname(""*"").length}),d.getelementsbyclassname=k.test(c.getelementsbyclassname),d.getbyid=ce(function(e){return a.appendchild(e).id=s,!c.getelementsbyname||!c.getelementsbyname(s).length}),d.getbyid?(b.filter.id=function(e){var t=e.replace(te,ne);return function(e){return e.getattribute(""id"")===t}},b.find.id=function(e,t){if(""undefined""!=typeof t.getelementbyid&&e){var n=t.getelementbyid(e);return n?[n]:[]}}):(b.filter.id=function(e){var n=e.replace(te,ne);return function(e){var t=""undefined""!=typeof e.getattributenode&&e.getattributenode(""id"");return t&&t.value===n}},b.find.id=function(e,t){if(""undefined""!=typeof t.getelementbyid&&e){var t.getelementsbytagname?t.getelementsbytagname(e):d.qsa?t.queryselectorall(e):void r}return o},b.find.class=d.getelementsbyclassname&&function(e,t){if(""undefined""!=typeof t.getelementsbyclassname&&e)return t.getelementsbyclassname(e)},s=[],v=[],(d.qsa=k.test(c.queryselectorall))&&(ce(function(e){var t;a.appendchild(e).innerhtml=""<a id='""+s+""'></a><select id='""+s+""-\r\\' msallowcapture=''><option selected=''></option></select>"",e.queryselectorall(""[msallowcapture^='']"").length&&v.push(""[*^$]=""+m+""*(?:''|\""\"")""),e.queryselectorall(""[selected]"").length||v.push(""\\[""+m+""*(?:value|""+r+"")""),e.queryselectorall(""[id~=""+s+""-]"").length||v.push(""~=""),(t=c.createelement(""input"")).setattribute(""name"",""""),e.appendchild(t),e.queryselectorall(""[name='']"").length||v.push(""\\[""+m+""*name""+m+""*=""+m+""*(?:''|\""\"")""),e.queryselectorall("":checked"").length||v.push("":checked""),e.queryselectorall(""a#""+s+""+*"").length||v.push("".#.+[+~]""),e.queryselectorall(""\\\f""),v.push(""[\\r\\n\\f]"")}),ce(function(e){e.innerhtml=""<a href='' disabled='disabled'></a><select disabled='disabled'><option/></select>"";var regexp(v.join(""|"")),s=s.length&&new regexp(s.join(""|"")),t=k.test(a.comparedocumentposition),y=t||k.test(a.contains)?function(e,t){var n=!e.comparedocumentposition-!t.comparedocumentposition;return pe(e,t);n=e;while(n=n.parentnode)a.unshift(n);n=t;while(n=n.parentnode)s.unshift(n);while(a[r]===s[r])r++;return se(e,null,null,t)},se.matchesselector=function(e,t){if(t(e),d.matchesselector&&e&&!n[t+"" ""]&&(!s||!s.test(t))&&(!v||!v.test(t)))try{var n=b.attrhandle[t.tolowercase()],r=n&&d.call(b.attrhandle,t.tolowercase())?n(e,t,!e):void void new error(""syntax error, unrecognized expression: ""+e)},se.uniquesort=function(e){var you=null,e},o=se.gettext=function(e){var e.textcontent)return e.textcontent;for(e=e.firstchild;e;e=e.nextsibling)n+=o(e)}else e.nodevalue}else while(t=e[r++])n+=o(t);return e.nodename&&e.nodename.tolowercase()===t}},class:function(e){var t=m[e+"" ""];return t||(t=new regexp(""(^|""+m+"")""+e+""(""+m+""|$)""))&&m(e,function(e){return t.test(""string""==typeof e.classname&&e.classname||""undefined""!=typeof e.getattribute&&e.getattribute(""class"")||"""")})},attr:function(n,r,i){return function(e){var t=se.attr(e,n);return ""+t.replace(b,"" "")+"" t,a=b.pseudos[e]||b.setfilters[e.tolowercase()]||se.error(""unsupported pseudo: ""+e);return n,r=a(e,o),i=r.length;while(i--)e[n=p(e,r[i])]=!(t[n]=r[i])}):function(e){return s[s]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&&(e[a]=!(t[a]=i))}):function(e,t,n){return function(e){return v.test(n||"""")||se.error(""unsupported lang: ""+n),n=n.replace(te,ne).tolowercase(),function(e){var t=n.location&&n.location.hash;return e===a},focus:function(e){return t=e.nodename.tolowercase();return""input""===t&&!!e.checked||""option""===t&&!!e.selected},selected:function(e){return j.test(e.nodename)},input:function(e){return q.test(e.nodename)},button:function(e){var t=e.nodename.tolowercase();return""input""===t&&""button""===e.type||""button""===t},text:function(e){var e}),odd:ve(function(e,t){for(var e}),lt:ve(function(e,t,n){for(var e}),gt:ve(function(e,t,n){for(var me(){}function xe(e){for(var r}function be(s,e,t){var you=e.dir,l=e.next,c=l||you,f=t&&""parentnode""===c,p=r++;return we(i){return te(e,t,n,r,i){for(var a}function ce(d,h,g,v,y,e){return v&&!v[s]&&(v=ce(v)),y&&!y[s]&&(y=ce(y,e)),le(function(e,t,n,r){var i,o,a,s=[],you=[],l=t.length,c=e||function(e,t,n){for(var p=te(p===t?p.splice(l,p.length):p),y?y(null,t,p,r):h.apply(t,p)})}function ee(e){for(var r=!o&&(n||t!==w)||((i=t).nodetype?you(e,t,n):l(e,t,n));return i=null,r}];s<r;s++)if(t=b.relative[e[s].type])c=[be(we(c),t)];else{if((t=b.filter[e[s].type].apply(null,e[s].matches))[s]){for(n=++s;n<r;n++)if(b.relative[e[n].type])break;return we(c)}return me.prototype=b.filters=b.pseudos,b.setfilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,you,l=x[e+"" ""];if(l)return in "")}),a=a.slice(n.length)),b.filter)!(r=g[o].exec(a))||you[o]&&!(r=youo)||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return n,v,y,m,x,r,i=[],o=[],a=a[e+"" i&&(k=h,w=p),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,you,l=""function""==typeof h.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!e,n,!t||ee.test(e)&&ye(t.parentnode)||t),n},d.sortstable=s.split("""").sort(j).join("""")===s,d.detectduplicates=!!l,t(),d.sortdetached=ce(function(e){return e.innerhtml=""<a href='#'></a>"",""#""===e.firstchild.getattribute(""href"")})||fe(""type|href|height|width"",function(e,t,n){if(!n)return e.innerhtml=""<input/>"",e.firstchild.setattribute(""value"",""""),""""===e.firstchild.getattribute(""value"")})||fe(""value"",function(e,t,n){if(!n&&""input""===e.nodename.tolowercase())return e.defaultvalue}),ce(function(e){return null==e.getattribute(""disabled"")})||fe(r,function(e,t,n){var h=function(e,t,n){var r=[],i=void r},t=function(e,t){for(var n},k=s.expr.match.needscontext;function a(e,t){return e.nodename&&e.nodename.tolowercase()===t.tolowercase()}var j(e,n,r){return m(n)?s.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodetype?s.grep(e,function(e){return e===n!==r}):""string""!=typeof t,n,r=this.length,i=this;if(""string""!=typeof e)return d,q=/^(?:\s*(<[\w\w]+>)[^>]*|#([\w-]+))$/;(s.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||d,""string""==typeof instanceof in t)m(this[r])?thisr:this.attr(r,t[r]);return e}s.fn.extend({has:function(e){var t=s(e,this),n=t.length;return this.filter(function(){for(var e?""string""==typeof this.pushstack(s.uniquesort(s.merge(this.get(),s(e,t))))},addback:function(e){return this.add(null==e?this.prevobject:this.prevobject.filter(e))}}),s.each({parent:function(e){var t=e.parentnode;return h(e,""parentnode"")},parentsuntil:function(e,t,n){return h(e,""parentnode"",n)},next:function(e){return o(e,""nextsibling"")},prev:function(e){return o(e,""previoussibling"")},nextall:function(e){return h(e,""nextsibling"")},prevall:function(e){return h(e,""previoussibling"")},nextuntil:function(e,t,n){return h(e,""nextsibling"",n)},prevuntil:function(e,t,n){return h(e,""previoussibling"",n)},siblings:function(e){return t((e.parentnode||{}).firstchild,e)},children:function(e){return t(e.firstchild)},contents:function(e){return null!=e.contentdocument&&r(e.contentdocument)?e.contentdocument:(a(e,""template"")&&(e=e.content||e),s.merge([],e.childnodes))}},function(r,i){s.fn[r]=function(e,t){var r(e){return e}function m(e){throw e}function i(e,t,n,r){var i;try{e&&m(i=e.promise)?i.call(e).done(t).fail(n):e&&m(i=e.then)?i.call(e,t,n):t.apply(void e,n;r=""string""==typeof n(e){s.each(e,function(e,t){m(t)?r.unique&&f.has(t)||s.push(t):t&&t.length&&""string""!==w(t)&&n(t)})}(arguments),t&&!i&&c()),this},remove:function(){return s.each(arguments,function(e,t){var s&&(s=[]),this},disable:function(){return a=you=[],s=t="""",this},disabled:function(){return!s},lock:function(){return a=you=[],t||i||(s=t=""""),this},locked:function(){return!!a},firewith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],you.push(t),i||c()),this},fire:function(){return f.firewith(this,arguments),this},fired:function(){return!!o}};return f},s.extend({deferred:function(e){var memory""),s.callbacks(""once memory""),s.callbacks(""once i},always:function(){return s.done(arguments).fail(arguments),this},""catch"":function(e){return a.then(null,e)},pipe:function(){var i=arguments;return s.deferred(function(r){s.each(o,function(e,t){var l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i<you)){if((e=a.apply(n,r))===o.promise())throw new typeerror(""thenable self-resolution"");t=e&&(""object""==typeof e||""function""==typeof e)&&e.then,m(t)?s?t.call(e,l(you,o,r,s),l(you,o,m,s)):(you++,t.call(e,l(you,o,r,s),l(you,o,m,s),l(you,o,r,o.notifywith))):(a!==r&&(n=void null!=e?s.extend(e,a):a}},s={};return s.each(o,function(e,t){var n=arguments.length,t=n,r=array(t),i=s.call(arguments),o=s.deferred(),a=function(t){return o.then();while(t--)i(i[t],a(t),o.reject);return o.promise()}});var w=/^(eval|internal|range|reference|syntax|type|uri)error$/;s.deferred.exceptionhook=function(e,t){c.console&&c.console.warn&&e&&w.test(e.name)&&c.console.warn(""jquery.deferred exception: ""+e.message,e.stack,t)},s.readyexception=function(e){c.settimeout(function(){throw e})};var f=s.deferred();function b(){e.removeeventlistener(""domcontentloaded"",b),c.removeeventlistener(""load"",b),s.ready()}s.fn.ready=function(e){return $=function(e,t,n,r,i,o,a){var in if(void l.call(s(e),n)})),t))for(;s<you;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return you(e,t){return t.touppercase()}function x(e){return e.replace(_,""ms-"").replace(z,you)}var v=function(e){return t=e[this.expando];return r,i=this.cache(e);if(""string""==typeof t)i[x(t)]=n;else for(r in t)i[x(r)]=t[r];return i},get:function(e,t){return void void t&&void n,r=e[this.expando];if(void r?[t]:t.match(p)||[]).length;while(n--)delete r[t[n]]}(void e[this.expando])}},hasdata:function(e){var t=e[this.expando];return void y=new g,q=new g,j=/^(?:\{[\w\w]*\}|\[[\w\w]*\])$/,k=/[a-z]/g;function z(e,t,n){var r,i;if(void n=void n}s.extend({hasdata:function(e){return q.hasdata(e)||y.hasdata(e)},data:function(e,t,n){return q.access(e,t,n)},removedata:function(e,t){q.remove(e,t)},_data:function(e,t,n){return y.access(e,t,n)},_removedata:function(e,t){y.remove(e,t)}}),s.fn.extend({data:function(n,e){var i}return""object""==typeof n?this.each(function(){q.set(this,n)}):$(this,function(e){var t;if(o&&void void this.each(function(){q.remove(this,e)})}}),s.extend({queue:function(e,t,n){var r;if(e)return t=(t||""fx"")+""queue"",r=y.get(e,t),n&&(!r||array.isarray(n)?r=y.access(e,t,s.makearray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||""fx"";var n=s.queue(e,t),r=n.length,i=n.shift(),o=s._queuehooks(e,t);""inprogress""===i&&(i=n.shift(),r--),i&&(""fx""===t&&n.unshift(""inprogress""),delete o.stop,i.call(e,function(){s.dequeue(e,t)},o)),!r&&o&&o.empty.fire()},_queuehooks:function(e,t){var n=t+""queuehooks"";return y.get(e,n)||y.access(e,n,{empty:s.callbacks(""once memory"").add(function(){y.remove(e,[t+""queue"",n])})})}}),s.fn.extend({queue:function(t,n){var this.each(function(){s.dequeue(this,e)})},clearqueue:function(e){return this.queue(e||""fx"",[])},promise:function(e,t){var e&&(t=e,e=void s(),i.promise(t)}});var ee=/[+-]?(?:\d*\.|)\d+(?:[ee][+-]?\d+|)/.source,te=new regexp(""^(?:([+-])=|)(""+ee+"")([a-z%]*)$"",""i""),ne=[""top"",""right"",""bottom"",""left""],re=e.documentelement,ie=function(e){return s.contains(e.ownerdocument,e)||e.getrootnode(oe)===e.ownerdocument});var ae=function(e,t){return""none""===(e=t||e).style.display||""""===e.style.display&&ie(e)&&""none""===s.css(e,""display"")};function se(e,t,n,r){var r.cur()}:function(){return ue={};function le(e,t){for(var e}s.fn.extend({show:function(){return le(this)},toggle:function(e){return""boolean""==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?s(this).show():s(this).hide()})}});var ve(e,t){var n;return n=""undefined""!=typeof e.getelementsbytagname?e.getelementsbytagname(t||""*""):""undefined""!=typeof e.queryselectorall?e.queryselectorall(t||""*""):[],void ye(e,t){for(var multiple='multiple'>"",""</select>""]);var me=/<|&#?\w+;/;function xe(e,t,n,r,i){for(var f}var be=/^([^.]*)(?:\.(.+)|)/;function ce(e,t){return e===function(){try{return e.activeelement}catch(e){}}()==(""focus""===t)}function ee(e,t,n,r,i,o){var a,s;if(""object""==typeof t){for(s in""string""!=typeof n&&(r=r||n,n=void e}if(null==r&&null==i?(i=n,r=n=void n?(i=r,r=void if(!i)return e;return s().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=s.guid++)),e.each(function(){s.event.add(this,t,i,r,n)})}function e.stopimmediatepropagation(),e.preventdefault(),n&&n.value}else o,a,s,you,l,c,f,p,d,h,g,v=y.get(t);if(v(t)){n.handler&&(n=(o=n).handler,i=o.selector),i&&s.find.matchesselector(re,i),n.guid||(n.guid=s.guid++),(you=v.events)||(you=v.events=object.create(null)),(a=v.handle)||(a=v.handle=function(e){return""undefined""!=typeof s&&s.event.triggered!==e.type?s.event.dispatch.apply(t,arguments):void you[d])}else for(d in events"")}},dispatch:function(e){var t,n,r,i,o,a,s=new c.postdispatch&&c.postdispatch.call(this,you),you.result}},handlers:function(e,t){var e(this.originalevent)}:function(){if(this.originalevent)return e[s.expando]?e:new t=this||e;return t=this||e;return t=e.target;return pe.test(t.type)&&t.click&&a(t,""input"")&&y.get(t,""click"")||a(t,""a"")}},beforeunload:{postdispatch:function(e){void instanceof s.event))return new s.event(e,t);e&&e.type?(this.originalevent=e,this.type=e.type,this.isdefaultprevented=e.defaultprevented||void e=this.originalevent;this.isdefaultprevented=we,e&&!this.issimulated&&e.preventdefault()},stoppropagation:function(){var e=this.originalevent;this.ispropagationstopped=we,e&&!this.issimulated&&e.stoppropagation()},stopimmediatepropagation:function(){var t,n=e.relatedtarget,r=e.handleobj;return n&&(n===this||s.contains(this,n))||(e.type=r.origtype,t=r.handler.apply(this,arguments),e.type=i),t}}}),s.fn.extend({on:function(e,t,n,r){return ee(this,e,t,n,r)},one:function(e,t,n,r){return r,i;if(e&&e.preventdefault&&e.handleobj)return r=e.handleobj,s(e.delegatetarget).off(r.namespace?r.origtype+"".""+r.namespace:r.origtype,r.selector,r.handler),this;if(""object""==typeof e){for(i in e)this.off(i,t,e[i]);return t||(n=t,t=void ke=/<script|<style|<link/i,ae=/checked\s*(?:[^=]|=\s*.checked.)/i,ne=/^\s*<!(?:\[cdata\[|--)|(?:\]\]|--)>\s*$/g;function je(e,t){return de(e){return e.type=(null!==e.getattribute(""type""))+""/""+e.type,e}function le(e,t){var in y.remove(t,""handle he(n,r,i,o){r=g(r);var d&&!y.checkclone&&ae.test(d))return n.each(function(e){var n}function oe(e,t,n){for(var e}s.extend({htmlprefilter:function(e){return e},clone:function(e,t,n){var le(e,c);return in t.events)i[r]?s.event.remove(n,r):s.removeevent(n,r,t.handle);n[y.expando]=void oe(this,e)},text:function(e){return $(this,function(e){return void t=je(this,e);t.insertbefore(e,t.firstchild)}})},before:function(){return he(this,arguments,function(e){this.parentnode&&this.parentnode.insertbefore(e,this)})},after:function(){return he(this,arguments,function(e){this.parentnode&&this.parentnode.insertbefore(e,this.nextsibling)})},empty:function(){for(var this},clone:function(e,t){return e=null!=e&&e,t=null==t?e:t,this.map(function(){return s.clone(this,e,t)})},html:function(e){return $(this,function(e){var t.innerhtml;if(""string""==typeof n=[];return he(this,arguments,function(e){var this.pushstack(n)}});var pe=new regexp(""^(""+ee+"")(?!px)[a-z%]+$"",""i""),re=function(e){var t=e.ownerdocument.defaultview;return t&&t.opener||(t=c),t.getcomputedstyle(e)},me=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},ie=new regexp(ne.join(""|""),""i"");function we(e,t,n){var r,i,o,a,s=e.style;return(n=n||re(e))&&(""""!==(a=n.getpropertyvalue(t)||n[t])||ie(e)||(a=s.style(e,t)),!y.pixelboxstyles()&&pe.test(a)&&ie.test(t)&&(r=s.width,i=s.minwidth,o=s.maxwidth,s.minwidth=s.maxwidth=s.width=a,a=n.width,s.width=r,s.minwidth=i,s.maxwidth=o)),void fe(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function t(e){return math.round(parsefloat(e))}var e(),r},pixelboxstyles:function(){return e(),o},pixelposition:function(){return e(),n},reliablemarginleft:function(){return e(),s},scrollboxsize:function(){return e(),i},reliabletrdimensions:function(){var e,t,n,r;return be=[""webkit"",""moz"",""ms""],$e=e.createelement(""div"").style,_e={};function ze(e){var t=s.cssprops[e]||_e[e];return t||(e in $e?e:_e[e]=function(e){var $e)return e}(e)||e)}var ye(e,t,n){var r=te.exec(t);return qe(e,t,n,r,i,o){var je(e,t,n){var in ke(e,t,n,r,i){return new ke.prototype.init(e,t,n,r,i)}s.extend({csshooks:{opacity:{get:function(e,t){if(t){var i,o,a,s=x(t),you=xe.test(t),l=e.style;if(you||(t=ze(s)),a=s.csshooks[t]||s.csshooks[s],void a&&""get""in a&&void a&&void i,o,a,s=x(t);return xe.test(t)||(t=ze(s)),(a=s.csshooks[t]||s.csshooks[s])&&""get""in in je(e,you,n)})},set:function(e,t,n){var e.getboundingclientrect().left}))+""px""}),s.each({margin:"""",padding:"""",border:""width""},function(i,o){s.csshooks[i+o]={expand:function(e){for(var e?e.split("" n}},""margin""!==i&&(s.csshooks[i+o].set=ye)}),s.fn.extend({css:function(e,t){return $(this,function(e,t,n){var o}return void e=ke.prophooks[this.prop];return e&&e.get?e.get(this):ke.prophooks._default.get(this)},run:function(e){var t,n=ke.prophooks[this.prop];return this.options.duration?this.pos=t=s.easingthis.easing:this.pos=t=e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):ke.prophooks._default.set(this),this}}).init.prototype=ke.prototype,(ke.prophooks={_default:{get:function(e){var t;return ze,et,tt,nt,rt=/^(?:toggle|show|hide)$/,it=/queuehooks$/;function at(){return c.settimeout(function(){ze=void st(e,t){var t&&(i.opacity=i.width=e),i}function ut(e,t,n){for(var r}function lt(o,e,t){var n=s.tween(o,l.opts,e,t,l.opts.specialeasing[e]||l.opts.easing);return l.tweens.push(n),n},stop:function(e){var n,r,i,o,a;for(n in e[n]),(a=s.csshooks[r])&&""expand""in a)for(n in o=a.expand(o),delete e[r],o)n in e||(e[n]=o[n],t[n]=i);else t[r]=i}(c,l.opts.specialeasing);r<i;r++)if(n=lt.prefilters[r].call(l,o,c,l.opts))return m(n.stop)&&(s._queuehooks(l.elem,l.opts.queue).stop=n.stop.bind(n)),n;return s.map(c,ut,l),m(l.opts.start)&&l.opts.start.call(o,l),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always),s.fx.timer(s.extend(you,{elem:o,anim:l,queue:l.opts.queue})),l}s.animation=s.extend(lt,{tweeners:{""*"":[function(e,t){var n=this.createtween(e,t);return se(n.elem,e,te.exec(t),n),n}]},tweener:function(e,t){m(e)?(t=e,e=[""*""]):e=e.match(p);for(var r,i,o,a,s,you,l,c,f=""width""in t||""height""in t,p=this,d={},h=e.style,g=e.nodetype&&ae(e),v=y.get(e,""fxshow"");for(r in t[r],o=o||""toggle""===i,i===(g?""hide"":""show"")){if(""show""!==i||!v||void in in in r=e&&""object""==typeof e?s.extend({},e):{complete:n||!n&&t||m(e)&&e,duration:e,easing:n&&t||t&&!m(t)&&t};return r.duration&&(r.duration in i=s.isemptyobject(t),o=s.speed(e,n,r),a=function(){var a=function(e){var t=e.stop;delete e.stop,t(o)};return""string""!=typeof i&&(o=e,e=i,i=void for(t in t.finish})}}),s.each([""toggle"",""show"",""hide""],function(e,r){var i=s.fn[r];s.fn[r]=function(e,t,n){return null==e||""boolean""==typeof this.animate(r,e,t,n)}}),s.timers=[],s.fx.tick=function(){var r=s.fx&&s.fx.speeds[r]||r,e=e||""fx"",this.queue(e,function(e,t){var n=c.settimeout(e,r);t.stop=function(){c.cleartimeout(n)}})},tt=e.createelement(""input""),nt=e.createelement(""select"").appendchild(e.createelement(""option"")),tt.type=""checkbox"",y.checkon=""""!==tt.value,y.optselected=nt.selected,(tt=e.createelement(""input"")).value=""t"",tt.type=""radio"",y.radiovalue=""t""===tt.value;var ct,ft=s.expr.attrhandle;s.fn.extend({attr:function(e,t){return this.each(function(){s.removeattr(this,e)})}}),s.extend({attr:function(e,t,n){var s.removeattr(e,t):i&&""set""in i&&void i&&null!==(r=i.get(e,t))?r:null==(r=s.find.attr(e,t))?void n=e.value;return e.setattribute(""type"",t),n&&(e.value=n),t}}}},removeattr:function(e,t){var a=ft[t]||s.find.attr;ft[t]=function(e,t,n){var r,i,o=t.tolowercase();return n||(i=ft[o],ft[o]=r,r=null!=a(e,t,n)?o:null,ft[o]=i),r}});var pt=/^(?:input|select|textarea|button)$/i,dt=/^(?:a|area)$/i;function ht(e){return(e.match(p)||[]).join("" "")}function gt(e){return e.getattribute&&e.getattribute(""class"")||""""}function vt(e){return array.isarray(e)?e:""string""==typeof e&&e.match(p)||[]}s.fn.extend({prop:function(e,t){return this.each(function(){delete this[s.propfix[e]||e]})}}),s.extend({prop:function(e,t,n){var i&&void i&&null!==(r=i.get(e,t))?r:e[t]},prophooks:{tabindex:{get:function(e){var t=s.find.attr(e,""tabindex"");return t=e.parentnode;return t&&t.parentnode&&t.parentnode.selectedindex,null},set:function(e){var t=e.parentnode;t&&(t.selectedindex,t.parentnode&&t.parentnode.selectedindex)}}),s.each([""tabindex"",""readonly"",""maxlength"",""cellspacing"",""cellpadding"",""rowspan"",""colspan"",""usemap"",""frameborder"",""contenteditable""],function(){s.propfix[this.tolowercase()]=this}),s.fn.extend({addclass:function(t){var ""+ht(i)+"" ""+o+"" "");i!==(s=ht(r))&&n.setattribute(""class"",s)}return this},removeclass:function(t){var this.each(function(e){s(this).removeclass(t.call(this,e,gt(this)))});if(!arguments.length)return ""+ht(i)+"" ""+o+"" ""))r=r.replace("" ""+o+"" "","" "");i!==(s=ht(r))&&n.setattribute(""class"",s)}return this},toggleclass:function(i,t){var o=typeof i,a=""string""===o||array.isarray(i);return""boolean""==typeof t&&a?t?this.addclass(i):this.removeclass(i):m(i)?this.each(function(e){s(this).toggleclass(i.call(this,e,gt(this),t),t)}):this.each(function(){var void ""+e+"" ""+ht(gt(n))+"" yt=/\r/g;s.fn.extend({val:function(n){var arguments.length?(i=m(n),this.each(function(e){var t?t+="""":array.isarray(t)&&(t=s.map(t,function(e){return null==e?"""":e+""""})),(r=s.valhooks[this.type]||s.valhooks[this.nodename.tolowercase()])&&""set""in r&&void r&&void t=s.find.attr(e,""value"");return null!=t?t:ht(s.text(e))}},select:{get:function(e){var t;s.push(t)}return s},set:function(e,t){var null===e.getattribute(""value"")?""on"":e.value})}),y.focusin=""onfocusin""in c;var mt=/^(?:focusinfocus|focusoutblur)$/,xt=function(e){e.stoppropagation()};s.extend(s.event,{trigger:function(e,t,n,r){var s.event(d,""object""==typeof regexp(""(^|\\.)""+h.join(""\\.(?:.*\\.|)"")+""(\\.|$)""):null,e.result=void r=s.extend(new this.each(function(){s.event.trigger(e,t,this)})},triggerhandler:function(e,t){var i=function(e){s.event.simulate(r,e.target,s.event.fix(e))};s.event.special[r]={setup:function(){var bt=c.location,wt={guid:date.now()},tt=/\?/;s.parsexml=function(e){var t,n;if(!e||""string""!=typeof e)return null;try{t=(new c.domparser).parsefromstring(e,""text/xml"")}catch(e){}return xml: ""+(n?s.map(n.childnodes,function(e){return e.textcontent}).join(""\n""):e)),t};var ct=/\[\]$/,et=/\r?\n/g,st=/^(?:submit|button|image|reset|file)$/i,kt=/^(?:input|select|textarea|keygen)/i;function at(n,e,r,i){var t;if(array.isarray(e))s.each(e,function(e,t){r||ct.test(n)?i(n,t):at(n+""[""+(""object""==typeof t&&null!=t?e:"""")+""]"",t,r,i)});else if(r||""object""!==w(e))i(n,e);else for(t in e)at(n+""[""+t+""]"",e[t],r,i)}s.param=function(e,t){var n,r=[],i=function(e,t){var n=m(t)?t():t;r[r.length]=encodeuricomponent(e)+""=""+encodeuricomponent(null==n?"""":n)};if(null==e)return"""";if(array.isarray(e)||e.jquery&&!s.isplainobject(e))s.each(e,function(){i(this.name,this.value)});else for(n in e)at(n,e[n],t,i);return r.join(""&"")},s.fn.extend({serialize:function(){return s.param(this.serializearray())},serializearray:function(){return this.map(function(){var e=s.prop(this,""elements"");return e?s.makearray(e):this}).filter(function(){var e=this.type;return this.name&&!s(this).is("":disabled"")&&kt.test(this.nodename)&&!st.test(e)&&(this.checked||!pe.test(e))}).map(function(e,t){var n=s(this).val();return null==n?null:array.isarray(n)?s.map(n,function(e){return{name:t.name,value:e.replace(et,""\r\n"")}}):{name:t.name,value:n.replace(et,""\r\n"")}}).get()}});var \t]*([^\r\n]*)$/gm,lt=/^(?:get|head)$/,ht=/^\/\//,ot={},pt={},rt=""*/"".concat(""*""),mt=e.createelement(""a"");function it(o){return function(e,t){""string""!=typeof e&&(t=e,e=""*"");var wt(t,i,o,a){var s={},you=t===pt;function l(e){var r;return n=t(i,o,a);return""string""!=typeof n||you||s[n]?you?!(r=n):void ft(e,t){var n,r,i=s.ajaxsettings.flatoptions||{};for(n in t)void text/xml"",json:""application/json, text/javascript""},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responsefields:{xml:""responsexml"",text:""responsetext"",json:""responsejson""},converters:{""* text"":string,""text json"":json.parse,""text t?ft(ft(e,s.ajaxsettings),t):ft(s.ajaxsettings,e)},ajaxprefilter:it(ot),ajaxtransport:it(pt),ajax:function(e,t){""object""==typeof e&&(t=e,e=void c,f,p,n,d,r,h,g,i,o,v=s.ajaxsetup({},t),y=v.context||v,m=v.context&&(y.nodetype||y.jquery)?s(y):s.event,x=s.deferred(),b=s.callbacks(""once ""]}return null==t?null:t.join("", "")},getallresponseheaders:function(){return h?p:null},setrequestheader:function(e,t){return null==h&&(e=s[e.tolowercase()]=s[e.tolowercase()]||e,a[e]=t),this},overridemimetype:function(e){return null==h&&(v.mimetype=e),this},statuscode:function(e){var t;if(e)if(h)t.always(e[t.status]);else for(t in e)w[t]=[w[t],e[t]];return this},abort:function(e){var t=e||you;return v.data&&(v.data=s.param(v.data,v.traditional)),wt(ot,v,t,t),h)return t;for(i v.data)&&(f+=(tt.test(f)?""&"":""?"")+v.data,delete ""+rt+""; transport"");function l(e,t,n,r){var in in script""]=function(){}),s=function(e,t,n,r){var in e.converters)l[a.tolowercase()]=e.converters[a];o=c.shift();while(o)if(e.responsefields[o]&&(n[e.responsefields[o]]=t),!you&&r&&e.datafilter&&(t=e.datafilter(t,e.datatype)),you=o,o=c.shift())if(""*""===o)o=you;else if(""*""!==you&&you!==o){if(!(a=l[you+"" ""+o]||l[""* ""+o]))for(i in l)if((s=i.split("" try{t=a(t)}catch(e){return{state:""parsererror"",error:a?e:""no conversion from ""+you+"" to t},getjson:function(e,t,n){return s.get(e,t,n,""json"")},getscript:function(e,t){return s.get(e,void m(t)&&(r=r||n,n=t,t=void t;for(t in e.headers)""content-type""===t.tolowercase()&&(e.contenttype=e.headers[t]||"""")}),s._evalurl=function(e,t,n){return script"":function(){}},datafilter:function(e){s.globaleval(e,t,n)}})},s.fn.extend({wrapall:function(e){var t;return e=this;while(e.firstelementchild)e=e.firstelementchild;return e}).append(this)),this},wrapinner:function(n){return m(n)?this.each(function(e){s(this).wrapinner(n.call(this,e))}):this.each(function(){var e=s(this),t=e.contents();t.length?t.wrapall(n):e.append(n)})},wrap:function(t){var n=m(t);return this.each(function(e){s(this).wrapall(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not(""body"").each(function(){s(this).replacewith(this.childnodes)}),this}}),s.expr.pseudos.hidden=function(e){return!s.expr.pseudos.visible(e)},s.expr.pseudos.visible=function(e){return!!(e.offsetwidth||e.offsetheight||e.getclientrects().length)},s.ajaxsettings.xhr=function(){try{return new c.xmlhttprequest}catch(e){}};var $t,y.ajax=$t=!!$t,s.ajaxtransport(function(i){var o,a;if(y.cors||$t&&!i.crossdomain)return{send:function(e,t){var n,r=i.xhr();if(r.open(i.type,i.url,i.async,i.username,i.password),i.xhrfields)for(n in i.xhrfields)r[n]=i.xhrfields[n];for(n in i.mimetype&&r.overridemimetype&&r.overridemimetype(i.mimetype),i.crossdomain||e[""x-requested-with""]||(e[""x-requested-with""]=""xmlhttprequest""),e)r.setrequestheader(n,e[n]);o=function(e){return function(){o&&(o=a=r.onload=r.onerror=r.onabort=r.ontimeout=r.onreadystatechange=null,""abort""===e?r.abort():""error""===e?""number""!=typeof r.responsetext?{binary:r.response}:{text:r.responsetext},r.getallresponseheaders()))}},r.onload=o(),a=r.onerror=r.ontimeout=o(""error""),void application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/\b(?:java|ecma)script\b/},converters:{""text script"":function(e){return s.globaleval(e),e}}}),s.ajaxprefilter(""script"",function(e){void r,i;if(n.crossdomain||n.scriptattrs)return{send:function(e,t){r=s(""<script>"").attr(n.scriptattrs||{}).prop({charset:n.scriptcharset,src:n.url}).on(""load _t,zt=[],ut=/(=)\?(?=&|$)|\?\?/;s.ajaxsetup({jsonp:""callback"",jsonpcallback:function(){var e=zt.pop()||s.expando+""_""+wt.guid++;return jsonp"",function(e,t,n){var json""]=function(){return o||s.error(r+"" was not e?[]:(""boolean""==typeof r,i,o},s.fn.load=function(e,t,n){var r,i,o,a=this,s=e.indexof("" s.grep(s.timers,function(e){return t===e.elem}).length},s.offset={setoffset:function(e,t,n){var t?t.using.call(e,f):c.css(f)}},s.fn.extend({offset:function(t){if(arguments.length)return void this.map(function(){var e=this.offsetparent;while(e&&""static""===s.css(e,""position""))e=e.offsetparent;return e||re})}}),s.each({scrollleft:""pagexoffset"",scrolltop:""pageyoffset""},function(t,i){var o=""pageyoffset""===i;s.fn[t]=function(e){return $(this,function(e,t,n){var r?r[i]:e[t];r?r.scrollto(o?r.pagexoffset:n,o?n:r.pageyoffset):e[t]=n},t,e,arguments.length)}}),s.each([""top"",""left""],function(e,n){s.csshooks[n]=fe(y.pixelposition,function(e,t){if(t)return t=we(e,n),pe.test(t)?s(e).position()[n]+""px"":t})}),s.each({height:""height"",width:""width""},function(a,s){s.each({padding:""inner""+a,content:s,"""":""outer""+a},function(r,o){s.fn[o]=function(e,t){var n=arguments.length&&(r||""boolean""!=typeof $(this,function(e,t,n){var r;return this.on(t,e)}}),s.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return this.mouseenter(e).mouseleave(t||e)}}),s.each(""blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu"".split("" ""),function(e,n){s.fn[n]=function(e,t){return n,r,i;if(""string""==typeof t&&(n=e[t],t=e,e=n),m(e))return t=s.type(e);return(""number""===t||""string""===t)&&!isnan(e-parsefloat(e))},s.trim=function(e){return null==e?"""":(e+"""").replace(xt,"""")},""function""==typeof define&&define.amd&&define(""jquery"",[],function(){return s});var vt=c.jquery,gt=c.$;return s.noconflict=function(e){return c.$===s&&(c.$=gt),e&&c.jquery===s&&(c.jquery=vt),s},""undefined""==typeof e&&(c.jquery=c.$=s),s}); </script> <meta name=""viewport"" content=""width=device-width, /> <style input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html solid ("" attr(href) "")""}abbr[title]:after{content:"" ("" attr(title) solid solid td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered solid #ddd!important}}@font-face{font-family:'glyphicons auto solid ease-in-out;-o-transition:all ease-in-out;transition:all solid solid old,old ul,ul old,ul dotted solid #eee}blockquote old:last-child,blockquote p:last-child,blockquote .small,blockquote footer,blockquote .small:before,blockquote footer:before,blockquote solid .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:''}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right solid solid solid solid #ddd}.table solid solid col[class*=col-]{position:static;display:table-column;float:none}table td[class*=col-],table screen and solid solid auto solid ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out .form-control{cursor:not-allowed}textarea.form-control{height:auto}input[type=search]{-webkit-appearance:none}@media screen and input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg label,.radio input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:not-allowed}.checkbox-inline.disabled,.radio-inline.disabled,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio-inline{cursor:not-allowed}.checkbox.disabled label,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .radio select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.form-inline .checkbox,.form-inline .checkbox label,.form-inline .radio .checkbox input[type=checkbox],.form-inline .radio .has-feedback .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .checkbox,.form-horizontal .has-feedback .form-group-lg .form-group-sm solid auto .btn-default,fieldset[disabled] .btn-default.active,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .btn-primary,fieldset[disabled] .btn-primary.active,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success.active,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info.active,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning.active,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger.active,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-link:focus,fieldset[disabled] linear;-o-transition:opacity linear;transition:opacity solid solid solid solid .caret,.navbar-fixed-bottom .dropdown .dropdown-menu,.navbar-fixed-bottom .dropdown .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn,.btn-toolbar .btn-group,.btn-toolbar .dropdown-toggle:active,.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn .btn-lg .dropdown-menu{left:auto}[data-toggle=buttons]>.btn input[type=checkbox],[data-toggle=buttons]>.btn input[type=radio],[data-toggle=buttons]>.btn-group>.btn input[type=checkbox],[data-toggle=buttons]>.btn-group>.btn .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group solid input[type=checkbox],.input-group-addon .open>a,.nav .open>a:focus,.nav solid solid #eee solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid solid transparent}@media solid transparent;-webkit-box-shadow:inset .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse,.navbar-fixed-top and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-brand,.navbar>.container-fluid solid .open .open .dropdown-menu .dropdown-header,.navbar-nav .open .open .open .dropdown-menu>li>a:focus,.navbar-nav .open .dropdown-menu>li>a:hover{background-image:none}}@media solid solid transparent;-webkit-box-shadow:inset .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.navbar-form .checkbox,.navbar-form .checkbox label,.navbar-form .radio .checkbox input[type=checkbox],.navbar-form .radio .has-feedback .navbar-brand:focus,.navbar-default .navbar-nav>li>a:focus,.navbar-default .navbar-nav>.active>a,.navbar-default .navbar-nav>.active>a:focus,.navbar-default .navbar-nav>.disabled>a,.navbar-default .navbar-nav>.disabled>a:focus,.navbar-default .navbar-nav>.disabled>a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .navbar-collapse,.navbar-default .navbar-nav>.open>a,.navbar-default .navbar-nav>.open>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.active>a,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#ccc;background-color:transparent}}.navbar-default .btn-link:focus,.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>li>a:focus,.navbar-inverse .navbar-nav>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>.active>a,.navbar-inverse .navbar-nav>.active>a:focus,.navbar-inverse .navbar-nav>.disabled>a,.navbar-inverse .navbar-nav>.disabled>a:focus,.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-nav>.open>a,.navbar-inverse .navbar-nav>.open>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-inverse .navbar-nav .open .navbar-link:hover{color:#fff}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse solid li{display:inline}.pager li>a,.pager solid li>a:focus,.pager li>a:hover{text-decoration:none;background-color:#eee}.pager .next>a,.pager .next>span{float:right}.pager .previous>a,.pager .previous>span{float:left}.pager .disabled>a,.pager .disabled>a:focus,.pager .disabled>a:hover,.pager .badge,.btn-xs .jumbotron,.container-fluid screen and .jumbotron,.container-fluid solid ease-in-out;-o-transition:border ease-in-out;transition:border ease-in-out}.thumbnail solid .close,.alert-dismissible ease;-o-transition:width ease;transition:width ease}.progress-bar-striped,.progress-striped .progress-bar{-webkit-animation:progress-bar-stripes linear infinite;-o-animation:progress-bar-stripes linear infinite;animation:progress-bar-stripes linear solid .list-group-item-heading,button.list-group-item .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-heading,.list-group-item.active .list-group-item-heading>.small,.list-group-item.active .list-group-item-heading>small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading>.small,.list-group-item.active:focus .list-group-item-heading>small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading>.small,.list-group-item.active:hover .list-group-item-heading>small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-heading,button.list-group-item-success .list-group-item-heading,button.list-group-item-info .list-group-item-heading,button.list-group-item-warning .list-group-item-heading,button.list-group-item-danger solid solid solid .list-group-item,.panel>.panel-collapse>.list-group .list-group-item:first-child,.panel>.panel-collapse>.list-group:first-child .list-group-item:last-child,.panel>.panel-collapse>.list-group:last-child caption,.panel>.table caption,.panel>.table-responsive>.table td:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child solid #ddd}.panel>.table>tbody:first-child>tr:first-child td,.panel>.table>tbody:first-child>tr:first-child .panel-heading+.panel-collapse>.list-group,.panel-group solid #ddd}.panel-group .panel-footer+.panel-collapse solid .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive solid .modal-dialog{-webkit-transition:-webkit-transform ease-out;-o-transition:-o-transform ease-out;transition:transform solid solid solid solid .btn-group solid solid solid ease-in-out ease-in-out ease-in-out all and ease-in-out;-o-transition:-o-transform ease-in-out;transition:transform top,right top,right .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control solid .btn{text-shadow:none}@media screen and .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control dd:after,.dl-horizontal dd:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before,.modal-footer:after,.modal-footer:before,.nav:after,.nav:before,.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.row:after,.row:before{display:table;content:"" ""}.btn-group-vertical>.btn-group:after,.btn-toolbar:after,.clearfix:after,.container-fluid:after,.container:after,.dl-horizontal dd:after,.form-horizontal and and and and and and and and and and print{.visible-print{display:block!important}table.visible-print{display:table!important}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}}@media print{.hidden-print{display:none!important}} </style> <script>/*! * bootstrap (http://getbootstrap.com) * copyright twitter, inc. * licensed under the mit license */ if(""undefined""==typeof jquery)throw new error(""bootstrap's javascript requires jquery"");+function(a){""use strict"";var b=a.fn.jquery.split("" new error(""bootstrap's javascript requires jquery version or higher"")}(jquery),+function(a){""use strict"";function b(){var a=document.createelement(""bootstrap""),b={webkittransition:""webkittransitionend"",moztransition:""transitionend"",otransition:""otransitionend otransitionend"",transition:""transitionend""};for(var c in b)if(void e=function(){c||a(d).trigger(a.support.transition.end)};return settimeout(e,b),this},a(function(){a.support.transition=b(),a.support.transition&&(a.event.special.bstransitionend={bindtype:a.support.transition.end,delegatetype:a.support.transition.end,handle:function(b){return a(b.target).is(this)?b.handleobj.handler.apply(this,arguments):void strict"";function b(b){return this.each(function(){var c=a(this),e=c.data(""bs.alert"");e||c.data(""bs.alert"",e=new d(this)),""string""==typeof b&&e[b].call(c)})}var c(){g.detach().trigger(""closed.bs.alert"").remove()}var e=a(this),f=e.attr(""data-target"");f||(f=e.attr(""href""),f=f&&f.replace(/.*(?=#[^\s]*$)/,""""));var g=a(f);b&&b.preventdefault(),g.length||(g=e.closest("".alert"")),g.trigger(b=a.event(""close.bs.alert"")),b.isdefaultprevented()||(g.removeclass(""in""),a.support.transition&&g.hasclass(""fade"")?g.one(""bstransitionend"",c).emulatetransitionend(d.transition_duration):c())};var e=a.fn.alert;a.fn.alert=b,a.fn.alert.constructor=d,a.fn.alert.noconflict=function(){return a.fn.alert=e,this},a(document).on(""click.bs.alert.data-api"",c,d.prototype.close)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.button""),f=""object""==typeof b&&b;e||d.data(""bs.button"",e=new c(this,f)),""toggle""==b?e.toggle():b&&e.setstate(b)})}var this.$element.attr(""aria-pressed"",!this.$element.hasclass(""active"")),this.$element.toggleclass(""active"")};var d=a.fn.button;a.fn.button=b,a.fn.button.constructor=c,a.fn.button.noconflict=function(){return a.fn.button=d,this},a(document).on(""click.bs.button.data-api"",'[data-toggle^=""button""]',function(c){var d=a(c.target);d.hasclass(""btn"")||(d=d.closest("".btn"")),b.call(d,""toggle""),a(c.target).is('input[type=""radio""]')||a(c.target).is('input[type=""checkbox""]')||c.preventdefault()}).on(""focus.bs.button.data-api blur.bs.button.data-api"",'[data-toggle^=""button""]',function(b){a(b.target).closest("".btn"").toggleclass(""focus"",/^focus(in)?$/.test(b.type))})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.carousel""),f=a.extend({},c.defaults,d.data(),""object""==typeof b&&b),g=""string""==typeof b?b:f.slide;e||d.data(""bs.carousel"",e=new c(this,f)),""number""==typeof b?e.to(b):g?e[g]():f.interval&&e.pause().cycle()})}var c=function(b,c){this.$element=a(b),this.$indicators=this.$element.find("".carousel-indicators""),this.options=c,this.paused=null,this.sliding=null,this.interval=null,this.$active=null,this.$items=null,this.options.keyboard&&this.$element.on(""keydown.bs.carousel"",a.proxy(this.keydown,this)),""hover""==this.options.pause&&!(""ontouchstart""in this.$items=a.parent().children("".item""),this.$items.index(a||this.$active)},c.prototype.getitemfordirection=function(a,b){var b;var this.$items.eq(f)},c.prototype.to=function(a){var b=this,c=this.getitemindex(this.$active=this.$element.find("".item.active""));return this.sliding?void this.sliding?void e=this.$element.find("".item.active""),f=d||this.getitemfordirection(b,e),g=this.interval,h=""next""==b?""left"":""right"",i=this;if(f.hasclass(""active""))return l=a(this.$indicators.children()[this.getitemindex(f)]);l&&l.addclass(""active"")}var m=a.event(""slid.bs.carousel"",{relatedtarget:j,direction:h});return "")).addclass(""active""),e.removeclass([""active"",h].join("" d=a.fn.carousel;a.fn.carousel=b,a.fn.carousel.constructor=c,a.fn.carousel.noconflict=function(){return a.fn.carousel=d,this};var e=function(c){var d,e=a(this),f=a(e.attr(""data-target"")||(d=e.attr(""href""))&&d.replace(/.*(?=#[^\s]+$)/,""""));if(f.hasclass(""carousel"")){var c=a(this);b.call(c,c.data())})})}(jquery),+function(a){""use strict"";function b(b){var c,d=b.attr(""data-target"")||(c=b.attr(""href""))&&c.replace(/.*(?=#[^\s]+$)/,"""");return a(d)}function c(b){return this.each(function(){var c=a(this),e=c.data(""bs.collapse""),f=a.extend({},d.defaults,c.data(),""object""==typeof d(this,f)),""string""==typeof b&&e[b]()})}var a=this.$element.hasclass(""width"");return a?""width"":""height""},d.prototype.show=function(){if(!this.transitioning&&!this.$element.hasclass(""in"")){var b,e=this.$parent&&this.$parent.children("".panel"").children("".in, .collapsing"");if(!(e&&e.length&&(b=e.data(""bs.collapse""),b&&b.transitioning))){var f=a.event(""show.bs.collapse"");if(this.$element.trigger(f),!f.isdefaultprevented()){e&&e.length&&(c.call(e,""hide""),b||e.data(""bs.collapse"",null));var h=function(){this.$element.removeclass(""collapsing"").addclass(""collapse h.call(this);var i=a.camelcase([""scroll"",g].join(""-""));this.$element.one(""bstransitionend"",a.proxy(h,this)).emulatetransitionend(d.transition_duration)g}}}},d.prototype.hide=function(){if(!this.transitioning&&this.$element.hasclass(""in"")){var b=a.event(""hide.bs.collapse"");if(this.$element.trigger(b),!b.isdefaultprevented()){var a.support.transition?void this.$elementc.one(""bstransitionend"",a.proxy(e,this)).emulatetransitionend(d.transition_duration):e.call(this)}}},d.prototype.toggle=function(){this[this.$element.hasclass(""in"")?""hide"":""show""]()},d.prototype.getparent=function(){return a(this.options.parent).find('[data-toggle=""collapse""][data-parent=""'+this.options.parent+'""]').each(a.proxy(function(c,d){var e=a(d);this.addariaandcollapsedclass(b(e),e)},this)).end()},d.prototype.addariaandcollapsedclass=function(a,b){var c=a.hasclass(""in"");a.attr(""aria-expanded"",c),b.toggleclass(""collapsed"",!c).attr(""aria-expanded"",c)};var e=a.fn.collapse;a.fn.collapse=c,a.fn.collapse.constructor=d,a.fn.collapse.noconflict=function(){return a.fn.collapse=e,this},a(document).on(""click.bs.collapse.data-api"",'[data-toggle=""collapse""]',function(d){var e=a(this);e.attr(""data-target"")||d.preventdefault();var f=b(e),g=f.data(""bs.collapse""),h=g?""toggle"":e.data();c.call(f,h)})}(jquery),+function(a){""use strict"";function b(b){var c=b.attr(""data-target"");c||(c=b.attr(""href""),c=c&&/#[a-za-z]/.test(c)&&c.replace(/.*(?=#[^\s]*$)/,""""));var d=c&&a(c);return d&&d.length?d:b.parent()}function d(b){return this.each(function(){var c=a(this),d=c.data(""bs.dropdown"");d||c.data(""bs.dropdown"",d=new g(this)),""string""==typeof b&&d[b].call(c)})}var e=a(this);if(!e.is("".disabled, :disabled"")){var f=b(e),g=f.hasclass(""open"");if(c(),!g){""ontouchstart""in document.documentelement&&!f.closest("".navbar-nav"").length&&a(document.createelement(""div"")).addclass(""dropdown-backdrop"").insertafter(a(this)).on(""click"",c);var d=a(this);if(c.preventdefault(),c.stoppropagation(),!d.is("".disabled, :disabled"")){var h="" li:not(.disabled):visible a"",i=e.find("".dropdown-menu""+h);if(i.length){var h=a.fn.dropdown;a.fn.dropdown=d,a.fn.dropdown.constructor=g,a.fn.dropdown.noconflict=function(){return a.fn.dropdown=h,this},a(document).on(""click.bs.dropdown.data-api"",c).on(""click.bs.dropdown.data-api"","".dropdown form"",function(a){a.stoppropagation()}).on(""click.bs.dropdown.data-api"",f,g.prototype.toggle).on(""keydown.bs.dropdown.data-api"",f,g.prototype.keydown).on(""keydown.bs.dropdown.data-api"","".dropdown-menu"",g.prototype.keydown)}(jquery),+function(a){""use strict"";function b(b,d){return this.each(function(){var e=a(this),f=e.data(""bs.modal""),g=a.extend({},c.defaults,e.data(),""object""==typeof b&&b);f||e.data(""bs.modal"",f=new c(this,g)),""string""==typeof b?fb:g.show&&f.show(d)})}var this.isshown?this.hide():this.show(a)},c.prototype.show=function(b){var a=this;this.$element.hide(),this.backdrop(function(){a.$body.removeclass(""modal-open""),a.resetadjustments(),a.resetscrollbar(),a.$element.trigger(""hidden.bs.modal"")})},c.prototype.removebackdrop=function(){this.$backdrop&&this.$backdrop.remove(),this.$backdrop=null},c.prototype.backdrop=function(b){var d=this,e=this.$element.hasclass(""fade"")?""fade"":"""";if(this.isshown&&this.options.backdrop){var f=a.support.transition&&e;if(this.$backdrop=a(document.createelement(""div"")).addclass(""modal-backdrop ""+e).appendto(this.$body),this.$element.on(""click.dismiss.bs.modal"",a.proxy(function(a){return if(!this.isshown&&this.$backdrop){this.$backdrop.removeclass(""in"");var g=function(){d.removebackdrop(),b&&b()};a.support.transition&&this.$element.hasclass(""fade"")?this.$backdrop.one(""bstransitionend"",g).emulatetransitionend(c.backdrop_transition_duration):g()}else b&&b()},c.prototype.handleupdate=function(){this.adjustdialog()},c.prototype.adjustdialog=function(){var a=window.innerwidth;if(!a){var b=document.documentelement.getboundingclientrect();a=b.right-math.abs(b.left)}this.bodyisoverflowing=document.body.clientwidth<a,this.scrollbarwidth=this.measurescrollbar()},c.prototype.setscrollbar=function(){var a=document.createelement(""div"");a.classname=""modal-scrollbar-measure"",this.$body.append(a);var b=a.offsetwidth-a.clientwidth;return d=a.fn.modal;a.fn.modal=b,a.fn.modal.constructor=c,a.fn.modal.noconflict=function(){return a.fn.modal=d,this},a(document).on(""click.bs.modal.data-api"",'[data-toggle=""modal""]',function(c){var d=a(this),e=d.attr(""href""),f=a(d.attr(""data-target"")||e&&e.replace(/.*(?=#[^\s]+$)/,"""")),g=f.data(""bs.modal"")?""toggle"":a.extend({remote:!/#/.test(e)&&e},f.data(),d.data());d.is(""a"")&&c.preventdefault(),f.one(""show.bs.modal"",function(a){a.isdefaultprevented()||f.one(""hidden.bs.modal"",function(){d.is("":visible"")&&d.trigger(""focus"")})}),b.call(f,g,this)})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tooltip""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.tooltip"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var class=""tooltip"" role=""tooltip""><div class=""tooltip-arrow""></div><div class=""tooltip-inner""></div></div>',trigger:""hover document.constructor&&!this.options.selector)throw new error(""`selector` option must be specified when initializing ""+this.type+"" on the window.document object!"");for(var e=this.options.trigger.split("" ""),f=e.length;f--;){var g=e[f];if(""click""==g)this.$element.on(""click.""+this.type,this.options.selector,a.proxy(this.toggle,this));else if(""manual""!=g){var h=""hover""==g?""mouseenter"":""focusin"",i=""hover""==g?""mouseleave"":""focusout"";this.$element.on(h+"".""+this.type,this.options.selector,a.proxy(this.enter,this)),this.$element.on(i+"".""+this.type,this.options.selector,a.proxy(this.leave,this))}}this.options.selector?this._options=a.extend({},this.options,{trigger:""manual"",selector:""""}):this.fixtitle()},c.prototype.getdefaults=function(){return c.defaults},c.prototype.getoptions=function(b){return b=a.extend({},this.getdefaults(),this.$element.data(),b),b.delay&&""number""==typeof b.delay&&(b.delay={show:b.delay,hide:b.delay}),b},c.prototype.getdelegateoptions=function(){var b={},c=this.getdefaults();return this._options&&a.each(this._options,function(a,d){c[a]!=d&&(b[a]=d)}),b},c.prototype.enter=function(b){var c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof a in c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof b=a.event(""show.bs.""+this.type);if(this.hascontent()&&this.enabled){this.$element.trigger(b);var e=this,f=this.tip(),g=this.getuid(this.type);this.setcontent(),f.attr(""id"",g),this.$element.attr(""aria-describedby"",g),this.options.animation&&f.addclass(""fade"");var h=""function""==typeof n=h,o=this.getposition(this.$viewport);h=""bottom""==h&&k.bottom+m>o.bottom?""top"":""top""==h&&k.top-m<o.top?""bottom"":""right""==h&&k.right+l>o.width?""left"":""left""==h&&k.left-l<o.left?""right"":h,f.removeclass(n).addclass(h)}var p=this.getcalculatedoffset(h,k,l,m);this.applyplacement(p,h);var q=function(){var a=e.hoverstate;e.$element.trigger(""shown.bs.""+e.type),e.hoverstate=null,""out""==a&&e.leave(e)};a.support.transition&&this.$tip.hasclass(""fade"")?f.one(""bstransitionend"",q).emulatetransitionend(c.transition_duration):q()}},c.prototype.applyplacement=function(b,c){var k=this.getviewportadjusteddelta(c,b,i,j);k.left?b.left+=k.left:b.top+=k.top;var a=this.tip(),b=this.gettitle();a.find("".tooltip-inner"")this.options.html?""html"":""text"",a.removeclass(""fade in top bottom left right"")},c.prototype.hide=function(b){function d(){""in""!=e.hoverstate&&f.detach(),e.$element.removeattr(""aria-describedby"").trigger(""hidden.bs.""+e.type),b&&b()}var e=this,f=a(this.$tip),g=a.event(""hide.bs.""+this.type);return this.$element.trigger(g),g.isdefaultprevented()?void a=this.$element;(a.attr(""title"")||""string""!=typeof a.attr(""data-original-title""))&&a.attr(""data-original-title"",a.attr(""title"")||"""").attr(""title"","""")},c.prototype.hascontent=function(){return this.gettitle()},c.prototype.getposition=function(b){b=b||this.$element;var e;var h=b.top-f-g.scroll,i=b.top+f-g.scroll+d;h<g.top?e.top=g.top-h:i>g.top+g.height&&(e.top=g.top+g.height-i)}else{var j=b.left-f,k=b.left+f+c;j<g.left?e.left=g.left-j:k>g.right&&(e.left=g.left+g.width-k)}return e},c.prototype.gettitle=function(){var a,b=this.$element,c=this.options;return a=b.attr(""data-original-title"")||(""function""==typeof new error(this.type+"" `template` option must consist of exactly top-level element!"");return this.$tip},c.prototype.arrow=function(){return c=this;b&&(c=a(b.currenttarget).data(""bs.""+this.type),c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c))),b?(c.instate.click=!c.instate.click,c.isinstatetrue()?c.enter(c):c.leave(c)):c.tip().hasclass(""in"")?c.leave(c):c.enter(c)},c.prototype.destroy=function(){var a=this;cleartimeout(this.timeout),this.hide(function(){a.$element.off("".""+a.type).removedata(""bs.""+a.type),a.$tip&&a.$tip.detach(),a.$tip=null,a.$arrow=null,a.$viewport=null})};var d=a.fn.tooltip;a.fn.tooltip=b,a.fn.tooltip.constructor=c,a.fn.tooltip.noconflict=function(){return a.fn.tooltip=d,this}}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.popover""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.popover"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var c=function(a,b){this.init(""popover"",a,b)};if(!a.fn.tooltip)throw new error(""popover requires class=""popover"" role=""tooltip""><div class=""popover-content""></div></div>'}),c.prototype=a.extend({},a.fn.tooltip.constructor.prototype),c.prototype.constructor=c,c.prototype.getdefaults=function(){return c.defaults},c.prototype.setcontent=function(){var a=this.tip(),b=this.gettitle(),c=this.getcontent();a.find("".popover-title"")this.options.html?""html"":""text"",a.find("".popover-content"").children().detach().end()this.options.html?""string""==typeof c?""html"":""append"":""text"",a.removeclass(""fade top bottom left right in""),a.find("".popover-title"").html()||a.find("".popover-title"").hide()},c.prototype.hascontent=function(){return this.gettitle()||this.getcontent()},c.prototype.getcontent=function(){var a=this.$element,b=this.options;return a.attr(""data-content"")||(""function""==typeof this.$arrow=this.$arrow||this.tip().find("".arrow"")};var d=a.fn.popover;a.fn.popover=b,a.fn.popover.constructor=c,a.fn.popover.noconflict=function(){return a.fn.popover=d,this}}(jquery),+function(a){""use strict"";function b(c,d){this.$body=a(document.body),this.$scrollelement=a(a(c).is(document.body)?window:c),this.options=a.extend({},b.defaults,d),this.selector=(this.options.target||"""")+"" .nav li > c(c){return this.each(function(){var d=a(this),e=d.data(""bs.scrollspy""),f=""object""==typeof c&&c;e||d.data(""bs.scrollspy"",e=new b(this,f)),""string""==typeof b=a(this),e=b.data(""target"")||b.attr(""href""),f=/^#./.test(e)&&a(e);return f&&f.length&&f.is("":visible"")&&[[f[c]().top+d,e]]||null}).sort(function(a,b){return a,b=this.$scrollelement.scrolltop()+this.options.offset,c=this.getscrollheight(),d=this.options.offset+c-this.$scrollelement.height(),e=this.offsets,f=this.targets,g=this.activetarget;if(this.scrollheight!=c&&this.refresh(),b>=d)return this.activetarget=null,this.clear();for(a=e.length;a--;)g!=f[a]&&b>=e[a]&&(void c=this.selector+'[data-target=""'+b+'""],'+this.selector+'[href=""'+b+'""]',d=a(c).parents(""li"").addclass(""active"");d.parent("".dropdown-menu"").length&&(d=d.closest(""li.dropdown"").addclass(""active"")), d.trigger(""activate.bs.scrollspy"")},b.prototype.clear=function(){a(this.selector).parentsuntil(this.options.target,"".active"").removeclass(""active"")};var d=a.fn.scrollspy;a.fn.scrollspy=c,a.fn.scrollspy.constructor=b,a.fn.scrollspy.noconflict=function(){return a.fn.scrollspy=d,this},a(window).on(""load.bs.scrollspy.data-api"",function(){a('[data-spy=""scroll""]').each(function(){var b=a(this);c.call(b,b.data())})})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tab"");e||d.data(""bs.tab"",e=new c(this)),""string""==typeof b&&e[b]()})}var b=this.element,c=b.closest(""ul:not(.dropdown-menu)""),d=b.data(""target"");if(d||(d=b.attr(""href""),d=d&&d.replace(/.*(?=#[^\s]*$)/,"""")),!b.parent(""li"").hasclass(""active"")){var e=c.find("".active:last f(){g.removeclass(""active"").find(""> .dropdown-menu > g=d.find(""> .active""),h=e&&a.support.transition&&(g.length&&g.hasclass(""fade"")||!!d.find(""> .fade"").length);g.length&&h?g.one(""bstransitionend"",f).emulatetransitionend(c.transition_duration):f(),g.removeclass(""in"")};var d=a.fn.tab;a.fn.tab=b,a.fn.tab.constructor=c,a.fn.tab.noconflict=function(){return a.fn.tab=d,this};var e=function(c){c.preventdefault(),b.call(a(this),""show"")};a(document).on(""click.bs.tab.data-api"",'[data-toggle=""tab""]',e).on(""click.bs.tab.data-api"",'[data-toggle=""pill""]',e)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.affix""),f=""object""==typeof b&&b;e||d.data(""bs.affix"",e=new c(this,f)),""string""==typeof b&&e[b]()})}var affix-top e=this.$target.scrolltop(),f=this.$element.offset(),g=this.$target.height();if(null!=c&&""top""==this.affixed)return h=null==this.affixed,i=h?e:f.top,j=h?g:b;return this.pinnedoffset;this.$element.removeclass(c.reset).addclass(""affix"");var a=this.$target.scrolltop(),b=this.$element.offset();return b=this.$element.height(),d=this.options.offset,e=d.top,f=d.bottom,g=math.max(a(document).height(),a(document.body).height());""object""!=typeof d&&(f=e=d),""function""==typeof e&&(e=d.top(this.$element)),""function""==typeof f&&(f=d.bottom(this.$element));var h=this.getstate(g,b,e,f);if(this.affixed!=h){null!=this.unpin&&this.$element.css(""top"","""");var i=""affix""+(h?""-""+h:""""),j=a.event(i+"".bs.affix"");if(this.$element.trigger(j),j.isdefaultprevented())return;this.affixed=h,this.unpin=""bottom""==h?this.getpinnedoffset():null,this.$element.removeclass(c.reset).addclass(i).trigger(i.replace(""affix"",""affixed"")+"".bs.affix"")}""bottom""==h&&this.$element.offset({top:g-b-f})}};var d=a.fn.affix;a.fn.affix=b,a.fn.affix.constructor=c,a.fn.affix.noconflict=function(){return a.fn.affix=d,this},a(window).on(""load"",function(){a('[data-spy=""affix""]').each(function(){var c=a(this),d=c.data();d.offset=d.offset||{},null!=d.offsetbottom&&(d.offset.bottom=d.offsetbottom),null!=d.offsettop&&(d.offset.top=d.offsettop),b.call(c,d)})})}(jquery);</script> <script>/** * @preserve shiv | @afarkas @jdalton @jon_neal @rem | licensed */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a,b){function c(a,b){var c.innerhtml=""x<style>""+b+""</style>"",d.insertbefore(c.lastchild,d.firstchild)}function d(){var a=t.elements;return""string""==typeof a?a.split("" ""):a}function e(a,b){var c=t.elements;""string""!=typeof c&&(c=c.join("" "")),""string""!=typeof a&&(a=a.join("" "")),t.elements=c+"" ""+a,j(b)}function f(a){var b=s[a[q]];return b||(b={},r++,a[q]=r,s[r]=b),b}function g(a,c,d){if(c||(c=b),l)return c.createelement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].clonenode():p.test(a)?(d.cache[a]=d.createelem(a)).clonenode():d.createelem(a),!e.canhavechildren||o.test(a)||e.tagurn?e:d.frag.appendchild(e)}function h(a,c){if(a||(a=b),l)return a.createdocumentfragment();c=c||f(a);for(var e}function i(a,b){b.cache||(b.cache={},b.createelem=a.createelement,b.createfrag=a.createdocumentfragment,b.frag=b.createfrag()),a.createelement=function(c){return t.shivmethods?g(c,a,b):b.createelem(c)},a.createdocumentfragment=function(""h,f"",""return function(){var n=f.clonenode(),c=n.createelement;h.shivmethods&&(""+d().join().replace(/[\w\-:]+/g,function(a){return b.createelem(a),b.frag.createelement(a),'c(""'+a+'"")'})+"");return n}"")(t,b.frag)}function j(a){a||(a=b);var a=b.createelement(""a"");a.innerhtml=""<xyz></xyz>"",k=""hidden""in a=b.createdocumentfragment();return""undefined""==typeof a.clonenode||""undefined""==typeof a.createdocumentfragment||""undefined""==typeof t={elements:n.elements||""abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time }; </script> <script>/*! respond.js min/max-width media query polyfill * copyright scott jehl * licensed under https://github.com/scottjehl/respond/blob/master/license-mit * */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a){""use strict"";a.matchmedia=a.matchmedia||function(a){var b,c=a.documentelement,d=c.firstelementchild||c.firstchild,e=a.createelement(""body""),f=a.createelement(""div"");return f.innerhtml='&shy;<style media=""'+a+'""> { width: strict"";function c={};a.respond=c,c.update=function(){};var d=[],e=function(){var a.xmlhttprequest}catch(c){b=new a.activexobject(""microsoft.xmlhttp"")}return function(){return b}}(),f=function(a,b){var all"")&&a.matchmedia(""only all"").matches,!c.mediaqueriessupported){var date).gettime();if(b&&g&&p>r-g)return a.cleartimeout(h),h=a.settimeout(you,p),void v in l)if(l.hasownproperty(v)){var c in d in f)if(f.hasownproperty(d)){var e=j.createelement(""style""),f=f[d].join(""\n"");e.type=""text/css"",e.media=d,q.insertbefore(e,o.nextsibling),e.stylesheet?e.stylesheet.csstext=f:e.appendchild(j.createtextnode(f)),n.push(e)}},v=function(a,b,d){var g=function(a){return }; </script> {font-size: {font-size: {font-size: {font-size: {font-size: {font-size: {font-size: code {color: inherit; background-color: pre:not([class]) { background-color: white }</style> <script> /** * jquery plugin: sticky tabs * * @author aidan lister <aidan@php.net> * adapted by ruben arslan to activate parent tabs too * */ (function($) { ""use strict""; $.fn.rmarkdownstickytabs = function() { var context = this; // show the tab corresponding with the hash in the url, or the first tab var showstufffromhash = function() { var hash = window.location.hash; var selector = hash ? 'a[href=""' + hash + '""]' : 'li.active > a'; var $selector = $(selector, context); if($selector.data('toggle') === ""tab"") { $selector.tab('show'); // walk up the ancestors of this element, show any hidden tabs $selector.parents('.section.tabset').each(function(i, elm) { var link = $('a[href=""#' + $(elm).attr('id') + '""]'); if(link.data('toggle') === ""tab"") { link.tab(""show""); } }); } }; // set the correct tab when the page loads showstufffromhash(context); // set the correct tab when a user uses their back/forward button $(window).on('hashchange', function() { showstufffromhash(context); }); // change the url when tabs are clicked $('a', context).on('click', function(e) { history.pushstate(null, null, this.href); showstufffromhash(context); }); return this; }; }(jquery)); window.buildtabsets = function(tocid) { // build a tabset from a section div with the .tabset class function buildtabset(tabset) { // check for fade and pills options var fade = tabset.hasclass(""tabset-fade""); var pills = tabset.hasclass(""tabset-pills""); var navclass = pills ? ""nav-pills"" : ""nav-tabs""; // determine the heading level of the tabset and tabs var match = tabset.attr('class').match(/level(\d) /); if (match === null) return; var tabsetlevel = var tablevel = tabsetlevel + // find all subheadings immediately below var tabs = tabset.find(""div.section.level"" + tablevel); if (!tabs.length) return; // create tablist and tab-content elements var tablist = $('<ul class=""nav ' + navclass + '"" role=""tablist""></ul>'); var tabcontent = $('<div class=""tab-content""></div>'); // build the tabset var activetab = tabs.each(function(i) { // get the tab div var tab = $(tabs[i]); // get the id then sanitize it for use with bootstrap tabs var id = tab.attr('id'); // see if this is marked as the active tab if (tab.hasclass('active')) activetab = i; // remove any table of contents entries associated with // this id (since we will be removing the heading element) $(""div#"" + tocid + "" li a[href='#"" + id + ""']"").parent().remove(); // sanitize the id for use with bootstrap tabs id = id.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_'); tab.attr('id', id); // get the heading element within it, grab it is text, then remove it var heading = tab.find('h' + tablevel + ':first'); var headingtext = heading.html(); heading.remove(); // build and append the tab list item var a = $('<a role=""tab"" data-toggle=""tab"">' + headingtext + '</a>'); a.attr('href', '#' + id); a.attr('aria-controls', id); var li = $('<li role=""presentation""></li>'); li.append(a); tablist.append(li); // set it is attributes tab.attr('role', 'tabpanel'); tab.addclass('tab-pane'); tab.addclass('tabbed-pane'); if (fade) tab.addclass('fade'); // move it into the tab content div tab.detach().appendto(tabcontent); }); // set active tab $(tablist.children('li')[activetab]).addclass('active'); var active = $(tabcontent.children('div.section')[activetab]); active.addclass('active'); if (fade) active.addclass('in'); if (tabset.hasclass(""tabset-sticky"")) tabset.rmarkdownstickytabs(); } // convert section divs with the .tabset class to tabsets var tabsets = $(""div.section.tabset""); tabsets.each(function(i) { buildtabset($(tabsets[i])); }); }; </script> <style type=""text/css"">.hljs-literal { color: } .hljs-number { color: } .hljs-comment { color: font-style: italic; } .hljs-keyword { color: font-weight: bold; } .hljs-string { color: } </style> <script <style type=""text/css""> code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: div.hanging-indent{margin-left: text-indent: ul.task-list{list-style: none;} </style> <style type=""text/css"">code{white-space: pre;}</style> <script type=""text/javascript""> if (window.hljs) { hljs.configure({languages: []}); hljs.inithighlightingonload(); if (document.readystate && document.readystate === ""complete"") { window.settimeout(function() { hljs.inithighlighting(); }, } } </script> <style type=""text/css""> .main-container { max-width: margin-left: auto; margin-right: auto; } img { } .tabbed-pane { padding-top: } .html-widget { margin-bottom: } button.code-folding-btn:focus { outline: none; } summary { display: list-item; } details > summary > p:only-child { display: inline; } pre code { padding: } </style> <!-- tabsets --> <style type=""text/css""> .tabset-dropdown > .nav-tabs { display: inline-table; max-height: min-height: overflow-y: auto; border: solid #ddd; border-radius: } .tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before { content: font-family: 'glyphicons halflings'; display: inline-block; padding: border-right: solid #ddd; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before { content: font-family: 'glyphicons halflings'; border: none; } .tabset-dropdown > .nav-tabs > li.active { display: block; } .tabset-dropdown > .nav-tabs > li > a, .tabset-dropdown > .nav-tabs > li > a:focus, .tabset-dropdown > .nav-tabs > li > a:hover { border: none; display: inline-block; border-radius: background-color: transparent; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li { display: block; float: none; } .tabset-dropdown > .nav-tabs > li { display: none; } </style> <!-- code folding --> </head> <body> <div class=""container-fluid main-container""> <div id=""header""> </div> <div id=""intraindividual-dynamic-network-of-affects"" class=""section dynamic network of <p>this repository hosts r code for a shiny application developed as part of <a href=""http://www.dynamore-project.eu"">dynamore</a> projct. it provides tools to fit an <strong>exogenous linear autoregressive mixed effects model</strong>, larmex, to ecological momentary assessments (ema).</p> <div id=""how-to-use-the-app"" class=""section to use the <div id=""install-as-an-r-package"" class=""section as an r <ul> <li>install <strong>r</strong> from <a href=""https://www.r-project.org/"">r-project</a> <ul> <li>optional: install <strong>rstudio</strong> from <a href=""https://posit.co/download/rstudio-desktop/"">rstudio-desktop</a></li> </ul></li> <li>to install packages from github one needs the r package remotes <ul> <li><strong><code>install.packages(&quot;remotes&quot;)</code></strong></li> </ul></li> <li>install <strong><code>larmexshiny</code></strong> <ul> <li><strong><code>remotes::install_github(repo = &quot;spooseh/larmexshiny&quot;, ref = &quot;master&quot;, dependencies = true)</code></strong></li> </ul></li> <li>load the package, <strong><code>library(larmexshiny)</code></strong></li> <li>run in command line <strong><code>runlarmex()</code></strong></li> </ul> </div> <div id=""download-source-code-and-run-locally"" class=""section source code and run <ul> <li>install <strong>rstudio</strong> from <a href=""https://posit.co/download/rstudio-desktop/"">rstudio-desktop</a> <ul> <li>see <code>sessioninfo.txt</code> for version information</li> </ul></li> <li>clone or download the repository <ul> <li><strong><code>git clone -b clone_and_run --single-branch https://github.com/spooseh/larmexshiny.git</code></strong></li> </ul></li> <li>navigate to the local directory, <strong><code>larmexshiny</code></strong>, in rstudio</li> <li>optional: for a smooth work flow, make this folder, by <code>setwd()</code>, the working directory</li> <li>open <strong><code>packinstaller.r</code></strong> and press <strong><code>source</code></strong> in rstudio <ul> <li>it runs the command <code>source(&quot;packinstaller.r&quot;)</code></li> <li>one could install the missing packages manually</li> <li>see <code>sessioninfo.txt</code> for version information</li> </ul></li> <li>open the <strong><code>runlarmex.r</code></strong> file and click the <strong><code>run app</code></strong> at the top of your editors menu</li> </ul> </div> </div> <div id=""what-you-see"" class=""section you <pre><code>- an rstudio window opens and shows the user interface - you can click **`open in browser`** or enter the address next to it, on a browser of your choice may be different in your case)</code></pre> <p><img am going alt=""runapp.png"" /></p> <p><br></p> <div id=""instructions"" class=""section <ul> <li>detailed instructions in <a href=""https://github.com/spooseh/larmexshiny/www/instructions.md"">larmexshiny/www/instructions.md</a></li> </ul> </div> <div id=""not-interested-in-a-gui"" class=""section interested in a <ul> <li>follow the r commands in <a href=""larmexshiny/data/demo.r"">larmexshiny/www/demo.rmd</a></li> </ul> </div> <div id=""to-do"" class=""section do <ul> <li>exception handling</li> <li>more documentation</li> </ul> <hr> <p><a rel=""license"" <img alt=""creative commons lizenzvertrag"" style=""right"" /></img></a></p> </div> </div> </div> </div> <script> // add bootstrap table styles to pandoc tables function bootstrapstylepandoctables() { $('tr.odd').parent('tbody').parent('table').addclass('table table-condensed'); } $(document).ready(function () { bootstrapstylepandoctables(); }); </script> <!-- tabsets --> <script> $(document).ready(function () { window.buildtabsets(""toc""); }); $(document).ready(function () { $('.tabset-dropdown > .nav-tabs > li').click(function () { $(this).parent().toggleclass('nav-tabs-open'); }); }); </script> <!-- code folding --> <!-- dynamically load mathjax for compatibility with self-contained --> <script> (function () { var script = document.createelement(""script""); script.type = ""text/javascript""; script.src = ""https://mathjax.rstudio.com/latest/mathjax.js?config=tex-ams-mml_htmlormml""; })(); </script> </body> </html>"
1,ema_assistant,a redcap them to assist in running surveys that are part of an ecological momentary assessment study,"# ecological momentary assessment assistant a redcap external module designed to create and manage surveys using the ecological momentary assessment (ema) method. in an example project, a participant might receive assessments per day for days. the timing of each assessment can be randomized within blocks throughout the day to try and get random but well distributed measurements. the duration of each measurement can be defined. a variety of configuration options specify the number and timing of participant notifications for assessment via sms. the them configuration file can be used to create these files or there is a web-based configuration builder that can be used. ## how it works: each participant may have multiple experiments for data collection (called windows) in a study. for example: baseline, month, and month. for each data collection window can be a multi-day configuration with multiple surveys per day. the scheduling of each window is 'triggered' by a logical expression and must have a baseline date field. looking at the two configuration objects helps understand how the module works: configuration of an ema event uses two objects: a `window` which controls if and on what days and a `schedule` which controls the timing of events in a given day. an ema window has the following parameters: - `window-name` e.g. baseline, month etc... - `window-trigger-logic` when true, all instances of scheduled assessments in the window will be created - `window-start-field` the field that holds the date the window begins yyyy-mm-dd, this is day not day - `window-start-event` event where the start field resides - `window-opt-out-field` if equal to scheduled alerts will be cancelled and not sent - calc field recommended - `window-opt-out-event` event where the opt out field resides - `window-days` e.g. number of days for window to run - this is an array of day offsets, e.g. to permit skipping days in more complex scenarios - `window-form` repeating form or form in repeating event where the ema details and survey are stored - it must use the fields from the template form - `window-form-event` event where the form resides - `window-schedule-name` name of the schedule configuration that corresponds to this window (see below) - `schedule-offset-default` default value of number of minutes past midnight this schedule starts (e.g. for - `schedule-offset-override-field` -- name of field that contains a custom start time for the window's schedule, e.g. [wake_time] - `schedule-offset-override-event` -- event where the offset override field resides - `text-message` -- wording of message to be sent to participant - -- wording of message to be sent as reminder (optional) - -- wording of message to be sent as reminder (optional) - `cell-phone-field` - field in project which holds the cell phone number - `cell-phone-event` - event where the cell phone field resides an ema schedule configuration controls the specific events within a given day of an active window. it is referenced from the window by the `window-schedule-name` parameter. there may be more than one window configuration that links to the same schedule. each schedule has the following parameters: - `schedule-name` -- used to link schedule with window - `schedule-offsets` - comma separated list of minutes past midnight when texts are sent - `schedule-randomize-window` - if entered, a random number of minutes between and this value will be added to the offset time when the schedule is generated - `schedule-reminders` - comma separated list of the number of minutes after each text is sent that a reminder will be sent. only reminders are currently possible. - `schedule-close-offset` - number of minutes after the scheduled send time to close the window. responses cannot be started after this time has passed for a given assessment. ### scenario example: customizing the first ema of the day most times in the module are in minutes from midnight. so = hours x minutes = so, if you set the `schedule-offset-default` to have the first assessment default to for participants by setting the value to and having the `schedule-offsets` array begin with a however, if we have one participant that wakes at and should begin their first ema two hours later at we can override the default value by specifying a value in the redcap field specified for `schedule-offset-override-field` and `schedule-offset-override-event`. the value here would be on each save for a record, we check if any windows need to be created. this is done by verifying the required fields are present for the window, such as start time, a text number to send to, and that the `window-trigger-logic` evaluates to true. if all is valid, then the schedule will be created for this window configuration in the current record. currently, window creation on bulk import is not supported - a save is required. the sending time for each ema survey instance will be determined when the window and schedule are generated and saved into unique instances of instruments/events for the window. as an example, if the window has days and there are surveys to be sent per day, then instances of the repeating survey form will be created. in the repeating form or event that contains the survey, the following data fields must be present for each instance: - `ema_window_name` - name of window configuration - `ema_window_day` - this is day number of the window configuration from the `window-days` definition. if there are days of surveys, this value will be the offset day from the start - `ema_sequence` - this is the survey number for the day that it is being sent and refers to the `schedule-offsets` parameter in the window schedule. if there are surveys sent per day, this number will be respectively. - `ema_offset` - this is the number of minutes from the first survey of the day that this survey will be scheduled. this field is not used for any logic but is copied in case needed for data analysis. - `ema_open` - this is the number of minutes past midnight that the survey is scheduled (i.e. if sequence starts at and the sequence-offset = and random = then this would have a value of + + = minutes) - `ema_open_ts` - this is a human readable timestamp value of when the survey is schedule in format ""yyyy-mm-dd h:i:s"" - `ema_status` - dropdown of status values: <ul> schedule calculated</li> notification sent</li> reminder sent</li> reminder sent</li> notification missed</li> window closed</li> survey access after closed</li> error sending text</li> </ul> - ema_actions // not currently set but may be used in the future (s/sent, aoac, x/cancelled, c/closed missed?) so, for the activated window, we just created entries for every day and every offset in the schedule (e.g. instances) the instance number is somewhat arbitrary. if all assessments are in the same repeating form, then they could share one redcap event. alternately, you could have repeating forms for multiple events. ## setup to use this external module, the external module config must be setup. in the configuration file, there is a checkbox option which determines where the configuration data is stored and how to load it. when the 'use config file' checkbox is selected, the window and schedule configurations will be retrieved from the external module configuration file. when unchecked, the configurations are loaded by the ema config page using the link on the left-hand sidebar in your project in the external module section. an example configuration loaded into the ema config webpage is displayed below. ### example of configurations saved into the ema config webpage ``` { ""windows"": [ { ""window-name"": ""baseline"", ""window-trigger-logic"": = ""window-days"": ""window-schedule-name"": ""window-form"":""ema_tracker"", ""window-opt-out-field"":""exclude_if"", ""schedule-offset-default"": ""schedule-offset-override-field"":""custom_start_date"", ""text-message"":""please complete this assessment"", is your first reminder to complete the assessment"", is your last reminder to complete the assessment"", ""cell-phone-field"": ""cell_phone"", ""cell-phone-event"": } ], ""schedules"": [ { ""schedule-offsets"": ""schedule-randomize-window"": ""schedule-reminders"": ""schedule-close-offset"": } ] } ``` this template can be used as a starting point to build configurations in the ema config page. ### processing each time a record is saved, each window configuration will be evaluated to see if it is time to create the window schedule. it is time when the window logic evaluates to true and there is phone number entered and the opt-out flag is not set. at this point, the instances are all created. ema instances are not created when records are imported. ### cron scheduler the cron schedule runs every minutes to determine if messages need to be sent. because of the processing bandwidth this cron is designed to be as 'lightweight' as possible. the scheduler will look through all configurations and check all instances for actions that need to be performed. since the send time is the only timestamp that is stored with each instance of the survey, the configurations will be loaded and the close window time will be calculated to see if any instance should be closed. since this close window is calculated at each checkpoint, any changes to the close window setup time will go into effect immediately. for instance, suppose participants are given minutes to complete the survey before the survey is closed but you decide to extend the survey window to minutes. you can make the change to the configuration and the next time the scheduler runs, it will use the minutes offset before closing the survey. when survey times pass, a text message will be sent using twilio. the body of the text can be specified in the config file and the link to the survey will be appended. the cron also checks to see if reminders are ready to be sent and if so, they will be sent also. ### survey check when participants click on the survey link they receive in text, the timestamp of the close window offset will be checked to make sure that the survey is still open for the participant. if the close window offset has passed, the participant will receive a message to tell them the survey is closed. the status of the survey will also be changed to ""survey access after closed"". otherwise, the participant will be able to complete the survey. once the survey has been taken, the ema_status field will be changed to 'closed: survey completed'. ### twilio credentials twilio credentials (phone number, sid, token) are required in the them configuration file."
1,ieso,"ieso is a platform where users can share their emotions and experiences, and receive help in processing them from other users as well as volunteer student social workers","# ieso ieso is a platform where users can share their emotions and experiences through posts, and receive help in processing them. posts not only help users come to terms with their difficult life experiences but also help social workers identify how to best assist individuals in processing their emotions. in addition, content contributed to the platform helps fuel natural language processing research on identifying states of distress. posting is done pseudonymously in order to protect users' identities. when creating a post, users are prompted to fill out a form in order to collect first-hand information regarding the users' emotional state similar to an ecological momentary assessment. this ultimately allows social workers and nlp researchers to understand participants' qualitative descriptions of their emotions and experiences more holistically. when users make posts, they are vetted by volunteer student social workers before being displayed either publically or privately. posts are always able to receive replies from student social workers, but public posts are also visible to and open to interaction from other users of the site. users are also given the option to receive a follow-up from a student social worker. in this case, they will receive a notification through the site that a student social worker is reaching out to them for further contact. at this point, users will be given the option of discussing with the student social worker over a voice or video call. ## getting started make sure to have docker up and running as well and `docker-compose` installed. then, the project can be run locally with: ``` docker-compose up ``` in order to rebuild the images, run: ``` docker-compose --build up ``` the website can be found at the database can be viewed at ## technical summary the project consists of a next.js webapp, a mongodb database, and a mongoexpress webapp. the next.js webapp renders webpages on the server-side and sends the compiled pages to the user. when the user is not requesting a page, but is ""interacting"" with the site, this is also handled by the next.js webapp. currently, the available interactions are ""signing in"", ""registering"", ""signing out"", and ""posting"". in these cases, the next.js webapp handles user sessions by giving visitors a jwt token. this, combined with another secret token, allows us to prevent abuse of the webapp's interactive components. during ""registration"", users provide a pseudonymous username and a password in order to protect their identity. passwords are hashed using bcrypt in order to maintain their security, and no password recovery mechanisms are offered, so as to prevent related attacks. the username and password are then stored in the mongodb database. during ""sign in"", users provide a pseudonymous username and a password. the webapp compares the password given to the corresponding hash found in the database, if it exists, in order to validate the user. during ""posting"", we currently require users to be ""signed in"" so as to prevent automated posting through the use of bots. however, this may change once another method of preventing botting is implemented. the mongoexpress webapp allows developers to explore the data in the mongodb database. all of these components are containerized and can be launched with the use of docker and docker-compose. during deployment, we will likely use a similar docker-compose file to launch the platform on a columbia provided server."
1,PeerSupportApp,"this application was created as a way for csu students to connect with each other while monitoring their personal mental health. the app has a search page to find other students and see what their major, academic level, and interests are. once a fellow student has been found, they can be added as a friend and the chat functionality is unlocked between the two. also, the main page contains an ema (ecological momentary assessment) which is basically a short survey that tracks how the students behaviors and school life is currently going. this app helps improve students mental health by connecting students with common interests and providing a way for students to track their personal mental health.","# peersupportapp this application was created as a way for csu students to connect with each other while monitoring their personal mental health. the app has a search page to find other students and see what their major, academic level, and interests are. once a fellow student has been found, they can be added as a friend and the chat functionality is unlocked between the two. also, the main page contains an ema (ecological momentary assessment) which is basically a short survey that tracks how the students behaviors and school life is currently going. this app helps improve students mental health by connecting students with common interests and providing a way for students to track their personal mental health. # design and implementation the app was created using react native while google firestore was used to store all the data online and the dependencies were managed using yarn. using react allowed for the app to be run on both android and ios devices which makes the overall development process much quicker. firestore was chosen since it was free and simple to implement. the first page of the app displayed is the login page where the user can enter their email and password to sign in, or if they do not have an account yet, there is a button at the bottom to open the register page. when the sign in button is selected, a function is run that checks in the firebase authentication to see if the entered email and password are an existing match in the database and if not, then an error is printed. the register page allows the user to fill out their personal data such as username, name, major, academic level and etc. when the register button is selected, each field is checked to make sure it is filled out while the password has a check to make sure it is at least six characters long. if the data is all good, then it is all sent to firebase and the email and password is used to create a new user while the rest of the data is stored in a users collection. when the login or registration is successful, app.js will recognize the auth state change and navigate to the home page which is the ema survey. the ema page works by displaying eight different questions about daily practices and mental well-being. all the textinputs are inside of a scrollview since they would not all fit in one page. when the submit button at the button is selected, all the questions are checked to make sure they are filled out and then all the data from the questions is sent to firebase and stores them in a collection named ema. the profile page draws all the data stored in the firebase under the users collection for the current user. the followers and following numbers are also stored in firebase for each user and updated when a user is followed. selecting the edit profile button opens a page that allows the change of the displayed fields. it has an option to set/change the users profile picture. finally the edit profile contains the logout button that when clicked runs the firebase signout function. the search page has a textinput that when text is entered, runs a querybyusername in firebase and displays the names in a flatlist below it. clicking on a profile opens that users profile page where they can be followed and or messaged. selecting the message button opens the chat page. the chatlist page displays all ongoing chats with other users and if there is a new message, the chat with the new message will be highlighted blue. in addition, the chat icon at the bottom has a notification badge on it. selecting a chat from the list will open the chat page where messages can be sent from one user to another. the chat allows for the sending of pictures and videos. these messages are stored in firebase inside a collection named chats which then holds another collection for each message. firestore authentication was setup using the simple email and password option. each user created has a unique user uid generated for it that is used to keep track each user and its data. in the images below, it can be seen that the uid for phart@gmail.com corresponds to the selected document under the users collection in the next image. this is where all the users personal data is stored. below are more images showing how the firebase storage works. the first image contains the ema scores for the selected user uid. the second image shows how the chat storage works. each chat has a unique uid for it. selecting the messages collection under a chat uid will display each message sent inside a document. # problems the first problem encountered was the difference in emulators. something may work perfectly fine running on an iphone but when its ran on an android, it acts completely different and vice versa. for example, on android the send button inside the chat page automatically moves up when the keyboard is opened. however, on an iphone, the button stays right where it is so the keyboard covers it up, making it impossible to actually send a message. another example is buttons that display the text normally on an iphone show up as a box inside another box on an android. the final problem run into was running the app on the web browser. a typeerror kept displaying for the web version that did not appear on either mobile device. after doing research online, it is found to be a problem that others are having with no notable solutions. # conclusion in summary, a react native app was created in conjunction with google firebase. this app works as a social platform for csu students to find other students with common interests and reach out and message them. this app also provides an ema survey that tracks the state of a students current mental and behavioral health."
1,workday,"this is an ios app using the researchkit framework that implements the photographic affect meter (pam), a novel tool for measuring affect. with pam survey respondents select a photo that best suits their current mood. pam is built in the ecological momentary assessment (ema) tradition, intended for frequent and unobtrusive measurement.","# readme # ### what is this repository for? ### * an researchkit based questionnaire ### how do i get set up? ### you need * xcode * cocoapods pro tip: be sure to use `git clone --recursive` to get the submodules ``` run pod install open workaday.xcworkspace in xcode ``` to see this in action, check it out in the app store here ### who do i talk to? ### * open issues in this repo for bugs or feature requests."
1,esmtools,:exclamation:thisisaread-onlymirrorofthecranrpackagerepository. reportbugsforthispackage:https: ...,"<!-- readme.md is generated from readme.rmd. please edit that file --> <br> # esmtools <!-- badges: start --> <p align=""center""> <a href=""https://www.repostatus.org/#active""><img src=""https://www.repostatus.org/badges/latest/active.svg"" alt=""repository status""/></a> <!-- <a href=""https://cran.r-project.org/package=esmtools ""><img src=""https://www.r-pkg.org/badges/version/esmtools"" alt=""cran version""/></a> --> </p> <!-- badges: end --> this r package proposes tools for preprocessing and analyzing data collected through ecological momentary assessment (ema) or experience sampling method (esm) studies. the esmtools package provides a range of functions to support preprocessing, to help researchers gain valuable insights from their datasets, and to help report their preprocessing practices and the quality of the preprocessing of the dataset. it has been developed as part of a set of tools introduced by revol and al.(in preparation). among developed tools, you can find the **esm preprocessing gallery** (<https://preprocess.esmtools.com/>) which provides instructions, r code, and practical examples to preprocess your esm dataset following a steps framework. please remember to cite us if you find our package, framework, and resources helpful in your study: - revol, j., carlier, c., lafit, g., verhees, m., sels, l., & ceulemans, e. (in preparation). *preprocessing esm data: a step-by-step framework, reporting templates, and r code website* ## installation you can install the development version of esmtools like so: host=""https://gitlab.kuleuven.be"", force=true) once installed, you can load the package, as follows: library(esmtools) to learn more about the available functions and their usage, please refer to the documentation: <https://package.esmtools.com/>. ## plot example the calendar plot can provide a comprehensive overview of the time the data was collected, allowing you to identify periods (e.g., holidays vs.regular weeks), or detect missing observations for the whole dataset or a specific participant. <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> <img /> <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> ## templates esmtools provides a set of rmarkdown templates that are bundled with the package. the templates are designed to assist in the reporting of the preprocessing phase and the assessment of data quality, allowing researchers to document and share their data preprocessing workflows efficiently. these templates can be accessed using the **esmtools::use_template()** function, which copies the template files to your working directory. available templates are: preprocess_report, advanced_preprocess_report, data_quality_report. for instance: esmtools::use_template(""preprocess_report"") for further information, please refer to the preprocessing report and the data characteristics report topics of the preprocessing esm gallery. ## reporting tool examples among the functions of this package, you can find functions that support reporting the preprocessing steps. for instance, you can highlight part of the text using the txt() function: <span class=""esm-mod""> modification the value of the x variable has been changed to additionally, the button() and endbutton() functions from the esmtools package delimite part of the document that can be revealed using a button. it is particularly useful to hide non-essential elements (but still important to report) to improve readibility. <div class=""esmtools-container""> <button class=""esmtools-btn"" onclick=""esmtools_togglecontent(this)""> description </button> <div style=""display:none;""> <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> ``` r + #> ``` <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> ``` r + #> ``` </div> </div> ## datasets examples the package contains three dataset examples. the first one is a simulated dataset (**esmdata_sim**) that is used in the esm preprocessing gallery website (for further details see <https://preprocess.esmtools.com/terminology.html>). the second dataset (**esmdata_raw**) is used as an illustrative dataset in the article (further details in the article). finally, the third dataset (**esmdata_preprocessed**), is the output of the preprocessing applied to the raw dataset. the preprocessing that was done can be found in the associated preprocessing report (for further details see the report). there are two ways to import the datasets: - **using the name** of the dataset. <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> ``` r library(esmtools) data = esmdata_raw ``` - **importing the csv version** by reconstructing the path to the file (stored in the package). <style> .esmtools-container{ .esmtools-container-open { border: solid border-radius: margin: padding: } .esmtools-btn{ display:inline-block; solid box-sizing: border-box; text-decoration:none; font-family:'roboto',sans-serif; font-weight: bold; color:#ffffff; text-align:center; transition: all margin: } .esmtools-btn:hover{ background-color:#ffffff; } /* highligh issue text */ .esm-issue{ font-weight: bold; text-decoration: underline } highlight data inspection text */ .esm-inspect{ font-weight: bold; text-decoration: underline } highlight data modification text */ .esm-mod{ font-weight: bold; text-decoration: underline } /* warning message: hidden content */ .warning_hide{ font-weight: bold; margin: color: } </style> <script> function esmtools_togglecontent(button) { var parentdiv = button.parentelement; var childnodes = parentdiv.childnodes; // toggle the 'esmtools-btn-open' class on the parent div parentdiv.classlist.toggle(""esmtools-container-open""); for (var i = i < childnodes.length; i++) { var node = childnodes[i]; // if (!node.classlist.contains(""content-container"")){ if (node.nodetype === node.element_node) { if (node.style.display === ""none"") { node.style.display = ""block""; console.log(""ok"") } else { node.style.display = ""none""; } } // } } } </script> ``` r file_path = system.file(""extdata"", ""esmdata_raw.csv"", package=""esmtools"") data = read.csv(file_path) ``` ## about to cite esmtools, please use: - revol, j., carlier, c., lafit, g., verhees, m., sels, l., & ceulemans, e. *preprocessing esm data: a step-by-step framework, tutorial website, r package, and reporting templates* for any questions, bug reports, or suggestions, please reach out to our team: - email: <jordan.revol@kuleuven.be> - report an issue - repository on gitlab we value your feedback and are committed to improving esmtools based on your needs and requirements. ## licence the package source code in this repository is licensed under the gnu general public license, version license. the documentation, vignettes, and other website materials by jordan revol are licensed under cc by"
1,beiwe-backend,beiwe is a smartphone-based digital phenotyping research platform. this is the beiwe backend code,"<p align=""left""> <img src=""https://github.com/onnela-lab/beiwe-backend/blob/main/beiwe-logo-color.png""> </p> # beiwe the onnela lab at the harvard t.h. chan school of public health has developed the beiwe (bee-we) research platform to collect smartphone-based high-throughput digital phenotyping data. the fully configurable open-source platform supports collection of a range of social, behavioral, and cognitive data, including spatial trajectories (via gps), physical activity patterns (via accelerometer and gyroscope), social networks and communication dynamics (via call and text logs), and voice samples (via microphone). the platform consists of a front-end smartphone application for ios (by apple) and android (by google) devices and a back-end system, which supports a web-based study management portal for data processing and storage, based on amazon web services (aws) cloud computing infrastructure. data analysis is increasingly identified as the main bottleneck; our data analysis platform, forest, makes sense of the data collected by beiwe. beiwe can collect active data (participant input required) and passive data (participant input not required). currently supported active data types for both android and ios include text surveys and audio recordings and their associated metadata. the questions, answers, and skip logic can be configured from the web-based dashboard. passive data can be further divided into two groups: phone sensor data (e.g., gps) and phone logs (e.g., communication logs). beiwe collects raw sensor data and phone logs, which is crucial in scientific research settings. beiwe has two front-end applications, one for android (written in java and kotlin) and another for ios (written in swift & objective-c). the beiwe back-end, which is based on amazon web services (aws) cloud computing infrastructure, and runs on python using the django webserver and orm framework. it also uses several aws services: primary (for flat file storage), (servers), elastic beanstalk (scaling servers), and rds (postgresql). every aspect of data collection is fully customizable, including which sensors to sample, sampling frequency, addition of gaussian noise to gps location, use of wi-fi or cellular data for uploads, data upload frequency, and specification of surveys and their response options. study participants simply download the beiwe application from the app store and enter three pieces of information: a system-generated user id, a system-generated temporary password, and an ip address of the back-end server. if no active data is being collected in the study (i.e., no surveys), this is the only time the participant will interact with the application. however, most studies make use of occasional self-reports or ema, and some use the audio diary feature to collect rich data on lived experiences. all beiwe data is encrypted while stored on the phone awaiting upload and while in transit, and are re-encrypted for storage on the study server. during study registration, beiwe provides the smartphone app with the public half of a rsa encryption key. with this key, the device can encrypt data, but only the server, which has the private key, can decrypt it. thus, the beiwe application cannot read its own temporarily stored data, and the study participant (or somebody else) cannot export the data. the rsa key is used to encrypt a symmetric advanced encryption standard (aes) key for bulk encryption. these keys are generated as needed by the app and must be decrypted by the study server before data recovery. data received by the cloud server is re-encrypted with the study master key and then stored. some of the data collected by beiwe contain identifiers, such as phone numbers. the beiwe app generates a unique cryptographic code, called a salt, during the beiwe registration process, and then uses the salt to encrypt phone numbers and other similar identifiers. the salt never gets uploaded to the server and is known only to the phone for this purpose. using the industry-standard (secure hash algorithm) and (password-based key derivation function algorithms, an identifier is transformed into an anonymized string that can then be used in data analysis. a recent study found that of medical studies were inconsistent when retested, and only were completely reproducible. reproducibility of studies using mobile devices may be even lower given the variability of devices, heterogeneity in their use, and lack of standardized methods for data analysis. all beiwe study data collection settings, from sensors to surveys, are captured in a human readable json file. these files can be imported into beiwe and exported out of beiwe. to replicate a study, the investigator can simply upload an existing configuration file. cite the code: # setup instructions ## configuring ssl because beiwe often deals with sensitive data covered under hipaa, it is important to add an ssl certificate so that web traffic is encrypted with https. the setup script uses aws certificate manager to generate an ssl certificate. aws certificate manager will check that you control the domain by sending verification emails to the email addresses in the domain's whois listing. ## configuring firebase to initialize the firebase sdk, generate a private key file. rename the file firebase_cloud_messaging_credentials.json and place it in the project root. *** # configuration settings ### mandatory settings if any of these environment options are not provided, beiwe will not run. empty strings and none are considered invalid. ``` flask_secret_key - a unique, cryptographically secure string aws_access_key_id - aws access key for aws_secret_access_key - aws secret key for - the bucket for storing app-generated data sysadmin_emails - a comma separated list of email addresses for recipients of error reports. (whitespace before and after addresses will be ignored) rds_db_name - postgress database name (the name of the database inside of postgres) rds_username - database username rds_password - database password rds_hostname - database ip address or url - the user id for access for your deployment - the secret key for access for your deployment ``` ### optional settings there are additional settings that you will find documented in the config/settings.py file. we _strongly_ recommend adding sentry dsns to all your beiwe servers. without these there is very little data to work with when something goes wrong, and we will not be able to assist. *** # development setup how to set up beiwe-backend running on a development machine (not a production instance! for a production instance, see https://github.com/onnela-lab/beiwe-backend/wiki/deployment-instructions---scalable-deployment) #### before starting: while it is possible to run your development environment inside of the system python environment, this practice is _strongly discouraged_. we recommend familiarizing yourself with one of the following: python's venv library (basic virtual environments), pyenv (allows for compiling particular target versions of python, plus some quality-of-life command-line she will integrations), or conda (another option, includes integrations with non-python libraries). note also that the codebase expects at least python version `sudo apt-get update; sudo apt-get install postgresql libpq-dev` `pip install --upgrade pip setuptools wheel` `pip install -r requirements.txt` create a file for your environment variables that contains at least these: ``` export export flask_secret_key=""asdf"" export export sysadmin_emails=""sysadmin@localhost"" ``` i usually store it at `private/environment.sh`. load up these environment variables by running `source private/environment.sh` at the bash prompt. for additional tips on running a local development enironment please see this wiki page. if you are having difficulty getting started, or believe you could assist with any issues of documentation, please post an issue with a documentation tag. ### local celery setup **update**: it is no longer necessary to use celery for local testing, though you still need it to be installed in your python environment in order to avoid import errors. a full test of celery requires the full setup below, including installing `rabbitmq`, but as long as the file for the rabbitmq host server ip and password (`manager_ip` in the root of the repository) is missing you will instead be presented with output similar to the example she will session below, indicating a that you are running in a _much_ more convenient single-threaded local testing mode: ``` in from services.celery_data_processing import * task declared, args: (), kwargs:{'queue': 'data_processing'} instantiating a falseceleryapp for celery_process_file_chunks. ``` for those souls brave enough to run the entire broker queue and celery task dispatch machinery locally, here are our best instructions. caveat: this configuration is based on a one that is known to work on ubuntu and is potentially incompatible with the version of rabbitmq provided in ubuntu also, due to the use of the system `service` command it is incompatible with the varient of ubuntu for use on the windows subsystem for linux. have at: install rabbitmq (https://docs.celeryproject.org/en/latest/getting-started/backends-and-brokers/rabbitmq.html#broker-rabbitmq) edit `/etc/rabbitmq/rabbitmq-env.conf` and add the line restart rabbitmq like this in the bash she will: `time sudo service rabbitmq-server restart` (`time` is not necessary, but it tells you that the command has finished, and how long the command took to execute... which can be... random and excessive?) `pip install -r requirements_data_processing.txt` (this will install celery using pip) create a file called `manager_ip` in the top level of your `beiwe-backend` repo, and enter these two lines in it. do not provide a trailing new-line character. ``` [your desired password] ``` where the password is the one you set when setting up rabbitmq run this command to create a user for rabbitmq: `rabbitmqctl add_user beiwe [insert that password here]` run this command to allow the beiwe user access to the appropriate queues: `sudo rabbitmqctl set_permissions -p / beiwe "".*"" "".*"" "".*""` if you intend to test firbase push notifications you will need to upload functional firebase credentials on the local website interface. to execute push notification tasks run this command _while inside the root of the repo_: `celery -a services.celery_push_notifications worker -q push_notifications --loglevel=info -ofair --hostname=%%h_notifications --pool=threads` to run data processing tasks run this command _while inside the root of the repo_: `celery -a services.celery_data_processing worker -q data_processing --loglevel=info -ofair --hostname=%%h_processing` to run forest tasks run this comand _while inside the root of the repo_: `celery -a services.celery_forest worker -q forest_queue --loglevel=info -ofair --hostname=%%h_forest` (forest is still in beta.) run this command to dispatch new tasks, which will then be consumed by the celery processes, _while inside the root of the repo_. `python services/cron.py five_minutes` ### forest warning: the forest integration is still in beta; running forest may because significant data processing costs."
1,forest,forest is a library for analyzing smartphone-based high-throughput digital phenotyping data,"[!build](https://github.com/onnela-lab/forest/actions/workflows/build.yml) [!documentation status](https://forest.beiwe.org/en/latest/) <img src=""forest-logo-color.png"" alt=""forest logo""> # forest (python the onnela lab at the harvard t.h. chan school of public health has developed the forest library to analyze smartphone-based high-throughput digital phenotyping data. the main intellectual challenge in smartphone-based digital phenotyping has moved from data collection to data analysis. our research focuses on the development of mathematical and statistical methods for analyzing intensive high-dimensional data. we are actively developing the forest library for analyzing smartphone-based high-throughput digital phenotyping data collected with the beiwe platform. forest will implement our methods for analyzing beiwe data as a python package and is released under the open-source license. the forest library will continue to grow over the coming years as we develop new analytical methods. forest can be run locally but is also integrated into the beiwe back-end on aws, consistent with the preferred big-data computing paradigm of moving computation to the data. integrated with beiwe, forest can be used to generate on-demand analytics, most importantly daily or hourly summary statistics of collected data, which are stored in a relational database on aws. the system also implements an api for tableau, which supports the creation of customizable workbooks and dashboards to view data summaries and troubleshoot any issues with data collection. tableau is commercial software but is available under free viewer licenses and may be free to academic users for the first year (see tableau for more information). for more detailed info on specific subpackages, see our documentation. please note that forest uses python # description description of how beiwe data looks (folder structure + on/off cycles) input: typically raw data from smartphones output: typically summary files - creating synthetic data - want to try out our methods, but do not have smartphone data at hand? use **bonsai** - data preparation - identifying time zones and unit conversion: use **poplar** - collate beiwe survey data into .csvs per participant or per study: use **sycamore** - data imputation - state-of-the-art gps imputation: use **jasmine** - data summarizing (see tables below for summary metrics) - mobility metrics from gps data: use **jasmine** - daily summaries of call & text metadata: use **willow** - survey completion time from survey metadata: use **sycamore** # usage to install, clone this repository to a local directory and then: ```console pip install path/to/forest ``` alternatively, install directly from github with `pip`. as the repo is public, it will not prompt you to login. if you have used forest in the past, it might be prudent to do a '''pip uninstall forest''' first. ```console pip install git+https://github.com/onnela-lab/forest ``` to immediately test out forest, adapt the filepaths in the code below and run: ```python # currently, all imports from `forest` must be explicit. for the below example you need to import the following # in future, it would be great to have all functions import automatically import datetime from forest.bonsai.simulate_log_data import sim_log_data from forest.bonsai.simulate_gps_data import sim_gps_data, gps_to_csv from import frequency, gps_stats_main from forest.willow.log_stats import log_stats_main # if you do not have any smartphone data (yet) you can generate fake data path_to_synthetic_gps_data = path_to_synthetic_log_data = path_to_gps_summary = path_to_log_summary = # generate fake call and text logs # because of the explicit imports, you do not have to precede the functions with forest.subpackage. sim_log_data(path_to_synthetic_log_data) # generate synthetic gps data and communication logs data as csv files # define parameters for generating the data # to save smartphone battery power, we typically collect location data intermittently: e.g. during an on-cycle of minutes, followed by an off-cycle of minutes. we will generate data in this way # number of persons to generate n_persons = # location of person to generate format: location = ""gb/bristol"" # start date of generated trajectories start_date = # end date of trajectories end_date = # api key for openroute service, generated from https://openrouteservice.org/ api_key = ""mock_api_key"" # length of off-cycle + length of on-cycle in minutes cycle = # length off-cycle / (length off-cycle + length on-cycle) percentage = # dictionary of personal attributes for each user, set to none if random, check attributes class for usage in simulate_gps_data module. personal_attributes = { ""user { ""main_employment"": ""none"", ""vehicle"" : ""car"", ""travelling_status"": ""active_status"": }, ""users { ""main_employment"": ""university"", ""vehicle"" : ""bicycle"", ""travelling_status"": ""active_status"": }, ""user { ""main_employment"": ""office"", ""vehicle"" : ""foot"", ""travelling_status"": ""preferred_exits"": [""cafe"", ""bar"", ""cinema""] } } sample_gps_data = sim_gps_data(n_persons, location, start_date, end_date, cycle, percentage, api_key, personal_attributes) # save data in format of csv files gps_to_csv(sample_gps_data, path_to_synthetic_gps_data, start_date, end_date) # specify parameters for imputation # see https://forest.beiwe.org/en/latest/jasmine.html for details # time zone where the study took place (assumes that all participants were always in this time zone) tz_str = # generate summary metrics e.g. frequency.hourly, frequency.daily or frequency.hourly_and_daily (see frequency class in constants.py) frequency = frequency.daily # save imputed trajectories? save_traj = false # hyperparameters class for imputation (default leave none), from import hyperparameters parameters = none # list of locations to track if visited, leave none if do not want these summary statistics places_of_interest = ['cafe', 'bar', 'hospital'] # list of openstreetmap tags to use for identifying locations, leave none to default to amenity and leisure tagged locations or if you do not want to use osm (see osmtags class in constants.py) osm_tags = none # impute location data and generate mobility summary metrics using the simulated data above gps_stats_main( study_folder = path_to_synthetic_gps_data, output_folder = path_to_gps_summary, tz_str = tz_str, frequency = frequency, save_traj = save_traj, parameters = parameters, places_of_interest = places_of_interest, osm_tags = osm_tags, ) # generate daily summary metrics for call/text logs option = frequency.daily time_start = none time_end = none participant_ids = none log_stats_main(path_to_synthetic_log_data, path_to_log_summary, tz_str, option, time_start, time_end, participant_ids) ``` ## more info * beiwe platform for smartphone data collection * onnela lab ## publications * straczkiewicz, m., huang, e.j., and onnela, jp. a one-size-fits-most walking recognition method for smartphones, smartwatches, and wearable accelerometers. _npj digit. med._ open access: * onnela jp, dixon c, griffin k, jaenicke t, minowada l, esterkin s, siu a, zagorsky j, and jones e. beiwe: a data collection platform for high-throughput digital phenotyping. journal of open source software,"
1,Beiwe-Analysis,beiwe is a smartphone-based digital phenotyping research platform. this repository contains some data analysis code.,"## project name beiwe data analysis code ## description this repository contains an evolving code base for running various types of analyses on data collected with the beiwe research platform for smartphone-based digital phenotyping. we will merge several distinct projects into this single repository by the end of note that this repository is distinct from the beiwe data anlaysis pipeline. for documentation of beiwe back-end, start here. ## documentation this is being updated but you can start here. we will migrate documentation over to sphinx, which is the most widely used documentation generator written and used by the python community. ## license this repository is published under the bsd see here. ## contribute we would love your contribution! to avoid fragmentation of the code base and maximize its usability, we have decided on the following guidelines: * all code should be placed on github in this repository * all new functionalities should be implemented in python (old ones are being converted into python) * for computationally intensive parts, use numpy and scipy, possibly consider c extension modules * use google's style guide for python * comment your functions generously using that same guideline (section comments and docstrings) * do use restructuredtext (rest) in your docstring, it helps with documentation generators ## credits the beiwe platform was developed by the onnela lab at harvard university. several individuals have contributed to this project. see the lab's web page for more information."
1,openwillis,python library for digital measurement of health,"openwillis is a python library for digital health measurement. it was developed by brooklyn health to establish standardized methods in digital phenotyping and make them open and accessible to the scientific community. it is freely available for non-commercial use (see license). release notes getting started list of functions research guidelines please report any issues using the issues tab. if you would like to contribute to openwillis or have general questions, please get in touch."
1,beiwe,beiwe is a smartphone-based digital phenotyping research platform.,"## project name beiwe ## description this repository contains documentation and code examples that are applicable to various parts of the beiwe platform. this repository was created in june the idea is that the python functions that can be used to download and process beiwe data are in the `code` directory, many of them in the `utils.py` module, and the jupyter notebooks demonstrating their use are in the `notebooks` directory. some of the code, whether run in a she will or jupyter notebook, will require setting up a virtual python environment. more details on that are available here. note that there is another repository for statistical analyses although we may merge these repositories at some point. for documentation of beiwe back-end, start here. ## documentation this is being updated but you can look here and here. ## sample configuration files these are example beiwe configuration files for passive data collection: * default passive data collection: json ## license this repository is published under the bsd see here. ## credits the beiwe platform was developed by the onnela lab at harvard university. several individuals have contributed to this project. see the lab's web page for more information."
0,neurobooth-os,python package for digital phenotyping data synchronization and acquisition,"neurobooth-os ------------- neurobooth-os is a python package to initialize, synchronize and record behavioral and physiological data streams from wearables, d-/rgb cameras, eye tracker, ecg, mouse and microphone in a booth. installations ------------- we recommend the anaconda python distribution. to install neurobooth-os, simply do: $ pip install -e git+https://github.com/neurobooth/neurobooth-os.git#egg=neurobooth_os and it will install neurobooth-os along with the dependencies which are not already installed. to check if everything worked fine, you can do:: $ python -c 'import neurobooth_os' and it should not give any error messages. install pylink running on the stm:: $ pip install --index-url=https://pypi.sr-support.com sr-research-pylink if pip install from sr-research does not work, please follow the following steps: * create an sr-research support account * download the `eyelink developers kit and bit)` installer from the sr research support forum. * install the eyelink developers kit * run: `$ cd c:'\\program files research\\eyelink\\sampleexperiments\\python\\'` * run: `$ python install_pylink.py` for pyspin flir installation on the acq: download sdk from https://www.flir.com/products/spinnaker-sdk/?vertical=machine+vision&segment=iis direct link to wheel file: then unzip the file, cd to the folder and run: `$ pip install setup ----- it requires a postgresql database running on a server. connection is established with the function `neurobooth_os.iout.metadator.get_conn()`. currently, as specified in `~/.neurobooth_os_secrets` the local ip is and remotely it connects to `neurodoor.nmr.mgh.harvard.edu` using the private key in '~/.ssh/id_rsa'. to setup a private key, first activate the vpn (partner's virtual private network), then run in the terminal:: $ ssh-keygen $ ssh-copy-id userid@neurodoor.nmr.mgh.harvard.edu next, set up the configuration data. please see the instructions at: https://github.com/neurobooth/neurobooth-os/blob/master/docs/system_configuration.md run ---- the program runs on different computers and the starting point is ``gui.py``. the computers are: * ctr (control) computer: this computer hosts the gui and relays commands to the other computers to start recording from the neurobooth devices and presenting stimuli. the lab recorder software is on this computer. * stm (stimulus) computer: this computer runs the tasks using ``psychopy``. * acq (acquisition) computer: this computer acquires data. each computer has a server that listens for communication from the other computers in the form of string messages. ctr and stm computer communicate with the database."
1,beiwe-android,beiwe is a smartphone-based digital phenotyping research platform. this is the beiwe android app code. the app is also available on the google play store to use with open source builds of the beiwe backend.,"## compiling and running the beiwe android app ## compiling to compile and sign the app, you must add a directory called `private` (`beiwe-android`'s `.gitignore` file keeps the `private` directory out of git), and a file called `private/keystore.properties`, containing these lines (no quotes around the values that you fill in): ``` storepassword=keystore_password keypassword=key_password keyalias=key_alias storefile=keystore_filepath ``` if it is your first time running the project, **open android studio and click ""sync project with gradle files""**. if you run into errors, open android studio's ""sdk manager"" and make sure you have the correct sdk platform installed (the ""api level"" should match the one specified in app/build.gradle's `compilesdkversion`). you will need to **generate a key file** by running build -> generate signed bundle/apk, and then, inside `private/keystore.properties`, update the four values with the information from your newly-generated key and keystore. (optional) you can also configure a sentry dsn for each build type inside your `private/keystore.properties` file. ``` ``` ## setting up firebase to receive push notifications, add firebase to your android project following these steps up through step ## build variants and product flavors when you build the android app, you choose one of the build variants and one of the product flavors. there are three of each, specified in the `buildtypes` section of `app/build.gradle`. to select which build variant the app compiles as, go to **build** > **select build variant** in the menu bar (see the documentation). #### the three build variants are: | build variant | app name | password requirements | debug interface | | --- | --- | --- | --- | | **release** | ""beiwe"" or | at least characters | no | | **beta** | ""beiwe-beta"" or | at least character | yes | | **development** | ""beiwe-development"" or | at least character | yes, plus extra buttons only useful for develpers, like buttons to crash the app. also includes some extra logging statements that write to logcat, but not to app log files that get uploaded. | #### the three product flavors are: | product flavor | app name | intended for | server url | record text message and call log stats | request background location permission | | --- | --- | --- | --- | --- | --- | | **googleplaystore** | | distribution via google play store | customizable at registration | no (forbidden by play store policies) | no (forbidden by play store policies) | | **onnelalabserver** | beiwe | download apk from studies.beiwe.org/download | hardcoded to studies.beiwe.org | yes | yes | | **commstatscustomurl** | beiwe | download apk from `/download` link on other beiwe deployments | customizable at registration | yes | yes | ## distributing the app _this section is only intended for developers maintaining the canonical copies of the beiwe and android apps; this is not useful for anyone working on a fork of the repo._ when we update the app version, we need to update the three public versions of the app: the googleplaystore flavor that is downloadable from google play, and the onnelalabserver and commstatscustomurl flavors which get compiled as apks, stored in a public bucket on amazon and linked to via `/download` links on other beiwe deployments. we use fastlane, running inside github actions, for building and distributing the app. ### creating and distributing new builds **upgrade the app version** in `app/build.gradle`, increment `versioncode` (a sequential integer) and increase `versionname` (a traditional x.y.z format version number). in `deviceinfo.java`, write a message about what changes the new version brings. create a new commit on `master` that only does the above two things, and does not introduce any other changes. i like to use a commit message formatted exactly like this: `updates app version to x.y.z, level xx`. then, only make builds off of this commit. that way it is very clear what git commit each build corresponds to. if you want to change something in the build, create a new version. **manually run the ""build"" github action**- this will run fastlane, executing two ""lanes"": `fastlane buildaab` builds the aab file and uploads it to google play's ""alpha"" (closed testing) track. `fastlane buildapks` builds the two apk files (onnelalabserver and commstatscustomurl) and uploads them to the bucket. it uploads two copies of each file: one copy of each apk gets saved with a quasi-permalink in this format: the other copy of each apk gets saved to the ""latest"" download link, with a format like this: this ""latest"" link is what a beiwe deployment's `/download` link should point to. **in the google play console, promote the alpha release to production.** #### fastlane local setup _you should not need to do this,_ other than for debugging the fastlane setup. we intend fastlane to be primarily run on the cloud, inside github actions. but if for some reason you decide to run it locally, here is how to do it: follow fastlane's android getting started documenation, including: install ruby. then `gem install bundler`, and then `bundle install`. make sure you have the following credentials, and that they are correct: the keystore inside this repo at `private/signing_keystore.jks` your `private/keystore.properties` file, which should include `releasedsn` your google service account credentials json file, which enables you to upload the android app bundle to google play. its location is defined in `faslane/appfile`. aws iam credentials that allow you to upload an object to the bucket used for hosting apk files for download. your credentials should be exported as two environment variables called `aws_access_key_id` and `aws_secret_access_key`. run `fastlane buildaab` run `fastlane buildapks`"
1,beiwe-ios,beiwe is a smartphone-based digital phenotyping research platform. this is the beiwe ios app code. the app is also available on the apple app store to use with open source builds of the beiwe backend.,"### building the beiwe ios app install xcode if you are on a mac with an processor, **open xcode using rosetta**. locate xcode in finder, right-click and choose ""get info"", and check the box that says ""open using rosetta"". in xcode, open beiwe.xcworkspace, **not** beiwe.xcodeproj install cocoapods. we recommend installing via homebrew, because that version supports macs running apple (arm) processors _without_ you needing to prepend `arch to your ` pod install` commands. install homebrew install cocoapods: `brew install cocoapods` inside this project directory (inside the `beiwe-ios` directory), run `pod install`. add a `googleservice-info.plist` file. note: this is connected to your specific firebase account. if you are using the beiwe service center but still want to build your own version of the beiwe ios app, you will need to ask someone at the onnela lab to provide this file to you. to add the file to the xcode project, drag it from finder into the xcode project navigator, just under the folder icon named ""beiwe"" (not the top level ""beiwe"" icon). this should bring up a dialog that says ""choose options for adding these files:""- in that, select ""copy items if needed"" and ""add to targets: beiwe"". it is not enough to move it into the beiwe-ios directory using finder or `mv`/`cp` in terminal. build the app to build for the simulator, click the ""run"" arrow button. to build for release, click product -> archive. ### build configurations there are two important build configurations: * ""beiwe"": the study server is hardcoded to studies.beiwe.org * the study server url gets set after you install the app, on the registration screen."
0,digital-phenotyping,year long masters advanced software project for @ the university of melbourne,"# digital phenotyping this is a project built as part of at the university of melbourne. ## directory structure frontend # react frontend backend # django backend readme.md ## how to run this project open **frontend** and **backend** folder to see more detailed instructions. ## deploying for production in production, the entire application can be deployed on a single instance in the following way: - django: gunicorn & nginx - react: served with nginx - mysql: running in the background on the server - certbot: used to automatically obtain https certificates clone the repository to the home directory (`~` on linux machines) ### setup the database (mysql) we use a mysql database for our django application. a mysql database has already been setup on the production instance, with the name a user has been created with read and write privlleges on the database and these credentials are passed to django. if deploying the app from scratch, then the sql dump file may need to be imported as the django migrations are not configured properly. it is better to import the .sql dump file as the migrations will not create the necessary tables. ### python backend (django) the python backend is deployed using gunicorn (a python wsgi web server) with nginx in front of it. navigate to the directory containing the python api `/backend`. create a virtual environment in this folder with the following command. this will create a subdirectory called /venv that will contain the virtual environment. -m venv venv` activate the virtual environment. from the /backend folder, enter the following command. this will now activate the virtual environment - all packages will now be installed in the /venv directory rather than globally `source venv/bin/activate` install the project's pythons dependencies in the virtual environment. from the /backend directory, run the following command: `pip install -r requirements.txt` now, add a text file named .env in the `/backend/django_site` directory. this will contain our environment variables needed for the django application to run. the production .env file can be found on the server in the `~/digital-phenotyping/backend/django_site/` directory. the environment file needs to contain the following lines: ``` # database connection info database_host database_password database_name database_user # google map information extraction google_api_key # twitter information extraction access_token access_token_secret bearer_token consumer_key consumer_secret # cron job interval scheduling. there are four scheduled tasks. these will run automatically on system startup. please try to make sure that the values are different ``` following the previous step, everything is ready for deployment. now the next step is to setup gunicorn . first, ensure that gunicorn has been installed in the virtual environment. with the virtual environment active, type the following command. you should see gunicorn in the list of installed packages. `pip list` next, we need to setup gunicorn . we will use linux's systemd and configure gunicorn as a systemd service. create a file named gunicorn.service in the `/etc/systemd/system` directory. this will point to the gunicorn installation in our project's python virtual environment. it should contain the following lines: ``` [unit] description=gunicorn daemon requires=gunicorn.socket after=network.target [service] user=ubuntu group=www-data workingdirectory=/home/ubuntu/digital-phenotyping/backend/django_site/ execstart=/home/ubuntu/digital-phenotyping/backend/venv/bin/gunicorn \ --access-logfile - \ --workers \ --bind unix:/run/gunicorn.sock \ src.wsgi:application [install] wantedby=multi-user.target ``` create another file named gunicorn.socket in the same /etc/systemd/system directory. it should contain the following: ``` [unit] description=gunicorn socket [socket] listenstream=/run/gunicorn.sock [install] wantedby=sockets.target ``` start gunicorn. run the following command: `sudo systemctl gunicorn start` done! now we need to configure nginx to forward requests to gunicorn. ### frontend (react) deployment of the react frontend is simple. one thing to note is the build step requires extensive compute resources and so building the react application on the instance itself is not recommended. building on will likely because the server to crash. therefore, it is better to build the react application on your local machine (via running yarn install and yarn run build) to create the production build and then using scp to transfer the build to the instance. this can be done in the following way on a linux/macos machine: `cd frontend | yarn run build` will create a /build directory in the frontend folder `scp -i <path-to-ssh-key> -r build <ubuntu@ipaddress>:~` will transfer the build to the home directory on the instance ensure that the /build folder containing the react build lives in the home directory (`~`) on the server; otherwise the following nginx configuration will not work. ### nginx nginx is used to serve both the react build and the django api. add the following files to /etc/nginx/sites-available create a file named backend in the etc/nginx/sites-available directory. this will hold our server block for the django api. the url is http://backend.senpsi.net and this can be used to access the django admin page. add the following lines. ``` server { server_name backend.senpsi.net; location = /favicon.ico { access_log off; log_not_found off; } location /static/ { root /home/ubuntu/digital-phenotyping/backend/django_site/; } location / { include proxy_params; proxy_pass http://unix:/run/gunicorn.sock; } } ``` create a file named react in the etc/nginx/sites-available directory. this will hold our server block for the react frontend. the url is http://dev.senpsi.net. add the following lines. ``` server { root /home/ubuntu/build; index index.html index.htm; server_name dev.senpsi.net; location / { try_files $uri /index.html } } ``` ### certbot follow this guide to setup https for both the backend and frontend using certbot: https://www.nginx.com/blog/using-free-ssltls-certificates-from-let us-encrypt-with-nginx/"
1,LAMP-core-ios,core scaffolding for digital phenotyping apps with reactive user interfaces. (ios),# lamp-core-ios core scaffolding for digital phenotyping apps with reactive user interfaces. (ios)
1,OpenDPMH,framework to facilitate the development of digital phenotyping applications,"# opendpmh: an extensible framework for developing mobile sensing applications of digital phenotyping <p align=""center""> opendpmh is a framework for developing mobile sensing applications able to collect useful user information for digital phenotyping of mental health (dpmh). </p> <p align=""center""> <img src=""https://github.com/jeancomp/opendpmh/blob/master/open-dpmh-example.jpg"" alt=""opendpmh"" /> </p> ## requirements * android version: * android api version: minsdkversion > ## documentation ### composition mode: composition mode is the app's behavior when a new data is collected by the middleware. the possibilities are: - send_when_it_arrives - group_all - frequency - setfrequency(value) ### the digital phenotyping manager ``` digitalphenotypingmanager = new dpmanager.builder(this) .setcompositionmode(compositionmode.frequency) .build(); digitalphenotypingmanager.start(); ``` ### stop the digital phenotyping manager ```sh digitalphenotypingmanager.stop(); ``` ## plugin > the opendpmh architecture is enabled to add plugins, which extend the framework's capabilities by allowing the addition of new data processing modules. ### plugin repository ## access our article in ieee xplore ### ieee xplore ## contributing opendpmh is an open-source project. if there is a bug, or other improvement you would like to report or request, we encourage you to contribute. please, feel free to contact us for any questions: [!gmail badge](mailto:ariel@lsdi.ufma.br) ## license opendpmh is licensed, as found in the [license][l] file. [l]: https://github.com/jeancomp/opendpmh/blob/master/license.md"
0,digital-phenotyping,digital phenotyping student project,"digital phenotyping student project (part of human identification project at parseq lab) repository. ------------ main issues ------------ * quantitative measurement of human phenotypic traits * image processing algorithm development * mps data analysis for varifind hid phenotype panel * phenotypic traits prediction models comparison ------------ project description ------------ the advent of modern molecular biology has resulted in the increased ability to perform human identification (hid) in forensics. nevertheless, traditional dna typing provides a way to determine only whether two samples (one from the crime scene, and the other from the suspect) are from the same person. that is why this technology is of little use in absence of a suspect. prediction of human externally visible characteristics seeks to get past this limitation by using the dna left at a crime scene to create a genetically based description of the unknown suspects appearance that can be used to narrow the search for suspects. with accumulation of information about human genetics, forensic dna phenotyping technologies are showing great promise, but accuracy of phenotypic traits prediction with currently published methods remains insufficient for routine use. one of the key challenges in phenotype prediction is a subjectivity of traits description, during both development and validation of models and prediction results interpretation. several methods of phenotypic traits measurement, at most based on digital image analysis, have been published recently, but none of them currently widely used. one of the parseq lab company projects is development of complex mps (massively parallel sequencing) solution for forensics, including phenotype prediction assay for human pigmentation, male pattern baldness and blood type. one of the issues in development and validation of human pigmentation prediction models is implementation of easy, precise and objective method of target phenotypic traits determination. ------------ project goals ------------ ### main goal improvement of phenotype prediction based on genotype data by quantitative measurement of human phenotypic traits, in particular, pigmentation. ### project objectives * obtain an insight into published methods of quantitative measurement of human phenotypic traits (eyes, hair and skin pigmentation; male pattern baldness stage) * selection of the most appropriate measurement method (instruments and conditions for measurements, algorithm of image analysis) for each of traits * development of an algorithm of image processing and its usage considerations * performance evaluation of the application by applying to a subset of volunteers * analysis of targeted mps sequencing results for loci associated with phenotypic traits of interest for the set of volunteers examined * improvement of published phenotypic traits prediction models based on usage of new traits measurement methods and comparison of results with ones derived by initial models"
0,ordinal-forecasting-digital-phenotyping,accompanying repository for the paper *forecasting mental states in schizophrenia using digital phenotyping data*,"# ordinal forecasting for digital phenotyping data accompanying repository for the paper *forecasting mental states in schizophrenia using digital phenotyping data* ## repository structure - `src/` hosts the code for xgboost and lstm models and the analysis pipeline for data preprocessing, model training and evaluation, and post-hoc statistics. - `scripts/` includes scripts to execute the analysis pipelines. - `results/` contains the models' evaluation performance and figures. ## installation create a new environment using python then install requirements via `pip install -r requirements.txt` ## tooling - data transformations use pandas, numpy, and scikit-learn - the analysis pipelines are defined using hamilton and runs are managed using hydra. - the xgboost library is used for gradient boosted decision trees and an ordinal implementation is defined following the scikit-learn api. - the lstm is implemented using pytorch lightning with the corn architecture from coral-pytorch and metrics are tracked using torchmetrics. - evaluation metrics from imbalance-learn are used and statistical testing is done with scipy and scikit-posthocs."
1,beiwe-backend,improved server backend for beiwe digital phenotype platform,"# setup instructions ## configuring ssl because beiwe often deals with sensitive data covered under hipaa, it is important to add an ssl certificate so that web traffic is encrypted with https. the setup script uses aws certificate manager to generate an ssl certificate. aws certificate manager will check that you control the domain by sending verification emails to the email addresses in the domain's whois listing. *** # configuration settings all the settings listed here can be found either in the constants file or in the config/settings.py file, or can have an environment variable set for them. optional settings if an environment variable is provided for any of these they will override the default value. more information is available in the constants and config/settings.py files in the config directory. ``` - the number of retries on attempts to connect to aws default: concurrent_network_ops - the number of concurrent network operations throughout the codebase default: file_process_page_size - the number of files pulled in for processing at a time default: asymmetric_key_length - length of key files used in the app default: iterations - iteration count for passwords default: ``` mandatory settings if any of these are not provided, beiwe will not run, empty and none values are considered invalid additional documentation can be found in config/setting.pys. ``` flask_secret_key - a unique, cryptographically secure string aws_access_key_id - aws access key for aws_secret_access_key - aws secret key for - the bucket for storing app-generated data - the source email address for error alerts other_email_address - the source email address for other error events sysadmin_emails - a comma separated list of email addresses for recipients of error reports. (whitespace before and after addresses will be ignored) rds_db_name - postgress database name (the name of the database inside of postgres) rds_username - database username rds_password - database password rds_hostname - database ip address or url - the user id for access for your deployment - the secret key for access for your deployment ``` how to add new features: ./config/constants.py ./frontend/templates/device_settings.html run to add new field in the postgresql table database_devicesettings (or postgres.sql) postgresql to backup all: pg_dumpall > postgres.sql to restore all: psql -f postgres.sql postgres allow port for non-root: setcap cap_net_bind_service=+eip"
1,beiwe-android,improved android app for beiwe digital phenotype platform,"## compiling and running the beiwe android app ### compiling to compile and sign the app, you must add a directory called `private` (`beiwe-android`'s `.gitignore` file keeps the `private` directory out of git), and a file called `private/keystore.properties`, with these lines (no quotes around the values that you fill in): ``` storepassword=keystore_password keypassword=key_password keyalias=key_alias storefile=keystore_filepath ``` you can also configure a sentry dsn for each build type in this file. ``` ``` ### three build variants there are three build variants of the android app, specified in the `buildtypes` section of `app/build.gradle`. to select which build variant the app compiles as, go to **build** > **select build variant** in the menu bar (see the documentation). the three build types are: * **release**- points to the production server (studies.beiwe.org) and does not have the debug interface. the app is named ""beiwe"" when installed on the phone. * **beta**- points to the staging server (staging.beiwe.org), has the debug interface, and allows passwords as short as character. the app is named ""beiwe-beta"" when installed on the phone. * **development**- points to the staging server (staging.beiwe.org), has the debug interface, and allows passwords as short as character. the debug interface also has some extra buttons that are only useful for developers, like buttons to crash the app. also includes some extra logging statements (that are printed to android monitor if the phone is plugged into a debugger, but are not printed to beiwe log files). the app is named ""beiwe-development"" when installed on the phone. ### to add a new feature/sensor org.beiwe.app.listeners : add new class backgroundservice.java : starttimers(), timerreceiver(): [both enabling and disabling], registertimers(), dosetup(), class backgroundservice persistentdata.java : class persistentdata, getters and setters, default timings textfilemanager.java : class textfilemanager, checktextfileavailable(), initialize(), makenewfilesforeverything(), getalluploadablefiles() debuginterfaceactivity.java : class debuginterfaceactivity, longclickbuttons, intent triggers such as gpson()/gpsoff() setdevicesettings.java : writedevicesettings() timer.java : class timer, timer() activity_debug_interface.xml"
0,fenotipagem_digital_saude_vs_0_1,framework to facilitate the development of digital phenotyping applications,"# opendp - framework to facilitate the development of digital phenotyping applications > a framework aimed at identifying behavior patterns, habits, customs of monitored individuals through the collection of data from physical and virtual sensors. [!github [!github [!github [!github summary ================= <!--ts--> * goals * project status * release history * how to use * prerequisites * installation * example of use * plugin * certification authority with mosquito * license * contribution * author <!--te--> goals ================= the general objective of this work is to provide a framework focused on digital mental health phenotyping (dpmh). the solution will facilitate the development of mobile applications that can passively collect context data, process it, and generate high-level information. therefore, this framework aims to create a software base to support the implementation of solutions that aim to recognize patterns of behavior and habits of users, which can support mental health professionals in their analyses, diagnoses, and treatments. align=""center""> <img alt=""arquitetura-framework"" title=""#arquitetura"" src=""/framework.png"" /> core components: * dpmanager: responsible for managing the framework (e.g., start/stop, start/stop the processors, configuring the composition mode of phenotypecomposer). * processormanager: manages activedataprocessor (e.g., start/stop activedataprocessor), start/stop sensors, and identifies new plugin that has been installed. * dataprocessor: the class where the processors will be implemented (e.g., sociability, mobility, sleep, physical activity). * rawdatacollector: the class responsible for collecting the raw data and distributing it to the broker, provides epl resources for the developer to create their cep rule. * phenotypecomposer: composes digital phenotypesevent of users, receiving directly from the data processor of detected events (eg phone calls, sms, gps, accelerometer). plugin components: * pluginmanager: class responsible for managing the plugin and its data processing modules that it belongs to. when starting, it sends the list of data processing modules to the core, when the core receives this list, it returns only the modules that it is interested in starting, receives data from the core's sensors, processes them, and returns to the core. * dataprocessor: features the same functionality in core. ![](header.png) project-status ================= align=""center""> framework - finished... ### features - [x] dpmanager - [x] processormanager - [x] dataprocessor - [x] phenotypecomposer - [x] rawdatacollector release-history ================= * * security adaptation (digital certificates) in progress. * adaptation of virtual sensors to the m-hub. how-to-use ================== prerequisites ----- * android version: * android api version: minsdkversion > installation ----- linux & windows: ```sh option (github project): * download the zip project, unzip it. * then open with in android studio ""open an existing project"", ready. ``` ```sh option (aar files): under construction... ``` ```sh option (apk): under construction... ``` example-of-use ----- dpmanager ```sh public dpmanager digitalphenotypingmanager; ``` start-framework: ```sh option: - send_when_it_arrives - group_all - frequency - setfrequency(value). ``` ```sh digitalphenotypingmanager = new dpmanager.builder(this) .setcompositionmode(compositionmode.frequency) .build(); digitalphenotypingmanager.start(); ``` stop-framework: ```sh digitalphenotypingmanager.stop(); ``` start-activedataprocessor: ```sh list<string> listprocessors = digitalphenotypingmanager.getinstance().startdataprocessors(listprocessors); ``` stop-disabledataprocessor: ```sh list<string> listprocessors = digitalphenotypingmanager.getinstance().stopdataprocessors(listprocessors); ``` plugin ================= instructions for use. ----- https://github.com/jeancomp/plugin certification-authority-with-mosquito ================= instructions for use. ----- https://github.com/jeancomp/certification-authority-with-mosquito license ================= your name @twitter jean.marques@lsdi.ufma.br distributed under the xyz license. see ``license`` for more information. https://github.com/ contribution ================= main developer: jean pablo (<https://github.com/jeancomp>) contributors: ariel teles (https://github.com/arielsteles) andr <!-- markdown link & img dfn's --> [npm-image]: https://img.shields.io/npm/v/datadog-metrics.svg?style=flat-square [npm-url]: https://npmjs.org/package/datadog-metrics [npm-downloads]: https://img.shields.io/npm/dm/datadog-metrics.svg?style=flat-square [travis-image]: https://img.shields.io/travis/dbader/node-datadog-metrics/master.svg?style=flat-square [travis-url]: https://travis-ci.org/dbader/node-datadog-metrics [wiki]: https://github.com/yourname/yourproject/wiki author ================= <a href=""https://github.com/jeancomp""> <a href=""https://imgbb.com/""><img src=""https://i.ibb.co/mslwgfj/jp.jpg"" alt=""jp"" /></a> <br /> <sub><b>jean pablo</b></sub></a> made by jean pablo contact! [!linkedin badge](https://www.linkedin.com/in/jean-pablo-marques-mendes/) [!gmail badge](mailto:jeancomp@gmail.com)"
1,LAMP-core-android,core scaffolding for digital phenotyping apps with reactive user interfaces. (android),"# native gradle sample using a node project folder an android studio project that uses the `node.js on mobile` shared library, as an example of using a node project folder inside the application. the sample app runs the node.js engine in a background thread to start an http server on port the app's main activity ui has a button to query the server and show the server's response (i.e. the `process.versions` value, alongside the result of using the `left-pad` npm module). alternatively, it is also possible to access the server from a browser running on a different device connected to the same local network. ## how to run - clone this project. - run `npm install` inside `android/native-gradle-node-folder/app/src/main/assets/nodejs-project/`. - download the node.js on mobile shared library from here. - copy the `bin/` folder from inside the downloaded zip file to `app/libnode/bin` (there are `copy-libnode.so-here` files in each architecture's path for convenience). if it is been done correctly you will end with the following paths for the binaries: - - - - - in android studio import the `android/native-gradle/` gradle project. it will automatically check for dependencies and prompt you to install missing requirements (i.e. you may need to update the android sdk build tools to the required version and install cmake to compile the c++ file that bridges java to the node.js on mobile library). - after the gradle build completes, run the app on a compatible device. ## how the sample was developed this sample was built on top of the `native-gradle` sample from this repo, with the same functionality, but uses a `nodejs-project` folder that contains the node part of the project. ### create the `nodejs-project` folder create a `nodejs-project` folder inside the project, in gradle's default folder for android's application assets (`app/src/main/assets/nodejs-project`). create the `main.js` and `package.json` files inside: - `app/src/main/assets/nodejs-project/main.js` contents: ```js var http = require('http'); var versions_server = http.createserver( (request, response) => { response.end('versions: ' + json.stringify(process.versions)); }); console.log('the node project has started.'); ``` - `app/src/main/assets/nodejs-project/package.json` contents: ```js { ""name"": ""native-gradle-node-project"", ""version"": ""description"": ""node part of the project"", ""main"": ""main.js"", ""author"": ""janeasystems"", ""license"": """" } ``` ### add an npm module to the `nodejs-project` having a `nodejs-project` path with a `package.json` inside is helpful for using npm modules, by running `npm install {module_name}` inside `nodejs-project` so that the modules are also packaged with the application and made available at runtime. install the `left-pad` module, by running `npm install left-pad` inside the `app/src/main/assets/nodejs-project/` folder. update `app/src/main/assets/nodejs-project/main.js` to use the module: ```js var http = require('http'); var leftpad = require('left-pad'); var versions_server = http.createserver( (request, response) => { response.end('versions: ' + json.stringify(process.versions) + ' left-pad: ' + }); console.log('the node project has started.'); ``` ### copy the `nodejs-project` at runtime and start from there to start the `node.js` engine runtime with a file path, we need to first copy the project to somewhere in the android file system, because the android application's apk is an archive file and `node.js` will not be able to start running from there. for this purpose, we choose to copy the nodejs-project into the application's `filesdir`. add the helper functions to `app/src/main/java/com/yourorg/sample/mainactivity.java`: ```java import android.content.context; import android.content.res.assetmanager; ... private static boolean deletefolderrecursively(file file) { try { boolean res=true; for (file childfile : file.listfiles()) { if (childfile.isdirectory()) { res &= deletefolderrecursively(childfile); } else { res &= childfile.delete(); } } res &= file.delete(); return res; } catch (exception e) { e.printstacktrace(); return false; } } private static boolean copyassetfolder(assetmanager assetmanager, string fromassetpath, string topath) { try { string[] files = assetmanager.list(fromassetpath); boolean res = true; if { //if it is a file, it will not have any assets ""inside"" it. res &= copyasset(assetmanager, fromassetpath, topath); } else { new file(topath).mkdirs(); for (string file : files) res &= copyassetfolder(assetmanager, fromassetpath + ""/"" + file, topath + ""/"" + file); } return res; } catch (exception e) { e.printstacktrace(); return false; } } private static boolean copyasset(assetmanager assetmanager, string fromassetpath, string topath) { inputstream in = null; outputstream out = null; try { in = assetmanager.open(fromassetpath); new file(topath).createnewfile(); out = new fileoutputstream(topath); copyfile(in, out); in.close(); in = null; out.flush(); out.close(); out = null; return true; } catch(exception e) { e.printstacktrace(); return false; } } private static void copyfile(inputstream in, outputstream out) throws ioexception { byte[] buffer = new int read; while ((read = in.read(buffer)) != { out.write(buffer, read); } } ``` before starting the node runtime, delete the previous `nodejs-project` and copy the current one into the `filesdir` and start the runtime from there: ```java new thread(new runnable() { @override public void run() { //the path where we expect the node project to be at runtime. string nodedir=getapplicationcontext().getfilesdir().getabsolutepath()+""/nodejs-project""; //recursively delete any existing nodejs-project. file nodedirreference=new file(nodedir); if (nodedirreference.exists()) { deletefolderrecursively(new file(nodedir)); } //copy the node project from assets into the application's data path. copyassetfolder(getapplicationcontext().getassets(), ""nodejs-project"", nodedir); startnodewitharguments(new string[]{""node"", nodedir+""/main.js"" }); } }).start(); ``` > attention: given the project folder can be overwritten, it should not be used for persistent data storage. ### copy the `nodejs-project` only after an apk change recopying the `nodejs-project` at each application's run can be expensive, so improve it by saving the last time the apk was updated on an application shared preference and check if we need to delete and copy the `nodejs-project`. add the helper functions to `app/src/main/java/com/yourorg/sample/mainactivity.java`: ```java import android.content.pm.packageinfo; import android.content.pm.packagemanager; import android.content.sharedpreferences; ... private boolean wasapkupdated() { sharedpreferences prefs = getapplicationcontext().getsharedpreferences(""nodejs_mobile_prefs"", context.mode_private); long previouslastupdatetime = prefs.getlong(""nodejs_mobile_apk_lastupdatetime"", long lastupdatetime = try { packageinfo packageinfo = getapplicationcontext().getpackagemanager().getpackageinfo(getapplicationcontext().getpackagename(), lastupdatetime = packageinfo.lastupdatetime; } catch (packagemanager.namenotfoundexception e) { e.printstacktrace(); } return (lastupdatetime != previouslastupdatetime); } private void savelastupdatetime() { long lastupdatetime = try { packageinfo packageinfo = getapplicationcontext().getpackagemanager().getpackageinfo(getapplicationcontext().getpackagename(), lastupdatetime = packageinfo.lastupdatetime; } catch (packagemanager.namenotfoundexception e) { e.printstacktrace(); } sharedpreferences prefs = getapplicationcontext().getsharedpreferences(""nodejs_mobile_prefs"", context.mode_private); sharedpreferences.editor editor = prefs.edit(); editor.putlong(""nodejs_mobile_apk_lastupdatetime"", lastupdatetime); editor.commit(); } ``` change the code that starts the node runtime to check if it needs to delete the previous `nodejs-project` and copy the current one into the `filesdir`: ```java new thread(new runnable() { @override public void run() { //the path where we expect the node project to be at runtime. string nodedir=getapplicationcontext().getfilesdir().getabsolutepath()+""/nodejs-project""; if (wasapkupdated()) { //recursively delete any existing nodejs-project. file nodedirreference=new file(nodedir); if (nodedirreference.exists()) { deletefolderrecursively(new file(nodedir)); } //copy the node project from assets into the application's data path. copyassetfolder(getapplicationcontext().getassets(), ""nodejs-project"", nodedir); savelastupdatetime(); } startnodewitharguments(new string[]{""node"", nodedir+""/main.js"" }); } }).start(); ``` ### redirect the stdout and stderr to logcat the node.js runtime and the node.js `console` module use the process' `stdout` and `stderr` streams. some code is needed to redirect those streams to the android system log, so they can be viewed with logcat. this sample adds c++ code to manage the redirection by starting two background threads (one for `stdout` and the other for `stderr`), to provide a more pleasant node.js debugging experience. add the helper functions to `app/src/main/cpp/native-lib.cpp`: ```cc #include <pthread.h> #include <unistd.h> #include <android/log.h> ... // start threads to redirect stdout and stderr to logcat. int int pthread_t thread_stdout; pthread_t thread_stderr; const char *adbtag = ""nodejs-mobile""; void *thread_stderr_func(void*) { ssize_t redirect_size; char while((redirect_size = buf, sizeof buf - > { //__android_log will add a new line anyway. if(buf[redirect_size - == '\n') --redirect_size; buf[redirect_size] = __android_log_write(android_log_error, adbtag, buf); } return } void *thread_stdout_func(void*) { ssize_t redirect_size; char while((redirect_size = buf, sizeof buf - > { //__android_log will add a new line anyway. if(buf[redirect_size - == '\n') --redirect_size; buf[redirect_size] = __android_log_write(android_log_info, adbtag, buf); } return } int start_redirecting_stdout_stderr() { //set stdout as unbuffered. setvbuf(stdout, _ionbf, pipe(pipe_stdout); stdout_fileno); //set stderr as unbuffered. setvbuf(stderr, _ionbf, pipe(pipe_stderr); stderr_fileno); if(pthread_create(&thread_stdout, thread_stdout_func, == return pthread_detach(thread_stdout); if(pthread_create(&thread_stderr, thread_stderr_func, == return pthread_detach(thread_stderr); return } ``` start the redirection right begore starting the node.js runtime: ```cc //start threads to show stdout and stderr in logcat. if { __android_log_write(android_log_error, adbtag, ""could not start redirecting stdout and stderr to logcat.""); } //start node, with argc and argv. return jint(node::start(argument_count,argv)); ```"
1,BraPolar,"brapolar is an android m-health for remote monitoring patients with bipolar affective disorder, presenting real-time mood and behavior fluctuations in participants through interaction with their mobile devices.","# brapolar align=""center""> <img src=""./doc/demo.gif"" /> --- ## about **brapolar is an android m-health for remote monitoring of patients with bipolar affective disorder. the app presents real-time mood and behavior fluctuations to specialists from participants through their interaction with mobile devices. this project was part of my master's degree dissertation in brazil. in this work, i could execute all software development cycles from scratch, including android applications, and documentation. also, i could practice all research processes of scientific research writing and presenting this work at an international conference in kyoto, japan. --- ## screenshots **project scratch** align=""center""> <img class=""center"" /> **task planning** align=""center""> <img src=""./doc/maquetado_trello.jpg"" /> **bipolar symptoms and how follow-up with cellphone sensors** align=""center""> <img /> **firebase data stream architecture** align=""center""> <img /> **brapolar login (left), participant home (center), keyboard typing (right) align=""center""> <img src=""./doc/brapolar_login.png"" /> <img src=""./doc/brapolar_participantehome.jpg"" /> <img src=""./doc/brapolar_keyboardtestwhatsapp.jpg"" /> **firebase active users during data capture** align=""center""> <img src=""./doc/usuarios_ativos.jpg"" /> **firebase non-relational database instance sample** align=""center""> <img src=""./doc/firebasedatabase.jpg"" /> **specialist user (center) monitoring mood fluctuations of two patients (left and right)** align=""center""> <img src=""./doc/demo.gif"" /> **paper presentation in kyoto, japan** align=""center""> <img <img --- ## versioning - brapolar (expected in - brapolar (relased in - brapolar (relased in - brapolar (relased in - brapolar (relased in - brapolar (relased in - brapolar (relased in - brapolar (relased in this project was part of my master's degree dissertation and my ph.d. thesis, which is running. from to preserve scientific code rights, i will not upload new public versions on github until concluding my doctoral degree and get the authorization to publish all code. --- ## main tracking features - [x] mood - [x] medication - [x] sleep patterns - [x] status overview - [x] physical activity - [x] social interaction - [ ] psycho-motor activity - [ ] specialized assistance - [ ] acoustic characteristics --- ## technology - android - java - firebase --- ## how to setup ```bash # clone the project $ git clone https://github.com/abelgonzalez/brapolar.git ``` ```bash # enter directory $ cd brapolar ``` download and install: - android studio - jre --- ## how to run *build a brapolar app: - make sure the database in firebase was correctly loaded, and you have a stable internet connection. - load the root project folder (**brapolar**) with android studio and run it. - when apps run, grant all permissions to android application. or *executes an apk in your android phone: - enter in (...)\brapolar\app\build and execute with login ""login instructions.txt"". --- ## scientific contributions * a. gonzlez mondjar, g. f. m. silva-calpa, a. barbosa raposo and d. c. mograbi, ""brapolar: an m-health application for remote monitoring of people with bipolar disorder,"" ieee international conference on serious games and applications for health (segah), kyoto, japan, pp. doi: * a. gonzlez mondjar, g. f. m. silva-calpa, a. barbosa raposo and d. c. mograbi, ""an m-health application for remote monitoring of people with bipolar disorder through digital phenotyping and smartphone dependency,"" ieee international symposium on computer-based medical systems (cbms), rochester, mn, usa, pp. doi: --- ## additional information * app demo youtube * brapolar patient interaction demo youtube * brapolar specialists interaction demo youtube * master degree dissertation document (in portuguese). * in case of sensitive bugs like security vulnerabilities, do not hesitate to contact me at abelgodev@gmail.com instead of using the issue tracker. i value your effort to improve the security and privacy of this project! --- ## license this project is under the mit license. see the file <a href=""https://github.com/abelgonzalez/brapolar/license"">licence</a> for more details. --- ## author <p align=""center"">done with by abel gonzlez mondjar</p> [!linkedin badge](https://www.linkedin.com/in/abelgonzalezmondejar/)"
0,daily_journal_dataflow_qc,app-based daily audio journal processing pipeline: dataflow and qc management,"# app-based daily audio journal processing pipeline: dataflow and qc management code for data organization, participation monitoring, and quality control of daily app-based audio journal recordings for psychiatric research. this pipeline is currently being used by the ampscz project -- a large, collaborative, multimodal data collection initiative spearheaded by the nimh. the audio journal format provides great opportunity for data science research directions that are not well suited for other more traditional speech sampling sources, and it also enables interesting patient-driven self reporting that cannot be obtained with other more common digital phenotyping approaches. note that i will use ""journal"" and ""diary"" interchangeably throughout. substantial additional information on both the ampscz project and the audio joural datatype can be found within my thesis. however, the present pipeline was written because of those arguments, to prevent neglect of audio diaries in the future. therefore all documentation specifically about this pipeline and its early utility within ampscz are restricted to the readme here. this readme provides setup and use information for future projects that might wish to utilize a version of this code, as well as implementation details and data monitoring tips to assist not only in potential adaptation of the pipeline but also its continued use in ampscz. the documentation is up to date as of early july at which time responsibility for the code is being gradually passed on to others involved in the project. - michaela ennis ### table of contents setup use - configuration files - input data requirements - key outputs - runtime and storage considerations implementation - site-level processing steps - server-wide summary steps guide to monitoring tools - weekly summary html email contents - weekly detailed logging email csvs and pdfs next directions ### setup <a name=""setup""></a> it is highly recommended that this code is run on a linux machine, but there are minimal hardware requirements as the pipeline was designed with low compute resources in mind. given the somewhat large file sizes of recorded audio however, a decent amount of system storage space is expected (to be detailed). the code requires ffmpeg (tested version and (tested version to be installed, as well as use of standard bash commands, including realpath and dirname. for the email alerting to work, the mailx and sendmail commands must be configured. the python package dependencies can be found in the setup/audio_process.yml file, with the exception of soundfile and librosa. if is installed this yml file can be used directly to generate a usable python environment. <details> <summary>for the ampscz project, the above dependencies were already installed and the mail commands configured on the relevant servers by it. thus i installed my code with the following steps (once in the directory location intended for software installs):</summary> <br> * git clone https://github.com/dptools/daily_journal_dataflow_qc.git * cd daily_journal_dataflow_qc/setup * conda env create -f audio_process.yml * conda activate audio_process * pip install soundfile * pip install librosa * sudo yum -y install libsndfile - this last step was done on prescient data aggregation server only, to get soundfile and librosa to work there. it may or may not be necessary to do this then, depending on what libraries are already installed by it on your machine. - if it is missing, it might require contacting it to do the libsndfile installation, if you do not have sudo access (which ideally the account officially running daily av processing should not, to protect raw file integrity). </details> note that the setup of the python audio_process environment is a subset of what is already described in the setup instructions for the process_offsite_audio repository, which handles dataflow and quality control for recordings of participant interviews collected by ampscz. if that repository is already fully installed and running, as was the case here, there is no need to do any of these installation steps besides cloning the repository (though i did confirm the availability of pytz and seaborn in the conda env and the usability of sendmail, as those are dependencies here but were never directly used in the interview code). one can proceed to the next section with instructions on use of the code instead. <details> <summary>if installing from scratch in a separate context, there will be other possible setup steps required after the above steps though, particularly for various integrations. for example, we used the same transcribeme sftp account for diaries as we did for interviews on each server, but if a separate project instead it would have been necessary to pursue transcribeme setup again. details on these possible extra steps for a blank projects are as follows:</summary> <br> in addition to the direct dependencies, there are also indirect dependencies on assumptions about mindlamp app recording and download settings, and for ampscz there are interactions with other tools written for the purposes of digital psychiatry study management as well -- mainly the lochness and dpdash codebases, which were further adapted specifically for the use of the ampscz project. lochness is used for pulling the data submitted by sites and enforcing the expected folder structure, but it would be possible to recreate the folder structure manually or with different software if desired. dpdash is used for visually monitoring updates to the dataset via a regularly refreshing web portal, but is not strictly necessary. for information on installing lochness and/or dpdash, please see the amp-scz github team. to ensure the mindlamp audio recording logistics are in-line with our default expectations, please consult with mindlamp representatives, making reference to the ampscz project and the dpacc software team. if all these steps are followed, the code here will be immediately able to function within the established framework, described further in the upcoming section on pipeline usage. finally, besides the code installation, note that for the transcript portion of the pipeline it will be necessary to have a transcribeme sftp account set up with expected transcription settings, including return format of .txt with no headers and encoding. specifically, ampscz uses the transcribeme full verbatim transcription service for its uploaded interviews with sentence-level timestamps, which is a manually done human (professional) service. produced transcripts are hipaa-compliant with personally identifying information (pii) marked. we use the ""ai learning team"" of transcribers to ensure a maximal level of care is taken in transcription accuracy. a transcribeme rep can assist in matching ampscz's protocol for future projects, as it will also be necessary to ensure that you have a username and password that would enable upload to a private sftp server setup by transcribeme, rather than using their default web interface for upload. for more details on the exact output conventions expected from transcribeme, please refer to transcribeme's (english) style guide. one can also search for more details on transcribeme within my thesis pdf. </details> ### use <a name=""use""></a> within the ampscz\_diaries\_launch subfolder of the present repository, we can see exactly how the codebase is used on the ampscz servers. the two high level wrapping scripts, pronet\_all\_sites\_cron\_script.sh and prescient\_all\_sites\_cron\_script.sh, are the scripts used to launch the full pipeline on pronet and prescient servers respectively, queued via cronjob. both of these files are split into two major sections demarcated by comments: ""server specific components"" and ""more general components"". the latter is the same between the two files, and for using the code on a new server with an otherwise identical infrastructure plan one could simply copy the entire script and change only the server specific settings as needed. <details> <summary>to better understand the overall structure of the code base, we can first walk through the steps done by ""more general components"":</summary> <br> using the provided absolute paths to both the code installation and the folder containing the configuration files of interest on the current server, the script calls the top level bash script run\_full\_pipeline\_all\_sites.sh to process each site with a config file found within the given settings folder path. * run\_full\_pipeline\_all\_sites.sh simply loops through each configuration .sh file found to run the per-site audio processing pipeline branch, the per-site transcript processing pipeline branch, and finally the per-site subject summaries pipeline branch. the bash scripts managing each of these branches can be found in the site\_level\_pipeline\_branches folder within this repository, and those scripts call on a number of python modules found in the site\_level\_pipeline\_branches/subject\_level\_functions subfolder. * logs for each site are saved in a site-specific subfolder within the logs folder created under the installation path of this repository, with one text file saved per pipeline branch and run (the latter is marked by unix timestamp). using the provided server monitoring settings, when intended the cronjob script will also run the top level bash script site\_wide\_summary\_generation.sh to create summaries of site by site progress across the entire server and email out additional monitoring information to specific contacts. * site\_wide\_summary\_generation.sh uses the python functions found in the server\_level\_summary\_functions folder within this repository, in addition to managing the bash functionalities required for compilation and sending of the monitoring emails. * logs from the summary run are saved in a date-specific subfolder within the logs/total subfolder created under the installation path of this repository, with a text file saved for each run alongside all of the generated stats and images used in the various emails. again using the provided server-specific settings, the group assignment and permissions of all generated code outputs are updated, to ensure access issues will not impact integration with other ampscz code or ultimately the downstream use of these outputs. note that further details on the code implementing the components of both steps and steps will be discussed in an upcoming section, and within this section there will shortly be a subsection on setting up the described configuration files. </details> <details> <summary>to actually utilize the described cron scripts in launching the code for a new server, we will now review the settings to be updated within ""server specific components"", as well as the commands run there to activate the needed dependencies before starting the main cronjob:</summary> <br> * server_label gives a name to be used within email subject lines and other server-wide summary output annotations. * repo_path should be the absolute path to the repository installation folder on the server. * configs_path should be the absolute path to the folder containing the configuration files for each site to be processed by the main pipeline. setup of configuration files will be discussed shortly. * permissions_group_name should be the name of the group on the server that you want all code outputs and log files to belong to. * data_root should be the absolute path to the main data structure, for ampscz expected to be the phoenix folder described also in the configs subsection below. * basic_email should be the comma-separated list of email addresses to receive the server-wide weekly basic html summary email, which is detailed within the below monitoring section. * basic_email_from gives the email address that the basic email will appear to be sent from via the sendmail command. * detailed_email should be the comma-separated list of email addresses to recieve the more detailed server-wide weekly monitoring attachments email, which is also detailed within the below monitoring section. this list would generally be expected to be a subset of basic_email. * mailx_attach should be the letter used in the flag for attachments with the version of mailx installed on the current server. for ampscz, we must use -a on pronet and -a on prescient, though -a is typically more common. thus the code will use -a if this is explicitly set to ""a"", otherwise it will assume -a. * daily_testing_mode when set to will run the summary step across sites daily and send the resulting emails to a different address list, otherwise the code will operate as normally intended -- i.e. running the site\_wide\_summary\_generation.sh wrapping script only on mondays, and ensuring the input recipient email addresses match the above mentioned settings. * testing_email gives the email addresses to receive both the basic and detailed emails instead of the normal lists, only when the code is in daily testing mode. finally, the server-specific components portion runs needed commands to set up dependencies, like the python environment and ffmpeg, that will be needed in order for the code to successfully run on cron (or at all). for pronet, this involves sourcing the conda.sh file under the server's installation of and then activating the audio_process environment. for prescient it is very similar, but also involves sourcing the running user's .bash_profile, where it is ensured that the folder containing the ffmpeg executable is part of the path variable, among other things. this part was determined somewhat through trial and error, but one could also systematically setup that all dependencies are findable on the server account that will run the cronjob via the provided commands in this section. </details> ##### configuration files <a name=""config""></a> within the repository subfolders ampscz\_diaries\_launch/pronet\_configs and ampscz\_diaries\_launch/prescient\_configs, we can find all config files currently being used to run the main diary pipeline on each respective ampscz server to date. as described above, there is one configuration file per site, which contains the needed settings information to run all the branches called by run\_full\_pipeline\_all\_sites.sh for that site. in this subsection, i will walk through all the settings found in a configuration file. implementation details of the main pipeline branches will then be covered in an upcoming section. <details> <summary>referring to example configs within the aforementioned config folders could provide additional useful context here. the settings that can be specified for the pipeline via site-level config file currently are as follows:</summary> <br> * data_root, which is the root path to the main data structure folder. for a given ampscz server this is the same across sites, and within the baker lab this would be the same across most studies (but not all, as data from some different collaborations are kept on different briefcases). in our terminology, this would be the path on the server to the phoenix folder. * site, which is the name of the site (e.g. pronetla) on the server, or if used for single-site projects, the name of an individual study to be processed (e.g. bls for the baker lab). this must match the folder name corresponding to the site (or study). * auto_send_on, which for ampscz is expected to always be ""y"" (or ""y""). if ""n"" (or anything else), then qc will be computed for the audio without sending anything to transcribeme. in that case, any audios selected for upload will be left in the corresponding subjects' audio_to_send folders, and issue logging will treat the files as if sftp upload failed. this means that if the auto_send_on is ever turned to ""y"", all backlog approved audios will also be uploaded to transcribeme at that time, unless they had been manually cleared out beforehand. * if the need does arise to pause processing for one or more ampscz sites, potentially due to budget constraints (a much harder problem to forecast for diaries than interviews), this variable could be used to accomplish that while maintaining basic tracking. however i would not recommend regularly flipping this setting back and forth to pause and unpause uploads, as it has not been thoroughly tested and could complicate project monitoring. * one could of course turn the code off entirely for a given site by removing its config file from the server's pool, or comment out the cronjob to pause the code across sites. note that this could because loss of transcripts for already uploaded audios though if it will be done for an extended period and the pausing process is not carefully manually monitored, whereas transcript pull will continue when auto_send_on = ""n"". * transcribeme_username, which should be the username used to login to the transcribeme sftp server where data transfer for the project is intended to take place. for ampscz this is one email for all pronet sites and one email for all prescient sites. for a lab group this may always be the same username across studies, or it may vary depending on payment allocation details. * length_cutoff, which is the minimum duration for an individual diary recording to be sent to transcribeme, in seconds. here we use second to avoid sending garbage recordings. * db_cutoff, which is the minimum volume for a diary recording to be considered acceptable for transcription. this may vary based on both data collection protocol details and project analysis goals/budgetary allowance. for these diaries we decided on db based on early testing. * transcription_language, which is a string (currently in all caps) that specifies the primary language at a given site. the pipeline uses this string in the filename it uploads to transcribeme, to assist their process in assigning the correct transcription team to a given upload. when transcripts are pulled back this part of the name is removed, so it is used only in the transcribeme upload process and not on actual pipeline outputs (or intermediates). this could theoretically be used to convey other messages to transcribeme such as transcription settings, in future adaptation of the code. the information here will also be compiled as part of metadata that goes to the nih data repository for ampscz. * at this time however we are only uploaded english-language audio journals to transcribeme, something discussed in more detail in the future directions section at the end of this readme. for foreign sites, it is less clear how we can accurately label language by simply assuming the same language will be used in all diaries site-wide, and transcribeme requires an accurate language designation to produce our transcripts currently. * timezone, which is the timezone to assume that all diary submissions from the given site are recorded in. this allows the utc submission time noted by mindlamp to be converted to the relevant local time, and study day assignment to be adjusted accordingly when needed. while there are edge cases where this will be incorrect, it is by and large a fine assumption for ampscz's purposes and the sites we are working with. the timezone should be listed in the settings file as a string matching an iana designation. iana timezone identifier can be found for any location by looking that location up on the website time.is. note that while these config settings share some similarities with the configs used for the interview dataflow/qc pipeline of ampscz, there are a number of distinctions and the ones used here were setup entirely separately. </details> to add new sites to the existing processing for the ampscz project, one can simply add another config in the appropriate folder for that central server, working from the existing configs for that server as a template (and referring to the settings list where additional details are needed). in general, only ""site"", ""transcription_language"", and ""timezone"" might require changes from site to site for an already established server within the scope of ampscz. one would then just need to make sure that there are not issues with folder permissions when lochness initializes the structure for that site. obviously for setting up a brand new process, one would aim to replicate the current setup for pronet and prescient as far as settings files and cronjob go, after following the installation instructions in the preceding section to get the code and its dependencies onto the new central server. in the case of a new central server, it would obviously be necessary to change some further settings within each new config -- such as the transcribeme username, which would require creating a separate sftp account with transcribeme reps first, as described in the setup instructions above. <details> <summary>on that note, the final component built into the config .sh file is the management of the password for the specified transcribeme sftp account, which i will describe how to set up for new servers/projects here:</summary> <br> in order for the code to run automatically on a cronjob, the password for the transcribeme sftp server needs to be stored somewhere on the source server. by default, this is assumed to be in a file named .passwords.sh directly under the repo folder where the code is being run. the .gitignore included with the code will ensure that the .passwords.sh file is never pushed back to the central repository (as well as any logs generated by the code more broadly). on both pronet and prescient data aggregation servers, this passwords file has permissions and is owned by the account that is set to run the pipeline code. for more on privacy/security, see the security review section in the process_offsite_audio repository, which already established all the needed considerations for working with sensitive audio data as part of ampscz. if one will use an identical setup to the ampscz central lochness servers, then it is straightforward to just create the daily_journal_dataflow_qc/.passwords.sh file directly and then paste in the following two lines: transcribeme_password=""password"" export transcribeme_password where of course ""password"" is replaced with the transcribeme sftp account password corresponding to that server's account (i.e. the username within the same config file). note that transcribeme will also periodically require this password to be updated, so for all projects (including both accounts for ampscz) it will be necessary to occasionally update the password contained in the .passwords.sh file directly on the applicable server. in our case, we can simply copy .passwords.sh from process_offsite_audio to daily_journal_dataflow_qc. if one wants to store the password file elsewhere or needs to use different password files for different studies/sites operating out of the same server (because different transcribeme sftp accounts are being used), the path to the passwords file can be specified using the passwords_path variable found at the bottom of each config file. the passwords file itself needs to be an *sh* file type with content matching the above to work out of the box, but there is no other restriction on the naming/folder placement (as long as the running account can access) when its path is appropriately specified within the corresponding config.sh settings file. </details> ##### input data requirements <a name=""inputs""></a> with configuration files set up, the code should be immediately runnable for new sites within the ampscz framework. however if planning to adapt to a different new project, it could be important to understand more deeply the specific input expepctations of the code -- for example, if needing to replicate input folder structure without using lochness, or wanting to move to a different app for diary collection than mindlamp. as such, i will provide here the specific input expectations for journals to be processed on a data aggregation server by this code. this subsection will additionally provide useful context for understanding the implementation details of the upcoming section. ultimately, the code expects to work within a phoenix data structure matching the conventions described in the ampscz standard operating procedure (sop). it is worth highlighting that this pipeline expects all inputs to be found as raw datatypes under phoenix, and similarly all outputs are saved/modified as processed datatypes only. the conventions specified therefore cover high level folder structure as well as details of raw diary paths. <details> <summary>more specifically, the overall folder structure is expected to meet the following criteria on the central server, for each site to be processed:</summary> <br> * there needs to be a folder named with corresponding site id under both the general and protected subfolders of phoenix. * under the site's general side folder there must be at least a processed subfolder, and under the protected site folder there must be both processed and raw subfolders. * under each of phoenix/protected/\[site\]/raw, phoenix/protected/\[site\]/processed, and phoenix/general/\[site\]/processed, there should be one subfolder for each enrolled participant -- with name matching the corresponding ampscz subject id. under each of those folders, we then expect a ""phone"" subfolder if the participant indeed does have phone data. * missing subject id folders will not prevent the code from running for other subjects in an input site, but it can obviously prevent any missing subjects from having possible diaries processed. </details> <details> <summary>we then expect raw audio journal data, found under each subject's protected side raw phone folder, to meet the following conventions:</summary> <br> * both recording and matching json metadata for every submitted diary by that subject will be found loose under the phoenix/protected/\[site\]/raw/\[subject\]/phone/ * the should be named as with datestamp defined based on unix time (i.e. utc) and number based on the submission number it was for that id on that (utc-determined) day, starting with * a specific example filename for an is * in that same folder, there must also be a json corresponding to each named as you\[mindlampid\]\_\[site\]\_activity\_\[datestamp\].json * note that if multiple were uploaded on a single utc date for that subject, they are expected to be matched to the same json. * the code does not necessarily expect a specific mindlampid for a given subject, except that it must match between json and correpoding available. * the jsons here contain info from both ema responses and audio diary metadata, so it is possible to have json files without any matching however, when actually parsing the data in the json, we can find where metadata expects a diary was recorded -- in this case, we absolutely do expect that the specified exist. * to determine if an object within a checked json is meant to be diary metadata, we look for a ""static_data"" field in that item, and a ""url"" field under the ""static_data"" field. for valid diaries, the value under the ""url"" field will specify the sound number as etc. non-diary records will not have any value in this field, if it exists at all. * when there are multiple diaries submitted in one utc day, there will simply be multiple objects within the json that have the sound number specified within the aforementioned field. for each of these, we expect to find an in the corresponding raw data folder with the same name as the json (sans extension), but with appended, according to the sound number given via the json. * obviously, for all found, we expect to find such a record directly in the correponding json too. * additionally, for a valid diary metadata json object, we also want to find the precise unix timestamp of submission directly under ""timestamp"" field of that item. note that a recent change made by mindlamp broke some of these json expectations, but it also broke the pulling of audio diary by lochness entirely, and this change only affected pronet for some reason, not prescient. we are working with mindlamp to revert this change and go back to the described expectations. </details> note in addition to the expectations for naming of incoming raw data, the code also requires a metadata file directly within the site-level folder contained on the general side, and will only process a particular participant id if that id appears as a row in said metadata file with a corresponding valid consent date (per lochness guidelines, though again this could be replicated independently). if there are issues encountered with the basic study setup appropriate error messages will be logged about violated conventions. the transcript side of the pipeline on the other hand primarily relies on outputs from the audio side, so once audio processing is successfully running structure should be automatically enforced for these downstream steps. however, it also expects transcribeme to return transcripts with a name identical to the uploaded audio filename, just with the extension switched to .txt. so it is possible, though not an issue we have encountered, that transcribeme could because a stall in processing by violating naming conventions. monitoring of audio pending transcription for an excessive number of days is built into the code in case we do need to catch this. ##### key outputs <a name=""outputs""></a> with code installed and folder structure and input expectations in place, we can finally discuss the primary outputs of the pipeline. thus in this subsection we first introduce and really motivate the pipeline by providing an outline of the most key outputs generated, along with how they might be used downstream and where they can be expected to be found on the server. details on intermediate outputs and more specifics about final output content (as well as how that content is obtained) will be part of the upcoming implementation section. for ampscz, lochness is already setup to push any text file or csv outputs found anywhere under the phone datatype on the general side of processed to the *predict* server for downstream processing. this is where files can be staged to be shared with the nih data repository or imported into tools like dpdash. we therefore have our key shareable outputs all found within corresponding phoenix/general/\[site\]/processed/\[subject\]/phone/audio_journals folders. <details> <summary>those shareable outputs are:</summary> <br> * redacted transcribeme transcript text files, each found under a subfolder ""transcripts"" of the mentioned audio_journals general processed folder. * file names for these transcripts are of the form \[site\]\_\[subject\]\_audiojournal\_day\[####\]\_submission\[#\]\_redacted.txt * csv-formatted transcripts with simple sentence-level metrics alongside the text and metadata pulled from transcribeme for each row. these csvs can be found under a subfolder ""csvs_with_per_sentence_stats"" of the aforementioned transcripts folder. * file names for the csvs match those for the corresponding transcript texts, except with txt extension removed and ""\_withsentencestats.csv"" appended instead. * provided sentence counting stats are basic metrics related to quanitfying known transcribeme notation; the exact columns included will be given when expanding on implementation details below. * found directly under each audio_journals shareable output folder for an applicable subject, we also have two dpdash-formatted csvs giving audio and transcript qc metrics (respectively) for each processed diary for that subject, where available. * the audio qc csv has name in the form \[twodigitsiteid\]-\[subject\]-diaryaudioqc-day\[startingstudyday\]to\[laststudyday\].csv, where twodigitsiteid is the last two characters of the site name (i.e. with no server identifier included) and startingstudyday and laststudyday are the first day number with a diary available (that has audio qc features) and the most recent day number with a diary available (again that has audio qc features). * the transcript qc csv is named analogously for the diary-level transcript features available, \[twodigitsiteid\]-\[subject\]-diarytranscriptqc-day\[startingstudyday\]to\[laststudyday\].csv * for more info on these conventions, see the dpdash documentation. columns contained in each dpdash qc csv here will be described within the implementation section below. </details> in addition to the outputs planned for wider sharing, there are also many file accounting and qc summary outputs that will be used to facilitate monitoring by select study staff. those are compiled on the data aggregation server but are not kept on the general side. they are instead communicated to those relevant monitoring personnel via an email alerting system, and where relevant are built on by subsequent runs of the pipeline. the monitoring emails and the data included in them/attached to them will be covered in depth in a later section. for anyone planning to monitor outputs of the code but not necessarily make changes to the pipeline's implementation, skipping all the way to said section on monitoring tools below is recommended. ##### runtime and storage considerations <a name=""server""></a> as a final brief subsection for code users before moving on to implementation details, i will summarize observations about runtime and storage requirements of this code base. it is apparent from this that in the grand scheme of things, audio journal storage pales in comparison to many other collected datatypes, and so any group already running analyses for interview recordings, raw accelerometry and gps data, or fmris should have no issue with compute or storage resources at all in expanding to cover diaries too. <details> <summary>click here for pilot notes on runtime requirements:</summary> <br> the file accounting step and even new audio file wav conversion take a negligible amount of time. by far the largest driver of runtime on the audio side of the pipeline is the upload to transcribeme, with a much smaller contribution by the audio qc computation (about one sixth of the time contributed by the sftp process). in all, it took minutes for the audio pipeline branch to finish processing when newly launched on the prescient site me. this included the upload of audio journals totalling minutes from across site me subjects (with checked for having any app-based active reporting data). with the pipeline regularly running, even once many more sites are actively collecting data, we would expect less data than this to come through on a given single day, so we should have minimal problem with runtime on prescient. the transcript side is expected to take notably less time than the audio for the same number/size of transcripts once they are returned, and to just check availability of all pending transcripts upon launch for site me it took less than minute. all per subject summary operations also took less than minute, and analogously for the server-wide summaries in these same conditions. we would never expect the summary operation to take significant time relative to the audio processing, so our focus would really be on audio. for the pronet aggregation server, resources are a bit more limited and we might expect code to run a little slower as a result. however the runtime is not too far off from what prescient projects might suggest -- in just under hours the code was able to process and upload a great deal of backlog audio from across different sites, including files and total minutes of audio from unique subjects. a safe guesstimate for the pipeline to run in its entirety then is to expect about minute of processing time per minutes of real newly uploaded audio, with a few additional minutes of overhead. this is very sustainable on both servers and would be unlikely to be an issue for other projects potentially adapting the code either. note though that the strength of internet connection that the server has may influence these results more profoundly than any other variables. </details> <details> <summary>click here for a summary of storage estimates:</summary> <br> an estimate of mb per minute of audio for storage of raw was found to be a good heuristic for eventual upload duration, so for storage of audio diaries pulled directly from mindlamp we can similarly assume mb needed per minute of submitted diary. for pipeline outputs, per diary transcript and csv stats take up a trivial amount of space in this context, but the converted/renamed wav files used for file accounting purposes and set aside for downstream feature extraction will of course take up a somewhat large chunk of space per diary file. a rough estimate for wav size is times larger than so we can assume mb per minute of audio for diary pipeline outputs. to be safe, we therefore might allocate total mb per expected minute of journal submission for server storage. however, it is of course difficult to estimate what participation rates will look like across heterogeneous sites with different enrollment goals (in submission frequency or average recording duration), so it is not as clear how to determine an estimate of needed storage across a diary project. still, minutes per subject consenting to diaries would be an ambitious goal, and so gb per subject with diary enrollment should be sufficient for data storage and pipeline outputs. </details> ### implementation <a name=""implement""></a> the pipeline has two distinct overall wrapping modules making up its structure: the main per-site processing steps that occur daily based on provided configuration files, and the monitoring add-on server-wide summary steps that typically occur weekly based on server-specific settings provided by the calling script. as described above, run\_full\_pipeline\_all\_sites.sh manages the former while site\_wide\_summary\_generation.sh manages the latter. in this section, i will review implementation details for both in individual subsections, starting with a subsection about the per-site processing steps ##### site-level processing steps <a name=""pipeline""></a> as mentioned in the ""use"" section, for each provided site config the following pipeline branch wrappers are run by the high level run\_full\_pipeline\_all\_sites.sh script, with each branch script found under the site\_level\_pipeline\_branches repo folder: audio\_side.sh, which manages the identification and metadata accounting of newly submitted journal audios, and then computes quality control metrics and uploads acceptable audios to transcribeme for further processing. transcript\_side.sh, which manages the syncing back of transcripts newly returned by transcribeme, and their subsequent processing and quality control. subject\_summaries\_update.sh, which manages more detailed error logging and compilation of final qc and accounting statistics for each subject at the given site. each branch pulls from python functions in the subject\_level\_functions subfolder of that site\_level\_pipeline\_branches folder. i will next describe for each branch, in order, the steps overseen and the python functions utilized to do so, along with any relevant implementation notes and documentation on notable intermediate outputs. <details> <summary>the audio side of the diaries pipeline completes the following tasks:</summary> <br> the wrapping audio\_side.sh script first confirms that the provided site config for the current run has valid settings information, and also checks that expected folder structure is available or can be created where needed. with basic data management and logging set up, the script then loops through available subject id folders with *any* raw active phone app data, working through the following steps for each such subject where possible: the mindlamp\_accounting.py function documents available json and file according to the input expectations provided above, identifying any newly available valid diary uploads. for those uploads, it gets an appropriate study day number and local submission time using the site-specific settings, mindlamp unix timestamp, and redcap/rpms consent date for the subject (found in the site's metadata csv here). it also uses this to correct the submission number for any day numbers that were adjusted from their utc-derived dates, and ultimately maps raw to appropriate renamed files -- with very similar convention to the transcript filenames mentioned in the key outputs list above. finally, it ensures that newly detected audio files have their raw name to rename map marked for downstream processing by the pipeline. this part of the file management is handled by a simple text file system found under the phone/audio_journals folder of each corresponding subject id's protected side processed folder (where all other intermediate and/or sensitive pipeline outputs are organized too). * note that diaries submitted before am local time are also considered as part of the prior day, so that late night recordings describing one's day do not get inappropriately assigned to the next day. * if after this step no new audios have been set aside for a given subject id, the audio branch will continue on to the next subject in the loop, skipping the subsequent steps for the current participant. for any newly detected audios that were flagged, run ffmpeg (from directly within the audio\_side.sh bash script) to create the appropriately renamed wav file version of that audio on the protected side of processed, to then proceed to next steps. these wavs will initially be stored in a temporary folder under they are directed to the appropriate final location given their properties. * when conversion successfully completes, also mark this in the file system (by removing todo prefix on that tracking txt) so that the newly detected audio is no longer considered new on later runs. run audio\_diary\_qc.py for the subject id, to get qc metrics for any newly converted wav audio diaries, which are found within the described temporary audio folder. in addition to computing the audio qc metrics and ensuring they are saved to the correct up-to-date audio qc tracking csv, this script also selects the new diary wavs that are appropriate for upload to transcribeme and sets them aside. audios meant for upload are moved to a folder for files intended for sftp and audios that are rejected are moved to a final rejected_audios folder for accounting purposes. if the code instead were to crash for some reason, audios that did not have any qc computed at all will therefore be flagged differently than audios that were legitimately rejected. the potential reasons for rejection are the following: * overall volume found to be under the db_cutoff setting for the site, which here we take to be * total duration (in seconds) found to be under the length_cutoff setting for the site, which here we take to be * submission number on the assigned study day for this subject was > as we will only upload one audio per day per subject, and default to the first. finally, if automatic transcribeme upload is turned on (which we expect it to be here), any new diaries that were set aside for transcription upload will be pushed to the transcribeme sftp server by the journal\_transcribeme\_sftp\_push.py function. as part of this function, all successfully uploaded audios will also be moved to a pending_audio subfolder for future tracking purposes. note that the primary audio qc csv record utilized by step here is maintained on the protected side of processed, and is then just copied over to the corresponding general side processed folder (and any old copies there deleted) at the end of the audio\_diary\_qc.py script. that copy will have appropriate dpdash naming and can be used as desired by dpacc, while the master copy saved under protected can be more confidently assumed to remain unaltered outside of the actions of the pipeline, as desired. this audio qc csv contains one row per processed audio journal, and will have a row for any audios that underwent qc successfully, regardless of whether they were later rejected by the pipeline or not. the full list of columns in audio qc are as follows: [""reftime"",""day"",""timeofday"",""weekday"",""site"",""subject"",""daily_submission_number"",""submit_hour_int"",""length_minutes"",""overall_db"",""mean_flatness"",""subject_consent_month"",""audio_approved_bool""] note that the first set of columns relates only to dpdash and other organizational and file identifying metadata, and the final couple of columns are additional metadata/summary stats intended to assist with csv sorting and filtering. the main feature columns here are the following: * submit_hour_int is the submission hour of the audio journal in the local timezone. this is an integer and taken to be the floor (i.e. a submission at is assigned submit_hour_int = note that the variable ranges from to because submissions prior to am are considered as part of the previous day instead. * length_minutes is the duration in minutes calculated using the file length and sampling rate of the wav when loaded in via soundfile. this has been well-validated already. * overall_db is the total volume in decibels of the recording, computed using rms of the entire loaded wav and then converting to db units. this has also been well-validated in prior datasets. * mean_flatness is the mean of the spectral flatness feature vector returned by librosa when inputting the loaded wav. this can range between and with theoretically indicating an audio file entirely filled with white noise and indicating pure tone audio throughout. excessive background noise or electronics issues may create too high of a mean spectral flatness value, but the feature is still considered an experimental qc metric at this time. for other intermediate outputs of potential interest, see the ""file_accounting_details"" and ""dpdash_source_csvs"" subfolders of each participant's phoenix/protected/\[site\]/processed/\[subject\]/phone/audio_journals output folder. however note that all of the features of greatest interest will be included in downstream summary csvs used for monitoring, and thus will be covered in subsequent parts of this implementation section. </details> <details> <summary>the transcript side of the diaries pipeline then completes the following tasks:</summary> <br> the wrapping transcript\_side.sh script obviously relies on successful use of the audio branch of the pipeline first, and primarily utilizes transcripts once they have been returned by transcribeme, which involves some delay after the initial upload. nevertheless, this script repeats many of the same sanity checks of the provided site configuration file and expected folder structure, and it then loops through those subject id folders where there is evidence that any audio has ever been uploaded to transcribeme (confirmed via existence of a ""pending_audio"" subfolder under the subject's phoenix/protected/\[site\]/processed/\[subject\]/phone/audio_journals output folder, as this will never be deleted by the code once it is created by the code for a particular subject, even though it of course may remain empty for long stretches). for the subject ids being looped over, it attempts the following steps: by running the journal\_transcribeme\_sftp\_pull.py function, it checks for any output transcript text files on transcribeme's server matching what is expected based on the contents of the corresponding pending_audio folder on the data aggregation server. for any new transcripts successfully located, they will be pulled back to the data aggregation server to a protected side processed subfolder named ""transcripts"". for confirmed successful pulls, subsequent file accounting/organization steps will be performed -- the transcript text file will be moved to an archive subfolder under the output folder on transcribeme's server, the corresponding audio uploaded to the audio folder on transcribeme's server will be deleted, and the same corresponding audio file within ""pending_audio"" on the aggregation server will be moved to a parallel ""completed_audio"" subfolder of protected side processed instead. * note that these initial returned transcripts are not truly redacted, but rather have all pii/phi identified by transcribeme denoted by wrapping in curly braces. the direct pull of each transcript thus needs to remain only on the protected side, but will of course be used in next steps. * for any subjects that do not yet have any text files under their phoenix/protected/\[site\]/processed/\[subject\]/phone/audio_journals/transcripts subfolder after this step, the transcript branch of the pipeline will not attempt the next steps and instead continue on to the next subject id. for all transcript files found, the phone\_transcript\_redaction.py function will then be used to create a redacted copy (where all words in curly braces are replaced with ""redacted"") if one does not already exist. like the process for audio qc described for the audio branch of the pipeline, the redacted versions of transcript texts will be created and primarily maintained by the pipeline on the protected side, and simply copied over to general as needed at the end of the pipeline branch. * note that the wrapping bash script for the transcript branch will additionally prevent this code from saving a redacted version of any transcript that is not encoded by transcribeme, so that we do not accidentally miss curly braces due to odd character encoding. warnings will of course be logged if this occurs. directly within the transcript\_side.sh bash script, all redacted text files are next converted to csv files to facilitate processing, if they have not been already. the code to do this that is embedded within the bash wrapper is analogous to the transcript csv conversion bash module found within ampscz's interview recording dataflow code. it simply turns each sentence into a csv row and formats the transcribeme speaker id and sentence start timestamp more systematically along with the actual verbatim text. transcript\_diary\_qc.py is next run to compute diary-level transcript qc stats for any redacted transcript csvs that have not yet been processed for qc. this script manages the transcript qc csv in an analogous fashion to the managament of the audio qc csv by the audio side of the pipeline. finally, phone\_transcript\_sentence\_stats.py creates for each transcript a new version of the transcript csv containing additional columns with various sentence-level counting stats centered on transcribeme notation quantification. this will be the csv copied over to the general side for push to *predict* alongside the redacted transcript text file from each transcription. the overall python function is also used to compute extra summary stats per processed transcript focused on disfluencies, which will be saved at this time only on protected side processed in another csv next to various qc source csvs. however the summary-level disfluency stats, which include both total counts and rate-based (per word) metrics for each disfluency category, are already used within the more detailed monitoring visualizations to be described. * of course the primary reason for computing the disfluencies is to provide them on a low level alongside the released transcripts, which is accomplished by the main sentence-level stats csvs. we are especially keen to do this because the disfluencies are very easy to quantify using known transcribeme verbatim notation, but could be a headache to reverse engineer for someone who is not aware of the full transcription capabilities purchased by ampscz. <br> to elaborate on the metrics computed by the final major steps of this branch of the pipeline, i will review the columns present in the corresponding csvs. for transcript qc we calculate a number of metrics, resulting in the following list of column names within the csv: [""reftime"",""day"",""timeofday"",""weekday"",""site"",""subject"",""daily_submission_number"", ""min_words_in_sen"",""max_words_in_sen"",""inaudible_count"",""questionable_count"", ""other_bracketed_notation_count"",""redacted_count"", ""final_timestamp_minutes"",""min_timestamp_space_seconds"",""max_timestamp_space_seconds"", ""min_timestamp_space_per_word"",""max_timestamp_space_per_word"", ""txt_encoding_type"",""redacted_csv_filename"",""date_transcript_processed""] the first and last included lines of column names are various pieces of tracking metadata, but here we also have many columns of actual qc metrics, which are defined as follows: * speakerid_count is the number of unique speakers labeled by transcribeme. in the transcription text, the first unique speaker will have their sentences marked with the second unique speaker that appears will have their sentences marked with and so on. in a diary we generally expect the total speaker count to be -- if it is more than it probably indicates either a transcribeme typo or unwanted background conversation (or e.g. tv voices) within the recording. * is the number of sentences spoken by speaker id number in the transcript. as long as speakerid_count is this will be a useless distinction, but in cases where speakerid_count is more than it can help us determine whether the extra id appears in only a single sentence versus throughout the transcript. * total_sentence_count is the total number of sentences, defined based on transcribeme's sentence splitting, in the provided transcript. note that transcribeme may split a recording into more or fewer sentences based on speech rate and pause patterns of the speakers, as well as the actual language content included, but it should generally reflect a natural division of the speech into a sentence by sentence structure. * word_count is the total number of words across the entire transcript, counted by splitting on spaces. tracking this can help to ensure that there is real linguistic content found in the journals submitted by a particular subject, and in the long term give some sense for engagement with the study over time. * min_words_in_sen and max_words_in_sen are the minimum and maximum word counts from an individual sentence within the transcript respectively, which can help provide additional information about transcribeme's sentence splitting of the recording. * inaudible_count is the number of occurrences of an ""\[inaudible\]"" marking by transcribeme, indicating that one or more words at the time of the marking were not transcribable. this is an obvious proxy for transcript and thus audio quality. * questionable_count is a very similar metric giving the number of transcribed words/phrases that transcribeme explicitly marked with uncertainty, through the use of a ? and enclosing brackets. * other_bracketed_notation_count is then a count of all words or phrases enclosed in brackets besides inaudible and questionable markings. this largely entails the transcription of various nonverbal utterances of interest like coughing, laughing, and crying. it may also be used to mark extended periods of silence, or in a setting with multiple speakers crosstalk. * redacted_count is the number of words marked as pii by transcribeme in this transcript. it is thus the sum of all words, split on spaces, that are found within a set of curly braces. * final_timestamp_minutes is the start timestamp (in minutes) of the last sentence of the transcript, for cross checking with the audio duration to ensure chunks of transcript are not missing. * min_timestamp_space_seconds and max_timestamp_space_seconds are the minimum and maximum durations (in seconds) of any individual sentence in the transcript respectively, when computed based on the time between transcribeme's sentence timestamps. the primary purpose of these features is to ensure that provided timestamps do not contain careless errors. * min_timestamp_space_per_word and max_timestamp_space_per_word are analogous features, except when the elapsed time is first normalized by the number of words in the intervening sentence. <br> finally, we also have the columns of the actual transcript csvs with added sentence stat information. each such csv includes the columns extracted directly from transcribeme-provided information about each sentence in the transcript (""speakerid"", ""timefromstart"", and ""text""). it then has the following primary sentence-level metrics as columns: * the sentence's ""word_count"", determined using spaces as the delimiter. * the sentence's ""inaudibles_and_questionables"" count, meaning the number of times a portion of the language was marked as inaudible or with uncertain transcription in that sentence. * the sentence's ""other_bracketed_words"" count, meaning the number of other usages of transcribeme's bracket notation (described in the preceding list) found within that sentence. * the sentence's ""redactions"" count, again defined analogously as for the matching transcript-wide qc metric. * the sentence's ""estimated_sentence_seconds"", computed by subtracting the next sentence's start timestamp (in seconds) from the current sentence's one. for the last sentence in the transcript, this is computed using the total audio duration value from the audio qc if available. * the sentence's ""nonverbal_edits"" count, i.e. the number of nonverbal utterances used as sentence filler. * the sentence's ""verbal_edits"" count, i.e. the number of verbal filler words used in that sentence. * the sentence's ""stutter_repeats"", ""word_repeats"", and overall ""repeats"" counts -- the first being the number of stutters denoted in the sentence and the second the number of times a word was directly repeated, with the third the sum of the two types of utterance repeats. * the sentence's ""restarts"" count, i.e. the number of times the sentence was marked as entirely restarting within itself (it is uncommon though not impossible for this to be > in a single sentence). note that the nonverbal edits, verbal edits, repeats, and restarts are all specific categories of linguistic disfluency, and we really leverage transcribeme's verbatim notation to be able to accurately count each category automatically. additional details on the detection of disfluencies in transcribeme transcripts and the validation of their verbatim markings, as well as more general discussion of the potential relevance of linguistic disfluencies, can be found within my thesis pdf. </details> <details> <summary>finally, the per-site daily summary component of the diaries pipeline completes the following tasks:</summary> <br> a large number of safety measures for catching issues have been built into the pipeline, along with more general progress monitoring tools. to accomplish fine grained tracking and enable the use of broader server-wide summary scripts, this branch of the pipeline compiles final subject-level outputs from existing products of both the audio and transcript sides described above. like those branches, this script begins with steps to ensure valid configuration settings and folder structure for the input site, and set up needed logging. it then loops through available subject id folders for the current site, running its steps on any such subjects with available diary pipeline outputs and at least one submitted audio journal recognized (even if that journal were rejected or some other issue with processing came up, so long as it was recognized at all). it will therefore not perform any additional processing on subject ids that only had ema recognized and therefore only had a small amount of accounting output from this pipeline. this branch of the code has only a handful of steps, but each has a number of important subcomponents. the first major step is executed entirely through the subject\_summaries\_update.sh wrapper. it looks for a variety of potential important issues within the diary dataset of the current subject, and if any are detected they are logged to the corresponding major issues logging csv found under the protected side pipeline outputs for the subject id. if this csv does not yet exist when an issue is found, one will first be initialized with the following columns: date_detected,site,subject,filename,file_stage,error_message the initial columns are all important tracking metadata, and file_stage helps to indicate how far along in the processing pipeline the diary was able to make it before encountering whatever issue. each possible unique error_message then maps to one of the error types checked for, with the following checks performed within the bash wrapper: * ensure no audio is found to be under the wav subfolder created specifically for the case where the audio qc function crashes. * ensure no audios that were selected for transcription failed the actual transcribeme sftp upload (i.e. are left under audio_to_send). * ensure no raw audio path names that were marked for wav conversion/processed renaming somehow failed the ffmpeg step, indicating possible corruption (or otherwise neglect of a new file due to some bug). * ensure that for all the raw audio names marked as having been successfully converted to wav/properly named, we can indeed find this wav in one of the expected (or otherwise error-logged) places, to protect against accidental deletion issues. * ensure no audios are found left in the temporary audio folder that is created for initial saving of new wav-converted files on a given pipeline run, in case the pipeline somehow crashed in an unexpected way. * ensure that all pulled transcript text files have a corresponding redacted sentence stats csv, indicating that transcript processing fully successfully completed. if not determine at what stage it failed, and give a unique error_message mapping to this: * sentence-level stats computation failed but otherwise everything is fine. this can indicate that the returned transcript file was devoid of actual language. * csv conversion failed but we do have a redacted text file. * no redacted text is available at all, only the direct pull from transcribeme -- indicating a likely text encoding mistake by transcribeme, as we require for all returned files. * ensure also that all audios marked as entirely completed do indeed have a returned transcript found to be pulled directly from transcribeme, again protecting against data deletion or other such issues. note that the date_detected will always be the current date, and any issues detected in the bash portion of monitoring will initially be added to the csv in duplicate if they were previously detected and have not yet been fixed. the python step that finalizes the major issue logging, journal\_outputs\_error\_check.py, will at the end remove all duplicate entries keeping only the earliest detection date in the final saved csv. however before doing so, it also performs its own set of checks for other possible unique error_message options that we would want to flag, as follows: * for each audio marked as having fully completed the pipeline (or still pending return of a transcript from transcribeme), confirm that a single unique record can be found in the protected audio qc results csv for that audio file. * for each wav file still in pending_audio, check how long ago it was processed and uploaded to the sftp server, and confirm that this was not more than days ago. * for each csv generated from a redacted transcribeme transcript, confirm that a single unique record can be found in the protected transcript qc results csv for that transcript file. * for each json diary metadata record successfully logged by the accounting script, confirm that a corresponding diary was found in raw. * for each file found by the initial audio tracking script, confirm that a corresponding metadata record was found within a json in raw. while this python script will remove duplicate entries about the same file, it otherwise maintains a complete log of all major issues ever encountered for the given subject. as such, tracking of issue resolution will need to be handled elsewhere semi-manually. however, most of the issues checked for have been raised rarely if ever during pilot processing, so we would not expect this to be a big burden at all. there is much less opportunity for error than can be found with the interview recording datatype. it is worth mentioning though that the break in mindlamp diary pulling by lochness on the pronet server was hardly captured by the issue logging system, because the change to the metadata jsons caused *both* lochness to stop pulling the and my accounting code to stop noticing the diary information within the jsons. so in that case it was not possible for major issue logging functionalities of the pipeline to directly notice the problem. of course with regular tracking of submission dynamics over time, a server-wide halt in new diaries will still be very noticeable. <br> taken across subjects and sites, the final csvs saved by journal\_outputs\_error\_check.py for any subject where a major issue has been detected at some point will be concatenated for distribution as part of the detailed weekly monitoring email to be described below, so that is the easiest way for study staff to access these records. note that audio naturally rejected by qc is not considered in the major issue logging -- these are isolated by a separate monitoring process, and those csvs concatenated are included as a separate attachment on the mentioned monitoring email. appropriately, the rejected qc information is compiled by the second and final major python step of the subject\_summaries\_update.sh pipeline branch: the diary\_qc\_compilation.py function. for the input subject id, this function outer merges available audio and transcript qc csvs along with other file accounting metadata found with the protected pipeline outputs, to obtain a more complete record of information per audio journal. the merged csv has columns filtered down somewhat to retain only the most independently useful information, and then rows of audio diaries that were rejected by qc are filtered out, thus creating a master record of the latest information about all accepted diaries from the current participant. at the same time, if any audios were rejected by qc for the subject, a much more filtered down csv is saved with a handful of relevant columns and only those rows corresponding to rejected audios. both of these csvs will also be later concatenated across subjects and emailed out as mentioned; see the upcoming section on monitoring tools for details on the included metrics. </details> ##### server-wide summary steps <a name=""summary""></a> the wrapping server-wide summary script is like a standalone pipeline branch that works directly with input settings variables rather than with full blown configuration files, and runs these same settings across all available recognized sites simultaneously. it directly utilizes available outputs matching expectations from the rest of the pipeline, regardless of what site they were produced by on that server. it obviously therefore requires that the other parts of the pipeline were previously run successfully on that server, and its summaries will only include information from sites that have an active (or previously active) configuration file running with the main diary code. it is extremely useful for easy ongoing monitoring of data collection progress and possible dataset problems. recall that the major end points here are two weekly summary emails sent for each server -- one to a larger group of project staff that will want basic updates on the datatype and another to a smaller group of project staff that will be moreso responsible for careful tracking of the diary dataset and its processing. <details> <summary>when this full summary is run for the pipeline across sites, the following steps are performed after initial script setup, mostly working from the python functions found under the server_level_summary_functions repository folder:</summary> <br> all available major issue logging, rejected audio qc file logging, and comprehensive accepted diary qc characterization csvs that are available from the main pipeline summary outputs described above are concatenated to make three important server-wide tracking csvs, each saved within the appropriate part of the logs subfolder structure within the repository folder (which was detailed in the ""use"" section further above). this step is performed by the concat\_key\_subject\_diary\_csvs.py script, and the saved csvs will be directly attached to the detailed monitoring email reviewed in the next section. using information from both the saved concatenated csvs and the general folder structure found on the server, the generate\_server\_wide\_diary\_summary\_csvs.py python script then creates two more csvs, one with summary stats per detected site and one with summary stats per detected subject (from across sites) about diary participation rates. these two csvs are saved alongside the concatenated diary logs, and will also be attached to the detailed monitoring email (and therefore columns described in a subsequent section). a few key columns found in the site by site summary csv are used to create the html-embedded progress summary tables in the higher level weekly monitoring email (again to be further discussed). using both the comprehensive accepted diary characterization csv and the summary csvs generated by the prior steps, the create\_shareable\_visualizations.py script saves all visualizations to be used across the two different weekly summary emails. as all created visualizations are included in one of these emails, they will all be described in greater detail below. it is worth noting here though that the create\_shareable\_visualizations.py script includes within the file a number of more general visualization helper functions, which are then called on by the specific script to fit directly in this pipeline. it should therefore be quite approachable to adapt the server-wide summary part of the pipeline to other projects, even though it does rely on more assumptions than the core parts of the pipeline. * note that when first launching for a brand new server and no sites have had any transcripts returned yet, this will limit the visuals that would normally be returned by the create\_shareable\_visualizations.py script. as a result, the attachments to the extended monitoring email will be notably fewer and embeded images will be missing from the html summary monitoring email in this case, until at least transcript is returned for at least site. finally, the finalize\_server\_summary\_email\_html.py python script uses created summary csvs and figure jpegs to save an html file that can be successfully used as the email body for the higher level summary weekly email. it embeds a few keys tables and visuals, while the more detailed monitoring email is just a series of attachments, but with a large amount of info found in the included csvs and many figures included via pdf attachments. * note that this step also uses the css style file information found within the repository at the file path -- it includes the contained css content within the final generated html file. this is an edited down version of the full style file that would replicate table formatting within a jupyter notebook, which can also be found in the repo at the file path just for references. irrelevant parts of the jupyter css specifications had to be deleted in order to prevent gmail from clipping the html due to long length. after these python-driven steps, the wrapping final summary bash script still has to manage the needed commands for setting up and executing the sendmail and mailx commands, to email the embedded html summary email and many attachments monitoring email, respectively. this requires a few specific tricks that can be referenced within the site\_wide\_summary\_generation.sh top level script if interested. note that an explicit path is given to the sendmail executable here instead of just using ""sendmail"", to avoid failure when running the code via cronjob on the pronet data aggregation server root account. this path is the typical install location for sendmail, but it still should be verified for a new server installation. </details> ### guide to monitoring tools <a name=""monitor""></a> to better understand the weekly monitoring outputs of the server-wide summary steps portion of this code, we will refer directly to the materials produced. this will begin with a guide to the contents of the weekly summary html email that is meant for a broader audience in one subsection, and it will end with a guide to the many attachments of the more detailed weekly monitoring email that is meant for more specific study staff in the other subsection. ##### weekly summary html email contents <a name=""html""></a> the aforementioned weekly server-wide basic progress summary email provides tables and figures with the latest high level summary information for that server, embedded via html. each such panel has a matching descriptive title, but otherwise the email content is restricted to the actual embedded panels, which report on the following information in order: * server per-site audio journal cumulative processed submission stats -- this is a table meant to show total diary processing progress thus far, with the following columns: * site * total successful audio journal submissions * sum minutes uploaded to transcribeme * server per-site audio journal subject count participation stats -- this is a table meant to show how progress with audio diaries compares to progress with other datatypes, with the following columns: * site * subject ids found * subjects w/ phone data * subjects submitting emas (>= * subjects submitting journals (>= * subjects recording a journal in last weeks * participation trends over time enrolled in study -- this is a figure containing two interrelated plots, each showing participation rates as a timecourse over the duration of study enrollment. the two included plots share an x-axis indicating study day, and each specifically depict: * the number of successfully processed (and uploaded to transcribeme) diaries assigned to each possible study day over one year of enrollment, as orange dots on the dot plot, and then the number of diary-submitting subjects that have reached a given study day across the same server as blue dots on that dot plot. * a rolling mean line plot with standard deviation shading, showing the average daily participation fraction (i.e. dividing the orange by the blue number from the first panel for a given day) over a day rolling window. * server-wide distribution of key qc features (for diaries with returned transcripts) -- this is a collection of horizontal histograms showing current distributions over completed diaries for the following metrics: * total duration in minutes, using specifically defined bins (top left) * transcript sentence count, using automtically generated bins (top right) * transcript word count, using automatically generated bins (bottom left) * rate (per word) of inaudible markings in the transcript, using specifically defined bins (bottom right) * relationship between subject submission counts and durations (as well as time in study so far) -- this is a set of two scatter plots showing number of journals uploaded to transcribeme versus sum minutes uploaded to transcribeme for each subject id. the two component plots are as follows: * the top plot gives an overall view of the landscape, and colors each subject id point by the site the id is from. * the bottom plot zooms in to subjects with so far lesser participation rates, with x- and y- axes limited to submissions and sum minutes respectively. each point here is instead colored based on the number of months that id has been enrolled in the study to date. this email is sent weekly on mondays for both ampscz servers, to the addresses specified in the basic_email variable in the settings at the top of each server's main wrapping bash cronjob script. because it is sent using the sendmail command, the basic_email_from settings variable is also used, to determine what address will appear as the sender. if the wrapping script is in testing mode, the email will instead be sent daily to the specified testing address (as would the more detailed logging email described next). for both ampscz servers the code is already prepared for normal operation though, and therefore this high level summary email goes to a number of relevant contacts every monday. an example subject line for this email is ""pronet production weekly journals data summary - for additional context, i will next provide visual examples for each of the major html email components that i have described. <details> <summary>click here for an example of the opening of the email, with both embedded tables:</summary> <br> !example html email </details> <details> <summary>click here for an example of the overall participation rate timecourses:</summary> <br> !example timecourse </details> <details> <summary>click here for an example of the overall key qc metric distributions:</summary> <br> !example histograms </details> <details> <summary>click here for an example of the subject-level participation scatterplots:</summary> <br> !example scatter </details> ##### weekly detailed logging email csvs and pdfs <a name=""csv""></a> the other weekly email is meant for extensive monitoring and thus contains a large number of potential attachments when the pipeline is able to generate them on the server (which it typically should be). note this monitoring email contains only attachments, no body. it is sent weekly on mondays for each ampscz server, right after the html email described in the preceding subsection, and it is sent to a smaller list of contacts specified via the detailed_email settings variable found in each server's primary wrapping bash script for running this pipeline. an example subject line for this email is ""pronet production weekly journals monitoring status details - sending here uses the mailx command and so the from address is simply a technical address of the corresponding server. <details> <summary>the intended audience is those that will need access to more detailed records for careful data monitoring on each server. they should receive tracking csvs and visualization pdfs within every detailed monitoring update, reflecting the latest state of diaries data across that server; those attachments are as follows:</summary> <br> * allsubjectsserverwide_successfuljournals_allqc_withmetadata.csv, which is the concatenated comprehensive record of qc metrics and associated metadata for all audio diaries that were successfully processed and deemed acceptable for upload to transcribeme. * allsubjectsserverwide_audioqcrejectedjournals_datalog.csv, which is the concatenated log of audio qc values for all journals that were rejected by the qc script across this server. * allsubjectsserverwide_audiojournalmajorissueslog.csv, which is the concatenated log of any major issues recorded by the warning detection system from across all considered subjects on the server. * serverwide_subjectslevel_journalsubmissionsummary.csv, which is the generated summary of various participation stats per recognized subject id. * serverwide_siteslevel_journalsubmissionsummary.csv, which is the generated summary of various participation stats per recognized site; many of the stats included in this csv would also be featured in the same day html summary email. * allsubjectsserverwide_participationstatdistributions_coloredbysite.pdf, which presents horizontal stacked histograms spread across pages, each depicting a particular subject-level participation tracking stat's distribution and colored by associated site. all bin ranges are pre-defined based on priors about the depicted features, which are as follows: * num_days_ema_submit - the number of total days with an ema submission for the subject (including only those ids with at least diary submission) * num_days_journal_submit - the number of total days with a journal submission for the subject * num_audio_files_uploaded - the number of total audio journals uploaded to transcribeme for the subject * sum_minutes_audio_uploaded - the sum total of journal minutes contributed by the subject to transcribeme uploads * first_accepted_submit_day - the study day of the subject's first diary submission that was uploaded to transcribeme * last_accepted_submit_day - the study day of the subject's most recent diary submission that was uploaded to transcribeme * time_since_last_accepted_submit - the number of days in real time that have passed since the subject's last diary upload to transcribeme * months_since_consent - the number of months that have passed since each subject enrolled in ampscz (including only those ids with at least diary submission) * alldiariesserverwide_qcdistributions_coloredbysite.pdf, which presents horizontal stacked histograms spread across pages, each depicting a diary-level metadata or qc stat's distribution and colored by associated site. only diaries successfully uploaded to transcribeme are included in these distributions. unless otherwise noted, all bin ranges are pre-defined based on priors about the depicted features, which are as follows: * day - the study day the diary was submitted on * submit_hour_int - the submission hour of the diary in local time (adjusted as described in the audio qc details above) * weekday - the day of the week the diary was submitted on, encoded using dpdash convention * length_minutes - the duration of the diary recording * overall_db - the total volume of the recording in decibels * mean_flatness - the mean spectral flatness of the recording per librosa * speakerid_count - the number of unique speakers labeled by transcribeme in the transcript * total_sentence_count - the number of sentences in the transcript, determined by transcribeme sentence split (auto-generated bins) * word_count - the number of words in the transcript, counted by splitting on spaces (auto-generated bins) * words_per_sentence - the mean word count per sentence in the transcript (auto-generated bins) * min_timestamp_space_seconds - the shortest elapsed time of a sentence in the transcript per transcribeme's timestamps * max_timestamp_space_seconds - the longest elapsed time of a sentence in the transcript per transcribeme's timestamps * inaudible_count - the number of inaudible markings made by transcribeme, as described in the transcription conventions discussion above (auto-generated bins) * questionable_count - the number of words marked as uncertain by transcribeme, as described in the transcription conventions discussion above (auto-generated bins) * other_bracketed_notations_count - the number of other special sound markings made by transcribeme, as described in the transcription conventions discussion above (auto-generated bins) * redacted_count - the number of words marked as pii by transcribeme, as described in the transcription conventions discussion above (auto-generated bins) * inaudible_rate_per_word - the inaudible_count of the transcript divided by its word count * questionable_rate_per_word - the questionable_count of the transcript divided by its word count * other_brackets_rate_per_word - the other_bracketed_notations_count of the transcript divided by its word count * redacted_rate_per_word - the redacted_count of the transcript divided by its word count * diariesbysiteserverwide_selectqcdistributions_coloredbysubject.pdf, which presents page per site with diary transcripts available, each page containing horizontal stacked histograms that depict key qc distributions across the diaries only from that site. these histograms are colored instead by subject id within the site. the four highlighted features here are the duration of the diary in minutes, the sentence count of the diary, the word count of the diary, and the inaudible rate per word of the diary. each uses predefined bins so that the histograms will be comparable even across sites that have quite different distributional properties. * note that when the number of subjects exceeds the coloring will cycle around but use hatching to ensure different subjects are still uniquely identifiable. if the number of subjects exceeds it will fail to generate however, something to possibly watch out for and eventually adapt as the project progresses. * if a diary value falls outside the prespecified range, it will not appear in the histogram, but the y-axis label will specify when this occurs and how many diaries fell outside of the range, so it can still be flagged during review. these adjustments apply to the functions used for histograms throughout the project. * alldiariesserverwide_disfluenciesdistributions.pdf, which presents page of horizontal histograms, each depicting the distribution over all journal transcripts of the rate of usage of a particular category of disfluency. all data from across the server is presented together here, and all bins are auto-generated. the four major categories of linguistic disfluency considered, which are discussed at greater length in the transcript pipeline implementation details above, are as follows: * nonverbal_edits_per_word * verbal_edits_per_word * repeats_per_word * restarts_per_word * serverwide_journalengagementscatterplots.pdf, which presents pages of scatter plots with server-wide participation-related statistics. each page contains two different related scatter plots, with the first pages containing various scatters of subject ids and the final page containing scatters of individual diaries. the exact content of each of the pages is as follows: * page contains the same scatter plots that form the final figure of the html email detailed previously, focusing on number of successful recordings versus sum minutes of successful recordings. * page contains two scatters with ""time_since_last_accepted_submit"" as the y-axis, with the top scatter having ""first_accepted_submit_day"" on the x-axis and the bottom scatter having ""last_accepted_submit_day"" on the x-axis. on both plots the subject id data points are colored based on ""months_since_consent"". * page contains two scatters with the same x-axis, marking the study day the diary was submitted on. the top scatter plots day number against the total word count of the transcript and colors the dots based on the weekday of the submission (dpdash encoding), while the bottom scatter plots day number against the submission hour of the transcript and colors the dots based on the duration of the recording in minutes. * serverwide_journalparticipationtimecourses.pdf, which presents server-wide page and then page per site with longitudinal timecourse info on participation rate. the first server-wide page is identical to the ""participation trends over time enrolled in study"" figure that is included in the html summary email discussed in the preceeding subsection, and then all subsequent pages are site-specific versions of the same style of figure. * persitebreakdown_journalengagementscatterplots.pdf, which presents page per site with primary scatter plot showing each of the diaries successfully uploaded to transcribeme from that site colored by subject id and located with x-coordinate corresponding to study day and y-coordinate corresponding to the recording length in minutes. the bottom plot on each page is identical (for reference against the site-specific top plot), scattering study day versus recording duration for all succcessful diaries from across the server, this time colored by associated site. </details> recall that these attachments are generated by the server-wide summary portion of the pipeline described at the end of the above implementation section. for the remainder of this subsection, i will discuss in more detail the key properties of each of the attachments, for reference by those that will be actively monitoring using said tools. it is worth highlighting here that under the monitoring\_examples folder of this repository, there is a subfolder detailed\_pdfs which contains examples of all of the pdfs in this list, from an early pronet run of the code. these can be referred to for context on the attachment descriptions, and they are also discussed briefly as part of the early interpretations provided below. <details> <summary>the files to check first/most regularly in a typical manual review process would be the error trackers. click here for more details on rejected audio qc and the other diary issues that may be logged:</summary> <br> the allsubjectsserverwide_audiojournalmajorissueslog.csv contains any warnings flagged by the subject-level summary branch of the main pipeline at any time, with brand new warnings detectable by looking at the corresponding date column. any potential issues that are found will have a detailed description associated via this csv. for information on all the possible problems that are checked for by the code, see the relevant implementation details above. thus far, we have found very few major errors to be logged: none were detected in the initial launch of prescient site me, and just a handful were found across the launch of the first pronet sites (ya, pa, nn, nc, ir, sf, and si). besides ya all of these sites may still have some transcriptions pending, but still we expect very few total issues to be logged, and we have covered over diaries at this point. the major issues we have seen to date are: * diaries that were accepted by qc were returned as empty transcripts. this subject will be discussed at greater length shortly. * and submission were each flagged as having an found on the data aggregation server but no associated json metadata. both were from right around the same time in mid-april, and very clearly relate directly to the problems caused by mindlamp api changes that ultimately stopped all diaries from being pulled to pronet. the major issues log was therefore helpful in identifying the exact problem, but we do not expect this error to be a recurring concern once the dataflow is restored by mindlamp. <br> the other relevant csv here is allsubjectsserverwide_audioqcrejectedjournals_datalog.csv, which contains a record of all journal audio files that were processed for qc but then rejected from upload to transcribeme. the following columns are included, to provide basic metadata info and elucidate exactly why the file was rejected: site,subject,day,daily_submission_number,overall_db,length_minutes,submit_hour_int,subject_consent_month in the initial pilot with the pronet ya site, we had total diaries summing about minutes rejected from upload, compared to diaries summing about minutes successfully uploaded. of the rejected ya diaries, were the second submission in the day and had volume below db (the original volume threshold i used). of those rejected audios were from the same subject upon further inspection of that subject's data, it became apparent that they often submitted bad audios, and that raising the volume threshold to db could filter a few more of their bad audios without coming close to removing any of the other subjects' recordings. in addition to the entirely empty transcripts from mentioned, there was also an audio file with unique speaker ids present that turned out to be a background recording of some sort of tv show. it seems apparent that was systematically submitting bad audio recordings, though they may have eventually stopped doing diaries at all. a question for the future is how we might handle a subject with such recurring issues when we detect them in real time. the results from launching to other pronet sites also boded well for the raising of the threshold to db. audios were rejected from across the other tested sites, but only were rejected due to actual quality concerns, the rest were all second (or later) submissions within the same study day. all quality rejections were due to volume, and the majority of those with especially low db indicating an obvious garbage file. volume rejection came from site ir, from site nn, and then each from pa and sf. all from pa came from who may be worth looking into further -- though they did have a large number of files successfully processed, many were quite short. the from sf were split across subjects, and the participant that had rejected had both with volume between and db, so a borderline case and again not really indicative of a systemic project with a subject. overall, there were no participants quite like across these other tested sites. </details> <details> <summary>it is possible for more minor quality issues to occur that will not be flagged by any of the aforementioned problem detection tools. there are also other progress monitoring/file accounting reasons to want to refer to a larger set of stats from across the completed audio diaries. click here for more details on available information in the successful journals compilation:</summary> <br> allsubjectsserverwide_successfuljournals_allqc_withmetadata.csv is by far the largest csv in the weekly monitoring toolset, containing a variety of information about all journals uploaded to transcribeme from across the server. columns include the following basic metadata information for identifying individual files: day,timeofday,weekday,site,subject,daily_submission_number in addition to the available audio qc metrics that have been merged in (see above implementation details for a comprehensive guide to each source csv's column definitions): submit_hour_int,length_minutes,overall_db,mean_flatness,subject_consent_month,audio_approved_bool and the merged in transcript qc metrics (which will be nan if not yet available): as well as select summary columns merged in from the diary-level disfluency stats: transcript_csv_name,nonverbal_edits_count,verbal_edits_count,repeats_count,restarts_count,total_disfluencies,nonverbal_edits_per_word,verbal_edits_per_word,repeats_per_word,restarts_per_word,disfluencies_per_minute and finally a few other merged metadata columns that were saved for logging purposes during the initial accounting phase: <br> using this csv, we can easily check for which diaries are still awaiting a transcript, or identify those diaries that have a more extreme value in a metric of interest. one might want to isolate diaries with more than unique speaker id or diaries with an especially high number of inaudibles for manual review, for example. we might also notice through sorting if a particular subject id tends to have many of the diaries with especially high or low values in a given feature, and more generally we can ask a number of distributional and correlational questions about the included features (or do timecourse modeling) through extra analyses when desired. by referring first to the issue logs and the attached visualizations, questions to search for in this denser csv can be more readily raised. other early observations of potential note found via the existing visual tools will be discussed shortly, and could also help to inform what factors are checked for here -- e.g. more careful consideration of the mean spectral flatness feature in the context of the diaries. </details> <details> <summary>to get a sense for participation trends by site, grouped summary csvs are also made readily available alongside the per diary stats. click here for more details on site- and subject- level summary stats csvs:</summary> <br> serverwide_siteslevel_journalsubmissionsummary.csv contributes a number of columns to the tables embedded in the html summary email: * num_subjects_found i.e. the number of unique subject id folders found under the sites' phoenix folder structure. * num_subjects_raw_protected_phone_folder i.e. the number of subjects from the site estimated to have some phone data, based on the presence of a protected side raw phone datatype folder. * num_subjects_any_ema i.e. the number of subjects from this site with any ema responses found on the server. * num_subjects_any_journal i.e. the number of subjects from this site with any audio journals found on the server. * num_audio_files_uploaded i.e. the total number of files sent to transcribeme from across this site. * sum_minutes_audio_uploaded i.e. the combined duration of all journals sent to transcribeme from this site. * num_subjects_submit_within_last_two_weeks i.e. the number of subjects from this site that successfully submitted an audio journal within the last two weeks of the current date. there are then additional site-level stats columns that can be looked up only within this csv: * num_subjects_any_active_app i.e. the number of subjects that have an ema *or* diary recognized. * num_subjects_within_first_two_weeks_of_enrollment i.e. the number of subjects with a consent date within two weeks of the current date. * fraction_diary_subjects_submit_after_two_weeks i.e. the fraction of num_subjects_any_journal that submitted at least one of their successful journals more than two weeks past their date of consent. * mean_minutes_per_diary_after_two_weeks i.e. the mean recording length of successful journals from this site that were submitted on a study day > * mean_accepted_diaries_per_subject_week_after_two_weeks i.e. the mean number of successful journals per diary-participating subject per week enrolled, beginning the count only after study day * mean_minutes_per_diary_first_two_weeks i.e. the mean recording length of successful journals from this site that were submitted within the first study days. * mean_accepted_diaries_per_subject_within_first_two_weeks i.e. the mean number of successful journals from within the first study days per diary-participating subject. given that many subjects do not even submit their first diary until well after two weeks into enrollment however, we may want to expand on the set of participation stats considered to account for this while still capturing the spirit of predicting prolonged involvement. regardless, we cannot really assess sites on most of these stats until the mindlamp pull code is fixed, as we do not currently have an accurate picture of ongoing participation. <br> for the analogous tracking csv on the subject level, we include one row per subject id with any ema *or* diary submission recognized. for each such subject we record the number of days they submitted an ema so far, the number of days they submitted a journal so far, and the number of days they submitted at least one of these so far. we also record the number of journals actually uploaded to transcribeme from the subject and the sum duration of those uploads. these stats all directly parallel aforementioned site-level ones. we then add a few other columns for subject tracking: * study_day_at_compute_time i.e. the days since consent as of the current date for the subject. * first_submit_day i.e. the study that the first successful diary was submitted for this subject. * last_submit_day i.e. the study day that the last successful diary (thus far) was submitted for this subject. * time_since_last_submit i.e. the number of days that have passed since this subject last submitted a successful journal, as of the current date. some of these features are utilized within attached visualizations to the extended monitoring email. however we again must wait until mindlamp pull is fixed to interpret most of the stats, through visuals or otherwise. even the overlap between ema and journals is currently skewed because the mindlamp api issue is not affecting download of the ema surveys. </details> <details> <summary>as emphasized throughout this monitoring section, the many visualizations attached to the detailed email can be extremely helpful for identifying possible anomalies to look further into. click here for some observations about the provided visualizations and possible trends to watch out for:</summary> <br> it is important to reiterate that until mindlamp pull is fixed, many of the stats and visuals related to participation trends are difficult to meaningfully interpret. additionally, of the sites included in the early pronet launch were specifically chosen due to promising file availability for the diary datatype, so we cannot really accurately generalize to other sites based on any early results here. we still have english-language pronet sites that are awaiting diary code launch, and a decent fraction of them we expect to have few total diaries available. that said, we can still make some preliminary observations from the provided visuals that might help to inform both what we will look for as the data further develops as well as what we might follow-up on via manual review for existing subjects. my pilot notes on this topic include the following points: * it is clear from the participation timecourses that some sites have started their participants with the journals much later in the enrollment process than others so far. si has started especially late, and sf and nn have also tended on the later side. across the board diary start dates have been later than i was anticipating, often a full month into enrollment. but for slower sites we are seeing a number of subjects starting months in. it will be worth keeping an eye out for whether this trend persists once the sites are in a more of a habit of collecting journals. if it does, is there something we should be doing about this? if diaries start too late we might not have good time alignment with e.g. available open interviews, and it is also not clear how waiting to enroll the app impacts participant willingness to consent. * regardless, this is something to watch out for in interpreting the server-wide participation timecourse. if different sites have different biases towards when in enrollment they begin diary collection, a possible participation drop-off over time occuring at different offsets may look more like mediocre participation levels remaining at a sustained rate for an extended period. * the server-wide scatter plots demonstrate how much one or two subjects per site contribute to the sum total of diary submissions and/or minutes associated with each tested site. it is therefore too early to draw site-specific conclusions about diary-enrolled subject participation rates. however, when looking at the larger set of eligible pronet sites, we do see many that have a much worse conversion rate between subjects that tried out ema and subjects that tried out diaries. some of that may be an artifact of the more recent diary pull problems, but once those are resolved it will be worth following up on sites with lacking diary-enrolled subject counts. rates of sustained engagement per site will need to be investigated later in the project when there is a larger sample size of subjects. * the high end of inaudible rates is much higher in diaries than found in the interviews, though this is not surprising given the much smaller total number of words that might occur in an individual diary recording. however it is obvious from the subject-colored qc distributions for each site that not only are the majority of high inaudible rates coming from a handful of sites, they are in fact coming from a handful of subjects. and are particularly bad, and have some other quirks with their diary qc values as well. these subjects may be worth some attention in manual quality review: * from the per site breakdown scatter plots, we can see that had a curious stretch when they first started submitting where they recorded a diary quite consistently day to day, and almost all of these diaries were very close to minutes in length, artificially so despite the lack of any official stop at minutes. from the diary-level qc feature distributions colored by site, we can also see that ir was the site most responsible for diary submissions that were uploaded to transcribeme with a very high (> mean spectral flatness value, which very likely maps to the diaries of this suggests that in addition to some manual check of the audio and transcripts from we might also want to investigate the relation between mean flatness and transcript quality more closely in the diaries, to perhaps enable an additional threshold to be added for upload approval. * from the per site breakdown scatter plots and subject-colored qc distributions, we can see too that almost exclusively submitted diaries under minute in duration, with many under seconds -- which is abnormally short for a participant contributing so many recordings. however there is an interesting pattern over time to this trend, as although an overall drop-off in duration is observed, there are very clear fluctuations on the timescale of weeks where has a local uptick or downturn in their journal duration. it is not surprising they might have high inaudible rates when some of their submissions are so exceedingly short, but it would certainly be of interest for future analyses to investigate what their diary content looks like over time. from a quality perspective, we should at least verify that this is not fake recording tactics but rather genuine behavioral fluctuation. * throughout the early dataset, we see a lot of participant-dependent variation, which is to be expected. recording duration for some subjects is concentrated at very high durations, for others at very low durations, and for others across a broader range. furthermore, not all frequent submitters contributed long journals, and not all consistently long submitters contributed a high number of journals. * while subject-specific duration distributions generally checked out with subject-specific sentence and word counts, alignment was not always perfect. for participants that seem to have slightly shorter diaries than one might otherwise expect from the audio file's duration, it may be worth reviewing manually (or checking acoustic features once we have them) whether this is attributable to a higher rate of natural pausing versus lower quality audio causing degraded transcript quality. * participant-dependent variation was apparent not only in feature distributions, but also just in the participation day breakdowns. some participants with a month or so worth of journals submitted them nearly every day at first and then entirely stopped (unclear yet when this was mindlamp issue versus true stoppage), while others with a similar number of total submissions had them spaced out at a couple times a week over or more months. * as more subjects enroll in ampscz and the pipeline launches to more total sites, we may be able to identify a few different participation profiles that could help guide data collection and downstream analysis decisions. </details> ### next directions <a name=""future""></a> the code currently runs as a cronjob at am local time on both the pronet and prescient servers. for pronet it is run by the root account and should thus be full setup already without need for long-term changes. for prescient it is run by a personal account and will need to be migrated to their new data aggregation server when that is launched, and ideally also be transferred to a non-personal account. as time goes on it will of course still be important to be aware of updates to any of the pipeline dependencies, and maintain the repository (and keep it updated across ampscz servers) accordingly. besides active monitoring of the existing code though, there are a number of immediate next steps to be done for maintaining and expanding on this pipeline for the ampscz project. the following todos all relate moreso to integrations and settings updates rather than required changes for the current codebase itself, but they could be highly informative in adjusting how we approach monitoring of diary data collection in the future, and they will certainly help to encourage more attention on the diary datatype. * we are awaiting a resolution for the issue with pull of mindlamp to pronet. the issue has been under investigation for approaching month, so it will hopefully be resolved soon. once that is fixed, we will be better equipped to start working on more precise participation modeling from pipeline outputs. * we are also awaiting approval to launch the pipeline for the rest of the pronet english-language sites. i have these configuration files ready to go, so it is just a matter of receiving the go ahead. once the code is running for all (english) pronet sites, we will be in a better position to work on a more complete characterization of the data collection to date. * further, results of characterization might inform other small additions to this pipeline for improvement of monitoring and ultimately budget forecasting. * upon completion of the pronet launch with corrected mindlamp functionality, we will want to consider more carefully how we might share methodological lessons learned and more general arguments about the utility of the journal datatype (as well as more formally release this code). the process for data review here can also connect directly to the transfer of diary-related responsibilities to other ampscz project members as i transition out of the lab. * because diaries have not yet been reviewed at all for ampscz, we will additionally need to establish protocol for when and how to contact sites if potential journal recording protocol problems (repeated quality flags, exceptionally low participation rates, etc.) are detected. i can go over some early site-specific trends and other patterns noticed to assist study staff in determining a plan. phil can help to oversee this process. * while the data aggregation servers that this code runs on for ampscz are meant only for lighter weight computations, we have a server set aside for av processing with pronet storage mounted and a similar plan underway for prescient. to integrate some basic acoustics feature extraction with the current repository (because while redacted transcripts can go to the data repository, raw audio cannot), we will want to make a separate repository with code that will run on the processing server but will utilize output assumptions from this pipeline to facilitate its dataflow. * the plan is that wav files can be selected directly from paths of the form phoenix/protected/\[site\]/processed/\[subject\]/phone/audio\_journals/completed\_audio/\[site\]\_\[subject\]\_ audiojournal\_day\[####\]\_submission\[#\].wav, as this indicates diaries that successfully completed pipeline processing. pronet it can write the scipt that manages the rate of dataflow in copying these files to the location where computation is planned to occur on the processing server, copying only files that have not yet been covered. * i can then write the separate processing server repository that works through the copied over files. i will look under the /opt/data/\[subject\]/phone folders to find wavs for processing, run opensmile on them (producing gemaps low level descriptor feature csv and perhaps also a higher level feature csv produced by opensmile config), copy the generated csvs to the appropriate spot on the actual phoenix data structure for downstream push to *predict*, and then after confirming the copy create a placeholder text file with name matching the wav to indicate processing completion, ending with deletion of the copied wav from /opt/data. * when initially implementing this, i will need to confirm installation of dependencies on the processing server, as well as setup of the cronjob and its integration with the transfer script written by pronet it. i will also want to do some benchmarking of runtime for the opensmile processing on this server as part of documenting the mini repository, and then i may want to add a small summary module too -- perhaps just determining the fraction of ms bins with vocal loudness near-zero as a simple stat for easy check of opensmile feature availability. that summary output could then be used directly in this repo to be included as an additional portion of the detailed monitoring email. * once the workflow is totally ironed out, a similar system will need to be setup on prescient. the code written by me should extend immediately once a few small server-specific settings are verified, but the dataflow written by pronet it is another key component that someone will need to replicate for prescient. this could perhaps be handled by habib in consultation with kevin and prescient it, when he takes care of migration of the diary and interview dataflow/qc pipelines to the new prescient data aggregation server? * when verifying dataflow, i should also confirm that both raw and processed phone datatype folders on the protected side of phoenix will never have data automatically deleted. this was already confirmed for the interviews, but they are largely an exception when it comes to ampscz dataflow. * can ask about general side of processed phone data as well, because even though pipeline does not rely on data persistence on the general side at all here, if there is not persistence for phone like there is for interview we might want to share opensmile outputs from the feature extraction pipeline on both sides. * an eventual extension to be made directly to this repository is the handling of diaries from foreign language sites. there will be adjustments that need to be made to the transcript processing code, which i am awaiting further information from transcribeme on. prior to that though, we need to determine how we will handle foreign sites with a highly bilingual population, as diaries could be recorded by the same participant in different languages without clear warning. transcribeme has already expressed annoyance with just a handful of montreal interviews being labeled as french when they were actuall english by our other processing pipeline, so relying on transcribeme to direct unclear language recordings to the appopriate transcription team is very unlikely to be an acceptable solution for the journals. we would therefore need a way to identify the language directly from the audio, which should be possible with existing libraries, but may not be feasible for running on the data aggregation server. having a pre-transcribeme step running on the processing server would be a large bottleneck, so resolving this is a major question before we can comfortably move forward with many of the foreign sites. of course most foreign language transcriptions are also more expensive per minute, and some languages are restricted to just or total ampscz sites -- so the cost/benefit of launching the diaries for various other languages is an open question to include in this consideration. * for any non-english languages we do move forward with, the transcript qc and disfluency counting may require various adjustments. we would like transcribeme to give us information on any language-specific differences in any of their verbatim transcription protocol notation, but most critically to the basic qc infrastructure we will need to know what word is used in place of ""inaudible"" in the various foreign languages. ideally we should follow-up too about specific disfluency or other verbatim markings we expect might be different in certain languages, particularly those with a very different character set. for example, would a stutter be encoded any differently in a mandarin or korean transcript? native speakers working on the project might help us to guide such questions if we are worried about missing anything. * ultimately, i may or may not work on this portion depending on when we receive more clarity, but at this point it does seem unlikely i will get to it. * there are entirely new sites joining the pronet central server soon, and there may be other site additions to both servers in the future. once we are in a normal state of operation, any english-language sites will want to be immediately added into the list of configurations for active running of this journal flow/qc code. for the latest sites, this should be handled by linying at some point in the future, to ensure she is prepared for taking over basic software maintenance. * the code's key general side outputs are already automatically pushed to *predict*, but for viewing the qc values in dpdash it will first be necessary for dpacc to perform various initialization steps. * tashrif can setup a cronjob to regularly import the generated subject-level diary qc csvs to dpdash. * einat can setup a configuration file on the dpdash interface for viewing of these subject-level qc timecourses. * any combined view or chart view to be created will need to be done via code on *predict*. if dpacc has any specific requests for such views, someone like linying or habib could draft the needed code based on the utility script running to perform a similar step with interview qc metrics, and then tashrif can review that code and ensure it runs regularly and the produced csvs are appropriately imported. einat would again manage creation of dpdash configs and periodic checking of the state of these views. * eventually, dpacc and team h will need to work together in the staging of diary data for the nda. key qc metrics and associated metadata will need to be compiled along with paths to the associated diary redacted transcripts and sentence stat csvs (and any acoustics features to be generated). write ups about the dataset will also need to be provided. while these action items all connect directly to the launch of the diary code for the ampscz project, the documentation throughout this readme should assist greatly for adaptation of the code to new projects collecting audio journals. please also feel free to reach out if you would like to utilize some or all of this pipeline for a new project and would benefit from more specific advice."
1,ResearchKit,researchkit is an open source software framework that makes it easy to create apps for medical research or for other research projects.,"researchkit framework =========== !vcs !platform !cocoapods !carthage compatible [!license](https://github.com/researchkit/researchkit#license) ![](https://travis-ci.com/researchkit/researchkit.svg?branch=master) the *researchkit framework* is an open source software framework that makes it easy to create apps for medical research or for other research projects. * getting started * documentation * best practices * contributing to researchkit * website * researchkit bsd license getting more information ======================== * join the *researchkit* forum for discussing uses of the *researchkit framework and* related projects. use cases =========== a task in the *researchkit framework* contains a set of steps to present to a user. everything, whether its a *survey*, the *consent process*, or *active tasks*, is represented as a task that can be presented with a task view controller. surveys ------- the *researchkit framework* provides a pre-built user interface for surveys, which can be presented modally on an *iphone*, *ipod touch*, or *ipad*. see *creating surveys* for more information. consent ---------------- the *researchkit framework* provides visual consent templates that you can customize to explain the details of your research study and obtain a signature if needed. see *obtaining consent* for more information. active tasks ------------ some studies may need data beyond survey questions or the passive data collection capabilities available through use of the *healthkit* and *coremotion* apis if you are programming for *ios*. *researchkit*'s active tasks invite users to perform activities under semi-controlled conditions, while *iphone* sensors actively collect data. see *active tasks* for more information. researchkit active tasks are not diagnostic tools nor medical devices of any kind and output from those active tasks may not be used for diagnosis. developers and researchers are responsible for complying with all applicable laws and regulations with respect to further development and use of the active tasks. charts ------------ *researchkit* includes a *charts module*. it features three chart types: a *pie chart* (`orkpiechartview`), a *line graph chart* (`orklinegraphchartview`), and a *discrete graph chart* (`orkdiscretegraphchartview`). the views in the *charts module* can be used independently of the rest of *researchkit*. they do not automatically connect with any other part of *researchkit*: the developer has to supply the data to be displayed through the views' `datasources`, which allows for maximum flexibility. getting started<a name=""gettingstarted""></a> =============== requirements ------------ the primary *researchkit framework* codebase supports *ios* and requires *xcode or newer. the *researchkit framework* has a *base sdk* version of meaning that apps using the *researchkit framework* can run on devices with *ios or newer. installation ------------ the latest stable version of *researchkit framework* can be cloned with ``` git clone -b stable https://github.com/researchkit/researchkit.git ``` or, for the latest changes, use the `main` branch: ``` git clone https://github.com/researchkit/researchkit.git ``` cocoapods installation ------------ for latest stable release ``` pod 'researchkit' ``` for early development releases ``` pod 'researchkit', :git => 'https://github.com/researchkit/researchkit.git', :branch => 'main' ``` building -------- build the *researchkit framework* by opening `researchkit.xcodeproj` and running the `researchkit` framework target. optionally, run the unit tests too. adding the researchkit framework to your app ------------------------------ this walk-through shows how to embed the *researchkit framework* in your app as a dynamic framework, and present a simple task view controller. ### add the researchkit framework to your project to get started, drag `researchkit.xcodeproj` from your checkout into your *ios* app project in *xcode*: <center> <figure> <img src=""../../wiki/addingresearchkitxcode.png"" alt=""adding the researchkit framework to your project"" align=""middle""/> </figure> </center> then, embed the *researchkit framework* as a dynamic framework in your app, by adding it to the *embedded binaries* section of the *general* pane for your target as shown in the figure below. <center> <figure> <img src=""../../wiki/addedbinaries.png"" alt=""adding the researchkit framework to embedded binaries"" align=""middle""/> <figcaption><center>adding the researchkit framework to embedded binaries</center></figcaption> </figure> </center> note: you can also import *researchkit* into your project using a dependency manager such as *cocoapods* or *carthage*. ### create a step in this walk-through, we will use the *researchkit framework* to modally present a simple single-step task showing a single instruction. create a step for your task by adding some code, perhaps in `viewdidappear:` of an existing view controller. to keep things simple, we will use an instruction step (`orkinstructionstep`) and name the step `mystep`. *objective-c* ```objc orkinstructionstep *mystep = [[orkinstructionstep alloc] initwithidentifier:@""intro""]; mystep.title = @""welcome to researchkit""; ``` *swift* ```swift let mystep = orkinstructionstep(identifier: ""intro"") mystep.title = ""welcome to researchkit"" ``` ### create a task use the ordered task class (`orkorderedtask`) to create a task that contains `mystep`. an ordered task is just a task where the order and selection of later steps does not depend on the results of earlier ones. name your task `task` and initialize it with `mystep`. *objective-c* ```objc orkorderedtask *task = [[orkorderedtask alloc] initwithidentifier:@""task"" steps:@[mystep]]; ``` *swift* ```swift let task = orkorderedtask(identifier: ""task"", steps: [mystep]) ``` ### present the task create a task view controller (`orktaskviewcontroller`) and initialize it with your `task`. a task view controller manages a task and collects the results of each step. in this case, your task view controller simply displays your instruction step. *objective-c* ```objc orktaskviewcontroller *taskviewcontroller = [[orktaskviewcontroller alloc] initwithtask:task taskrunuuid:nil]; taskviewcontroller.delegate = self; [self presentviewcontroller:taskviewcontroller animated:yes completion:nil]; ``` *swift* ```swift let taskviewcontroller = orktaskviewcontroller(task: task, taskrun: nil) taskviewcontroller.delegate = self present(taskviewcontroller, animated: true, completion: nil) ``` the above snippet assumes that your class implements the `orktaskviewcontrollerdelegate` protocol. this has just one required method, which you must implement in order to handle the completion of the task: *objective-c* ```objc - (void)taskviewcontroller:(orktaskviewcontroller *)taskviewcontroller didfinishwithreason:(orktaskviewcontrollerfinishreason)reason error:(nserror *)error { orktaskresult *taskresult = [taskviewcontroller result]; // you could do something with the result here. // then, dismiss the task view controller. [self dismissviewcontrolleranimated:yes completion:nil]; } ``` *swift* ```swift func taskviewcontroller(_ taskviewcontroller: orktaskviewcontroller, didfinishwith reason: orktaskviewcontrollerfinishreason, error: error?) { let taskresult = taskviewcontroller.result // you could do something with the result here. // then, dismiss the task view controller. dismiss(animated: true, completion: nil) } ``` if you now run your app, you should see your first *researchkit framework* instruction step: <center> <figure> <img src=""../../wiki/helloworld.png"" alt=""helloworld example screenshot"" align=""middle""/> </figure> </center> what else can the researchkit framework do? ----------------------------- the *researchkit* `orkcatalog` sample app is a good place to start. find the project in researchkit's `samples` directory. this project includes a list of all the types of steps supported by the *researchkit framework* in the first tab, and displays a browser for the results of the last completed task in the second tab. the third tab shows some examples from the *charts module*. license<a name=""license""></a> ======= the source in the *researchkit* repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) - apple inc. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder(s) nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. no license is granted to the trademarks of the copyright holders even if such marks are included in this software. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
0,AppCore,core code shared by the initial researchkit apps.,"appcore =================== appcore is a layer built on top of researchkit which forms the core of the five initial researchkit apps. it includes some of the key features of those initial researchkit apps, including: * dashboard with progress graphs * data storage back end * json serialization and deserialization * integration with sage bionetworks' bridge service we are excited about how helpful appcore has been in the development of several researchkit apps. in order to help the researchkit community derive the most utility from the individual components in appcore, were working hard with many developers to transition components of appcore into the main researchkit repo. as a result, we will only be accepting bug fixes to appcore moving forward and hope you will continue giving feature and ui enhancements once the pieces are fully integrated into researchkits repo. we posted appcore at the time the researchkit was released as a way to provide functionality that the researchkit framework did not have at the time. since then, there have been many improvements to researchkit which make it no longer necessary to use appcore. before you decide to use appcore, consider these researchkit alternatives for appcores components: * dashboard use the chart library in researchkit: http://researchkit.org/docs/docs/charts/chartsandgraph.html * json serialization and deserialization use the researchkit has json serialization functionality: https://github.com/researchkit/researchkit/blob/master/testing/orktest/orktest/orkeserialization.h * integration with sage bionetworks' bridge service use sage bridge sdk instead. also take a look the researchkit sample app (orksample) to see how to use the latest researchkit capabilities. https://github.com/researchkit/researchkit/tree/master/samples/orksample/orksample building appcore ---------------- appcore does not build stand-alone, but rather is built as part of other projects. to build it, go to one of the projects that uses it, such as share the journey. openssl ------- this version of appcore differs from the version in the shipping apps because it does not include openssl, which is used in the shipping apps for cryptographic message syntax (cms) encryption support. cms is used by the apps in order to protect sensitive data stored temporarily on the phone, and while in transit. it helps reduce requirements on back-ends, so that https endpoints can safely be terminated earlier than the final hop, because data encryption and decryption occurs at the application layer. to re-enable openssl, build openssl as an ios static library, add it to the appcore library target, and then switch the cms code to use openssl by removing `apccms_noencryption_justastub.m` from the target and adding `apccms_usingopenssl.m` instead. license ======= the source in the appcore repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) apple inc. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder(s) nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. no license is granted to the trademarks of the copyright holders even if such marks are included in this software. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
1,ResearchStack,an sdk for building research study apps on android.,"# researchstack researchstack is an sdk and ux framework for building research study apps on android. be sure to check out researchstack.org and the researchstack forum for general information and announcements about the framework. ## documentation documentation is written and maintained using javadoc: - backbone documentation - skin documentation ## download add one or both to your app/build.gradle: ```groovy compile compile ``` you may also need to add the following source repos to your project's build.gradle: ```groovy allprojects { repositories { jcenter() maven { url ""https://jitpack.io"" } // for mpandroidchart dependency, not on jcenter yet } } ``` ##backbone - the core building blocks of research stack - tasks, steps, and results - consent - file/database storage and encryption ##skin - framework/template that pulls together backbone components to take most of the work out of building a researchstack app - designed to work with minor changes to an existing researchkit ios app's resources ##examples - sample app * shows how to create a researchstack app using the skin framework. - backbone example app * uses only backbone features. * shows how to create simple tasks (consent and a survey), present them to the user, and process the results. - molemapper android * the full source code of the molemapper android app, which will be available soon on google play. * useful to compare against the open source code of ios/researchkit implementation of mole mapper. ## things to look out for when converting your researchkit app - assets can be dragged and dropped into the assets folder of your project. - please make sure to validate and check for malformed json - please make sure your links define a url in your html. an empty href attribute will reload the same file in a different activity. - researchstack adds attributes to the documentproperties object for consent. additionally, researchstack also supports quiz conent define in the same json file. please update your consentsection json file to reflect these changes. an example can be found in the sampleapp project. - images can be defined in the same directory of an html doc or through android's drawable directories. you can do this using the following path as an example ""file:///android_res/drawable/image_name.png"". please note, loading assets through drawable path breaks when using applicationidsuffix in gradle. - css font-family attribute should be changed to what exists on the system (i.e. sans-serif, sans-serif-light, etc..). - you will need to implement a class that extends the researchstack class and pass an instance of it into researchstack.init() in your application.oncreate() method - inside your researchstack implementation you may need to return your own implementations of things such as resourcemanager to point to your own resources - look at sample app for examples of all of this. most of the resources were pulled from the asthma ios app and modified base on the above points. ## tasks and steps tasks and steps should function very similarly to apple's researchkit. extend task if you need to do something different with step order that is not in orderedtask or smartsurveytask. if you want to implement a custom step, create a step and make getsteplayoutclass() return the class of your own extension of steplayout. this provides the view for your custom step and is responsible for creating the stepresult and passing it back up to the viewtaskactivity. if you just want a custom questionstep with an answer type that is not supported yet, you will need to just create your own answerformat subclass. all questionsteps use the same steplayout, but the answerformat provides a stepbody class that determines what the inner ui for the question looks like (date picker, text field, slider, etc). ## third-party libraries used <b> /> /> com.android.support:design<br /> </b> - used for theming and styling views within the framework. libraries also provide backward-compatible versions of android framework apis (e.g. vector icons, preferences) <b>com.github.philjay:mpandroidchart</b> - charting library used to visualize data <b>com.android.support:multidex</b> - multidex support library enables us to go past the default method limit for an android project <b> co.touchlab.squeaky:squeaky-query </b> - squeaky is a database orm for android, simplifying database functions and used to store task / step result information <b> co.touchlab.squeaky:squeaky-processor </b> - annotation processor for the squeaky ormlite database library. the library creates auto-generated code at compile time for our database pojos (see taskrecord or steprecord classes) <b> net.zetetic:android-database-sqlcipher </b> - enables full aes encryption of sqlite database <b> com.scottyab:aes-crypto </b> - api to perform aes encryption on android, used within the fileaccess class to write raw data to disk <b> compile 'com.cronutils:cron-utils </b> - used to parse crons within the tasks_and_schedules json file and calculating system notification execution time <b> com.google.code.gson:gson </b> - parses and maps json to java objects, used for converting json files defined in raw resource directory <b> io.reactivex:rxandroid io.reactivex:rxjava </b> - used to compose asynchronous and event-based networking and database calls. also used for event-based ui calls for varius ui widgets. <b> /> com.jakewharton.rxbinding:rxbinding-design<br /> /> com.jakewharton.rxbinding:rxbinding </b> - rxjava binding apis for android ui widgets from the platform and support libraries. provides helper methods that wrap api methods and returns rx observables <b> </b> - networking libraries used for network interface"
1,survey_kit,flutter library to create beautiful surveys (aligned with researchkit on ios),"<p align=""center""> <img src=""https://github.com/quickbirdstudios/survey_kit/blob/main/example/assets/surveykit_logo.png?raw=true"" </p> # surveykit: create beautiful surveys with flutter (inspired by ios researchkit surveys) do you want to display a questionnaire to get the opinion of your users? a survey for a medical trial? a series of instructions in a manual-like style? surveykit is an flutter library that allows you to create exactly that. thematically it is built to provide a feeling of a professional research survey. the library aims to be visually clean, lean and easily configurable. we aim to keep the functionality close to ios researchkit surveys. we also created a surveykit version for native android developers, check it out here this is an early version and work in progress. do not hesitate to give feedback, ideas or improvements via an issue. # examples ###### flow <p align=""center""> <img src=""https://github.com/quickbirdstudios/survey_kit/blob/main/example/assets/survey-kit-demo.gif?raw=true"" </p> ###### screenshots | | | | | | | :---: | :---: | :---: | :---: | :---: | | <img | <img | <img | <img | <img | ## overview: creating research surveys - what surveykit does for you - what surveykit does not (yet) do for you - setup - add the dependecy - install it - import it - usage - create survey steps - create a task - evaluate the results - style - start the survey - custom steps - vs : comparison of flutter surveykit, surveykit on android to researchkit on ios - author - contributing - license ## what surveykit does for you - simplifies the creation of surveys - provides rich animations and transitions out of the box (custom animations planned) - build with a consistent, lean, simple style, to fit research purposes - survey navigation can be linear or based on a decision tree (directed graph) - gathers results and provides them in a convinient manner to the developer for further use - gives you complete freedom on creating your own questions - allows you to customize the style - provides an api and structure that is very similar to ios researchkit surveys ## what surveykit does not (yet) do for you as stated before, this is an early version and a work in progress. we aim to extend this library until it matches the functionality of the ios researchkit surveys. # setup to use this plugin, add flutter_surveykit as a dependency in your pubspec.yaml file. ## add the dependecy `pubspec.yaml` ```yaml dependencies: survey_kit: ``` ## install it ``` flutter pub get ``` ## import it ```dart import 'package:survey_kit/survey_kit.dart'; ``` # usage ## example a working example project can be found here ### create survey steps to create a step, create an instance of one of these classes: #### `instructionstep` ```dart instructionstep( title: 'your journey starts here', text: 'have fun with a quick survey', buttontext: 'start survey', ); ``` the `title` is the general title of the survey you want to conduct. the `text` is, in this case, the introduction text which should give an introduction, about what the survey is about. the `buttontext` specifies the text of the button, which will start the survey. all of these properties have to be resource ids. #### `completionstep` ```dart completionstep( title: 'you are done', text: 'you have finished !!!', buttontext: 'submit survey', ); ``` the `title` is the general title of the survey you want to conduct, same as for the `instructionstep`. the `text` is here should be something motivational: that the survey has been completed successfully. the `buttontext` specifies the text of the button, which will end the survey. all of these properties have to be resource ids. #### `questionstep` ```dart questionstep( title: 'sample title', text: 'sample text', answerformat: textanswerformat( maxlines: ), ); ``` the `title` same as for the `instructionstep` and `completionstep`. the `text` the actual question you want to ask. depending on the answer type of this, you should set the next property. the `answerformat` specifies the type of question (the type of answer to the question) you want to ask. currently there these types supported: - `textanswerformat` - `integeranswerformat` - `scaleanswerformat` - `singlechoiceanswerformat` - `multiplechoiceanswerformat` - `booleananswerformat` all that is left is to collect your steps in a list or add them inline in the widget. ```dart var steps = ...] ``` ### create a task next you need a task. each survey has **exactly one** task. a `task` is used to define how the user should navigate through your `steps`. <br><br> #### orderedtask ```dart var task = orderedtask(steps: steps) ``` the `orderedtask` just presents the questions in order, as they are given. #### navigableorderedtask ````dart var task = navigableorderedtask(steps: steps) ```` the `navigableorderedtask` allows you to specify navigation rules.<br> there are two types of navigation rules: with the `directstepnavigationrule` you say that after this step, another specified step should follow. ```dart task.addnavigationrule( fortriggerstepidentifier: navigationrule: directstepnavigationrule( destinationstepstepidentifier: ), ); ``` with the `multipledirectionstepnavigationrule` you can specify the next step, depending on the answer of the step. ```dart task.addnavigationrule( fortriggerstepidentifier: navigationrule: conditionalnavigationrule( resulttostepidentifiermapper: (input) { switch (input) { case ""yes"": return case ""no"": return default: return null; } }, ), ); ``` ### evaluate the results when the survey is finished, you get a callback. no matter of the `finishreason`, you always get all results gathered until now. the `surveyresult` contains a list of `stepresult`s and the `finishreason`. the `stepresult` contains a list of `questionresult`s. ```dart surveykit( onresult: (surveyresult result) { //read finish reason from result (result.finishreason) //and evaluate the results }, ) ``` ### export the results to json after obtaining the `surveyresult` object in the callback described above, you can use its `tojson()` method to either print the results in a json format, or to pass that json (map) object on, and for example store it (in your db, sharedpreferences, as a separate file etc.) ```dart surveykit( onresult: (surveyresult result) { final jsonresult = result.tojson(); // print the json-formatted results debugprint(jsonencode(jsonresult)); // or store them yourdbhandler.store(jsonresult); }, ) ``` ### style there are already many adaptive elements for android and ios implemented. in the future development other parts will be adapted too. the styling can be adjusted by the build in flutter theme. | texttheme | used in | |-------------|-----------------------------| | | title of question | | | text of question | | | text of listtiles | | | textstyle used in textfields| ### localization if you want to override the fixed texts or adapt them to different languages like close, next, .... you need to provide surveykit a map of translations ```dart surveykit( localizations: { 'cancel': 'cancel', } ); ``` here is a complete list of keys that can be overriden: | key | value | |-------|--------| | cancel| cancel | | next | next | | | | ### start the survey all that is left is to insert the survey in the widget tree and enjoy. ```dart scaffold( body: surveykit( onresult: (surveyresult result) { //evaluate results }, task: orderedtask(), theme: customthemedata(), ) ); ``` # custom steps at some point, you might want to define your own custom question steps. that could, for example, be a question which prompts the user to pick color values or even sound samples. these are not implemented yet but you can easily create them yourself: you will need a `customresult` and a `customstep`. the result class tells surveykit which data you want to save. ```dart class customresult extends questionresult<string> { final string customdata; final string valueidentifier; final identifier identifier; final datetime startdate; final datetime enddate; final string value; //custom value } ``` next you will need a customstep class. it is recommended to use the `stepview` widget as your foundation. it gives you the appbar and the next button. ```dart class customstep extends step { final string title; final string text; customstep({ @required stepidentifier id, bool isoptional = false, string buttontext = 'next', this.title, this.text, }) : super(isoptional, id, buttontext); @override widget createview({@required questionresult questionresult}) { return stepview( step: widget.questionstep, result: () => customresult( id: id, startdate: datetime.now(), enddate: datetime.now(), valueidentifier: 'custom'//identification for navigabletask, result: 'custom_result', ), title: text('title'), child: container(), //add your view here ); } } ``` if you want to create a complete custom view or just override the navigation behavior you should use the surveycontroller with its three methods: * onnextstep() * onstepback() * onclosesurvey() # vs : comparison of flutter surveykit, surveykit on android to researchkit on ios this is an overview of which features ios researchkit surveys provides and which ones are already supported by surveykit on android. the goal is to make all three libraries match in terms of their functionality. <p> <img src=""https://github.com/quickbirdstudios/survey_kit/blob/main/example/assets/survey-kit-features.png?raw=true""> </p> # : create your survey via json you are also able to load and create your survey via json. this gives you the oppertunity to dynamicly configure and deliver different surveys. to create your survey in json is almost as easy as in dart. just call ```dart task.fromjson() ``` with your json-file or response. the json should look like this: ```json { ""id"": ""type"": ""navigable"", ""rules"": [ { ""type"": ""conditional"", ""triggerstepidentifier"": { ""id"": }, ""values"": { ""yes"": ""no"": } }, { ""type"": ""direct"", ""triggerstepidentifier"": { ""id"": }, ""destinationstepidentifier"": { ""id"": } }, { ""type"": ""direct"", ""triggerstepidentifier"": { ""id"": }, ""destinationstepidentifier"": { ""id"": } } ], ""steps"": [ { ""stepidentifier"": { ""id"": }, ""type"": ""intro"", ""title"": ""welcome to the\nquickbird studios\nhealth survey"", ""text"": ""get ready for a bunch of super random questions!"", ""buttontext"": ""let us go!"" }, { ""stepidentifier"": { ""id"": }, ""type"": ""question"", ""title"": ""how old are you?"", ""answerformat"": { ""type"": ""integer"", ""defaultvalue"": ""hint"": ""please enter your age"" } }, { ""stepidentifier"": { ""id"": }, ""type"": ""question"", ""title"": ""medication?"", ""text"": ""are you using any medication"", ""answerformat"": { ""type"": ""bool"", ""positiveanswer"": ""yes"", ""negativeanswer"": ""no"", ""result"": ""positive"" } }, { ""stepidentifier"": { ""id"": }, ""type"": ""completion"", ""text"": ""thanks for taking the survey, we will contact you soon!"", ""title"": ""done!"", ""buttontext"": ""submit survey"" } ] } ``` you can find the complete example here # author this flutter library is created with by quickbird studios. # contributing open an issue if you need help, if you found a bug, or if you want to discuss a feature request. open a pr if you want to make changes to surveykit. # license surveykit is released under an mit license. see license for more information."
1,mPower,"researchkit app studying parkinson's disease, developed by sage bionetworks and university of rochester.","mpower app ========== the parkinson app is one of the first five apps built using researchkit. mpower is a unique iphone application that uses a mix of surveys and tasks that activate phone sensors to collect and track health and symptoms of parkinson disease (pd) progression - like dexterity, balance or gait. the goal of this app is to learn more about the variations of pd, and to improve the way we describe these variations and to learn how mobile devices and sensors can help us to measure pd and its progression to ultimately improve the quality of life for people with pd. building the app ================ ###requirements * xcode * ios sdk ###getting the source first, check out the source, including all the dependencies: ``` git clone --recurse-submodules https://github.com/researchkit/mpower.git ``` ###building it open the project, `parkinson.xcodeproj`, and build and run. other components ================ several survey instruments used in the shipping app have been removed from the open source version because they are not free to use: * (parkinson disease questionnaire) * mds-updrs (parkinson disease rating scale) the shipping app also uses openssl to add extra data protection, which has not been included in the published version of the appcore project. see the appcore repository for more details. license ======= the source in the mpower repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) sage bionetworks, inc. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright holder or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
1,CardinalKit,"open-source framework for rapid development of modern, interoperable digital health applications on ios devices","> [!important] > the cardinalkit ios template application is in maintenance mode. all new projects should use stanford spezi, our modular and standards-based framework successor to cardinalkit. check out the [spezi template application](https://github.com/stanfordspezi) as a great way to get started. !cardinalkit logo !cardinalkit logo <!-- all-contributors-badge:start - do not remove or modify this section --> [!all contributors](#contributors-) <!-- all-contributors-badge:end --> --- <img src=""https://raw.githubusercontent.com/cardinalkit/.github/main/assets/ck_map.jpg"" alt=""cardinalkit map""> includes: * informed consent process using researchkit. * track day-to-day adherence with carekit. * monitor health data with healthkit. * collect and upload ehr data. * coremotion data demo. * awesome swiftui templates. * zero-code customizable configuration file. * gcp firebase integration. cardinalkit runs on ios and up. xcode is required for development. ## build your app with cardinalkit this repository contains a fully functional example in the `cardinalkit-example` directory that you can use as a starting point for building your own app. to get started, clone this repository and follow our simple setup instructions. feel free to join our slack community or attend one of our workshops or buildathons for help customizing your app! learn more at https://cardinalkit.org. ## contribute to cardinalkit head on over to https://cardinalkit.org/ to get onboarded to our open source community ## contributors thanks goes to these wonderful people (emoji key): <!-- all-contributors-list:start - do not remove or modify this section --> <!-- prettier-ignore-start --> <!-- markdownlint-disable --> <table> <tr> <td align=""center""><a href=""http://gutierrezsantiago.com""><img alt=""""/><br /><sub><b>santiago gutierrez</b></sub></a><br /><a title=""code""></a></td> <td align=""center""><a href=""http://varunshenoy.com""><img alt=""""/><br /><sub><b>varun shenoy</b></sub></a><br /><a href=""https://github.com/cardinalkit/cardinalkit/commits?author=varunshenoy"" title=""code""></a></td> <td align=""center""><a href=""https://github.com/mhittle""><img alt=""""/><br /><sub><b>mhittle</b></sub></a><br /><a href=""#ideas-mhittle"" title=""ideas, planning, & feedback""></a> <a href=""#maintenance-mhittle"" title=""maintenance""></a> <a href=""#projectmanagement-mhittle"" title=""project management""></a></td> <td align=""center""><a href=""https://github.com/aamirrasheed""><img alt=""""/><br /><sub><b>aamirrasheed</b></sub></a><br /><a href=""#content-aamirrasheed"" title=""content""></a> <a href=""#video-aamirrasheed"" title=""videos""></a></td> <td align=""center""><a href=""http://apollozhu.github.io/en""><img alt=""""/><br /><sub><b>zhiyu zhu/</b></sub></a><br /><a href=""https://github.com/cardinalkit/cardinalkit/commits?author=apollozhu"" title=""code""></a></td> <td align=""center""><a href=""http://vishnu.io""><img alt=""""/><br /><sub><b>vishnu ravi</b></sub></a><br /><a href=""https://github.com/cardinalkit/cardinalkit/commits?author=vishnuravi"" title=""code""></a></td> <td align=""center""><a href=""https://github.com/griffinac""><img alt=""""/><br /><sub><b>ashley griffin</b></sub></a><br /><a href=""#ideas-griffinac"" title=""ideas, planning, & feedback""></a> <a href=""https://github.com/cardinalkit/cardinalkit/commits?author=griffinac"" title=""code""></a></td> </tr> <tr> <td align=""center""><a href=""http://ase.in.tum.de/schmiedmayer""><img alt=""""/><br /><sub><b>paul schmiedmayer</b></sub></a><br /><a href=""https://github.com/cardinalkit/cardinalkit/commits?author=pschmiedmayer"" title=""code""></a></td> </tr> </table> <!-- markdownlint-restore --> <!-- prettier-ignore-end --> <!-- all-contributors-list:end --> this project follows the all-contributors specification. contributions of any kind welcome! ## license cardinalkit is available under the mit license. see the license file for more info. !stanford byers center for biodesign logo !stanford byers center for biodesign logo"
1,GlucoSuccess,"researchkit app studying diabetes, developed by massachusetts general hospital.","glucosuccess ================ glucosuccess is a unique iphone application that utilizes researchkit and healthkit to get a more accurate understanding of how various things affect the progression and management of type diabetes. the app presents a variety of surveys and tasks to track health behaviors such as physical activity, diet and medications. massachusetts general hospitals goals in this study are to understand how health behaviors influence blood glucose in real life, with a resolution greater than ever before. at the same time, the app provides personalized insights into how ones daily diet and physical activity relate to their blood glucose values. building the app ================ ###requirements * xcode * ios sdk ###getting the source first, check out the source, including all the dependencies: ``` git clone --recurse-submodules https://github.com/researchkit/glucosuccess.git ``` ###building it open the project, `diabetes.xcodeproj`, and build and run. other components ================ the shipping app also uses openssl to add extra data protection, which has not been included in the published version of the appcore project. see the appcore repository for more details. data upload to bridge has been disabled, the logos of the institutions have been removed, and the consent material has been marked as an example. license ======= the source in the glucosuccess repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) massachusetts general hospital. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder(s) nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. no license is granted to the trademarks of the copyright holders even if such marks are included in this software. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
0,Depressed,swift ios app that tests if you are depressed,"[!swift [!license](https://raw.githubusercontent.com/derlobi/depressed/master/license) [!build status](https://travis-ci.org/derlobi/depressed) --- !depressed? *depressed?* is an app that asks you the nine questions from the questionnaire to determine if you are depressed. the questionnaire is implemented with apple's researchkit. [!download on the app ## disclaimer :warning: this is just a quick test that you can do yourself, it is no replacement for diagnosis from a professional. if you have the feeling that you might be depressed, please talk to a doctor or a friend. you can also contact me if you need someone to talk. ## setup - clone the repo - run `pod install` to install the dependencies - open `depressed?.xcworkspace` and run the app ## license *depressed?* is released under the mit license. see license for details."
1,SurveyKit,android library to create beautiful surveys (aligned with researchkit on ios),"<p align=""center""> <img src=""assets/top/surveykit-logo.png"" </p> # surveykit: create beautiful surveys on android (inspired by researchkit surveys on ios) do you want to display a questionnaire to get the opinion of your users? a survey for a medical trial? a series of instructions in a manual-like style? <br/> surveykit is an android library that allows you to create exactly that. thematically it is built to provide a feeling of a professional research survey. the library aims to be visually clean, lean and easily configurable. we aim to keep the functionality close to ios researchkit surveys. this is an early version and work in progress. do not hesitate to give feedback, ideas or improvements via an issue. # examples ###### flow <p align=""center""> <img src=""assets/gifs/survey-kit-demo.gif?raw=true"" </p> ###### screenshots | | | | | | | :---: | :---: | :---: | :---: | :---: | | <img src=""assets/top/instruction_qbs.png?raw=true"" | <img src=""assets/top/how_old_are_you_with_hint.png?raw=true"" | <img | <img | <img src=""assets/top/color-picker.png?raw=true"" | ## overview: creating research surveys - what surveykit does for you - what surveykit does not (yet) do for you - library setup - add the repository - add the dependency - usage - add and find the survey in the xml - create survey steps - create a task - evaluate the results - configure - start the survey - location steps - custom steps - comparison to researchkit on ios - author - contributing - license ## what surveykit does for you - simplifies the creation of surveys - provides rich animations and transitions out of the box (custom animations planned) - build with a consistent, lean, simple style, to fit research purposes - survey navigation can be linear or based on a decision tree (directed graph) - gathers results and provides them in a convinient manner to the developer for further use - gives you complete freedom on creating your own questions - allows you to customize the style - provides an api and structure that is very similar to ios researchkit surveys - is used in production by quickbird studios ## what surveykit does not (yet) do for you as stated before, this is an early version and a work in progress. we aim to extend this library until it matches the functionality of the ios researchkit surveys. # library setup > all of the available versions of surveykit has been moved to mavencentral. ## add the repository surveykit is now available via mavencentral which is normally added as part of every new android project. however, if it is not present, you can add it as show here. ```groovy allprojects { repositories { mavencentral() } } ``` ## add the dependency `build.gradle.kts` ````kotlin dependencies { } ```` find the latest version or all releases # usage ## example a working example project can be found here ### add and find the survey in the xml add the surveyview to your `xml` (it looks best if it fills the screen). ````xml <com.quickbirdstudios.survey_kit.survey.surveyview android:id=""@+id/survey_view"" android:layout_width=""match_parent"" android:layout_height=""match_parent"" /> ```` find the view in the `xml` and save it for further use. ```kotlin var surveyview: surveyview = view.findviewbyid(r.id.survey_view) ``` ### create survey steps to create a step, create an instance of one of these classes: #### `instructionstep` ```kotlin instructionstep( title = r.string.intro_title, text = r.string.intro_text, buttontext = r.string.intro_start ) ``` the `title` is the general title of the survey you want to conduct. <br/> the `text` is, in this case, the introduction text which should give an introduction, about what the survey is about.<br/> the `buttontext` specifies the text of the button, which will start the survey. all of these properties have to be resource ids. #### `completionstep` ```kotlin completionstep( title = r.string.finish_question_title, text = r.string.finish_question_text, buttontext = r.string.finish_question_submit ) ``` the `title` is the general title of the survey you want to conduct, same as for the `instructionstep`. <br/> the `text` is here should be something motivational: that the survey has been completed successfully. <br/> the `buttontext` specifies the text of the button, which will end the survey. all of these properties have to be resource ids. #### `questionstep` ```kotlin questionstep( title = r.string.about_you_question_title, text = r.string.about_you_question_text, answerformat = answerformat.textanswerformat( multiplelines = true, maximumlength = ) ) ``` the `title` same as for the `instructionstep` and `completionstep`. <br/> the `text` the actual question you want to ask. depending on the answer type of this, you should set the next property.<br/> the `answerformat` specifies the type of question (the type of answer to the question) you want to ask. currently there these types supported: - `textanswerformat` - `integeranswerformat` - `scaleanswerformat` - `singlechoiceanswerformat` - `multiplechoiceanswerformat` - `locationanswerformat` all that is left is to collect your steps in a list. ```kotlin val steps = ...) ``` ### create a task next you need a task. each survey has **exactly one** task. a `task` is used to define how the user should navigate through your `steps`. <br><br> #### orderedtask ```kotlin val task = orderedtask(steps = steps) ``` the `orderedtask` just presents the questions in order, as they are given. #### navigableorderedtask ````kotlin val task = navigableorderedtask(steps = steps) ```` the `navigableorderedtask` allows you to specify navigation rules.<br> there are two types of navigation rules: <br/> with the `directstepnavigationrule` you say that after this step, another specified step should follow. ```kotlin task.setnavigationrule( navigationrule.directstepnavigationrule( destinationstepstepidentifier = ) ) ``` <br><br/> with the `multipledirectionstepnavigationrule` you can specify the next step, depending on the answer of the step. ```kotlin task.setnavigationrule( navigationrule.multipledirectionstepnavigationrule( resulttostepidentifiermapper = { input -> when (input) { ""yes"" -> ""no"" -> else -> null } } ) ) ``` ### evaluate the results when the survey is finished, you get a callback. no matter of the `finishreason`, you always get all results gathered until now. <br/> the `taskresult` contains a list of `stepresult`s. the `stepresult` contains a list of `questionresult`s. ```kotlin surveyview.onsurveyfinish = { taskresult: taskresult, reason: finishreason -> if (reason == finishreason.completed) { taskresult.results.foreach { stepresult -> log.e(""logtag"", ""answer ${stepresult.results.firstornull()}"") } } } ``` ### style these is how you add custom styling to your survey. we will add even more options in the future. ```kotlin val configuration = surveytheme( themecolordark = contextcompat.getcolor(requirecontext(), r.color.cyan_dark), themecolor = contextcompat.getcolor(requirecontext(), r.color.cyan_normal), textcolor = contextcompat.getcolor(requirecontext(), r.color.cyan_text) ) ``` ### start the survey all that is left is to start the survey and enjoy. ```kotlin surveyview.start(task, configuration) ``` # cancel survey dialog when you cancel the survey, there is an option to change dialog default strings. must be imported from resources. ``` val configuration = surveytheme( themecolordark = contextcompat.getcolor(this, r.color.cyan_dark), themecolor = contextcompat.getcolor(this, r.color.cyan_normal), textcolor = contextcompat.getcolor(this, r.color.cyan_text), abortdialogconfiguration = abortdialogconfiguration( title = r.string.title, message = r.string.message, neutralmessage = r.string.no, negativemessage = r.string.yes ) ) ``` # location steps you need add below to your own application `androidmanifest.xml` file to use google map. ```xml <meta-data android:name=""com.google.android.gms.version"" android:value=""@integer/google_play_services_version"" /> <meta-data android:value=""google api key"" /> ``` also need to append location permissions on `androidmanifest.xml`. this is not required. but if you gave this permissions, map can select current location automatically. ```xml <uses-permission android:name=""android.permission.access_coarse_location"" /> <uses-permission android:name=""android.permission.access_fine_location"" /> ``` you might want to run location question steps test or example app on this project. need to add api keys on `local.properties` file. ```kotlin google_sdk_key=""[api_key]"" //if you want to use yandex address suggession on example app yandex_sdk_key=""[api_key]"" ``` and finally you can instante location question step like below. ```kotlin questionstep( title = ""title"", text = this.resources.getstring(r.string.location_question_text), lifecycle = lifecycle, answerformat = answerformat.locationanswerformat( lifecycle = lifecycle, //addressprovider = yandexaddresssuggestionprovider(api_key) ) ) ``` default address provider is `geocoderaddresssuggestionprovider` based on `android.location.geocoder`. if you want to use custom address provider. you can use `addresssuggestionprovider` interface and make your own implements like `yandexaddresssuggestionprovider`. # custom steps at some point, you might want to define your own custom question steps. that could, for example, be a question which prompts the user to pick color values or even sound samples. these are not implemented yet but you can easily create them yourself: you will need a `customresult` and a `customstep`. the result class tells surveykit which data you want to save. ```kotlin @parcelize data class customresult( val customdata: string, override val stringidentifier: string, override val id: identifier, override val startdate: date, override var enddate: date ) : questionresult, parcelable ``` next you will need a customstep class: ```kotlin class customstep : step { override val isoptional: boolean = true override val id: stepidentifier = stepidentifier() val tmp = id override fun createview(context: context, stepresult: stepresult?): stepview { return object : stepview(context, id, isoptional) { override fun setupviews() = unit val root = view.inflate(context, r.layout.example, this) override fun createresults(): questionresult = customresult( root.findviewbyid<edittext>(r.id.input).text.tostring(), ""stringidentifier"", id, date(), date() ) override fun isvalidinput(): boolean = this@customstep.isoptional override var isoptional: boolean = this@customstep.isoptional override val id: stepidentifier = tmp override fun style(surveytheme: surveytheme) { // do styling here } init { root.findviewbyid<button>(r.id.continue) .setonclicklistener { onnextlistener(createresults()) } root.findviewbyid<button>(r.id.back) .setonclicklistener { onbacklistener(createresults()) } root.findviewbyid<button>(r.id.close) .setonclicklistener { oncloselistener(createresults(), finishreason.completed) } root.findviewbyid<button>(r.id.skip) .setonclicklistener { onskiplistener() } root.findviewbyid<edittext>(r.id.input).settext( (stepresult?.results?.firstornull() as? customresult)?.customdata ?: """" ) } } } } ``` # vs : comparison of surveykit on android to researchkit on ios this is an overview of which features ios researchkit surveys provides and which ones are already supported by surveykit on android. the goal is to make both libraries match in terms of their functionality. | steps | ios researchkit | android surveykit| | :------------------------ | :---: | :---: | | instruction | | | | single selection | | | | multi selection | | | | boolean answer | | | | value picker | | | | image choice | | | | numeric answer | | | | time of day | | | | date selection | | | | text answer (unlimited) | | | | text answer (limited) | | | | text answer (validated) | | | | scale answer | | | | email answer | | | | location answer | | | # author this android library is created with by quickbird studios. # contributing open an issue if you need help, if you found a bug, or if you want to discuss a feature request. open a pr if you want to make changes to surveykit. for the moment, a mandatory requirement for a pr to be accepted is also applying ktlint when submitting this pr. # license surveykit is released under an mit license. see license for more information."
1,AsthmaHealth,"researchkit app studying asthma, developed by mt sinai.","asthma health ============= the asthma mobile health study is a personalized app that helps individuals gain greater insight into their asthma, adhere to treatment plans, and avoid triggers. the app presents a variety of surveys to better understand unique triggers for asthma exacerbations, and connects with healthkit to track inhaler usage and peak flow values. building the app ================ ###requirements * xcode * ios sdk ###getting the source first, check out the source, including all the dependencies: ``` git clone --recurse-submodules https://github.com/researchkit/asthmahealth.git ``` ###building it open the project, `asthma.xcodeproj`, and build and run. other components ================ the euroqol survey instrument is used in the shipping app, but has been removed from the open source version because it is not free to use. the shipping app also uses openssl to add extra data protection, which has not been included in the published version of the appcore project. see the appcore repository for more details. data upload to bridge has been disabled, the logos of the institutions have been removed, and the consent material has been marked as an example. license ======= the source in the asthmahealth repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) icahn school of medicine at mount sinai. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder(s) nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. no license is granted to the trademarks of the copyright holders even if such marks are included in this software. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
1,ShareTheJourney,"researchkit app studying breast cancer, developed by sage bionetworks.","share the journey ================= share the journey is one of the first five apps built using researchkit. sage bionetworks' goal in this study is to understand the causes of the symptom variations after breast cancer treatment; to learn how mobile devices and sensors can help us to these symptoms and their progression; and to ultimately improve the quality of life for people after breast cancer treatment. the share the journey app asks the participant to answer questions about herself, medical history, and current health. the app also collects information while the participant perform specific tasks while using a mobile phone, such as to provide a journal about her symptoms. additionally, the app asks permission to collect sensor data from the phone itself. building the app ================ ###requirements * xcode * ios sdk ###getting the source first, check out the source, including all the dependencies: ``` git clone --recurse-submodules https://github.com/researchkit/sharethejourney.git ``` ###building it open the project, `breastcancer.xcodeproj`, and build and run. other components ================ several survey instruments used in the shipping app have been removed from the open source version because they are not free to use: * par q+ (exercise readiness survey) * psqi (sleep quality survey) * paofi (assessment of functioning survey) the shipping app also uses openssl to add extra data protection, which has not been included in the published version of the appcore project. see the appcore repository for more details. data upload to bridge has been disabled, the logos of the institutions have been removed, and the consent material has been marked as an example. license ======= the source in the sharethejourney repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) sage bionetworks, inc. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright holder or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
0,ios-health-fitness-apps,"ios health & fitness apps, medical researches and tutorials","<img width = <img width = <img width = here is the collaborative list of open-source apps and demos to use apple's healthkit, researchkit and carekit. feel free to contribute. thanks! ## apple healthkit ### apple healthkit apis ### apple's sample apps: - reading and writing healthkit series data(ios - fit: store and retrieve healthkit data - speedysloth: using healthkit to build a workout app for apple watch - loophealth: using health documents and activity rings in healthkit and healthkitui - activity rings: contributing to activity rings on apple watch - swingwatch: using device motion on the watch ## apple researchkit ### programming guide ### sample apps: - sageresearch - more ## apple carekit ## fda regulatory on mobile medical apps ### mobile medical applications ### policy for device software functions and mobile medical applications ### examples of device software functions the fda regulates ## connecting to bluetooth low energy (ble) devices babybluetooth bluetoothkit ios-nrf-toolbox_swift bluejay rxbluetoothkit bluecap ## most-porpular health & fitness apps in app store (rankings): top free: https://www.similarweb.com/apps/top/apple/store-rank/us/health-and-fitness/top-free/iphone top paid: https://www.similarweb.com/apps/top/apple/store-rank/us/health-and-fitness/top-paid/iphone ## most-porpular medical apps in app store (rankings): top free: https://www.similarweb.com/apps/top/apple/store-rank/us/medical/top-free/iphone top paid: https://www.similarweb.com/apps/top/apple/store-rank/us/medical/top-paid/iphone ## open-source apps ### health back to top - abby's cycle: menstrual cycle tracker <details><summary><code>swift</code> </summary> added july license: `other` <div><img alt='abby's cycle image <img alt='abby's cycle image </div> </details> - arex: reminders for taking your medications <details><summary><code>swift</code> <code>carthage</code> <code>pistachio</code> <code>reactivecocoa</code> </summary> added june license: `mit` </details> - caseassistant: cases recording, study, & sharing for ophthalmologist ` app store` <details><summary><code>swift</code> <code>realm</code> </summary> https://github.com/herrkaefer/caseassistant<br> added june license: <div><img alt='caseassistant image <img alt='caseassistant image <img alt='caseassistant image <img alt='caseassistant image <img alt='caseassistant image <img alt='caseassistant image </div> </details> - depressed: test if you are depressed ` app store` <details><summary><code>swift</code> </summary> https://github.com/derlobi/depressed<br> added january license: `mit` <div><img alt='depressed image <img alt='depressed image <img alt='depressed image <img alt='depressed image </div> </details> - glucosio: diabetes management and research <details><summary><code>swift</code> <code>objc</code> <code>healthkit</code> <code>realm</code> </summary> https://github.com/glucosio/glucosio-ios<br> added january license: </details> - healthkit~swift: sample app <details><summary><code>swift</code> <code>healthkit</code> </summary> https://github.com/darktt/healthkit-swift<br> added october license: `other` <div><img alt='healthkit~swift image <img alt='healthkit~swift image <img alt='healthkit~swift image <img alt='healthkit~swift image src='https://i.imgur.com/iuiwmyy.png'> </div> </details> - hidrate: interacts with smart water bottle <details><summary><code>objc</code> </summary> https://github.com/mjcuva/hidrate<br> added may license: `other` <div><img alt='hidrate image src='https://i.imgur.com/noahewe.png'> <img alt='hidrate image <img alt='hidrate image <img alt='hidrate image src='https://i.imgur.com/mcdjdld.png'> </div> </details> - myweight history: body mass tracker with easy data input & access to history ` app store` <details><summary><code>swift</code> </summary> https://github.com/diogot/myweight<br> added june license: `mit` <div><img alt='myweight history image </div> </details> #### fitness back to top - jim: track your gym workouts <details><summary><code>swift</code> <code>parse</code> </summary> https://github.com/kylejm/jim<br> added january license: `other` </details> - logu: simple logging app for strength athletes <details><summary><code>swift</code> </summary> https://github.com/brettalcox/logu-swift<br> added april license: `other` <div><img alt='logu image <img alt='logu image <img alt='logu image <img alt='logu image <img alt='logu image </div> </details> - raceme: run tracking & ghosting <details><summary><code>swift</code> <code>parse</code> </summary> added july license: `other` <div><img alt='raceme image </div> </details> - racerunner: a run-tracking app for runners who race ` app store` <details><summary><code>swift</code> </summary> added march license: `mit` <div><img alt='racerunner image <img alt='racerunner image <img alt='racerunner image <img alt='racerunner image <img alt='racerunner image <img alt='racerunner image </div> </details> - runner-stats: record running data <details><summary><code>iphone</code> </summary> added october license: <div> </div> </details> - rtracker: a generic, customizable personal data tracker ` app store` <details><summary><code>objc</code> </summary> https://github.com/rob-miller/rtracker<br> added april license: <div><img alt='rtracker image <img alt='rtracker image <img alt='rtracker image <img alt='rtracker image <img alt='rtracker image </div> </details> - swift-walk-tracker: track your walks <details><summary><code>swift</code> </summary> https://github.com/kevinvanderlugt/swift-walk-tracker<br> added june license: `other` <div><img alt='swift-walk-tracker image src='https://github.com/kevinvanderlugt/swift-walk-tracker/raw/master/images/screenshot_map.png'> <img alt='swift-walk-tracker image src='https://github.com/kevinvanderlugt/swift-walk-tracker/raw/master/images/screenshot_list.png'> </div> </details> - theseus: personal analytics app <details><summary><code>objc</code> </summary> https://github.com/lazerwalker/theseus<br> added april license: <div><img alt='theseus image src='https://raw.githubusercontent.com/lazerwalker/theseus/master/readmeimages/triptych.png'> </div> </details> ### researchkit back to top - alzprevent: clinical research platform for alzheimer's disease ` app store` <details><summary><code>swift</code> </summary> https://github.com/bbbinc/alzprevent-ios<br> added august license: <div><img alt='alzprevent image <img alt='alzprevent image <img alt='alzprevent image <img alt='alzprevent image <img alt='alzprevent image </div> </details> - asthmahealth: asthma study <details><summary><code>objc</code> </summary> https://github.com/researchkit/asthmahealth<br> added april license: <div><img alt='asthmahealth image <img alt='asthmahealth image <img alt='asthmahealth image <img alt='asthmahealth image <img alt='asthmahealth image <img alt='asthmahealth image </div> </details> - colorblind: easy test for colorblind people <details><summary><code>swift</code> </summary> https://github.com/boostcode/researchkit-colorblind<br> added may license: `other` <div><img alt='colorblind image <img alt='colorblind image <img alt='colorblind image </div> </details> - glucosuccess: diabetes study <details><summary><code>objc</code> </summary> https://github.com/researchkit/glucosuccess<br> added april license: <div><img alt='glucosuccess image <img alt='glucosuccess image <img alt='glucosuccess image <img alt='glucosuccess image <img alt='glucosuccess image <img alt='glucosuccess image </div> </details> - mpower: parkinson's disease study ` app store` <details><summary><code>objc</code> </summary> https://github.com/researchkit/mpower<br> added april license: <div><img alt='mpower image <img alt='mpower image <img alt='mpower image <img alt='mpower image <img alt='mpower image </div> </details> - myheartcounts: personalized tool that can help you measure daily activity, fitness, & cardiovascular risk ` app store` <details><summary><code>objc</code> </summary> https://github.com/researchkit/myheartcounts<br> added october license: <div><img alt='myheartcounts image <img alt='myheartcounts image <img alt='myheartcounts image <img alt='myheartcounts image </div> </details> - share the journey: breast cancer study <details><summary><code>objc</code> </summary> https://github.com/researchkit/sharethejourney<br> added april license: <div> </div> </details> ## apple watch back to top - cortado: track your caffeine consumption habits ` app store` <details><summary><code>objc</code> </summary> https://github.com/lazerwalker/cortado<br> added june license: `mit` <div><img alt='cortado image <img alt='cortado image <img alt='cortado image <img alt='cortado image <img alt='cortado image </div> </details> - gulps: track your daily water consumption ` app store` <details><summary><code>swift</code> </summary> https://github.com/fancypixel/gulps<br> added april license: `mit` <div><img alt='gulps image </div> </details> - heartcontrol: continuous heart rate measurement during workouts <details><summary><code>swift</code> </summary> https://github.com/thomaspaulmann/heartcontrol<br> added august license: `other` <div><img alt='heartcontrol image src='https://i.imgur.com/aggsuxa.png'> <img alt='heartcontrol image <img alt='heartcontrol image src='https://i.imgur.com/zckknwc.png'> </div> </details> - heartrate: show streaming heart rate from the watch <details><summary><code>swift</code> </summary> https://imgur.com/a/xvqqj<br> added july license: `other` <div><img alt='heartrate image src='https://i.imgur.com/hofxcbx.png'> </div> </details> - myweight history: body mass tracker with easy data input & access to history ` app store` <details><summary><code>swift</code> </summary> https://github.com/diogot/myweight<br> added june license: `mit` <div><img alt='myweight history image </div> </details> - watchos new features example code <details><summary><code>swift</code> </summary> added june license: `mit` <div><img image </div> </details>"
1,research.package,a flutter package implementing support for surveys like researchstack and researchkit,"# research package [!pub package](https://pub.dartlang.org/packages/research_package) [!style: effective dart](https://pub.dev/packages/pedandic_dart) [!github stars](https://github.com/cph-cachet/research.package) [!mit license](https://opensource.org/licenses/mit) research package is a flutter package for building research study apps on android and ios using flutter. research package is a flutter implementation of the apple researchkit available for ios (just like researchstack is for android). the overarching goal of researchpackage is to enable developers and researchers to design and build cross-platform (ios and android) research applications using the same codebase. research package is designed from the ground up to meet the requirements of most scientific research, including capturing participant consent, extensible input tasks, and the security and privacy needs necessary for irb approval. the main features of research package are: - obtaining informed consent from participants, including support for a signature. - creating surveys and questionnaires with a wide range of answer formats (e.g., likert scale, date pickers, image pickers, etc.), such as the survey. - supporting localizations of surveys and informed consent. research package is part of the overall copenhagen research platform (carp) with also provides a flutter package for mobile and wearable sensing called carp mobile sensing. the pulmonary monitor app shows how mobile sensing can be combined with collection of survey data from users. ## documentation there is a set of tutorials, describing: - the overall software architecture of research package - how to create an informed consent flow - how to define and run user surveys - how to enable localization the research package flutter api is available (and maintained) as part of the package release at pub.dev. ## example application there is an example app which demonstrates the different features of research package as implemented in a flutter app. ## who is backing this project? research package is made by the copenhagen center for health technology (cachet) and is an important component in the copenhagen research platform (carp), which is used in a number of applications and studies. the current project maintainers are mads vedel saaby christensen and jakob e. bardram. ## how can i contribute? we are more than happy to take contributions and feedback. use the issues page to file an issue or feature request. besides general help for enhancement and quality assurance (bug fixing), we welcome input on new answer types. ## license this software is copyright (c) copenhagen center for health technology (cachet) at the technical university of denmark (dtu). this software is available 'as-is' under a mit license."
1,MyHeartCounts,myheart counts is a researchkit app developed by stanford.,"building the app ================ ###requirements * xcode * ios sdk ###getting the source first, check out the source, including all the dependencies: ``` git clone --recurse-submodules git@github.com:researchkit/myheartcounts.git ``` ###building it open the project, `cardiohealth.xcodeproj`, and build and run. other components ================ the shipping app also uses openssl to add extra data protection, which has not been included in the published version of the appcore project. see the appcore repository for more details. license ======= the source in the myheartcounts repository is made available under the following license unless another license is explicitly identified: ``` copyright (c) stanford medical. all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. neither the name of the copyright holder(s) nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission. no license is granted to the trademarks of the copyright holders even if such marks are included in this software. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall the copyright owner or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage. ```"
1,ionic-researchKit,an open source library equivalent of apple's researchkit framework built on ionic which makes it easy to create cross-platform hybrid native apps for medical research or for other research projects.,"# what is ionicresearchkit? an open source library equivalent of apple's researchkit framework built on ionic which makes it easy to create cross-platform hybrid native apps for medical or non-medical research and for other survey-type projects. # app showcase - mit voice up - allows users to track various aspects of their mental health through a series of survey questions and speech prompts. get it on itunes get it on google play - civique.org - the platform helps cities and organizations to create challenges on topics that matter to citizens and communities which also helps them document their because, make sense of their data, and engage with people. get it on itunes get it on google play - bites'n'bits - a research project of the ecole polytechnique fdrale de lausanne which aims to understand the modes of consumption and the perception of food and beverages consumed in everyday life. get it on itunes get it on google play # demo survey demo consent demo finger tapping task demo audio task demo # ionic version compatibility - ionic - --> fully compatible - ionic --> not yet tested # installation download and import the plugin script.<br /> `<script src=""lib/ionic-researchkit/ionic-researchkit.js""></script>` download and import the plugin stylesheet.<br /> `<link href=""lib/ionic-researchkit/ionic-researchkit.css"" rel=""stylesheet"">` add `ionicresearchkit` to your angular app module dependencies list.<br /> `angular.module('myapp', ['ionicresearchkit']);` # usage add a modal view to your app using $ionicmodal add the following to your modal view template: ### survey ``` <ion-modal-view class=""irk-modal""> <irk-ordered-tasks> <irk-task> <irk-instruction-step title=""your title here."" text=""additional text can go here."" /> </irk-task> <irk-task> <irk-scale-question-step title=""your question here."" text=""additional text can go here."" /> </irk-task> <irk-task> <irk-boolean-question-step title=""your question here."" text=""additional text can go here."" true-text=""yes"" false-text=""no"" /> </irk-task> <irk-task> <irk-text-question-step title=""your question here."" text=""additional text can go here."" /> </irk-task> <irk-task> <irk-text-question-step title=""your question here."" text=""additional text can go here."" multiple-lines=""false"" /> </irk-task> <irk-task> <irk-text-choice-question-step title=""your question here."" text=""additional text can go here."" style=""single""> <irk-text-choice text=""choice <irk-text-choice text=""choice <irk-text-choice text=""choice detail-text=""additional text can go here.""></irk-text-choice> </irk-text-choice-question-step> </irk-task> <irk-task> <irk-text-choice-question-step title=""your question here."" text=""additional text can go here."" style=""multiple""> <irk-text-choice text=""choice <irk-text-choice text=""choice <irk-text-choice text=""choice detail-text=""additional text can go here.""></irk-text-choice> </irk-text-choice-question-step> </irk-task> <irk-task> <irk-numeric-question-step title=""your question here."" text=""additional text can go here."" unit=""your unit."" /> </irk-task> <irk-task> <irk-date-question-step title=""your question here."" text=""additional text can go here."" /> </irk-task> <irk-task> <irk-time-question-step title=""your question here."" text=""additional text can go here."" /> </irk-task> <irk-task> <irk-value-picker-question-step title=""your question here."" text=""additional text can go here."" > <irk-picker-choice text=""choice <irk-picker-choice text=""choice <irk-picker-choice text=""choice </irk-value-picker-question-step> </irk-task> <irk-task> <irk-image-choice-question-step title=""your question here."" text=""additional text can go here."" > <irk-image-choice text=""choice normal-state-image=""ion-sad-outline"" selected-state-image=""ion-sad""></irk-image-choice> <irk-image-choice text=""choice normal-state-image=""ion-happy-outline"" selected-state-image=""ion-happy""></irk-image-choice> </irk-image-choice-question-step> </irk-task> <irk-task> <irk-form-step title=""your question here."" text=""additional text can go here."" > <irk-form-item title=""your section title.""></irk-form-item> <irk-form-item type=""text"" id=""firstname"" text=""first name"" placeholder=""john""></irk-form-item> <irk-form-item type=""text"" id=""lastname"" text=""last name"" placeholder=""suhr""></irk-form-item> <irk-form-item title=""your section title.""></irk-form-item> <irk-form-item type=""email"" id=""email"" text=""email"" placeholder=""john@suhr.com""></irk-form-item> <irk-form-item type=""tel"" id=""phone"" text=""phone"" </irk-form-step> </irk-task> <irk-task> <irk-instruction-step title=""your title here."" text=""additional text can go here."" button-text=""done"" /> </irk-task> </irk-ordered-tasks> </ion-modal-view> ``` ### consent ``` <ion-modal-view class=""irk-modal""> <irk-ordered-tasks> <irk-task> <irk-visual-consent-step type=""overview"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""data-gathering"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""privacy"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""data-use"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""time-commitment"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""study-survey"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""study-tasks"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""withdrawing"" summary=""your summary goes here.""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-visual-consent-step type=""custom"" title=""your title"" text=""learn more"" summary=""your summary goes here."" image=""custom-image-class""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> <irk-visual-consent-step type=""only-in-document"" title=""your title (in document only)""> lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-visual-consent-step> </irk-task> <irk-task> <irk-consent-sharing-step summary=""your summary goes here."" investigator-short-description=""yourinstitution"" investigator-long-description=""yourinstitution and its partners"" > lorem ipsum dolor sit amet, consectetur adipiscing elit. nam adhuc, meo fortasse vitio, quid ego quaeram non perspicis. plane idem, inquit, et maxima quidem, qua fieri nulla maior potest. quonam, inquit, modo? </irk-consent-sharing-step> </irk-task> <irk-task> <irk-consent-review-step type=""review"" title=""your title"" reason-for-consent=""lorem ipsum dolor sit amet...""></irk-consent-review-step> </irk-task> <irk-task> <irk-consent-review-step type=""name"" text=""lorem ipsum dolor sit amet..."" signature-page-title=""consent"" signature-page-content=""i agree to participate in this research study.""> <irk-consent-name title=""participant"" given-name="""" family-name="""" requires-name=""true""/> </irk-consent-review-step> </irk-task> <irk-task> <irk-consent-review-step type=""signature""> <irk-consent-signature signatureimage="""" signaturedate="""" signature-date-format="""" requires-signature-image=""true""/> </irk-consent-review-step> </irk-task> </irk-ordered-tasks> </ion-modal-view> ``` ### active task ``` <ion-modal-view class=""irk-modal""> <irk-ordered-tasks> <irk-task> <irk-instruction-step title=""tapping speed"" text=""this activity measures your tapping speed."" button-text=""next"" image=""irk-phone-tapping"" footer-attach=""true""/> </irk-task> <irk-task> <irk-instruction-step title=""tapping speed"" text=""rest your phone on a flat surface. two buttons will appear on your screen for seconds. using two fingers on the same hand, take turns tapping the buttons as quickly as you can."" button-text=""get started"" image=""irk-hand-tapping"" footer-attach=""true""/> </irk-task> <irk-task> <irk-two-finger-tapping-interval-task </irk-task> <irk-task> <irk-completion-step </irk-task> </irk-ordered-tasks> </ion-modal-view> ``` # directives ### survey `<irk-ordered-tasks>` is the equivalent of the `orkorderedtask` class and will encompass one or more `<irk-task>` elements. `<irk-task>` is the equivalent of the `orktask` class and will encompass one of the available `<irk-*-step>` elements. `<irk-instruction-step>` is the equivalent of the `orkinstructionstep` class and includes the `id`, `title`, `text`, `link`, `link-text` and `image` attributes. `<irk-scale-question-step>` is the equivalent of the `orkquestionstep` and `orkscaleanswerformat` classes combined and includes the `id`, `title`, `text`, `min`, `max`, `step`, `value`, `min-text`, `max-text`, and `optional` attributes. `<irk-boolean-question-step>` is the equivalent of the `orkquestionstep` and `orkbooleananswerformat` classes combined and includes the `id`, `title`, `text`, `true-value`, `true-text`, `false-value`, `false-text`, and `optional` attributes. `<irk-text-question-step>` is the equivalent of the `orkquestionstep` and `orktextanswerformat` classes combined and includes the `id`, `title`, `text`, `placeholder`, `max-length`, `multiple-lines`, and `optional` attributes. `<irk-text-choice-question-step>` is the equivalent of the `orkquestionstep` and `orktextchoiceanswerformat` classes combined and includes the `id`, `title`, `text`, and `optional` attributes. this encompass several `<irk-text-choice>` elements where each include the `value`, `text`, and `detail-text` attributes. `<irk-numeric-question-step>` is the equivalent of the `orkquestionstep` and `orknumericanswerformat` classes combined and includes the `id`, `title`, `text`, `min`, `max`, `unit`, `placeholder`, and `optional` attributes. `<irk-date-question-step>` is the equivalent of the `orkquestionstep` and `orkdateanswerformat` classes combined and includes the `id`, `title`, `text`, and `optional` attributes. `<irk-time-question-step>` is the equivalent of the `orkquestionstep` and `orktimeofdayanswerformat` classes combined and includes the `id`, `title`, `text`, and `optional` attributes. `<irk-value-picker-question-step>` is the equivalent of the `orkquestionstep` and `orkvaluepickeranswerformat` classes combined and includes the `id`, `title`, `text`, and `optional` attributes. this encompass several `<irk-picker-choice>` elements where each include the `value`, `text` attributes. `<irk-image-choice-question-step>` is the equivalent of the `orkquestionstep` and `orkimagechoiceanswerformat` classes combined and includes the `id`, `title`, `text`, and `optional` attributes. this encompass several `<irk-image-choice>` elements where each include the `value`, `text`, `type`, `normal-state-image`, `selected-state-image` attributes. `<irk-form-step>` is the equivalent of the `orkformstep` class and includes the `id`, `title`, `text` attributes. this encompass several `<irk-form-item>` elements which are the equivalent of the `orkformitem` class and each include the `title`, `id`, `type`, `text` and `placeholder` , and `optional` attributes. ### consent `<irk-visual-consent-step>` is the equivalent of the `orkvisualconsentstep` class. `<irk-consent-sharing-step>` is the equivalent of the `orkconsentsharingstep` class. `<irk-consent-review-step>` is the equivalent of the `orkconsentreviewstep` class. depending on it is `type` attribute, it could encompass either `<irk-consent-name>` or `<irk-consent-signature>` elements which are the broken up equivalent of the `orkconsentsignature` class. the consent document pdf is automatically generated as a string and can be retrieved by using `irkconsentdocument.getdocument().getdataurl()`. ### active tasks `<irk-countdown-step>` is the equivalent of the `orkcountdownstep` class and supports the `duration` attribute. `<irk-completion-step>` is the equivalent of the `orkcompletionstep` class. `<irk-two-finger-tapping-interval-task>` is the equivalent of the `orkpredefinedactivetask` class that is for two finger tapping and supports the `text` and `duration` attributes. `<irk-audio-task>` is the equivalent of the `orkpredefinedactivetask` class that is for audio capture and supports the `text`, `duration`, `auto-record`, `auto-complete`, and `optional` attributes. license ======= the source in the ionic-researchkit repository is made available under the following license unless another license is explicitly identified: ``` the mit license (mit) copyright (c) nino guba permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""software""), to deal in the software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, and to permit persons to whom the software is furnished to do so, subject to the following conditions: the above copyright notice and this permission notice shall be included in all copies or substantial portions of the software. the software is provided ""as is"", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software. ```"
0,ResearchKit-ColorBlind,colorblind app - researchkit swift app,# colorblind app [!download on the app colorblind app is a **swift** app developed on top of researchkit. it makes use of patterns based on images developed by instead of ishihara ones. this app has been built for #ioscon conference as poc.
1,ResearchKitOnFHIR,fhir structured data capture with researchkit on ios,"<!-- this source file is part of the researchkitonfhir open source project spdx-filecopyrighttext: stanford university and the project authors (see contributors.md) spdx-license-identifier: mit --> # researchkitonfhir [!build and test](https://github.com/stanfordbdhg/researchkitonfhir/actions/workflows/build-and-test.yml) [!codecov](https://codecov.io/gh/stanfordbdhg/researchkitonfhir) researchkitonfhir is a framework that allows you to use fhir questionnaires with researchkit to create healthcare surveys on ios based on the structured data capture implementation guide for more information, please refer to the api documentation. ## features - converts fhir questionnaires into researchkit tasks - serializes results into fhir questionnaireresponses - supports survey skip-logic by converting fhir `enablewhen` conditions into researchkit navigation rules - supports answer validation during entry - supports contained fhir valuesets as answer options ### fhir <-> researchkit conversion | fhir questionnaireitemtype | researchkit type | fhir response type |------------------------------|-----------------------------|--------------------------| | attachment | orkimagecapturestep | valueattachment | boolean | orkbooleananswerformat | valueboolean | choice | orktextchoice | valuecoding | date | orkdateanswerformat(style: orkdateanswerstyle.date) | valuedate | datetime | orkdateanswerformat(style: orkdateanswerstyle.dateandtime) | valuedatetime | decimal | orknumericanswerformat.decimalanswerformat | valuedecimal | display | orkinstructionstep | *none* | group | orkformstep | *none* | integer | orknumericanswerformat.integeranswerformat | valueinteger | quantity | orknumericanswerformat.decimalanswerformat(withunit: quantityunit) | valuequantity | string | orktextanswerformat | valuestring | text | orktextanswerformat | valuestring | time | orktimeofdayanswerformat | valuetime ### navigation rules the following table describes how the fhir enablewhen is converted to a researchkit orkskipstepnavigationrule for each supported type and operator. (the conversion is performed by constructing an orkresultpredicate from the enablewhen expression and negating it.) multiple enablewhen expressions are supported, using the enablebehavior element to determine if any or all of the expressions should be applied. if enablebehavior is not defined, all expressions will be applied. | fhir questionnaireitemtype | supported questionnaireitemoperators | researchkit orkresultpredicate | | ---------------------------- | ------------------- | ------------------------------ | | boolean | =, != | .predicateforbooleanquestionresult | integer | =, !=, <=, >= | .predicatefornumericquestionresult | decimal | =, !=, <=, >= | .predicatefornumericquestionresult | date | >, < | .predicatefordatequestionresult | coding | =, != | .predicateforchoicequestionresult ## installation researchkitonfhir can be installed into your xcode project using swift package manager. in xcode and newer (requires swift go to file add packages... enter the url to this github repository, then select the `researchkitonfhir` package to install. ## usage the `example` directory contains an xcode project that demonstrates how to create a researchkit task from an fhir questionnaire and extract the results in the form of an fhir questionnaireresponse. ### converting from fhir to researchkit #### instantiate an fhir questionnaire from json ```swift let data = <fhir json data> var questionnaire: questionnaire? do { questionnaire = try jsondecoder().decode(questionnaire.self, from: data) } catch { print(""could not decode the fhir questionnaire"": \(error)"") } ``` #### create a researchkit navigable task from the fhir questionnaire ```swift var task: orknavigableorderedtask? do { task = try orknavigableorderedtask(questionnaire: questionnaire) } catch { print(""error creating task: \(error)"") } ``` now you can present the task as described in the researchkit documentation. ### converting researchkit task results to fhir questionnaireresponse in your class that implements the `orktaskviewcontrollerdelegateprotocol`, you can extract an fhir questionnaireresponse from the task's results as shown below. ```swift func taskviewcontroller( _ taskviewcontroller: orktaskviewcontroller, didfinishwith reason: orktaskviewcontrollerfinishreason, error: error? ) { switch reason { case .completed: let fhirresponse = taskviewcontroller.result.fhirresponse // ... } } ``` ## license this project is licensed under the mit license. see licenses for more information. ## contributors this project is developed as part of the stanford university projects at stanford. see contributors.md for a full list of all researchkitonfhir contributors. ## notices researchkit is a registered trademark of apple, inc. fhir is a registered trademark of health level seven international. !stanford byers center for biodesign logo !stanford byers center for biodesign logo"
0,cordova-plugin-researchkit,cordova / phonegap plugin for the apple's researchkit,"# cordova researchkit plugin by eddy verbruggen <img ## important notes: * this plugin does not currently work in the simulator because of missing framework slices. use a real device. * installation warning: after `cordova plugin add ..` open the project in xcode or higher, choose target > general > embedded binaries > + > researchkit.framework (see this). ## supported survey answer formats at the moment this plugin can only be used for surveys / questionnaires. see the demo to learn how to use the plugin. the supported answer formats currently are: #### orkbooleananswerformat (user must choose yes/no) ```js { 'id': 'title': 'do you consent to a background check?', 'answerformat' : 'orkbooleananswerformat' // or 'boolean' } ``` <img src=""img/answerformats/booleananswerformat.png"" #### orknumericanswerformat (user must enter a number) ```js { 'id': 'title': 'how old are you?', 'answerformat': 'orknumericanswerformat', // or 'numeric' 'unit': 'years', 'minimum': // optional 'maximum': // optional } ``` <img src=""img/answerformats/numericanswerformat.png"" #### more formats will be added soon"
0,MoleMapperAndroid,an open-source implementation of mole mapper for android using researchstack.,"# introduction molemapper android is an open source port of the mole mapper researchkit(tm) melanoma research study to researchstack. this implementation of molemapper on android was created to serve as an open source example of best practices for creating a production-ready researchstack application. initial funding was generous provided by a grant from the robert wood johnson foundation. oregon health & science university will be posting their public fork of mole mapper for android in the near future, which will more closely follow the mole mapper android app (being released soon by ohsu on google play). we will prove links to that project and the app on google play as they become available. # about molemapper mole mapper is a personalized tool to help you map, measure, and monitor the moles on your skin. using a familiar maps-like interface, you can measure the size of a mole using the camera and a common reference object like a coin. if you are or older, mole mapper also gives you the option to participate in a research study developed in partnership with researchers at oregon health & science university and sage bionetworks, a nonprofit research organization to better understand skin biology and melanoma risks. keeping track of the size, shape and color of your moles is the best way to catch potential skin cancers like melanoma in their early stages. whether you use mole mapper to keep track of a single suspicious mole over time or construct a full-body map, we hope this app will make being vigilant about your health a bit more enjoyable. the molemapper research study was created in partnership with researchers at oregon health & science university and sage bionetworks. unless otherwise noted, it should be assumed that all images, logos, and trademarks are copyrighted and should be used only with permission of the original copyright owners. happy mapping! ### library disclosures <b> /> /> com.android.support:design </b> - used for theming and styling views within the app. libraries also provide backward-compatible versions of android framework apis (e.g. vector icon support) - support is a set of code libraries that provide backward-compatible versions of android framework apis. we use support for fragmentcompat and its use in receiving the results for permission requests. <b>com.android.support:multidex</b> - the android multidex support library enables us to go past the default method limit for an android project. <b>com.davemorrissey.labs:subsampling-scale-image-view</b> - used within the molemeasurementactivity, allows user to zoom and pan an image with subsampling for low impact on memory - annotation processor for the squeaky ormlite database library. the library creates auto-generated code at compile time for our database pojos (see mole or measurement classes) <b> pl.charmas.android:android-reactive-location<br /> com.google.android.gms:play-services-location<br /> </b> - play-services-location allows the app to get the user's location while being conscious of battery life. android-reactive-location library wraps the location services apis in rx observables. <b>com.crashlytics.sdk.android:crashlytics</b> - crash / logging library being used during the qa period. this library will be removed at release."
1,CareKit,carekit is an open source software framework for creating apps that help people better understand and manage their health.,"!carekit # carekit [!license](https://github.com/carekit-apple/carekit#license) [!swift versions](https://swiftpackageindex.com/carekit-apple/carekit) [!os's](https://swiftpackageindex.com/carekit-apple/carekit) !xcode [!spm](https://github.com/apple/swift-package-manager) carekit is an open source software framework for creating apps that help people better understand and manage their health. the framework provides modules that you can use out of the box, or extended and customized for more targeted use cases. it is composed of three spm packages which can each be imported separately. * **carekit:** this is the best place to start building your app. carekit provides view controllers that tie carekitui and carekitstore together. the view controllers leverage combine to provide synchronization between the store and the views. * **carekitui:** provides the views used across the framework. the views are open and extensible subclasses of uiview. properties within the views are public, allowing for full control over the content. * **carekitstore:** provides a core data solution for storing patient data. it also provides the ability to use a custom store, such as a third party database or api. # table of contents * requirements * getting started * ockcatalog app * ocksample app * carekit * list view controllers * synchronized view controllers * custom synchronized view controllers * carekitui * tasks * charts * contacts * styling * carekitstore * store * schema * scheduling * custom stores and types * getting help * license # requirements <a name=""requirements""></a> the primary carekit framework codebase supports ios and requires xcode or newer. the carekit framework has a base sdk version of # getting started <a name=""getting-started""></a> * website * documentation * wwdc: researchkit and carekit reimagined ### option one: install using swift package manager you can install carekit using swift package manager. create a new xcode project and navigate to `file > swift packages > add package dependency`. enter the url `https://github.com/carekit-apple/carekit` and tap `next`. choose the `main` branch, and on the next screen, check off the packages as needed. to add localized strings to your project, add the strings file to your project: english strings ### option two: install as an embedded framework download the project source code and drag in carekit.xcodeproj, carekitui.xcodeproj, and carekitstore.xcodeproj as needed. then, embed each framework in your app by adding them to the ""embedded binaries"" section for your target as shown in the figure below. <img alt=""embedded-framework"" ### ockcatalog app <a name=""ockcatalog-app""></a> the included catalog app demonstrates the different modules that are available in carekit: ockcatalog !ockcatalog ### ocksampleapp <a name=""ocksample-app""></a> the included sample app demonstrates a fully constructed carekit app: ocksample !ocksample # carekit <a name=""carekit""></a> carekit is the overarching package that provides view controllers to tie carekitui and carekitstore together. when importing carekit, carekitui and carekitstore are imported under the hood. ### list view controllers <a name=""list-view-controllers""></a> carekit offers full screen view controllers for convenience. the view controllers query for and display data from a store, and stay synchronized with the data. * `ockdailytaskspageviewcontroller`: displays tasks for each day with a calendar to page through dates. * `ockcontactslistviewcontroller`: displays a list of contacts in the store. ### synchronized view controllers <a name=""synchronized-view-controllers""></a> for each card in carekitui, there is a corresponding view controller in carekit. the view controllers are self contained modules that you can place anywhere by using standard view controller containment. the view controller for each card provides synchronization between the view and the store. the following code creates a synchronized view controller. ```swift // create a store to hold your data. let store = ockstore(named: ""my-store"", type: .ondisk) // create a view controller that queries for and displays data. the view will update automatically whenever the data in the store changes. let viewcontroller = ocksimpletaskviewcontroller(taskid: ""doxylamine"", eventquery: ockeventquery(for: date()), store: store) ``` all synchronized view controllers have a view synchronizer. the view synchronizer defines how to instantiate the view to display, and how to update the view when the data in the store changes. you can customize view synchronizers and inject them into a view controller to perform custom behavior. ```swift // define a custom view synchronizer. class customsimpletaskviewsynchronizer: ocksimpletaskviewsynchronizer { override func makeview() -> ocksimpletaskview { let view = super.makeview() // customize the view when it is instantiated here. return view } override func updateview(_ view: ocksimpletaskview, context: ocksynchronizationcontext<ocktaskevents>) { super.updateview(view, context: context) // update the view when the data changes in the store here. } } // instantiate the view controller with the custom classes, then fetch and observe data in the store. var query = ockeventquery(for: date()) query.taskids = [""doxylamine""] let viewcontroller = ocksimpletaskviewcontroller(query: query, store: store, viewsynchronizer: customsimpletaskviewsynchronizer()) ``` ### custom synchronized view controllers <a name=""custom-synchronized-view-controllers""></a> carekit supports creating a custom view that can pair with a synchronized view controller. this allows synchronization between the custom view and the data in the store. ``` swift // define a view synchronizer for the custom view. class taskbuttonviewsynchronizer: viewsynchronizing { // instantiate the custom view. func makeview() -> uibutton { return uibutton(frame: cgrect(x: y: width: height: } // update the custom view when the data in the store changes. func updateview( _ view: uibutton, context: ocksynchronizationcontext<ockanyevent?> ) { let event = context.viewmodel view.titlelabel?.text = event?.task.title view.isselected = event?.outcome != nil } } var query = ockeventquery(for: date()) query.taskids = [""doxylamine""] let events = store .anyevents(matching: query) .map { } let viewcontroller = synchronizedviewcontroller( initialviewmodel: nil, viewmodels: events, viewsynchronizer: taskbuttonviewsynchronizer() ) ``` # carekitui <a name=""carekitui""></a> carekitui provides cards to represent tasks, charts, and contacts. there are multiple provided styles for each category of card. you build all cards in a similar pattern. this makes it easy to recognize and customize the properties of each card. cards contain a `headerview` at the top that displays labels and icons. the contents of the card are inside a vertical `contentstackview`. this allows for easy placement of custom views into a card without breaking existing constraints. for creating a card from scratch, see the `ockcardable` protocol. conforming to this protocol makes it possible for a custom card to match the styling used across the framework. ### tasks <a name=""tasks""></a> here are the available task card styles: !task this example instantiates and customizes the instructions task card: ```swift let taskview = ockinstructionstaskview() taskview.headerview.titlelabel.text = ""doxylamine"" taskview.headerview.detaillabel.text = am to am"" taskview.instructionslabel.text = ""take the tablet with a full glass of water."" taskview.completionbutton.isselected = false taskview.completionbutton.label.text = ""mark as completed"" ``` ### charts <a name=""charts""></a> here are the available chart card styles: !chart this example instantiates and customizes the bar chart: ```swift let chartview = ockcartesianchartview(type: .bar) chartview.headerview.titlelabel.text = ""doxylamine"" chartview.graphview.dataseries = [ ockdataseries(values: title: ""doxylamine"") ] ``` ### contacts <a name=""contacts""></a> here are the available contact card styles: !contact this example instantiates and customizes the simple contact card: ```swift let contactview = ocksimplecontactview() contactview.headerview.titlelabel.text = ""lexi torres"" contactview.headerview.detaillabel.text = ""family practice"" ``` ### styling <a name=""styling""></a> to provide custom styling or branding across the framework, see the `ockstylable` protocol. all stylable views derive their appearance from a list of injected constants. you can customize this list of constants for quick and easy styling. here is an example that customizes the separator color in a view, and all of it is descendents: ```swift // define your custom separator color. struct customcolors: ockcolorstyler { var separator: uicolor { .black } } // define a custom struct to hold your custom color. struct customstyle: ockstyler { var color: ockcolorstyler { customcolors() } } // apply the custom style to your view. let view = ocksimpletaskview() view.customstyle = customstyle() ```` note that each view in carekitui is styled with `ockstyle` by default. setting a custom style on a view propagates the custom style down to any subviews that do not already have a custom style set. you can visualize the style propagation rules in this diagram demonstrating three separate view hierarchies: !styling for information on styling swiftui views with `ockstylable`, see swiftui in carekitui. # carekitstore <a name=""carekitstore""></a> the carekitstore package defines the `ockstoreprotocol` that carekit uses to communicate to data stores, and a concrete implementation that leverages coredata, called `ockstore`. it also contains definitions of most of the core structures and data types that carekit relies on, such as `ockanytask`, `ocktaskquery`, and `ockschedule`. ### store <a name=""store""></a> the `ockstore` class is an append-only, versioned store packaged with carekit. it is implemented on top of coredata and provides fast, secure, on-device storage. `ockstore` is designed to integrate with carekit's synchronized view controllers, but is usable in isolation as well. ```swift import carekitstore let store = ockstore(named: ""my-store"", type: .ondisk) let breakfastschedule = ockschedule.dailyattime(hour: minutes: start: date(), end: nil, text: ""breakfast"") let task = ocktask(id: ""doxylamine"", title: ""doxylamine"", careplanid: nil, schedule: breakfastschedule) let storedtask = try await store.addtask(task) ``` the most important feature of `ockstore` is that it is a versioned store with a notion of time. when querying the store using a date range, the result returned is for the state of the store during the interval specified. if no date interval is provided, the query returns all versions of the entity. ```swift // on january let task = ocktask(id: ""doxylamine"", title: ""take tablet of doxylamine"", careplanid: nil, schedule: breakfastschedule) let addedtask = try await store.addtask(task) // on january let task = ocktask(id: ""doxylamine"", title: ""take tablets of doxylamine"", careplanid: nil, schedule: breakfastschedule) let updatedtask = try await store.updatetask(task) // on some future date. let earlyquery = ocktaskquery(dateinterval: /* jan - */) let earlytasks = try await store.fetchtasks(query: earlyquery) let laterquery = ocktaskquery(dateinterval: /* jan - */) let latertasks = try await store.fetchtasks(query: laterquery) // queries return the newest version of the task during the query interval. let midquery = ocktaskquery(dateinterval: /* jan - */) let midtasks = try await store.fetchtasks(query: laterquery) // queries with no date interval return all versions of the task. let allquery = ocktaskquery() let alltasks = try await store.fetchtasks(query: allquery) ``` this graphic visualizes how to retrieve results when querying versioned objects in carekit. note how a query over a date range returns the version of the object that is valid in that date range. ### schema <a name=""schema""></a> carekitstore defines six high level entities in this diagram: !schema * **patient:** a patient represents the user of the app. * **care plan**: a patient has zero or more care plans. a care plan organizes the contacts and tasks associated with a specific treatment. for example, a patient may have one care plan for heart disease and a second for obesity. * **contact:** a care plan has zero or more associated contacts. contacts might include doctors, nurses, insurance providers, or family. * **task:** a care plan has zero or more tasks. a task represents some activity that the patient performs. examples include taking a medication, exercising, journaling, or checking in with their doctor. * **schedule:** each task must have a schedule. the schedule defines occurrences of a task, and may optionally specify target or goal values, such as how much of a medication to take. * **outcome:** each occurrence of a task may have an associated outcome. the absence of an outcome indicates no progress was made on that occurrence of the task. * **outcome value:** each outcome has zero or more values associated with it. a value might represent how much medication was taken, or a plurality of outcome values could represent the answers to a survey. it is important to note that tasks, contacts, and care plans can exist *without* a parent entity. many carekit apps target well defined use cases, and it can often be expedient to simply create tasks and contacts without defining a patient or care plan. ### scheduling <a name=""scheduling""></a> the scheduling tools provided in carekit allow very precise and customizable scheduling of tasks. you create an instance of `ockschedule` by composing one or more `ockscheduleelements`. each element defines a single repeating interval. static convenience methods exist to help with common use cases. ```swift let breakfastschedule = ockschedule.dailyattime(hour: minutes: start: date(), end: nil, text: ""breakfast"") let everysaturdayatnoon = ockschedule.weeklyattime(weekday: hours: minutes: start: date(), end: nil) ``` you can create highly precise, complicated schedules by combining schedule elements or other schedules. ```swift // combine elements to create a complex schedule. let elementa = ockscheduleelement(start: today, end: nextweek, interval: datecomponents(hour: let elementb = ockscheduleelement(start: lastweek, end: nil, interval: datecomponents(day: let complexschedule = ockschedule(composing: [elementa, elementb]) // combine two schedules into a composed schedule. let dailyschedule = ockschedule.dailyattime(hour: minutes: start: tomorrow, end: nextyear, text: nil) let crazyschedule = ockschedule(composing: [dailyschedule, complexschedule]) ``` schedules have a number of other useful properties that you can set, including target values, durations, and textual descriptions. ```swift let element = ockscheduleelement( start: today, // the date and time this schedule begins. end: nextyear, // the date and time this schedule ends. interval: datecomponents(day: // occurs every days. text: ""before bed"", // show ""before bed"" instead of clock time. targetvalues: units: ""ml"")], // specifies what counts as ""complete"". duration: duration = // the window of time to complete the task. ) ``` * `text`: by default, carekit view controllers prompt users to perform tasks using clock time, such as if you provide a `text` property, then carkit uses the text to prompt the user instead, such as ""before bed"" in the code above. * `duration`: if you provide a duration, carekit prompts the user to perform the scheduled task within a window, such as - pm"". you can also set the duration to `.allday` if you do not wish to specify any time in particular. * `targetvalues`: carekit uses target values to determine if a user completed a specific task. see `ockadherenceaggregator` for more information. ### custom stores and types <a name=""custom-store-and-types""></a> the `ockstore` class that carekit provides is a fast, secure, on-device store that serves most use cases. it may not fully meet the needs of all developers, so carekit also allows you to write your own store. for example, you could write a wrapper around a web server, or even a simple json file. you can use any class that conforms to the `ockstoreprotocol` in place of the default store. writing a carekit store adapter requires defining the entities that live in your store, and implementing asynchronous **create**, **read**, **update**, and **delete** methods for each. stores are free to define their own types, as long as those types conform to a certain protocol. for example, if you are writing a store that can hold tasks, you might do it like this. ```swift import carekitstore struct mytask: ockanytask & equatable & identifiable { // mark: ockanytask let id: string let title: string let schedule: string /* ... */ // mark: custom properties let difficulty: difficultyrating /* ... */ } struct mytaskquery: ockanytaskquery { // mark: ockanytaskquery let ids: [string] let careplanids: [string] /* ... */ // mark: custom properties let difficult: difficultyrating? } class mystore: ockstoreprotocol { typealias task = mytask typealias taskquery = mytaskquery /* ... */ // mark: task crud methods func fetchtasks(query: taskquery, callbackqueue: dispatchqueue, completion: @escaping ockresultclosure<[task]>) { /* ... */ } func addtasks(_ tasks: [task], callbackqueue: dispatchqueue, completion: ockresultclosure<[task]>?) { /* ... */ } func updatetasks(_ tasks: [task], callbackqueue: dispatchqueue, completion: ockresultclosure<[task]>?) { /* ... */ } func deletetasks(_ tasks: [task], callbackqueue: dispatchqueue, completion: ockresultclosure<[task]>?) { /* ... */ } /* ... */ } ``` using the four basic crud methods you supply, carekit is able to use protocol extensions to imbue your store with extra functionality. for example, a store that implements the four crud methods for tasks automatically receives the following methods. ```swift func fetchtask(withid id: string, callbackqueue: dispatchqueue, completion: @escaping ockresultclosure<task>) func addtask(_ task: task, callbackqueue: dispatchqueue, completion: ockresultclosure<task>?) func updatetask(_ task: task, callbackqueue: dispatchqueue, completion: ockresultclosure<task>?) func deletetask(_ task: task, callbackqueue: dispatchqueue, completion: ockresultclosure<task>?) ``` the provided methods employ naive implementations. you are free to provide your own implementations that leverage the capabilities of your underlying data store to achieve greater performance or efficiency. if you are considering implementing your own store, read over the protocol notes and documentation carefully. # getting help <a name=""getting-help""></a> github is our primary forum for carekit. feel free to open up issues about questions, problems, or ideas. # license <a name=""license""></a> this project is made available under the terms of a bsd license. see the license file."
0,AppleWatchHeartRateCollection,use researchkit to collect apple watch heart rate data on ios devices,# applewatchheartratecollection use researchkit and healthkit to collect apple watch heart rate data on ios devices data is also sent to a local testing server via http with ssl (self-signed certificate) ## os versions and dependencies - xcode >= (well you also need macos for that) - watchos - swift - researchkit ## referenced projects - accessing heart rate data for your researchkit study - - researchkit sample projects
1,lifespace,source code for the lifespace ios app,"<img /> <br /> to evaluate how environmental conditions influence health, we have developed a novel measure of the space within which individuals live and move. we will create individual life-space maps, based on a custom smartphone application that uses global positioning system (gps)-based methods. by mapping the space within which individuals live and move, we can study features of the social and built environment that support health, and identify opportunities for intervention to protect disadvantaged communities. odden research lab ## built with - cardinalkit - firebase - mapbox - researchkit ## installation please refer to installation guide for installation instructions. ## lead developers - annabel tan (annabelxtan@stanford.edu) - vishnu ravi (vishnur@stanford.edu)"
1,Mindful-Moves,adherence of canadian movement guideline profiles in young adults through personal smart devices and the potential links to depressive symptoms. a pilot study,"# mindful-moves software development kits and wearable devices in physical activity research this project aims to enhance research methods in physical activity studies by leveraging the capabilities of software development kits (sdks) and wearable smart devices. the canadian guidelines recommend physical activity for overall health benefits, including cognitive, emotional, functional, and physical health. however, traditional research methods are inefficient and outdated. background the paper proposes a new approach for conducting physical activity research, using a generic mobile application transformed into a research-based mobile application. the researchers used three open-source sdks, namely researchkit, carekit, and healthkit, to develop the desired application. methodology the researchers identified the research question and goals, then used researchkit for informed consent, surveys, and active tasks, carekit for protocol management, and healthkit for accessing and sharing health-related data. the application was evaluated by a content expert, and the participant experience was optimized for easy use. the collected health-related data were analyzed to identify any significant findings. results wearable health devices offer a convenient and non-invasive way to monitor and track health-related information. using sdks and wearable devices in physical activity research can enhance research methods and provide valuable insights into overall health benefits. conclusion the paper concludes that leveraging the data provided by wearable devices, researchers can gain insights into the effectiveness of interventions and inform the development of evidence-based physical activity guidelines. by adopting sdks and wearable devices in physical activity research, researchers can improve their methods, enhance their data collection, and provide more comprehensive insights into overall health benefits. keywords physical activity, research methods, wearable smart devices, software development kits, canadian guidelines, mobile application, healthkit, researchkit, carekit, physical health !screenshot at pm !screenshot at pm !screenshot at pm !screenshot at pm !screenshot at pm"
0,SurveyNative,"native ios surveys built from declarative definitions (json). many question types, skip logic etc.","# surveynative native surveys built from declarative definitions (json). many question types, skip logic etc. ## features - displays a single question at a time, but allow the user to scroll up to read and change previous answers. - takes input from a json file. - many supported question types, including single selection, multiple selection, single text field, additive text fields, segment choice, year picker, date picker, and table-style questions. - support for sub-questions. - support for showing/hiding questions based on previous answers. ## example survey !video showing example app ## json input example json input file the expected input is an array of `questions` and a `submit` object, detailing how to submit the answers. ### keys used in questions #### some keys are standard across all question types. others are only present for some question types. - `id` (_string_): required. used to key answer. also used to check show/hide conditions. - `header` (_string_): optional. displayed as section header. - `question` (_string_): required. text to display for question. - `question_type` (_string_): required. the chosen type may require additional keys. - `single_select` screenshot | json - `multi_select` screenshot | json - `year_picker` screenshot | json - `date_picker` screenshot | json - `single_text_field` screenshot | json - `single_text_area` screenshot | json - `multi_text_field` screenshot | json - `dynamic_label_text_field` screenshot | json - `add_text_field` screenshot | json - `segment_select` screenshot | json - `table_select` screenshot | json - `sub_questions` (_array of questions_): optional. expected keys in each question are the same as a top-level question, except that header is not required (or shown if provided). normally, a sub-question would have a `show_if` key, but it is not required. the `show_if` section of a sub-question may refer to previous sub-question answers. - `show_if` (_conditions_): optional. if not provided, the question will default to being shown. see the structure for show/hide question below for more info. #### the keys below are specific to certain question types. - `options` (_array of strings or other object_): required for `single_select`, `mult_select`, `table_select` question_types. the `table_select` does not support the other object. the other object is a json object with a key for `title`. when selected, the user may enter text into a text field. - `label` (_string_): optional for `single_text_field` question type. - `label_options` (_array containing strings or string arrays_): required for `dynamic_label_text_field`. - `input_type` (_string_): optional for `single_text_field`, `dynamic_label_text_field`, `add_text_field` question_types. can be set to `number` to change the default keyboard to the number keyboard for the text field(s). - `max_chars` (_string_): options for `single_text_field`, `multi_text_field`, `single_text_area` question_types. determines the max number of characters the user may enter. - `validations` (_array of dictionaries_): optional for `single_text_field`, `dynamic_label_text_field`, `single_text_area` question_types. check value meets the validations when `next` tapped. if not `validationfailed(message: string)` is called on your `validationfaileddelegate`. validations consist of attributes: - `operation` - `value` or `answer_to_question_id` - `on_fail_message` - `for_label` (only used for `dynamic_label_text_field`) supported operations: - `equals` - `not equals` - `greater than` - `greater than or equal to` - `less than` - `less than or equal to` - `values` (_array of string_): required for `segment_select` question_type. these are the values the user will choose between. - `fields` (_array of dictionaries_): required for `multi_text_field` question_type. each dictionary must contain a `label` key and an `input_type` key. - `low_tag` (_string_): optional for `segment_select` question_type. this is a label for the lowest (first) value. - `high_tag` (_string_): optional for `segment_select` question_type. this is a label for the highest (last) value. - `table_questions` (_array of table questions_): required for `table_select` question_type. each table question should have a `title` and an `id` attribute. - `min_year` (_string_): optional for `year_picker` question_type. can be an integer or ""current_year"". see more about year picker below for more info. - `max_year` (_string_): optional for `year_picker` question_type. can be an integer or ""current_year"". see more about year picker below for more info. - `num_years` (_string_): optional for `year_picker` question_type. see more about year picker below for more info. - `initial_year` (_string_): optional for `year_picker` question_type. if set, this year will be selected when the picker is first opened. - `sort_order` (_string_): optional for `year_picker` question_type. may be ""asc"" (ascending) or ""desc"" (descending). defaults to ""asc"". - `date` (_string in yyyy-mm-dd format or ""current_date""_): optional for `date_picker` question_type. if specified, the picker will initially be set to this value (unless the question is already answered, in which case it will be set to the previous answer). if unset, defaults to the current date. - `max_date` (_string in yyyy-mm-dd format or ""current_date""_): optional for `date_picker` question_type. if specified, the picker will not allow the user to choose a date later than this. if min_date is specified and min_date > max_date, both values will be ignored. - `min_date` (_string in yyyy-mm-dd format or ""current_date""_): optional for `date_picker` question_type. if specified, the picker will not allow the user to choose a date earlier than this. if min_date is specified and min_date > max_date, both values will be ignored. - `date_diff` (_dictionary of string to int values_): optional for `date_picker` question_type. valid keys are `day`, `month`, and `year`. only takes effect if exactly one of `min_date` and `max_date` is set. the unset min/max value will be set by adding the affect of this to the set min/max value. `date_diff` should be overall positive if `min_date` is set and negative if `max_date` is set. if `date_diff` is set such that `min_date` > `max_date`, both values will be ignored. #### more about year picker you only need to specify two of `min_year`, `max_year`, and `num_years`. the missing values will be calculated from what is provided. if all three are provided, the `num_years` value will be ignored. if less than two values are provided, we will guess reasonable values for the missing ones. ### structure for show/hide question whether a question is shown or hidden is dependent on the `show_if` key. if the key is missing, the default is to show the question. both simple conditions and decision trees are supported. the decision trees can contain other decision trees, so you can have fairly complicated logic. there is probably some limit to how far you can nest them. #### simple condition keys - `id` (_string_): required. this is the id for a question. - `subid` (_string_): optional. this allows access to answers to `table_select` questions to be used, or any other answer that is within a dictionariy. - `operation` (_string_): required. supported operations: - `equals` - `not equals` - `greater than` - `greater than or equal to` - `less than` - `less than or equal to` - `contains` - `not contains` - `value` (_any_): required. this is the value to compare the answer to. #### decision tree keys - `operation` (_string_): required. can be `or` or `and`. if you need a combination, you should be able to use nesting to get it. - `subconditions` (_array of simple conditions or decision trees_): required. #### custom conditions if these options are inadequate, you can set a _customconditiondelegate_ and use it to make the show/hide decision. - `ids` (_array of strings_): required. must be non-empty. these are the ids for questions the your delegate needs the answers to in order to perform it is show/hide calculation. your delegate will be called as soon as any of the questions are answered, so you may have nil data for one or more answers. - `operation` (_string_): required. should be set to 'custom'. - `extra` (_dictionary with string keys_): optional. this will be passed to the _isconditionmet_ method of your _customconditiondelegate_. ### submit the submit object (a peer to `questions`) requires only two keys, `button_title` and `url`. both are required strings. ### question type examples #### single_select ``` { ""id"": ""ice_cream"", ""header"": ""question ""question"": ""what is your favorite ice cream flavor?"", ""question_type"": ""single_select"", ""options"": [ ""strawberry"", ""chocolate"", ""vanilla"", { ""title"": ""other"", ""type"": ""freeform"" } ] } ``` ""single_select example"") #### multi_select ``` { ""id"": ""music_types"", ""header"": ""question ""question"": ""what types of music do you like?"", ""question_type"": ""multi_select"", ""options"": [ ""pop"", ""rock"", ""rap"", ""country"", { ""title"": ""other"", ""type"": ""freeform"" } ] } ``` ""multi_select example"") #### year_picker ``` { ""id"": ""birthyear"", ""header"": ""question ""question"": ""enter the year of your birth."", ""question_type"": ""year_picker"" ""max_year"" : ""current_year"", ""num_years"" : ""sort_order"" : ""desc"" } ``` ""year_picker example"") #### date_picker ``` { ""id"": ""date"", ""header"": ""question ""question"": ""what is was the best day of the last year?"", ""question_type"": ""date_picker"", ""date"" : ""current_date"", ""max_date"" : ""current_date"", ""date_diff"" : { ""year"" : }, } ``` #### single_text_field ``` { ""id"": ""age"", ""header"": ""question ""question"": ""what is your current age in years?"", ""question_type"": ""single_text_field"", ""label"": ""years"", ""input_type"": ""number"", ""max_chars"": ""validations"": [ { ""operation"": ""greater than"", ""value"": ""on_fail_message"": ""age must be at least }, { ""operation"": ""less than"", ""value"": ""on_fail_message"": ""you must be or younger"" } ] } ``` ""single_text_field example"") #### single_text_area ``` { ""id"": ""perfect_day"", ""header"": ""question ""question"": ""how would you describe your perfect day?"", ""question_type"": ""single_text_area"" } ``` ""single_text_area example"") #### multi_text_field ``` { ""id"":""pets"", ""header"": ""question ""question"": ""how many pets do you have?"", ""question_type"": ""multi_text_field"", ""fields"": [ { ""label"" : ""dogs"", ""input_type"" : ""number"" }, { ""label"" : ""cats"", ""input_type"" : ""number"" } ] } ``` ""multi_text_field example"") #### dynamic_label_text_field ``` { ""id"": ""height"", ""header"": ""question ""question"": ""how tall are you?"", ""question_type"": ""dynamic_label_text_field"", ""label_options"": [ [ ""feet"", ""inches"" ], ""centimeters"" ], ""options_metadata"": { ""id"": ""unit_system"", ""types"": [ ""imperial"", ""metric"" ] }, ""input_type"": ""number"", ""validations"": [ { ""for_label"": ""feet"", ""operation"": ""greater than"", ""value"": ""on_fail_message"": ""height must be at least feet"" }, { ""for_label"": ""feet"", ""operation"": ""less than"", ""value"": ""on_fail_message"": ""height must be less than feet"" }, { ""for_label"": ""centimeters"", ""operation"": ""greater than"", ""value"": ""on_fail_message"": ""height must be at least }, { ""for_label"": ""centimeters"", ""operation"": ""less than"", ""value"": ""on_fail_message"": ""height must be less than } ] } ``` ""dynamic_label_text_field example"") #### add_text_field ``` { ""id"": ""which_sports"", ""question"": ""which sports do you like to play?"", ""question_type"": ""add_text_field"", ""input_type"": ""default"" } ``` ""add_text_field example"") #### segment_select ``` { ""id"": ""happiness"", ""header"": ""question ""question"": ""how happy are you?"", ""question_type"": ""segment_select"", ""low_tag"": ""not happy"", ""high_tag"": ""super happy"", ""values"": [ ] } ``` ""segment_select example"") #### table_select ``` { ""id"": ""weekend_activities"", ""header"": ""question ""question"": ""on the weekends, do you:"", ""question_type"": ""table_select"", ""options"": [ ""yes"", ""sometimes"", ""no"" ], ""table_questions"": [ { ""title"": ""play sports?"", ""id"": ""play_sports"" }, { ""title"": ""read books?"", ""id"": ""read_books"" }, { ""title"": ""go dancing"", ""id"": ""go_dancing"" }, { ""title"": ""watch tv and movies?"", ""id"": ""watch_tv"" } ] } ``` ""table_select example"") ### contributing areas we would love to see contributions: - bug fixes - support for `optional` boolean flag on every question type that adds a skip button. - new question types - customizable styling - customizable animation - dynamic question number substitution in header - option to enable/disable animations - android port - export qualtrics/survey-monkey surveys to surveynative - carekit/researchkit integration"
1,QuestionnaireKit,swift framework for fhir questionnaires using researchkit.,"# questionnairekit swift framework for presenting fhir questionnaires in your ios app using apple researchkit surveys. questionnairekit is currently compatible with: * fhir * ios and newer * swift * xcode dependencies include: * **smart on fhir** via swift package manager (spm) * apple researchkit version integrated as a git submodule (does not yet support spm) this framework was extracted from the to enable ios apps to easily include fhir questionnaires presented using the apple researchkit framework surveys. the orginal code was also updated to support fhir installation ------------ download _questionnairekit_ from github as follows: * using terminal.app, navigate to your project directory and execute: ``$ git clone --recursive https://github.com/clinical-cloud/questionnairekit.git`` * this will download the latest codebase and all dependencies of the master branch. to use a different branch, e.g. the develop branch, add -b develop to the clone command or checkout the appropriate branch after cloning. * open questionnairekit.xcworkspace using xcode see the _qkdemo_ app included in this repo for an example on how to include fhir questionnaires in your app, presented using researchkit surveys. the demo app includes sample fhir questionnaire resources that illustrate this framework's capabilities. for more detail on usage, see questionnaires license ------- this work is apache licensed. fhir is the registered trademark of and is used with the permission of"
1,viranos,open-source platform for accelerating research into long term effects of google cloud fund,"!image # viranos up to of people infected with have reported persistent symptoms more than weeks after diagnosis. long term effects of are still not well understood. viranos is an open-source platform to support long covid research including an ios app and a clinician & researcher dashboard. ## about viranos is an ios app developed using the cardinalkit framework to help patients suffering from long-term where patients experience ongoing symptoms like fatigue, fever and memory lapses. our app aims to provide support and symptom monitoring for these patients while also serving as a data collection tool to enable researchers to better understand the long-term sequelae of features: * informed consent process using researchkit. * schedules daily tasks and surveys with carekit. * monitors health data with healthkit. * collects and upload medical records via from apple health records. * provides resources for patients (support groups, clinical studies) * integrated with google cloud platform firebase. ## demo video [!viranos demo video](https://www.youtube.com/watch?v=mcuefssv_da) ## built with - researchkit - healthkit - carekit - google cloud platform ## lead contributors - ashley griffin (@griffinac) - vishnu ravi (@vishnuravi)"
1,AssessmentCenter,swift framework for assessmentcenter api,"# assessmentcenter swift framework for patient reported outcome measures (pro-measures). computer adaptive test (backed by item response theory) provided by assessmentcenter at northwestern university. ## researchkit `assessmentcenter` framework module includes `researchkit` as a submodule. ac by itself only utilizes its survey module. applications can potentially add other `researchkit` modules if required. ## updates - update to swift - researchkit ## getting started ### installation ``` $ git clone --recursive https://github.com/raheelsayeed/assessmentcenter.git ``` add `assessmentcenter.xcodeproj` and `researchkit.xcodeproj` into the project directory of your app in xcode. build the frameworks in xcode. link and embed the `assessmentcenter.framework` and `researchkit.framework` by selecting your app's target > **build phases** > **link binary with libraries** and **embed frameworks**. ### initialize by creating a `acclient` ```swift import assessmentcenter // initialize assessment center client let baseurlstring = ""<# https://www.assessmentcenter.net/ac_api/.. #>"" let accessid = ""<# accessidentifier #>"" let accesstoken = ""<# accesstoken #>"" let client = acclient(baseurl: url(string: baseurlstring)!, accessidentifier: accessid, token: accesstoken) ``` ### list all available instruments provided by the assessment center. ```swift // fetches a list of available of `acform` from assessment center client.listforms { (list) in if let list = list { list.foreach{ } } } ``` ### instrument session - `acform` is passed to `actaskviewcontroller` a subclass of `orktaskviewcontroller` - each response is sent to assessmentcenter to get the next question. ```swift // initialise `acform` with oid. // alternatively, `client.listforms()` let instrumentform = acform(_oid: ""<# ac form oid #>"", _title: ""<# promis sleep #>"", _loinc: ""<# loinc code #>"") // downloads complete instrument with questions and responses // complete instrument `acform` is passed to create a `orktaskviewcontroller` (researchkit's qa interface) client.form(acform: form, completion: { [unowned self] (completeform) in dispatchqueue.main.sync { if let completeform = completeform { // actaskviewcontroller is a subclass of orktaskviewcontroller (researchkit) let taskviewcontroller = actaskviewcontroller(acform: completeform, client: client, sessionidentifier: ""neuro-clinic-testing"") self.present(taskviewcontroller, animated: true, completion: nil) } } } ```"
0,m-chat,ios app for modified checklist for autism in toddlers & survey based on researchkit for getting insights into autism,"## m-chat ios app for modified checklist for autism in toddlers using researchkit to gether data for autism research ### about autism autism is a neurodevelopmental disorder characterized by impaired social interaction, verbal and non-verbal communication, and restricted and repetitive behavior. parents usually notice signs in the first two years of their child's life. these signs often develop gradually, though some children with autism reach their developmental milestones at a normal pace and then regress. the diagnostic criteria require that symptoms become apparent in early childhood, typically before age three ### set up researchkit framework https://github.com/researchkit/researchkit.git"
1,ResearchKit,chrome and firefox extension for quickly doing research.,"# researchkit research quickly on the go! researchkit is a chrome browser extension that has no interface. the user simply highlights a section of text to research, right clicks it, and selects ""researchkit."" once they do so, windows will appear on the screen with a wikipedia search and a britannica encyclopedia search along with their respective summaries. click here to download for <a href=""https://chrome.google.com/webstore/detail/researchkit/lcgjhfnkeejlbbamennaijghaodllbgj"" target=""_blank"">google chrome</a> or for <a href=""https://addons.mozilla.org/en-us/firefox/addon/researchkit/?src=search"" target=""_blank"">firefox</a>."
0,iOS-Research-App,ios research app built off of researchkit,# ios-research-app ios research app built off of researchkit this research app is being created for a doctorate student's disertation. this researchkit based study aims to solidify the relationship between breast feeding and post partum return to cycle for women who have recently gave birth.
0,OneTouch,ios app developed as part of the ios foundation course at parthenope university of naples. the app is designed to assist patients with amyotrophic lateral sclerosis (als) in managing their medication reminders.,"# onetouch this repository contains the code for an ios app developed as part of the ios foundation course at parthenope university of naples. the app is designed to assist patients with amyotrophic lateral sclerosis (als) in managing their medication reminders. it utilizes swift ui and leverages apple's researchkit framework for enhanced functionality. please note that this app is developed for educational purposes only. ## features - medication reminder functionality for **als patients** - integration with **researchkit framework** for data collection and tracking - user-friendly interface with intuitive design using swift ui - server communication for interaction between patients and their doctors - incorporation of medical advice for enhanced usability and accuracy ## technologies used - **swift** programming language - **swiftui** framework - **apple researchkit framework** - server-side technologies ## getting started to run the app locally, follow these steps: clone the repository: `git clone https://github.com/carminecoppola/onetouch.git` open the project in xcode. build and run the app using the ios simulator or a physical device. please note that certain features, such as server communication, may require additional setup and configuration. ## contributions this project was developed by: - coppola carmine - team c ## license copyright (c) [onetouch] all rights reserved. duplication or reproduction, in whole or in part, in any form or by any means, is prohibited without the prior written permission of the author, except as permitted by copyright laws. the appost project, including all its files, documentation, and resources, is the exclusive property of [carmine coppola]. unauthorized use of these materials is prohibited."
1,survey-kit,android library for dynamic surveys,"<p align=""center""> <img src=""assets/top/surveykit-logo.png"" </p> # whoop version of surveykit ### purpose this version was created to allow for surveys to be devined remotely on a sever and sent to the client app in the form of json which can then be deserialized into a kotlin object form and presented to the user.<br> additionally, a ""decimal"" answer format was added to allow for numeric input that includes a decimal portion ### build instructions set environment variable $nexus_rm_username and $nexus_rm_password with credentials for nexus update artifact version in [library.kt] run command ""gradlew publishreleasepublicationtomavenrepository"" <br> the resulting artifact can be found in whoop's nexis repo ## original readme below # surveykit: create beautiful surveys on android (inspired by researchkit surveys on ios) do you want to display a questionnaire to get the opinion of your users? a survey for a medical trial? a series of instructions in a manual-like style? <br/> surveykit is an android library that allows you to create exactly that. thematically it is built to provide a feeling of a professional research survey. the library aims to be visually clean, lean and easily configurable. we aim to keep the functionality close to ios researchkit surveys. this is an early version and work in progress. do not hesitate to give feedback, ideas or improvements via an issue. # examples ###### flow <p align=""center""> <img src=""assets/gifs/survey-kit-demo.gif?raw=true"" </p> ###### screenshots | | | | | | | :---: | :---: | :---: | :---: | :---: | | <img src=""assets/top/instruction_qbs.png?raw=true"" | <img src=""assets/top/how_old_are_you_with_hint.png?raw=true"" | <img | <img | <img src=""assets/top/color-picker.png?raw=true"" | ## overview: creating research surveys - what surveykit does for you - what surveykit does not (yet) do for you - library setup - add the repository - add the dependency - usage - add and find the survey in the xml - create survey steps - create a task - evaluate the results - configure - start the survey - location steps - custom steps - comparison to researchkit on ios - author - contributing - license ## what surveykit does for you - simplifies the creation of surveys - provides rich animations and transitions out of the box (custom animations planned) - build with a consistent, lean, simple style, to fit research purposes - survey navigation can be linear or based on a decision tree (directed graph) - gathers results and provides them in a convinient manner to the developer for further use - gives you complete freedom on creating your own questions - allows you to customize the style - provides an api and structure that is very similar to ios researchkit surveys - is used in production by quickbird studios ## what surveykit does not (yet) do for you as stated before, this is an early version and a work in progress. we aim to extend this library until it matches the functionality of the ios researchkit surveys. # library setup > all of the available versions of surveykit has been moved to mavencentral. ## add the repository surveykit is now available via mavencentral which is normally added as part of every new android project. however, if it is not present, you can add it as show here. ```groovy allprojects { repositories { mavencentral() } } ``` ## add the dependency `build.gradle.kts` ````kotlin dependencies { implementation(""implementation } ```` find the latest version or all releases # usage ## example a working example project can be found here ### add and find the survey in the xml add the surveyview to your `xml` (it looks best if it fills the screen). ````xml <com.quickbirdstudios.surveykit.survey.surveyview android:id=""@+id/survey_view"" android:layout_width=""match_parent"" android:layout_height=""match_parent"" /> ```` find the view in the `xml` and save it for further use. ```kotlin var surveyview: surveyview = view.findviewbyid(r.id.survey_view) ``` ### create survey steps to create a step, create an instance of one of these classes: #### `instructionstep` ```kotlin instructionstep( title = r.string.intro_title, text = r.string.intro_text, buttontext = r.string.intro_start ) ``` the `title` is the general title of the survey you want to conduct. <br/> the `text` is, in this case, the introduction text which should give an introduction, about what the survey is about.<br/> the `buttontext` specifies the text of the button, which will start the survey. all of these properties have to be resource ids. #### `completionstep` ```kotlin completionstep( title = r.string.finish_question_title, text = r.string.finish_question_text, buttontext = r.string.finish_question_submit ) ``` the `title` is the general title of the survey you want to conduct, same as for the `instructionstep`. <br/> the `text` is here should be something motivational: that the survey has been completed successfully. <br/> the `buttontext` specifies the text of the button, which will end the survey. all of these properties have to be resource ids. #### `questionstep` ```kotlin questionstep( title = r.string.about_you_question_title, text = r.string.about_you_question_text, answerformat = answerformat.textanswerformat( multiplelines = true, maximumlength = ) ) ``` the `title` same as for the `instructionstep` and `completionstep`. <br/> the `text` the actual question you want to ask. depending on the answer type of this, you should set the next property.<br/> the `answerformat` specifies the type of question (the type of answer to the question) you want to ask. currently there these types supported: - `textanswerformat` - `integeranswerformat` - `scaleanswerformat` - `singlechoiceanswerformat` - `multiplechoiceanswerformat` - `locationanswerformat` all that is left is to collect your steps in a list. ```kotlin val steps = ...) ``` ### create a task next you need a task. each survey has **exactly one** task. a `task` is used to define how the user should navigate through your `steps`. <br><br> #### orderedtask ```kotlin val task = orderedtask(steps = steps) ``` the `orderedtask` just presents the questions in order, as they are given. #### navigableorderedtask ````kotlin val task = navigableorderedtask(steps = steps) ```` the `navigableorderedtask` allows you to specify navigation rules.<br> there are two types of navigation rules: <br/> with the `directstepnavigationrule` you say that after this step, another specified step should follow. ```kotlin task.setnavigationrule( navigationrule.directstepnavigationrule( destinationstepstepidentifier = ) ) ``` <br><br/> with the `multipledirectionstepnavigationrule` you can specify the next step, depending on the answer of the step. ```kotlin task.setnavigationrule( navigationrule.multipledirectionstepnavigationrule( resulttostepidentifiermapper = { input -> when (input) { ""yes"" -> ""no"" -> else -> null } } ) ) ``` ### evaluate the results when the survey is finished, you get a callback. no matter of the `finishreason`, you always get all results gathered until now. <br/> the `taskresult` contains a list of `stepresult`s. the `stepresult` contains a list of `questionresult`s. ```kotlin surveyview.onsurveyfinish = { taskresult: taskresult, reason: finishreason -> if (reason == finishreason.completed) { taskresult.results.foreach { stepresult -> log.e(""logtag"", ""answer ${stepresult.results.firstornull()}"") } } } ``` ### style these is how you add custom styling to your survey. we will add even more options in the future. ```kotlin val configuration = surveytheme( themecolordark = contextcompat.getcolor(requirecontext(), r.color.cyan_dark), themecolor = contextcompat.getcolor(requirecontext(), r.color.cyan_normal), textcolor = contextcompat.getcolor(requirecontext(), r.color.cyan_text) ) ``` ### start the survey all that is left is to start the survey and enjoy. ```kotlin surveyview.start(task, configuration) ``` # cancel survey dialog when you cancel the survey, there is an option to change dialog default strings. must be imported from resources. ``` val configuration = surveytheme( themecolordark = contextcompat.getcolor(this, r.color.cyan_dark), themecolor = contextcompat.getcolor(this, r.color.cyan_normal), textcolor = contextcompat.getcolor(this, r.color.cyan_text), abortdialogconfiguration = abortdialogconfiguration( title = r.string.title, message = r.string.message, neutralmessage = r.string.no, negativemessage = r.string.yes ) ) ``` # location steps you need add below to your own application `androidmanifest.xml` file to use google map. ```xml <meta-data android:name=""com.google.android.gms.version"" android:value=""@integer/google_play_services_version"" /> <meta-data android:value=""google api key"" /> ``` also need to append location permissions on `androidmanifest.xml`. this is not required. but if you gave this permissions, map can select current location automatically. ```xml <uses-permission android:name=""android.permission.access_coarse_location"" /> <uses-permission android:name=""android.permission.access_fine_location"" /> ``` you might want to run location question steps test or example app on this project. need to add api keys on `local.properties` file. ```kotlin google_sdk_key=""[api_key]"" //if you want to use yandex address suggession on example app yandex_sdk_key=""[api_key]"" ``` and finally you can instante location question step like below. ```kotlin questionstep( title = ""title"", text = this.resources.getstring(r.string.location_question_text), lifecycle = lifecycle, answerformat = answerformat.locationanswerformat( lifecycle = lifecycle, //addressprovider = yandexaddresssuggestionprovider(api_key) ) ) ``` default address provider is `geocoderaddresssuggestionprovider` based on `android.location.geocoder`. if you want to use custom address provider. you can use `addresssuggestionprovider` interface and make your own implements like `yandexaddresssuggestionprovider`. # custom steps at some point, you might want to define your own custom question steps. that could, for example, be a question which prompts the user to pick color values or even sound samples. these are not implemented yet but you can easily create them yourself: you will need a `customresult` and a `customstep`. the result class tells surveykit which data you want to save. ```kotlin @parcelize data class customresult( val customdata: string, override val stringidentifier: string, override val id: identifier, override val startdate: date, override var enddate: date ) : questionresult, parcelable ``` next you will need a customstep class: ```kotlin class customstep : step { override val isoptional: boolean = true override val id: stepidentifier = stepidentifier() val tmp = id override fun createview(context: context, stepresult: stepresult?): stepview { return object : stepview(context, id, isoptional) { override fun setupviews() = unit val root = view.inflate(context, r.layout.example, this) override fun createresults(): questionresult = customresult( root.findviewbyid<edittext>(r.id.input).text.tostring(), ""stringidentifier"", id, date(), date() ) override fun isvalidinput(): boolean = this@customstep.isoptional override var isoptional: boolean = this@customstep.isoptional override val id: stepidentifier = tmp override fun style(surveytheme: surveytheme) { // do styling here } init { root.findviewbyid<button>(r.id.continue) .setonclicklistener { onnextlistener(createresults()) } root.findviewbyid<button>(r.id.back) .setonclicklistener { onbacklistener(createresults()) } root.findviewbyid<button>(r.id.close) .setonclicklistener { oncloselistener(createresults(), finishreason.completed) } root.findviewbyid<button>(r.id.skip) .setonclicklistener { onskiplistener() } root.findviewbyid<edittext>(r.id.input).settext( (stepresult?.results?.firstornull() as? customresult)?.customdata ?: """" ) } } } } ``` # vs : comparison of surveykit on android to researchkit on ios this is an overview of which features ios researchkit surveys provides and which ones are already supported by surveykit on android. the goal is to make both libraries match in terms of their functionality. | steps | ios researchkit | android surveykit| | :------------------------ | :---: | :---: | | instruction | | | | single selection | | | | multi selection | | | | boolean answer | | | | value picker | | | | image choice | | | | numeric answer | | | | time of day | | | | date selection | | | | text answer (unlimited) | | | | text answer (limited) | | | | text answer (validated) | | | | scale answer | | | | email answer | | | | location answer | | | # author this android library is created with by quickbird studios. # contributing open an issue if you need help, if you found a bug, or if you want to discuss a feature request. open a pr if you want to make changes to surveykit. for the moment, a mandatory requirement for a pr to be accepted is also applying ktlint when submitting this pr. # license surveykit is released under an mit license. see license for more information."
1,Jointwise,an ios application to monitor and register joints pain for people affected by rheumatoid arthritis.,"# jointwise - monitoring and registering rheumatoid arthritis symptoms !jointwise logo welcome to jointwise, an ios application designed to help people affected by rheumatoid arthritis monitor and register joint pain. this app empowers users to track their symptoms, gain insights into their condition, and collaborate with healthcare providers to manage arthritis effectively. ## table of contents - introduction - features - installation - usage - technologies used - contributing - license - contact - acknowledgments ## introduction rheumatoid arthritis is a chronic inflammatory disorder that affects joints, causing pain, swelling, and stiffness. jointwise aims to provide a user-friendly platform for individuals to record and analyze their joint pain symptoms over time, enabling better communication with healthcare professionals and optimizing treatment plans. ## features - user registration: users can create accounts. - joint pain monitoring: log daily joint pain levels and track changes over time. - joint diary: maintain a journal of registered pain level over one week. - reminders: set reminders for tasks' availability. - data visualization: visualize joint pain trends through charts and graphs. - collaboration: share pain reports with healthcare providers for better insights. - privacy and security: ensuring data security and privacy compliance. ## installation jointwise is available for ios devices. to set up the app, follow these steps: clone this repository to your computer. download researchkit from github, and add it to the xcode project. fetch carekit in the xcode project. run the app on xcode simulator/your iphone. ## usage **user registration**: create a profile providing your personal info. **joint pain monitoring**: log your joint pain levels daily, selecting the affected joints and providing a pain rating. **joint diary**: keep track of pain ratings over one week through graphs. **reminders**: reminders to complete tasks in the app. **data visualization**: view charts and graphs to understand trends in joint pain levels over time. **collaboration**: share your pain reports with healthcare providers to facilitate better treatment decisions. ## technologies used - ios development: swift and xcode, carekit, researchkit, healthkit - user experience: swiftui and uikit, carekitui - data storage: carekitstore - data visualization: charts, carekit - privacy and security: compliant with data protection standards (gathering consent). ## contributing we welcome contributions from the community to enhance jointwise and make it more effective in supporting people with rheumatoid arthritis. to contribute, follow these steps: fork the repository. create a new branch for your feature or bug fix: `git checkout -b feature/your-feature-name`. make your changes and commit them: `git commit -m ""add feature/fix for xyz""`. push your changes to your fork: `git push origin feature/your-feature-name`. submit a pull request to the `master` branch of the original repository. please follow coding standards, write unit tests, and ensure all tests pass before submitting a pull request. ## license jointwise is open-source software released under the gnu general public license ## acknowledgments we would like to thank the following contributors for their valuable input and support: biagio marra"
0,CHFManager,"xcode project for chf manager, an ios app for the management of congestive heart failure.","# chfmanager ## overview chfmanager is an ios application built with swift and swiftui. the app is designed to manage various aspects of chf (congestive heart failure) and aims to provide a seamless user experience. ## features - news feed - user authentication - data management ## technologies used - swift/swiftui - firebase - firestore - google sign-in - inspired by apple's carekit and researchkit frameworks ## requirements - ios - xcode ## installation ### cocoapods run the following command to install the necessary cocoapods: ```bash pod install ``` ### firebase setup download the `googleservice-info.plist` file from your firebase console and add it to your xcode project. initialize firebase in `appdelegate.swift`: ```swift import firebase ... func application(_ application: uiapplication, didfinishlaunchingwithoptions launchoptions: [uiapplication.launchoptionskey: any]?) -> bool { firebaseapp.configure() ... } ``` ### google sign-in setup configure google sign-in in `googlesigninmanager.swift`: ```swift import googlesignin ... gidsignin.sharedinstance().clientid = ""your_client_id"" ``` ## usage run `pod install` to install dependencies. open the `.xcworkspace` file in xcode. build and run the project. ## contributing pull requests are welcome. for major changes, please open an issue first to discuss what you would like to change. ## license mit"
0,MoleMapper_iOS_public,public release of molemapper code,"# molemapper for ios this repository contains the source code for the molemapper ios researchkit app, authored and originally developed by dan webster. ## license molemapper is available under the bsd license: copyright (c) oregon health and science university all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * neither the name of sage bionetworks nor the names of bridgesdk's contributors may be used to endorse or promote products derived from this software without specific prior written permission. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall oregon health and science university be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage."
0,LeishMapper,"map, measure, and monitor cutaneous leishmaniasis lesions.","# leishmapper for ios this repository contains the source code for the leishmapper ios researchkit app, a re-implementation of molemapper, authored and originally developed by dan webster. leishmapper is used to map and measure cutaneous leishmaniasis, a parasitic disease that causes skin lesions. ## license leishmapper is available under the bsd license: copyright (c) daniel lachance copyright (c) oregon health and science university all rights reserved. redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * neither the name of sage bionetworks nor the names of bridgesdk's contributors may be used to endorse or promote products derived from this software without specific prior written permission. this software is provided by the copyright holders and contributors ""as is"" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. in no event shall oregon health and science university be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage."
0,OTFToolBox,otftoolbox is theraforge's umbrella framework that incorporates all the other sub-frameworks,"# otftoolbox theraforge toolbox (*otftoolbox*) is an open software development kit (sdk) for rapid application development (rad) of digital health solutions running on apple ios. it comprises a set of ios frameworks for students, researchers and professional developers, designed to accelerate rapid prototyping of digital health applications. otftoolbox includes support for persistent secure local storage with cloud synchronization and *offline-first capabilities*, digital health ui/ux components synchronized with data changes, support for powerful app templating and styling, rest api support to connect to theraforge's secure cloudbox service, applewatch support, wearable device support as health data sources, and much more. ## change log <details open> <summary>release <ul> <li>added watch os support</li> </ul> </details> <details> <summary>release <ul> <li>removed warnings and made various other improvements in the sub-frameworks. verified support for xcode improved dependency diagram and formatting in the readme</li> </ul> </details> <details> <summary>release <ul> <li>first beta release of the framework</li> </ul> </details> # table of contents * overview * features * installation * cloud setup * cloud analytics portal * no-code app customization * otftoolbox subspecs * otftoolbox dependency diagram * otftoolbox file protection * license # overview <a name=""overview""></a> otftoolbox is a client-side frontend sdk comprising several components: * a cloud client framework for interconnection to theraforges cloudbox serverless service (baas): otfcloudclientapi * enterprise-grade digital health frameworks: otfcarekit, otfresearchkit * enterprise-grade persistent storage and synchonization frameworks: otfcloudantstore, otfcdtdatastore * a templating framework for app customization and styling: otftemplatebox in reality, otftoolbox is the top-level umbrella framework that includes all of the above sub-frameworks. so it represents the entire toolbox sdk. otftoolbox also enables apps to connect to a secure cloud service, **theraforge cloudbox**, which supports encrypted data storage in compliance with gdpr and hipaa requirements as well as data synchronization and offline-first app behavior. cloudbox works similarly to cloud services such as dropbox but for app data. cloudbox also supports a configurable web-based dashboard for doctors and patients, as well as a detailed analytics dashboard for backend monitoring. the setup process of toolbox and of a cloudbox account is described in the sections below. for more information on the theraforge sdk and cloud services, you can send an email to info@hippocratestech.com . # toolbox features <a name=""features""></a> the theraforge toolbox sdk supports the following features: * no-code app customization and configuration * powerful styling capabilities * sf symbols support * support for dark mode, dynamic font sizes, high contrast, and other accessibility features * customizable *no-code template app*: **magicbox** * **researchkit** support * app onboarding * informed consent * surveys * medical task-based assessments * **carekit** support * virtual care/tele-medicine capabilities for remote care plan management * adherence tracking * fhir support * standard ui cards and styles * **healthkit** support * monitoring of health data * external sensor support * fhir support * conditional inclusion only when needed by app * **cloudbox** support (aws, ibm hyperprotect (future)) * rest apis * *offline-first* local storage (not just a cache) * multi-device synchronization * robust data versioning * automatic data storage in the cloud * notification protocol based on server-sent events (sse) technology * *hipaa and gdpr compliant* encryption at rest and in flight (tls * *hipaa and gdpr compliant* authentication * sign in with apple and with google * passwordless sign-in based on touchid or faceid * ssl pinning * prometheus-based analytics dashboard * sonarqube-based code security analysis * cocoapods support # installation <a name=""installation""></a> * prerequisites * project setup ## prerequisites <a name=""prerequisites""></a> an intel-based mac running macos catalina or later or a mac with apple's silicon running macos big sur. macos monterey and xcode are supported. if you want to learn more about ios development, you may want to check out the free stanford class here: ### installation prerequisites in order to develop ios apps, make sure to download xcode, apple's integrated development environment (ide), from the mac app store. if you have not done it yet, follow this xcode article to install and configure it. (note that in case of xcode apple recommends to download it directly from the apple developer web site https://developer.apple.com/download/all/?q=xcode. some developers consider this installation method *preferable for all versions of xcode*, that is, its considered a best practice. however, in this case you also need to install the *command line tools for xcode*, which are a separate download.) after installing the xcode app, you will also need to install the cocoapods dependency manager for swift and objective-c cocoa projects. if you are new to cocoapods you can refer to the cocoapods guides to learn more about it. cocoapods is built with the ruby language and can be installed with the default version of ruby available with macos. however, before installing cocoapods, we recommend that you also install the homebrew package manager. refer to our homebrew installation page for prerequisites and caveats. to do that, open the terminal application (you can type +spacebar to bring up the macos spotlight search, enter `terminal` in it, and then press return). then type the following command in terminal: ``` /bin/bash -c ""$(curl -fssl https://raw.githubusercontent.com/homebrew/install/head/install.sh)"" ``` as explained in the homebrew main page. (if you get an error, check out our homebrew installation page.) wait for the installation to end. !alt text otftoolbox by default includes apple's researchkit framework. building it requires the installation of the `git-lfs` tool like so: ``` brew install git-lfs ``` finally, to install cocoapods in terminal enter: ``` sudo gem install cocoapods ``` as shown below: !alt text refer to our cocoapods installation page for prerequisites, caveats and troubleshooting suggestions. after successful installation of `git-lfs` and cocoapods, you can start creating your xcode project. ## project setup <a name=""project-setup""></a> ### create an xcode project #### create a project sub-directory in the *developer* directory you need to create a project directory in your user directory. for example, in `terminal` go to your personal directory by typing this command: ``` cd ~ ``` in the finder that corresponds to your home directory (the one with the home icon and your username). the canonical way to store software development projects is by creating a ~/developer sub-directory. the finder has a special ""hammer"" icon just for this sub-directory (that you can also add to the sidebar): !alt text so go ahead and create a developer directory (if you have not done it already) in the finder or in terminal like so: ``` mkdir developer ``` this directory will be used to add projects to it. #### add an existing project **note:** the theraforge sdk supports pre-packaged template applications that can be downloaded and installed directly. **magicbox** is theraforges main template app that can be downloaded and customized to create quick protypes in just a few hours. if you would like to use magicbox (for example if you are not very experienced with development), then go to the readme file of otfmagicbox and proceed with the installation from there. in any case, it may be convenient to install magicbox as a model app for reference. if you wish to use only the sdk, instead, then proceed with the process below to create a new project. #### create a brand new project for example, you may want to call your new project *mydigitalhealthapp*. so launch xcode (you can search for xcode in spotlight and press return). then select **create new project**. name your project **mydigitalhealthapp** as shown below: !alt text !alt text feel free to pick either **storyboard** or **swiftui** type. then, make sure sure to select the **developer** folder as location for your new project. voil. xcode will create a sub-folder called *mydigitalhealthapp* with the basic project files. ### initialize cocoapods after creating the project, head back to the terminal app and go to the mydigitalhealthapp folder (type `cd mydigitalhealthapp` where you originally created the project). after that run the `pod init` command: !alt text this command will create a file named **podfile** inside your mydigitalhealthapp folder: !alt text once your project podfile is created, you can start adding required modules under the targets in this file. ### module (a.k.a. pod) installation open the podfile in your favourite text editor (for example, using xcode or textedit). the content of that file should look like the following text: ```ruby # uncomment the next line to define a global platform for your project # platform :ios, target 'mydigitalhealthapp' do # comment the next line if you do not want to use dynamic frameworks use_frameworks! # pods for mydigitalhealthapp end ``` in the file, you need to add two things: you need to add two sources at the top to tell cocoapods where to search for the modules to install: ```ruby source 'https://cdn.cocoapods.org' source 'https://github.com/theraforge/otfcocoapodspecs ``` you also need to specify that you want to install the otftoolbox parent framework/module like so: ```ruby pod 'otftoolbox' ``` the latter installs all the theraforge frameworks through a common parent framework. (if you wish to integrate specific theraforge frameworks then please check otftoolbox subspecs for more detailed installation.) then, your file should look like this: ```ruby # uncomment the next line to define a global platform for your project # platform :ios, source 'https://cdn.cocoapods.org' source 'https://github.com/theraforge/otfcocoapodspecs target 'mydigitalhealthapp' do # comment the next line if you do not want to use dynamic frameworks use_frameworks! # pods for mydigitalhealthapp pod 'otftoolbox' end ``` head back to the `terminal` window after saving the file and run: ```ruby pod install ``` then you should see the modules getting installed like so: !alt text after successful completion of the installation process (be patient, sometimes it make take several minutes), your folder structure should look like the one in the following image: !alt text ### compile & run make sure not to open the `mydigitalhealthapp.xcodeproj` file but, instead, you should always open the `mydigitalhealthapp.xcworkspace` file (which is what cocoapods altered). your xcode app window should look like this: !alt text type `cmd + b` or click on the **product** -> **build** menu item to build the project. you may want to select a specific iphone model from the dropdown menu before building. make sure that it is compiling without any errors: !alt text now you are ready to rock! if you wish to integrate specific theraforge frameworks then please check the otftoolbox subspecs for more detailed installation information. # theraforge cloud setup <a name=""cloud-setup""></a> the theraforge secure cloud service is a shared hosting baas that provides cloud connectivity and synchronization to apps (and much more). in order to use it in their apps, clients need to register an account with the minimal information that is required by the backend services. we divided the registration process in two parts: the first one is the <b>client registration</b> and the second one is the <b>api key registration</b>. ## client registration <a name=""client-registration""></a> to sign up for the theraforge secure cloud service, use the theraforge client registration form available here: client-registration-form. the client registration form requires some basic information about the client's organization. this is the list of the input fields that are presented in the form: company name (required) company email address (required) contact name (required) contact email address (required) contact phone number (optional) let us know about your work (required) once you submit the form, our *support team* will review the information provided and then they will guide you on the subsequent steps to complete the api key registration process. ## api key registration and backend configuration information <a name=""key-registration""></a> after successful submission of the *client registration* form, you will be contacted to go through the api key registration process via a setup form. this is the list of the input fields that are shown in the backend setup form: company developer email address (required): it represents the contact information to which an api key will be associated. organization source email address (optional): the organization source email address is the source address that will be used to send emails to users for general communications, for example, when they forget the access password to the dashboard. organization email server (optional): an organization email server address is required when the backend needs to configure the mail service for sending emails to users. here is the format for the organisation email server: **mail.organisation-domain.com**. organization source email address password (optional): this is the password for the source email server. gmail client id (optional): the gmail client id is used to enable the sign in with gmail functionality. the gmail client id is optional for the initial configuration.<br> apple id (optional): apple id is used to enable the sign in with apple functionality. the apple id is optional for the initial configuration. redirect url for sign in with apple (optional): the apple redirect url is used in the web dashboard to redirect the user after it is authenticated by an apple server. this url is optional for the initial configuration. once you submit this setup form, our development team will review the information. once the information is configured, then our support team will share the api key with you and will support you through any further steps to complete the backend configuration process. ## using the cloud registration information <a name=""using-registration""></a> once an api key is received, the next step is to add it to the appropriate configuration file that is used by the otfcloudclientapi framework to establish the communication with the cloud backend. in the app code, before creating an instance of the ``theraforgenetwork object, you need to create a `configurations` object with the api key assigned to you and with the theraforge cloud server url like so: ```swift let configurations = networkinglayer.configurations(apibaseurl: url(string:""cloud server url""), apikey: ""your api_key"") theraforgenetwork.configurenetwork(configurations) let otfnetworkservice = theraforgenetwork.shared ``` you can refer to the otfcloudclientapi readme file and review the documentation in which the configuration and other steps are discussed in detail. ## rebuild the app using the cloud registration information <a name=""rebuild-after-registration""></a> when you have configured your files, you can rebuild your app in xcode by clicking the build command in the menu bar. now your app will be running with your organisation's api key. you can now sign up users and login into the cloud service using user-provided credentials. # theraforge cloud analytics portal <a name=""theraforge-analytics""></a> the theraforge cloud analytics portal is a dashboard in which users can review their server and clients' related statistics. once you have configured the above parameters and have access to the cloud services, our support team will share the credentials of the analytics portal. through these credentials you will be able to login and review the available metrics. these are the statistics that are currently available in the analytics dashboard: client metrics: this section will show the stats related to your organization, i.e., number of users, care plan tasks, etc. <br> server metrics: this section will show the graphs related to server stats. <br> database metrics: this section show the httpd connections established with the backend database. <br> !alt text !alt text # no-code app customization <a name=""customization""></a> !alt text !alt text otftoolbox leverages the otftemplatebox framework to provide quick customization options for your digital health application through the `appsysparameters.yml` file. this reference shows you how to customize that file to suit your needs. the file is divided into various sections to customize different aspects of the app. each section contains a list of keys (which define the objects to customize) and of associated values. every key must be associated to a value but the app will **not crash** if the value is missing or mistyped. #### onboarding the *onboarding* keys are grouped as shown below. each group of keys is used to customize a single panel in the onboarding paging view. | key | values | | ------------- | ------------- | | title | a title for the page | | description | a description for the page | | logo | an emoji or number for the page | #### consent the values for these elements in the file will build the consent process. at least section is required. | consent form items | | ------------- | | title | | data gathering | | privacy | | data use | | time commitment | | study survey | | study tasks | | withdrawing | ### application configuration | key | values | | ------------- | ------------- | | login-sign-in-with-apple | the title of your application | | login-passwordless | sign in using a passwordless setup (this process also needs to be activated on firebase refer to our documentation to get started) | | login step title | title for logging in | | login step text | subtext for logging in | | key | values | | ------------- | ------------- | | study title | the title of your application | | team name | the name of your team or department | | email | a support email for users to contact | | phone | a support phone number for users to contact | | copyright | a copyright/informative statement that shows up at the bottom of the profile view | | website | a website url with more information about your app | | tint color | a hexadecimal color for secondary text and iconography in researchkit popovers (i.e. | | primary color | a hexadecimal color for buttons and text throughout the cardinalkit app | | review consent step text | text for consent form review | | consent file name | name of saved consent pdf file | | reason for consent text | text for consent alert | | passcode text | text for passcode selection | | passcode type | or the number of numbers in the passcode | | completion step title | title for completing onboarding | | completion step text | subtext for completing onboarding | | failed login title | failed login title | | failed login text | subtext for failing login | | health permissions title | access user health records using apple's fhirmodels by setting enabled to | health records | title for completing onboarding | | health permissions text | subtext for requesting health permisions | | background read frequency | immediate, hourly, daily, or weekly: how often to read from healthkit data records| | withdrawal instruction title | title for withdrawal step | | withdrawal instruction text | subtext for withdrawal step | | withdraw title | title to show after withdrawing | | withdraw text | subtext to show after withdrawing | | passcode on return text | text to show when user returns to app and sees passcode request | | consent title | title of consent form document | | use carekit | enable a carekit dashboard as a tab in the application | | healthkit data to read | a list of healthkit object types to read from the user (see: healthkit object types) | --------------------------------------------------------------------------------------------------------------------------------------------------- # additional information for developers ## otftoolbox subspecs <a name=""otftoolbox-subspecs""></a> otftoolbox is the parent framework of theraforge that includes the sub-frameworks as listed in the overview. ### otftoolboxcore to integrate otftoolbox/core with an existing workspace requires the extra line below in your podfile. add pod 'otftoolbox/core' under target in podfile. ```ruby pod 'otftoolbox/core' ``` ### otfcarekit to integrate theraforge otfcarekit requires the extra line below in your podfile. add pod 'otftoolbox/carekit' under target in podfile. ```ruby pod 'otftoolbox/carekit' ``` ### otfcarekitui to integrate otfcarekitui specifically which provides the views used across the framework. add pod 'otftoolbox/carekitui' under target in podfile. ```ruby pod 'otftoolbox/carekitui' ``` ### otfcarekitstore to integrate otfcarekitstore specifically which provides the solution for storing patient data across the framework. add pod 'otftoolbox/carekitstore' under target in podfile. ```ruby pod 'otftoolbox/carekitstore' ``` ### otfcloudantstore to integrate otfcloudantstore which is a cloudant sync to store and query local json data. add pod 'otftoolbox/cloudantstore' under target in podfile. ```ruby pod 'otftoolbox/cloudantstore' ``` ### otfcloudclientapi to integrate otfcloudclientapi which is a rest api sdk to connect to theraforge cloud. add pod 'otftoolbox/api' under target in podfile. ```ruby pod 'otftoolbox/api' ``` after installing the required podspec for your application you can import the integrated modules and use them in your project. # otftoolbox dependency diagram <a name=""dependency""></a> the diagram below depicts otftoolbox and its sub-framework dependencies: !alt text you can also find this dependency diagram at this url: # otftoolbox file protection <a name=""fileprotection""></a> there are different types of file protection levels natively available in ios and categorised by the nsfileprotectiontype key: **nsfileprotectioncomplete**: a file is kept encrypted on the storage device and cannot be read from or written to while the device is locked or booting. **nsfileprotectioncompleteunlessopen**: a file is stored in an encrypted format after it is closed. **nsfileprotectioncompleteuntilfirstuserauthentication**: a file is stored in an encrypted format and cannot be accessed until after the device has booted and the user unlocks it. security researchers often simply call it after first unlock (afu). it is the **default mode**. **nsfileprotectionnone**: the file has no special protections associated with it. building upon apples nsfileprotectiontype setting, otftoolbox provides three types of strict file protection models that help developers set a specific application behavior that minimizes the time a file encryption key is kept in memory (and is therefore potentially accessible by an intruder). these modes allow an app to run to completion or to run in the background for a predetermined amount of time before the protection level is switched to complete mode (nsfileprotectioncomplete). in this way, the app is kept in complete protection mode for as long as possible based on the developers needs. the goal is to not use nsfileprotectioncompleteuntilfirstuserauthentication (afu) state because that is problematic as described in this article. selecting one of the modes below will apply the file protection that you require for your files before starting and after finishing any operation: in this mode the application is required to complete any background operation (e.g., cloud synchronization) within seconds. after seconds the application will not be able to access its files in the background as it switches to the nsfileprotectioncomplete state. a developer can use this mode when the app is guaranteed to complete a file access operation in the background within seconds: the software will set nsfileprotectiontype to completeunlessopen for seconds. afterwards, it will change the nsfileprotectiontype to complete automatically and any running file access operation will not be able to complete in the background. a developer can use this mode in case an app cannot finish a background operation (such as syncing) within seconds and needs more time. will allot a seconds time frame to finish any running operation. after seconds nsfileprotectiontype will be changed to complete automatically and any running operation will not be able to access encrypted files in the background. **backgroundmode**: a developer can use this mode in case an app needs to periodically run in the background to do things such as automatic syncs. it will allocate a second timeframe to finish any operation in the background. after seconds nsfileprotectiontype will be changed to complete automatically and any running operation will not be able to access files after that. to leverage the above protection levels (otfprotectionlevel) in an application install theraforge otftoolbox and then use the functions below with the otftoolbox datastore object: ```objectivec /// call encryption function with the help of datastore object in objective c # -(void)setprotectionlevel: (otfprotectionlevel)level;' /// replace with any other available mode. # [datastore setprotectionlevel: ``` ```swift /// call encryption function with the help of datastore object in swift - # datastore.setprotectionlevel(.level) ``` # license <a name=""license""></a> this project is made available under the terms of a modified bsd license. see the license file."
1,moyo_ios,ios application for the moyo health network,"## table of contents - getting started - users - user login + aws - upload to - contributors # getting started !dependencies system requirements a. install research kit framework https://github.com/researchkit/researchkit b. install cocoapods https://cocoapods.org c. install the following pods into your podfile (pod install x) * pod alamofire * pod keychain swift * pod swiftcharts * pod swiftyjson * pod iosdropdown d. edit constants.swift file with your own urls and endpoints ## users ### user login *this route is present for the login of users* **path:** request type | url --- | --- post | https://yourloginurl/loginparticipant **params:** name | type | description --- | --- | --- participantid | string | **required.** user's registered id. password | string | **required.** password provided must be at least characters long. **status codes:** code | type | description ---|---|--- | success | server has processed the request and has successfully updated the user. | error | unauthorized. incorrect username and/or password combination. **example body:** ``` { ""participantid"": your participant id, ""password"": ""yourpassword"" } ``` **example response:** ``` { ""capacity"":""coordinator"" } ``` **example failure response:** ``` { ""error"": ""json parsing error"", ""error description"": ""key or value of json is formatted incorrectly"" } ``` ## aws ### upload to *this route is present for the amazon file uploads* **path:** request type | url --- | --- post | https://youruploadurl/upload **headers:** name | type | description --- | --- | --- authorization | string | **required.** mars token. weekmillis | long | **required.** timestamp **params:** name | type | description --- | --- | --- upload | string | **required.** files to be uploaded. **status codes:** code | type | description ---|---|--- | success | server has processed the request and has successfully updated the user. | error | unprocessable entry. specified parameters are invalid. **example header:** ``` authorization: mars ""weekmillis"": ``` **folder and file structure:** folder: yourfolder/studybucket/participantid/timestamp/ file: participantid_timestamp_deviceplatform_assessmentname.extension **example response:** ``` { ""success"": ""you have completed upload"" } ``` **privacy policy:** the moyo health network provided this application as a free app. this service is provided by the moyo health network at no cost and is intended for use as is. this page is used to inform visitors regarding my policies with the collection, use, and disclosure of personal information if anyone decided to use my service. if you choose to use my service, then you agree to the collection and use of information in relation to this policy. the personal information that i collect is used for providing and improving the service. i will not use or share your information with anyone except as described in this privacy policy. the terms used in this privacy policy have the same meanings as in our terms and conditions, which is accessible at moyo health network unless otherwise defined in this privacy policy. **information collection and use** for a better experience, while using our service, i may require you to provide us with certain personally identifiable information, including but not limited to moyo health network collects user entered photos, vital signs and mood survey scores but this information is not tied to any identifiable information. users are identified internally by a series of randomly generated log in credentials and no information regarding name, date of birth, etc. are collected. **log data** i want to inform you that whenever you use my service, in a case of an error in the app i collect data and information (through third party products) on your phone called log data. this log data may include information such as your device internet protocol (ip) address, device name, operating system version, the configuration of the app when utilizing my service, the time and date of your use of the service, and other statistics. **cookies** cookies are files with a small amount of data that are commonly used as anonymous unique identifiers. these are sent to your browser from the websites that you visit and are stored on your device's internal memory. this service does not use these cookies explicitly. however, the app may use third party code and libraries that use cookies to collect information and improve their services. you have the option to either accept or refuse these cookies and know when a cookie is being sent to your device. if you choose to refuse our cookies, you may not be able to use some portions of this service. **service providers** i may employ third-party companies and individuals due to the following reasons: * to facilitate our service; * to provide the service on our behalf; * to perform service-related services; or * to assist us in analyzing how our service is used. i want to inform users of this service that these third parties have access to your personal information. the reason is to perform the tasks assigned to them on our behalf. however, they are obligated not to disclose or use the information for any other purpose. **security** i value your trust in providing us your personal information, thus we are striving to use commercially acceptable means of protecting it. but remember that no method of transmission over the internet, or method of electronic storage is secure and reliable, and i cannot guarantee its absolute security. **links to other sites** this service may contain links to other sites. if you click on a third-party link, you will be directed to that site. note that these external sites are not operated by me. therefore, i strongly advise you to review the privacy policy of these websites. i have no control over and assume no responsibility for the content, privacy policies, or practices of any third-party sites or services. **childrens privacy** these services do not address anyone under the age of i do not knowingly collect personally identifiable information from children under years of age. in the case i discover that a child under has provided me with personal information, i immediately delete this from our servers. if you are a parent or guardian and you are aware that your child has provided us with personal information, please contact me so that i will be able to do necessary actions. **changes to this privacy policy** i may update our privacy policy from time to time. thus, you are advised to review this page periodically for any changes. i will notify you of any changes by posting the new privacy policy on this page. this policy is effective as of **contact us** if you have any questions or suggestions about my privacy policy, do not hesitate to contact me at clabdevelopment@gmail.com. all images are unlicense and free to use. this privacy policy page was created at privacypolicytemplate.net and modified/generated by app privacy policy generator # contributors whitney bremer, corey shaw, tony nguyen, daniel phan"
0,Hactive,heart rate monitoring,"# hactive hactive an ios application that extracts heart rate data from apples smartwatch to construct heart rate profiles. ## getting started ### installing device prerequisites * to collect heart rate data you will need access to an apple watch with the apple workout app installed. * hactive requires an ios device to operate. software prerequisites and installation hactive can only run on an apple mac computer since it is build with xcode. download xcode from the app store on your mac the app also uses **carthage** as it is dependency manager. install it by opening a terminal and using brew to `brew install carthage` or follow the install guide on github. clone this repository. open the `.xcodeproj` file in this project (this will open the project in xcode). connect your ios device. build the application on your ios device by selecting it as the target device and clicking the play button in the top lefthand corner. hactive should now be on your iphone. ## known problems ### reinstall problem under hactive's current implementation, we have decided not to put the app on the app store. as such, when you download and use this application through xcode, the code-signing tool only validates the app for days. this means that after this period, the app will cease to work and will require you to build it again through xcode. we understand the inconvenience this causes to the fundamental usability of the application. however, until we decide the app is ready for the app store, this problem will subsist. the silver lining is that because the data is managed by apple's health app, the data will persist after the application reinstalls. when this problem occurs, do not uninstall the application but simply connect your device to xcode and rebuild the app. ### problems with ios simulators this is not so much a problem but it is important to call out: the ios simulators on your computer does not come with dummy data. this means that although the application will technically work using one of the inbuilt simulators, you will not get the full hactive experience without data. you will see that the list of 'past workouts' will be empty. this is why we recommend using an actual iphone and apple watch. the apple watch can collect data from your workouts and only an actual iphone can read this data since it is stored in the healthkit app on the iphone (more on this later). ## how it works ### user flow record workouts on your apple watch using the default workout application. both running and walking workout types are compatible with hactive since these workouts also record gps activity. !alt text !alt text open hactive application on your iphone to view the list of workouts. select a workout to see a detailed graphical view along with the associated heart rate dynamic profiles. add a title and a description of the workout along with the age and weight of the person who is workout this belongs to. age and weight are used to determine the hrdp's of each workout. if there is no value set, hactive will take the values stored in apple's health app. failing that, it will default to `age = and `weight = if you are using this application as a researcher you will need to enter the weight and age of each user to their corresponding workout (this can be done by tapping the button `label` on the workout page. if however, you are using the application for personal use, simple set age and weight once in apple's health application. exported the data as a csv file. !alt text ### calculating hrdp one of the biggest challenges in constructing reliable heart rate profiles from heart rate data in a free-living environment is that it is difficult to accurately identify periods of physical activities from the long, and possibly noisy, continuous monitoring time series data. in our previous work, we used gps and time data to estimate a persons physical movement and therefore their energy expenditure (ee). this works well when the person is subjected to prescribed activities that involve physical displacement such as stair-climbs and running. however, this ee approach does not capture stationary physical exertions such as weight-lifting, jumping and running on a treadmill. also, the ee approach relies on good gps data, which may can be jeopardised by areas with poor signal (such as indoors) or lower-grade devices. to circumvent the problems with using ee to identify periods of physical activities, we developed an alternative approach that relies on the patterns in the heart rate time series alone. the first step of this new method was to find a time threshold of twenty seconds in which bpm was strictly nondecreasing. we then established two criteria by which we can assess if this period reflects the beginning of a hr profile. if the final recorded bpm at the end of that twenty-second period was greater than of that individuals maximum possible heart rate (estimated as minus one's age), it was a sign that they were in a medium to high-intensity exercise zone. for example, if a person is years of age, their maximum heart rate is and therefore indicates a bpm of - the second criterion is to take the percentage difference of an individuals heart rate from the beginning to the end of that time threshold. a percentage increase was reflective of an individual beginning some form of exercise and therefore was an appropriate threshold. to take someone years of age; their maximum heart rate is if their hr started at and increased to over seconds, their percentage increase is of their maximum, which will breach our threshold. as there was no historical to determine this threshold, this value was modified appropriately while testing. once both of these criteria were met, we marked the beginning of the hr profile. this was graphically represented as a series of alternating red and black dots, each set reflecting a different hr profile. it is important to note that if one of these criteria failed, we did not discard the zone entirely but rather increased the span of the zone we were analysing. for instance, if we were looking at a random period of twenty strictly non-decreasing bpm recordings, that did not meet the criteria, we increase the zone to twenty-one seconds and so on until the criteria was met or the zone began decreasing. this accounts for the fact that a users bpm may be increasing gradually and it takes more than twenty seconds to pass our user is-active threshold. once all the hr profiles have been extracted, hactive can scale the profile down to time series. these scaled profiles can then be displayed in a single plot to allow for a visual comparison of all the hr profiles. furthermore, hactive computes statistical summaries of the hr profiles such has maximum hr found in a profile. !alt text the above are examples of heart rate profile views of hactive. (a) the heart rate time series of an entire workout. the alternating pairs of red and black dots represent unique zones of heightened physical activity within the scope of the entire workout as identified by an algorithm in hactive. the first pair of red dots indicates the start and end of the first zone. the following pair of black dots indicates the second zone et al. (b) heart rate profiles of multiple zones of physical activity scaled and interlaced onto a single chart for visual comparison. the beginning of each zone is marked by blue dots, the peak hr is marked by red dots and the end of each zone is marked by green dots. ### data management hrdp are not persisted. they are constructed every time you view a workout and destroyed when you exit the view workout page. this means most of the computation is done when viewing each individual workout. the only data that is persisted is the label, description, age and weight entered by the user. the app is optimised to use apple's existing data infrastructure (ios persistent datastore). this means privacy and security is handled by apple. hactive access this data through apple healthkit. we have utilised the swifts core data framework which is used to manage the model layer object of hactive. in general, core data is a persistent data management tool for the model layer object of an ios application. in the case of this application, it was used to store the labelling data inputted by the user on the activity page. through this feature, users are provided with the ability to title their workouts, rate how intensive it was (from a scale zero to ten) and provide any extra detail about their workout. this mechanism provides researchers with labelled data for future potential machine learning algorithms. having a strenuous rating, for example, allows researchers to model and compare workouts of the same intensity. furthermore, should researchers require the users of hactive to provide any other relative health information, such as current fitness level and proneness to heart problems, they can provide this information by saving it with core data. swift has a medically orientated api researchkit, which was designed to support researchers and clinicians in conducting studies and collecting sensitive data. this kit allows medical researches to embed consent flows, surveys and real-time dynamic, active tasks into an application. a template consent form has been installed in hactive to allow future researchers to incorporate their own approved consent document once one is created. like researchkit, healthkit was developed to manage, monitor and safely store sensitive medical health data. to avoid the management of sensitive data such as heart rate, hactive has offloaded this to healthkit. by making fetch requests to healthkit rather than storing the data within the application, we avoid managing the massive data pile that will inevitably build up as a result of recording and storing workouts as well as the security risks associated with this data. as a simple evaluation, we recorded twenty-five workouts, which were stored in healthkit on a test mobile device. extraction of all these workouts from healthkit took an average of seconds. of the twenty-five workouts, the average length is twenty-seven minutes. to load a single workout of this length takes seconds. the longest workout of minutes, took seconds to load, which we attribute to the increase in the number of hrdp extracted during such a lengthy exercise. we are generally comfortable with the runtime performance. ### consent form a default consent form is available in the application. manipulate it to suit your scientific study. !alt text !alt text ## privacy hactive takes your privacy very seriously. the data recorded by your apple watch and managed by hactive, is secured by apple. the application makes no network calls and so the data remains safely in your ios device. ## built with * swift - the programming language used * researchkit - for the consent form * charts - graphical display ## authors * **adam goldberg** - *core development* - linkedin * **dr. joshua w. k. ho** - *research idea and supervision* - ho laboratory ## license this project is licensed under the mit license - see the license.md file for details ## acknowledgments the work was supported in part by funds from the national health and medical research council of australia, and the national heart foundation of australia."
1,elicitation-engine,web app for creating quantitative scientific surveys,"the nearzero elicitation engine is a **web app for creating and hosting scientific surveys**. !screenshot of elicitation authoring interface - easy to setup, author and launch surveys targeted toward scientists and other experts - includes a visual+web-based authoring interface which makes it easy for collaborators to design the survey - includes more than a dozen widgets designed to help you frame scientific queries - pop-down definitions allow concise on-screen questions with progressive disclosure of detail as needed - custom scripting allows complex interactions - easy to implement new widgets for any web developer if you have a custom question type - authoring interface is built in javascript and runs in-browser, for fast responsive editing - thoughtfully developed over several years in response to the practical needs of scientists at near zero ##builtin widgets !available widgets ## try it out in about minutes: [!deploy to azure](https://azuredeploy.net/) create a microsoft account if you do not already have one: https://account.microsoft.com/ sign up for windows azure if you have not already - usually a free trial: https://azure.microsoft.com deploy an elicitation engine by clicking: [!deploy to azure](https://azuredeploy.net/) * specify a real username (i.e *not* 'admin') for the new server and a **strong password or the deploy will fail**. * the deploy will take a couple minutes to create the new web server and sql database. now find the url of your new elicitation engine web server: * after the deploy completes, click ""manage your resources"" to open the windows azure portal. * find the elicitationengine-######### app service in the right hand list and click it to open * on the right hand side near the top, find the ""url"" and open it to access your elicitation-engine. url should be something like http://elicitationengine-#########.azurewebsites.net login with your elicitation admin username and password, and starting creating elicitations! * see http://wiki.nearzero.org/elicitation-authoring for some docs and advice on elicitation authoring * the default configuration should cost about and uses small servers. this should be ok for many elicitations, but you might want to ""scale up"" both the ""app service plan"" and ""sql database"" to the next azure hostingplan level before you run the elicitation, esp. if consulting more than a hundred experts. ### supported databases the elicitation-engine uses the nodejs sequelize library (http://sequelizejs.com) for database access. any database well-supported by sequelize should work, including postgresql, ms sql server, mysql, mariadb and sqlite. you can configure the elicitation-engine to use your database using the elicitation\_sequelize\_config environment variable. ##development ### getting started install node and npm if necessary install npm dependencies by running ""npm install"" in elicitation-engine/ by default the elicitation-engine will use sqlite in the local directory (./elicitation.db.sqlite). this should work fine for development, but if you already have a db you would like to use, see ""supported databases"" above. we use webpack to transpile our javascript, in a separate terminal run ""npm run-script build"" in elicitation-engine/ to compile the javascript. by default this will watch for changes and recompile. run ""npm start"" to start the elicitation engine open ### source code organization - **/app** : this contains the bulk of the elicitation-engine source code, and runs in-browser as a ""single page app"". its built with the emberjs framework, though development started with a /very/ early version of emberjs, so its not a conventional modern emberjs app in a lot of varieties (does not use routing, etc) - **/app/widgets** : all of the elicitation 'question types' (time-trend, box-and-whiskers, etc) are defined here - **/public** : static web server assets - **/server and server.js** : a basic nodejs/express based web-server backend for hosting the /app frontend, authentication, storing results to the db, etc. relatively little code lives here, most elicitation logic is in the front-end."
0,Fitbit,data parsing and processing programs for clinical survey and biometric data,# a collection of data analysis programs for fitbit data ## documentation the enclosed programs parse biometric and survey data for analyses for the ongoing collaborative trial with litmus health at the university of chicago. # parser parser contains programs for the first iteration of the trial. programs in this parser include plotting and basic analyses. this has since been deprecated. # parser parser contains a command line utility that parses and analyzes a json file to determine participant compliance. # dependencies - numpy - pandas - matplotlib - statsmodels - seaborn # pubs:
0,family-healthcare,a mhealth android app developed as part of a group (group - based assessment for the module,# family-healthcare a mhealth android app developed as part of a group (group - based assessment for the module
0,ScreenSafeFuture,screensafefuture: a parent-empathetic and pragmatic mhealth application for toddlers' brain development addressing screen-addiction challenges,# screensafefuture screensafefuture: a parent-empathetic and pragmatic mhealth application for toddlers' brain development addressing screen-addiction challenges ## table of contents - minimalistic push - table of contents - background - functionality - design - features - features (upcoming versions) - platforms - contributions ## background ## functionality ## design ## features ## features (upcoming versions) ## platforms ## contributions
0,TIME-mood-prediction,"the aim of the project is to use multi-model data (motion sensing, location, ...) to predict affective measurements (stress level, mood, productivity, ...)","# mood prediction from time dataset this repository contains the code for a project from the time study - a longitudinal study conducted by northeastern university mhealth lab. the aim of the project is to use multi-model data (motion sensing, location, ...) to predict affective measurements (stress level, mood, productivity, ...)"
0,HealNet-Mobile_Health,health monitoring mobile application - data extracting from real time patient data using arduino,# healnet-mobile_health health monitoring mobile application - data extracting from real time patient data using arduino
0,CareMonitorIPe,"caremonitor is a react native expo mobile health app integrated with firebase. it enables users to manage health data, including audio recording, playback, and storage.","# caremonitor caremonitor is a react native expo mobile health app integrated with firebase. it enables users to manage health data, including audio recording, playback, and storage."
0,GHT-APPFILES,ght app pycharm code,"# ght-app (global health tracking app) ## ght app: your health journey unveiled discover the global health landscape on the go ## what is ght app? the ght app is your mobile health companion, putting the power to track sickness and diseases in travel locations right in the palm of your hand. it is not just an app; it is your lens into the health landscape of different regions. with a simple tap, the ght app let us you explore and understand the health situations around you, providing historical and current data on disease occurrences based on the specific location, whether it is a city, region, or country. ## how it works: imagine you are planning a trip or just curious about your local health environment. open the ght app, select your location, and instantly access valuable information on disease outbreaks. the app is designed with you in mind, providing an intuitive interface for effortless navigation. stay informed, stay healthy. ## why ght app? ght app empowers you to make informed decisions about your health, travel, and daily activities. whether you are a globe-trotter, a concerned parent, or simply someone who cares about their community, ght app is your go-to tool for health insights tailored to your location. ## key features: - location-based insights: historical and current data on disease occurrences. - user-friendly interface: simple and intuitive, making health information accessible to everyone. - personalized alerts: stay updated with alerts about disease outbreaks in your chosen areas. - visual data representation: interactive maps and charts for a clearer understanding of health trends. ## why do a ght journey? so, you are in a fascinating location, and you want to share more than just the scenery. do a ght journey! show your friends the health situation in your vicinity. whether you are exploring a new city, enjoying nature, or simply concerned about your community, ght app allows you to share the health story of any location with a comprehensive perspective. ## what is next? ght app is not just an app; it is a movement towards informed and connected communities. join us as we redefine how we perceive and share health information. the world is full of stories, and with ght app, you can tell the health story of your location. download the app today and start your health journey unveiling!"
1,SemperTibi,android app to help users in daily stress situations,"align=""center""> align=""center""> masters project in health care it align=""center""> fh krnten / cuas <p align=""center""> <a href=""https://www.fh-kaernten.at/"" target=""blank""><img align=""center"" src=""https://www.fh-kaernten.at/fileadmin/template/fh_kaernten/images/fh-kaernten-logo.png"" alt=""fh kaernten"" /></a></p> the master thesis was written at the carinthia university of applied sciences in june with the title ""user experience & cyber security in a stress monitoring mhealth application"". a copy can be found in the local library at the campus in primoschgasse, klagenfurt, austria."
0,heart-mobile-app,an mhealth app destined for self-management and risk prediction of cardiovascular diseases,"# heart-mobile-app an mhealth app destined for self-management and risk prediction of cardiovascular diseases(cvds), developed for the course `m-health and e-health technologies` at ece ntua."
0,ba,mhealth app for depression using spotify data,"## getting started this project is the implementation part of my bachelor thesis. the app aims to help depressed people using their spotify data. ## how to use **step download or clone this repo by using the link below: ``` https://github.com/pantageepapa/ba.git ``` **step go to project root and execute the following command in console to get the required dependencies: ``` flutter pub get ``` **step execute this command to launch the app: ``` flutter run ``` ### folder structure here is the core folder structure which flutter provides. ``` flutter-app/ |- android |- build |- ios |- lib |- test ``` here is the folder structure we have been using in this project ``` lib/ |- models/ |- pages/ |- services/ |- main.dart ``` now, let us dive into the lib folder which has the main code for the application. ``` models - contains store(s) for state-management of the application, to connect the reactive data of the application with the ui. pages - contains all the ui of the project, contains sub directory for each screen. services - contains the utilities/common functions of the application. main.dart - this is the starting point of the application. all the application level configurations are defined in this file i.e, theme, routes, title, orientation etc. ```"
0,Heapp,this project is a mobile health coach app. this will be integrated with automation desktop applications via database and framework.,# heapp this project is a mobile health coach app. this will be integrated with automation desktop applications via database and framework.
0,MobileHealthMonitoringusingRPi,mobile health monitoring using raspberry pi and custom designed photoplesythmographic sensor circuit,"# abstract most heart cases need continuous monitoring of the heart condition. apart from indicating the soundness of the heart, heart rate helps in assessing the cardiovascular system. analysis of heart rate helps in diagnosis and detection of coronary diseases. the normal range of heart rate among adults is beats per minute (bpm). if heart rate is higher than normal the condition is known as tachycardia, in the opposite case it is known as bradycardia. there are many devices available in the market to measure heart rate. the constructed device brings about some major changes compared to the available ones. firstly, this is a cost effective option to measure heart rate. secondly, the device provides an easy way to interface with personal computers and mobile phones. thirdly, although there are a few analog devices to measure heart rate, the patient needs help from another person to do so. this device can be used without any need of assistance from others. finally, the device is easy to use. the user only needs to place a fingertip on a sensor. the signal from the sensor is sent to raspberry pi which counts the heart rate and sends it to the display. coding of raspberry pi is done using python language. python is a widely used high-level, general-purpose, interpreted, dynamic programming language. its design philosophy emphasizes code readability, and its syntax allows programmers to express concepts in fewer lines of code than would be possible in languages such as c++ or java. moreover python is the main programming language of raspberry pi. along with the heartbeat sensor, a temperature sensor is also interfaced to display the surrounding temperature. the temperature sensor used is a precision integrated-circuit temperature sensor, whose output voltage is linearly proportional to the celsius (centigrade) temperature. the thus has an advantage over linear temperature sensors calibrated in kelvin, as the user is not required to subtract a large constant voltage from its output to obtain convenient centigrade scaling. the does not require any external calibration or trimming to provide typical accuracies of at room temperature and cover a full to temperature range. this temperature sensor could be used in such a way that it measures the temperature of the patient. the display used is which is a bit backlit lcd display. the heart beat and temperature sensed by the sensors are displayed on this display through the python code run through raspberry pi. thus the heartbeat of the patient could be continuously monitored and in case of any abnormality, a message or an alert is sent to a particular predefined person. in addition to this the data of the vitals could be stored in cloud or precisely in mail."
0,Lab-on-App,the repository for ph.d project of zhuo zhi,"# lab-on-app: ai empowered point-of-care diagnostics for ageing population _the repository for zhuo zhi's ph.d project_ <img this repository contains the information of zhuo zhis phd project (dept electronic and electrical engineering, university college london). the content of this readme.md document is as follows: introduction of the project structure of the repository participants of the project ## introduction of the project ### background of the anemia anaemia is a serious global public health problem that particularly affects young children and pregnant women. who estimates that of children less than years of age and of pregnant women and of the older population worldwide are anaemic. most commonly, people with anemia report feelings of weakness or fatigue, and sometimes poor concentration. they may also report shortness of breath on exertion. in very severe anemia, the patient may have symptoms related to this, such as palpitations, angina (if pre-existing heart disease is present), intermittent claudication of the legs, and symptoms of heart failure. therefore, the diagnosis of anemia and its causes is important for improving human well-being. ### problems existing in traditional anemia detection methods anaemia, defined as reduced haemoglobin concentration. the diagnosis of anemia in men is based on a hemoglobin of less than to g/l to g/dl). in women, it is less than to g/l to g/dl). the traditional diagnosis of anaemia requires laboratory-based measurements of a venous blood sample, which could bring trauma and pain to patients, even wound infection. the diagnosis process involves complex equipment which requires professional operators and fixed test site. to address these issues, researchers keep looking for novel anemia detection methods. ### problems existing in novel anemia detection methods novel anemia detection methods based on ai data analysis and advanced sensing technology. for the first part, the ml/dl models can be built for classifying patients finger nail, fundu, conjuctival or other bio-images into anemia and normal condition. however, these models are not able to give the because of the anemia or predict the anemia in a early stage. at the same time, the privacy protection agreement and time/labor cost make it difficult to collect biometric images of patients at scale, which limits the performance of models. for the second part, researchers have developed sensors based on the principle of multispectral analysis, transmission spectrum analysis, etc. similarly, these methods can not explain the reason of the anemia and it is unable to iterate and update the algorithm with new biomarks. ### what do we want to achieve? we would like to develop a lab-on-app to non-invasively diagnose anaemia and its causes (e.g. genetics, diet, or injury) that can be easily used by older people, carers, or healthcare professionals. it is a system with portable device and corresponding software deployment. it is anticipated that the successful demonstration of our proposed lab-on-app will lead to additional work by this team using mobile health technology to diagnose other conditions afflicting older population (kidney diseases, colon diseases, or vitamin deficiencies). ### how do we achieve the goal? the project solution consists of five parts: the patient data acquisition, the data analysis, the diagnostic result, the hardware integration and the software deployment. the project solution is shown as follows. <img src=""https://github.com/zhuozhi-ucl/lab-on-app/blob/main/introduction/image/image.png""/> the patient data acquisition (the patient data are collected through four parts.) - ehr data ehr data contain the demographic, vitals, lab test results, disease and medication records of each patient. we will get the access to it and select useful information. - non-invasive biometric sensor we will develop the non-invasive biometric sensor based on multispectral (or other prin- ciples) to measure the hemoglobin, blood oxygen concentration and other biometrics from skin. the data analysis we will develop the multi-modal model to analysis different kinds of data and combine the useful information for regression or classification. the model involves the function of prepro- cessing, imputation, feature selection, interpretation, uncertainty and calibration, etc. the diagnostic result the diagnostic result consists of three parts. - the diagnosis of anemia as well as its causes. - the suggested personalized treatment planning, for example, the medication and some mechanical equipments. - the diagnosis of other diseases. the hardware integration we would like to integrate all sensors, mcu, battery, etc into a compact, portable and low- power platform. the integrated module design, the wireless/wired communication and the embedded system development are the main parts that need attention. the software deployment (the software deployment includes three parts.) - app development an ios/ android app will be developed and all functions are performed in it. - cloud computing and data interaction the ml/dl model will be deployed in the server due to the limited computing ability of the mobile device. all patient data are also stored on the server. distributed computing and privacy computing are needed to be considered for the process. - database development a database needs to be established for all patients to facilitate version iteration and update ### the innovation of our solution there are two main innovation of our solution. ehr data is combined for the diagnosis - multiple health histories of users are modeled to analyze and predict disease occurrence and reasonable suggestions can be given. - combining the ehr data with other biomarks have shown better performance than single-input model. - the continuous update of ehr data can realize the monitoring and prediction of the patients condition. truly portable and intelligent diagnosis - truly portable diagnosis no external power supply is required. the system has low power consumption, low weight and size. - the cloud service ehr and sensor data can be uploaded to the cloud to maximize user history. - intelligent diagnosis machine learning models are built for diagnosis. the disease prediction, diagnosis and health advice can be given. - user universality no professional operation is needed, which is suitable for user with all age. ## structure of the repository the structure of the repository is shown as follows. <img the repository consists of three parts: the progress record, the action points record and the code. the progress record the progress record records weekly progress and presents it in .pdf, .ppt, etc. the action points record the action points record records weekly action points by weekly meeting and presents it in .docx. the code it is the most important part of the project. we firstly divide the code into four parts (ehr data, image data, other biomarks data and multimodal data) according to the data type. then, for each kind of data, we create separate folder for data from different sources (eg. ehr data from stanford university (ehr-su)). finally, three steps are performed on selected data: the data preprocessing, ml/dl model building and evaluation and analysis. the data preprocessing includes outlier detection, normalization, feature selection, imputation, data clipping, etc. the structure and weights of the ml/dl model will be stored in ml/dl model building. in evaluation and analysis step, we will propose the required evaluation metrics and conduct comparative experiments as well as analyse the result. ## participants of the project project supervisor - professor miguel rodrigues, dept electronic and electrical engineering, university col- lege london project co-supervisors - dr mine orlu, ucl school of pharmacy, university college london - professor andreas demosthenous, dept electronic and electrical engineering, univer- sity college london project collaborators - dr moe elbadawi, ucl school of pharmacy, university college london - professor abdul basit, ucl school of pharmacy, university college london - dr adam daneshmend, imperial college healthcare nhs trust"
1,clarity,clarity is the first healthcare prevention and health management software that allows for physicians and insurance providers to see what their patients consume in real-time.,"<img align=""left"" # clarity <a align=""right"" alt=""clarity-thumbnail"" **view pitch here** ## table of contents mission statement pitch problem problem statement problem for health insurance providers problem for physicians solution solution statement solution for health insurance providers solution for physicians product product implementation demo user case example market nationwide market size clients vendors references startup school start-up school pitch ## mission statement clarity is a software project that aims to mitigate the burden of chronic disease in america by applying an intermediary layer of computation behind every food and drug-related transaction made by all individuals in our economy today. we believe that software can and should be capable of changing behavior for the better and we believe that a new paradigm of healthcare prevention software can realize that belief system. ## pitch clarity is the first healthcare prevention and health management software company that allows physicians and insurance providers to see what their patients' consume in real-time. extract ## problem > an apple a day keeps the doctor away ### problem statement most deaths in the you.s. are preventable and are related to our nutrition. less than of healthcare in the you.s. is preventative. physicians do not have access to any of their patients food & drug-related consumption data. the cost of healthcare in the next years will rise from of gdp to of gdp. why is there a current lack of healthcare prevention software? we have a healthcare system that is focused on illness rather than wellness. healthcare prevention is bad business because a healthy person is a non-existent patient. the american healthcare crisis is not a healthcare-based problem, its a market-based problem. that requires a market-based solution. ### problem for health insurance providers in a board of physicians at the institute of medicine discovered that of all health care spending is waste. the cost of healthcare to the you.s. economy is trillion dollars per year. - the united states spent approximately twice as much as other developed countries on medical care, yet utilization rates in the united states were largely similar to those in other nations. - total health care spending consumes about of the gross domestic product (gdp) and as costs are projected to rise up to by year rising healthcare costs present a challenge not only for the federal government but also for private payers, however an innovative implementation of effective measures to eliminate economic waste represents an opportunity reduce the continued increases in us health care expenditures. - if we help insurance providers in reducing the economic waste we can pass the savings on to the consumer and reduce the cost of healthcare in the you.s. - despite efforts to reduce overtreatment, improve care, and address overpayment, it is likely that substantial waste in us health care spending remains. - in a review a board of physicians at the national institute of medicine discovered that of all health care spending is wasted. estimates that the you.s. loses some billion annually to medical fraud, inefficiencies, and other siphons in the health-care system. - failure of care delivery, billion to billion - failure of care coordination, billion to billion - overtreatment of care, billion to billion - pricing failure, billion to billion - fraud and abuse, billion to billion - administrative complexity, billion in comparison, the defense department budget billion for the war in iraq over the eight years it was there. despite efforts to reduce overtreatment, improve care, and address overpayment, it is likely that substantial waste in us health care spending remains. health insurers underwriting margins could be better optimized if they had nutritional data on their entitlement populations. if insurers had access to a patients food and drug related spending they could in turn better assessing, underwriting, and price risk. how do we address the administrative costs / complexity waste? clarity the united states has a voluntary private employer-based and individual-based system. private insurance as the primary form of insurance is highest in the united states at !fig > shrank, william h et al. waste in the us healthcare system: estimated costs and potential for savings. jama vol. ### problem for physicians there may be no such thing as dying from old age. from a study of more than forty-two thousand consecutive autopsies, centenariansthose who live past one hundredwere found to have succumbed to diseases in percent of the cases examined. though most were perceived, even by their physicians, to have been healthy just prior to death, not one died of old age. until recently, advanced age had been considered to be a disease but people do not die as a consequence of maturing. they die from disease, most commonly heart attacks. most deaths in the united states are preventable, and they are related to what we eat. our diet is the number-one because of premature death and the number-one because of disability. how not to die: discover the foods scientifically proven to prevent and reverse disease greger, michael, md ## solution clarity is the first healthcare prevention software that provides nutritional data on transactions made for an insurance provider's entitlement population as well as a healthcare provider's patient population. in doing so we increase diagnostic accuracy, and we help reduce the rates of risk ### solution statement ### solution for health insurance providers // define key metrics to optimize for insurance provider? population health management software. data collection and platform infrastructure clarity collects an individuals food & drug-related transactions. parse and generates a patient profile nutritional data structure from those transactions. integrate and pipeline that data into pre-existing legacy software to reduce onboarding expenses. we provide entitlement's nutritional intake behavioral patterns, by providing food and drug-related transactional metadata for insurers. by providing nutritional data on transactions made for an insurance provider's entitlement population we help reduce waste. how do we reduce waste? we provide entitlement data for insurance providers to more accurately... assess risk underwrite risk price risk insurance companies run on underwriting margin. insurance companies will not be creatively destroyed. health insurance companies have two things that maintain their status... their capital, and they are at the center of all the data. what we think we know about healthcare is wrong by luke williams | cliche | hypothesis | |---------------------------------------------------| ----------------------- | | healthcare costs always go up | what if we keep healthcare costs flat or even lower them? | healthy people are a better risk than sick people | what if the sickest populations were the best kind of risk? | waste in the healthcare system is unavoidable | what if we could pay for the uninsured by reducing waste? what if we could pay back half the nation's debt by fixing this problem? ### solution for physicians pipeline that data structure in pre-existing web-based ems portal. (ems - electronic medical records systems). ## product !preview !preview ```yml [ { ""timestamp"": ""yyyy-mm-ddthh:mn:ssz"", ""transaction"": [ { ""location"": """", ""vendor"": """", ""vendor-id"": """" } ], ""general"": [ { // barcode of the product ""code"": // url of the product page ""url"": ""https://xxx.com"", // date that the product was added (unix timestamp format) ""created_t"": ""yyyy-mm-ddthh:mn:ssz"", // date that the product was last modified (unix timestamp format) ""last_modified_t"": ""yyyy-mm-ddthh:mn:ssz"", // name of the product ""product_name"": ""cherios"", // generic name of the product ""generic_name"": ""cereal"", // field that designates quantity and unit size ""quantity"": } ], ""tags"" : [ { ""packaging"": shape, material, ""packaging_tags"": """", ""brands"": """", ""brand_tags"": """", ""categories"": """", ""categories_fr"": """", ""origins"": ""origins of ingredients"", ""origintags"": """", // locations where manufactured or transformed ""manufacturing_places"": """", ""manufacturing_places_atgs"": """", ""labels"": """", ""labels_tags"": """", ""emb_codes"": """", ""emb_code_tags"": """", // coordinates corresponding to the first packaging code indicated ""first_packaging_code_geo"": """", ""cities"": """", ""cities_tags"": """", ""purchase_places"": """", ""stores"": """", // list of countries where the product is sold ""countries"": """", ""countries_tags"": """" } ], ""ingredients"" : [ { ""ingreidents_text"": """", ""traces"": """", ""traces_tags"": """" } ], ""misc_data"" : [ { // serving size in g ""serving_side"": ..., // indicates if the nutrition facts are indicated on the food label ""no_nutrients"": ..., ""additives"": ..., ""additives_tags"": ..., ""ingredients_from_palm_oil_n"": ..., ""ingreidents_from_palm_oil"": ..., ""ingreidents_from_palm_oil_tags"": ..., ""ingreidents_that_may_be_from_palm_oil_n"": ..., ""ingreidents_that_may_be_from_palm_oil_tags"": ..., // nutrition grade ('a' to 'e') // reference: https://fr.openfoodfacts.org/nutriscore ""nutrition_grade_fr"": ""a"", ""main_category"": ..., } ], ""nutrition_facts"": [ { ..., ..., ... } ], ""nutrition_facts"" : [ { ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., // % vol of alcohol ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., // also known as vitamine ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., ..., // ph (no unit) ..., // % of fruits, vegetables, and nuts (excluding potatoes, yams, manioc) ..., } ], // nutri-score // nutrition score derived from the uk fsa score and adapted for the french market (formula defined by the team of professor hercberg) : ""a"", // nutrition score defined by the uk food standards administration (fsa) ""a"", } ] ``` ### product implementation utilizing the following, aetnas interoperability api developer portal uber api stripes api ### demo ### user case example ## market ### nationwide market size the total addressable market size in the united states. adoption for key clients health insurance companies healthcare providers million americans / define total smartphone users. ### clients bluecross blueshield aetna humana mckesson united healthcare cvshealth amerisourcebergen aetnas interoperability api developer portal ### vendors ### feedback actuary's at health insurance companies ### further research #### open banking open banking would make it easier to get the transaction history. will be good to look out for that in the coming years. - - - https://en.wikipedia.org/wiki/open_banking - https://www.mckinsey.com/industries/financial-services/our-insights/data-sharing-and-open-banking - https://www.linkedin.com/pulse/apple-opens-up-open-banking-sanjeev-kumar/ #### apple healthkit need to look into whether any health insurance company has already integrated with healthkit to get activity, and ecg data. > ...a recent survey of americans showed that almost would be more willing to buy a fitness tracker if it meant they could pay less for health insurance source: - - https://technologyadvice.com/blog/healthcare/study-wearable-technology-preventative-healthcare/ - **tldr**: humana appears to be pioneering using data from your fitness trackers and using incentives to affect insurance premiums john hancock too: - - https://www.aetna.com/individuals-families/health-insurance-through-work/health-insurance-information/discounts.html - - > tech entrepreneurs in the health space say insurance companies are currently figuring how to best access the data generated by todays fitness trackers. source: --- additionally, apple research is a very interesting application of healthkit. apple partners with research institutions and allows iphone and apple watch users to enroll in scientific studies and share all of their health and activity data. #### legal implications read about legality of ""discriminating"" against people based based on their personal habits. it looks like discriminating based on race/sex/religion is not allowed, but the law did not catch up yet on the usage of fitness trackers and payments history to affect insurance premiums. - - - #### measuring healthy eating habits using glucose sensors measuring blood glucose levels using a wearable device is becoming easier. this would give us a good way to track healthy/unhealthy food hobbits. - https://www.healthline.com/diabetesmine/wrist-smartwatches-and-diabetes-tech#garmin-watches-and-diabetes-data apple has been researching this since and the feature may come in a future apple watch. dexcom the manufacturer of glucose monitoring systems and unitedhealthcare partnered to track time-time data on their patients with diabetes. dexcom's devices are intended to help members reduce their use of perscription drug medication and in turn reduce permiums. #### security concerns since users can get lower insurance premiums by eating healthy food & etc, some computer-savvy users could ""hack"" our program to report data that would be beneficial for lowering their insurance premiums. similarly, malicious actors might benefit from getting access to clarity's data. need to research relevant security standards and implications (i.e, hipaa) #### data integrity concerns ## integrity even if the consumer does in fact cheat meaning one of the following options for a single transaction may occur: clarity. clarity recognizes transaction, consumer consumes all items clarity recognizes transaction, consumer consumes some of the items. clarity recognizes transaction, consumer consumes none of the items. ### figure | clarity % in transaction recognization | user % consumption of transactions.items[all] | |---------|----------| | | | | | < | | | | | < | ? | | | ? | ## references ### health care and the budget: issues and challenges for reform congressional budget office. health care and the budget: issues and challenges for reform. cbo testimony, june > total federal spending for medicare and medicaid under assumptions about the > health cost growth differential. the health cost growth differential refers to > the number of percentage points by which the growth of annual health care > spending per beneficiary is assumed to exceed the growth of nominal gross > domestic product per capita, after an adjustment for the growth and aging of the > medicare and medicaid populations. this study presents cbos projections of > federal spending on medicare and medicaid and health care spending generally > over the next years. despite the substantial uncertainties surrounding > projections over that long a period, particularly ones involving the growth of > health care costs, such a horizon is useful for illustrating the long-term > fiscal challenges that this country faces. #### you.s. department of health and human services (hhs) #### centers for disease control and prevention (cdc) #### you.s. center for medicare & medicaid services (cms #### reinvesting the health insurance business shrank wh, rogstad tl, parekh n. waste in the us health care system: estimated costs and potential for savings. jama. oct doi: pmid: #### you.s. health insurance industry analysis report all of us united healthcare student resources uber api food labeling waste in the us health care system: estimated costs and potential for savings"
0,WearableSensorData,"this repository provides the codes and data used in our paper ""human activity recognition based on wearable sensor data: a standardization of the state-of-the-art"", where we implement and evaluate several state-of-the-art approaches, ranging from handcrafted-based methods to convolutional neural networks.","# wearablesensordata this repository provides the codes and data used in our paper ""human activity recognition based on wearable sensor data: a standardization of the state-of-the-art"", where we implement and evaluate several state-of-the-art approaches, ranging from handcrafted-based methods to convolutional neural networks. also, we standardize a large number of datasets, which vary in terms of sampling rate, number of sensors, activities, and subjects. ## requirements - scikit-learn - keras (recommended version - tensorflow (recommended version - python ## quick start clone this repository run ```bash python ``` for example ```bash python data/loso/mhealth.npz ``` ## data format the raw signal provided by the original dataset was segmented by using a temporal sliding window of seconds. its format is (number of samples, temporal window size, number of sensors) ## contributing contributions to this repository are welcome. examples of things you can contribute: * implementation of other methods. see template_hancrafted.py and template_convnets.py * accuracy improvements. * reporting bugs. the table below shows the mean accuracy achieved by the methods using the leave-one-subject-out (loso) as validation protocol. the symbol 'x' denotes which was not possible to execute the method on the respective dataset. | method | mhealth | | uschad | | | wharf | wisdm | mean accuracy | | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | | kwapisz et al. | | | | | | | | | | catal et al. | | | | | | | | | | kim et al. | | | | | | | | | | chen and xue | | | | x | x | | | | | jiang and yin | | x | | x | x | | | | | ha et al. | | | x | x | x | x | x | | | ha and choi | | | x | x | x | x | x | | mean accuracy[]() | | | | | | | | x | please cite our paper in your publications if it helps your research. ```bash author = {artur jordao, antonio carlos nazare, jessica sena and william robson schwartz}, title = {human activity recognition based on wearable sensor data: a standardization of the state-of-the-art}, journal = {arxiv}, year = eprint = } ```"
1,tb-mobile-app,tb treatment support tools frontend,"# tuberculosis treatment support tools: development branch tests: [!circleci](https://circleci.com/gh/uwcirg/tb-mobile-app/tree/develop) <img alt=""screen shot at am"" ## mhealth intervention to support people with tb tuberculosis remains one of the top ten causes of death globally despite it being largely curable. patients face many challenges to adhere to treatment and mobile health (mhealth) interventions may address these challenges and support patients to complete their treatment. we aim to develop an application that has implications not only for tb adherence but disease management more generally and to improve our understanding of how to support patients throughout challenging treatment regimens. ## branches used in deployments pilot study - code available on the branch. clinical trial - current). code available on the branch. indonesian pilot study - current). code available on the branch. ## system components **main frontend:** react application code: tb-mobile-app (this repo) **back end api:** ruby on rails app + docker-compose deployment configuration code: tb-foundation ## tests there are very minimal tests, but this could be an area to improve in the future. current tests use react-testing-library and there are important configuration files in `jest.config.js`,`src/testsetup.js `, and `package.json` to run the test suite run: ``` yarn test ``` to check coverage run: ``` yarn test:coverage ``` ## getting started with development more details are available in the wiki page: deployment and build processes running the full application requires docker. you will need to spin up the services outlined in the docker-compose.yml file from this repo tb-foundation. once that process has completed, its best to run the react development server outside of docker like this: ```bash yarn install yarn start ``` if you are having node version issues, you can use nevermind to install the correct version of node. we have set up a .nvmrc file to make this easier. ```bash nevermind use ``` ## production build process beacause this react app has been dockerized, the build process is a bit different from most react apps. some environment variables and configuration files are modified at container up time to allow for deployments with different settings. see deployment and build processes for more details. ## publications about this project ### academic journal articles patient-centered mobile tuberculosis treatment support tools (tb-tsts) to improve treatment adherence: a pilot randomized controlled trial exploring feasibility, acceptability and refinement needs ( lancet regional health americas, september mobile tuberculosis treatment support tools to increase treatment success in patients with tuberculosis in argentina: protocol for a randomized controlled trial (jmir research protocols, january insights from participant engagement with the tuberculosis treatment support tools intervention: thematic analysis of interactive messages to guide refinement to better meet end user needs (international journal of medical informatics, may, ### blogs initiative and comotion co-fund grant to better treat and prevent tuberculosis ## contact sarah iribarren is the primary investegator for this research project, please reach out with any inquirys about research or collaboration. kyle goodwin lead most of the technical development, reach out with any technical questions."
0,TrackCOVID,an open source project which provides privacy-preserving contact tracing for communities using qr codes,"# trackcovid an open source project which provides privacy-preserving contact tracing for communities using qr codes !logo this is an open source project which we provide freely to communities which are interested in setting up digital contact tracing to supplement manual contact tracing in a way that is both easy to use and private. we propose a concrete strategy for setting up qr code-based contact tracing in your community, and we provide all of the source code necessary for this to happen. we believe our approach can add an additional layer of protection as public places begin reopening. manual contact tracing in public places is very difficult, if not impossible in many cases. our approach can help to notify people of potential exposure at these public places in a way that does not invade their privacy. if you are interested, we are happy to collaborate as needed to make this a reality in your community. we do this as a public service without asking for anything in return. if you are interested in setting up this project in your community or jurisdiction, click here to learn more. - about the project: https://trackcovid.net - app demo: https://demo.trackcovid.net - read the peer-reviewed paper in jmir mhealth and uhealth: - instructions for setting up in your community or jurisdiction: https://github.com/tyleryasaka/trackcovid-community#trackcovid-community ## source code the app source code in this repository is stale. the up-to-date code is located at: https://github.com/tyleryasaka/trackcovid-community ## contributors - ben stedman: logo - tyler yasaka: development - translation (spanish) - @sawravchy: translation (bengali) - you? (check out our interest form)"
0,CerebralCortex-2.0-legacy,"cerebral cortex is the backend architecture, powered by apache spark, that is designed to analyze population-scale mhealth data","# cerebral cortex is the big data cloud companion of mcerebrum designed to support population-scale data analysis, visualization, model development, and intervention design for mobile sensor data. cerebral cortex is the backend architecture, powered by apache spark, that is designed to analyze population-scale mhealth data you can find more information about software on our software website or the organization on our website. ## examples #### intellij setup environment variables in run configuration * * * `pyspark_submit_args=--packages pyspark-she will` add `pyspark.zip` to your project libraries: * go to file -> project structure * now select modules and then ""dependencies"" tab * click the ""+"" icon and select ""library"" * click ""new library"" and select java (i know it is weird...) * now choose multiple modules / egg and ""ok"". * select ""classes"" from categories. * give your new library a name, ""my python not java library"" * and finally click ""add selected"" ## contributing please read our contributing guidelines for details on the process for submitting pull requests to us. we use the python pep style guide. our code of conduct is the contributor covenant. bug reports can be submitted through jira. our discussion forum can be found here. ## versioning we use semantic versioning for versioning the software which is based on the following guidelines. major.minor.patch (example: major version when incompatible api changes are made, minor version when functionality is added in a backwards-compatible manner, and patch version when backwards-compatible bug fixes are introduced. for the versions available, see this repository's tags. ## contributors link to the list of contributors who participated in this project. ## license this project is licensed under the bsd - see the license file for details. ## acknowledgments * national institutes of health - big data to knowledge initiative * grants: * national science foundation * grants: * intelligence advanced research projects activity * contract:"
0,del-container,digital enhanced living container app,"# del-container digital enhanced living service container app _this container application is a research prototype and is currently under development. new features are constantly being added which may break existing functionality. please refer to the branch for the latest changes._ ## table of contents about architecture container apis currently available data examples ## about the digital enhanced living (del) container (del-container) is the container application and one of the user modules for the del platform which handles micro health services. the service manages several micro applications and allows a user to use several health services from one single app. the container exposes several apis that can be used to develop mini health applications for the container. other services contributing to the platform include __del-auth__, __del-web__ and __del-api__. once developed, registration of apps is much like other commercial app stores - mini health applications for the platform can be registered with the del-api service which then becomes available to users on the platform. more details can be found on the service page. _please note that the repositories may be private at the moment and will be made public as they are developed._ _the __del-api__ service is required for the app to function. once launched, the appropriate ip address/hostname and port have to be configured in the constants class (com.del.delcontainer.utils.constants) in the container._ ## architecture the container is based on the following architecture - <p align=""center""><img src=""./assets/del-container-arch.png"" the figure shows four main components - the application manager, data manager, conversation manager and the device manager. these components are responsible for managing active mini-apps, handling the conversations with the bot, managing connected devices and user data. health data can be fetched from several sources including manual entry, from connected devices and even from other services. these can be divided into personal and environmental factors and are highlighted in the following figure - <p align=""center""><img src=""./assets/datapoints.png"" the following sequence diagram outlines a high level control and data flow within the container - <p align=""center""><img src=""./assets/mini-app-data-flow.png"" _please note that the current prototype implementation does not support all these metrics. they will be added as the container is developed further._ ## container apis as of now, the container exposes one interface for registering application details, data requests and callbacks. all mini applications must contain the function **setappid** that accepts a string id passed by the container when the mini app is launched. this id must then be used for registering requests or calling any other functions offered by the container. ``` // sample - setappid accepts the id injected by the container // which is then used later function setappid(appid) { this.appid = appid; initapp(); } ``` the mini apps can request available data from the container (see currently available data) and these requests can be registered with the container with a call to the `setcallbackrequest` function in delutils that accepts a json string with the app id injected by the container on app launch along with an array (**requests**) of json objects specifying the **resource** and the **callback** function the container should call once the data is available. the following example shows a request object - ``` { ""resource"" : ""access_pedometer"", ""callback"" : ""processstepcount"" } ``` in the above example, once the step count is available, the container will attempt to call the _processstepcount_ function in the mini app and pass it two parameters - the **data type** and the **data**, which can then be used as required. the following example shows a simplified flow of the above steps performed in a mini app - ``` // expose function to accept app id from the container function setappid(appid) { this.appid = appid; initapp(); } // initialize app and register requests for location and step count function initapp() { let apprequest = { ""appid"" : this.appid, ""requests"" : [ { ""resource"" : ""access_pedometer"", ""callback"" : ""processstepcount"" }, { ""resource"" : ""access_location"", ""callback"" : ""processlocation"" } ] }; delutils.setcallbackrequest(json.stringify(apprequest)); } // use step count data function processstepcount(datatype, steps) { if (""step_count"" == datatype) { // do something } } // use the location data function processlocation(datatype, location) { if (""location"" == datatype) { // do something } } ``` data specific to a mini app can be managed in separate files on the container through the following functions - |function | description | |-------------|-----------------| | setappdata(appid, content) | _store app-specific data in a separate file_ | | getappdata(appid) | _get previously stored app-specific data_ | the following example shows their implementation - ``` // storing app specific data in file function storeworkoutdata() { let appdata = { // application specific data stored in a separate file }; delutils.setappdata(appid, appdata); } // getting app-specific data from file function fetchworkoutdata() { let workoutdata = delutils.getappdata(appid); // parse workout data and use as required } ``` smartphone sensors are often used in the micro-mhealth apps with the initialization process setting up the data provider tasks on the container. however, this does not implicitly enable sensor logs (i.e., storing data in the database). if needed, sensor data can be stored in the app database and later fetched using the following functions - |function | description | |-------------|-----------------| | setsensorloggerrequest(requestdefinition) | _request the container to set logging requests_ | | getsensordata(appid, type) | _get sensor data stored previously_ | | getsensordata(appid, type, start-date, end-date) | _get sensor data stored previously filtered by date_ | setting the sensor logger request notifies the container data provider to log the requested sensor data in the database. the following figure shows an overview of the events starting/stopping this activity. <p align=""center""><img src=""./assets/del-sensor-log-flow.png"" like the initial resource requests, sensor logs also require an object with two properties **resource** (see currently available data) and **toggle** (true or false to enable or disable log requests) - ``` { ""resource"": <requested resource>, ""toggle"" : <true / false> } ``` the following snippet shows how sensor logs are enabled for two sensors - ``` function startworkout() { // log requests - set toggle to true to enable let loggerrequests = { ""appid"": this.appid, ""requests"": [{ ""resource"": ""access_pedometer"", ""toggle"": true }, { ""resource"": ""access_location"", ""toggle"": true }] }; // start recording data delutils.setsensorloggerrequest(json.stringify(loggerrequests)); } ``` stored data can then be fetched using the overloaded `getsensordata` functions. the following example shows the use of the function to fetch stored location details - ``` function getworkoutdata() { var appdata = delutils.getsensordata(appid, ""access_location"", starttime, endtime); // use appdata as required } ``` similarly, a mini app can also push a notification to the user through the `createnotification` function - |function | description | |------------------|------------------| |createnotification(appid, notificationmessage) | _push a notification through the container_ | the following example shows the use of the notification function - ``` function pushappnotification() { // app logic let notificationmessage = ""some notification...""; delutils.createnotification(this.appid, notificationmessage); } ``` _more details to come soon!_ ## currently available data the project is currently a research prototype and offers limited functionality for testing and usability evaluations. more features would be added as the platform is developed further. currently, the container provides access to the following data - |data type | resource key | update interval | |--------------------|------------------|------------------| | location | `access_location` | | | step count | `access_pedometer` | | | heart rate | `access_heart_rate` | | | accelerometer (raw data) | `access_accelerometer` | | | gyroscope (raw data) | `access_gyroscope` | | the step count and heart rate are currently provided as numbers while the location and raw accelerometer data are injected as a json string with the relevant details. the location object provides the _latitude_, _longitude_ and _accuracy_, and the accelerometer data comprises the raw acceleration in the _x_, _y_ and _z_ planes. the following example demonstrates how this data can be extracted and used - ``` // handle accelerometer data function accelerometerdatacallback(datatype, accelerometerdata) { var accdata = json.parse(accelerometerdata); if (""accelerometer"" == datatype && object.keys(accdata).length > { var x = accdata.x; var y = accdata.y; var z = accdata.z; // do something } } // handle location data function locationcallback(datatype, locationdata) { var coordinates = json.parse(location); if (datatype == ""location"" && object.keys(coordinates).length > { var lat = coordinates.latitude; var long = coordinates.longitude; var accuracy = coordinates.accuracy; // do something } } ``` _please note that platform only supports a zephyr hxm heart rate monitor. more devices will be added shortly_ _more details to come soon!_ ## examples the following gifs show a sample mini-health-app on the container. _the design has been updated since the gifs were recorded. this will be updated soon!_ installation <p style=""align:left""><img src=""./assets/install.gif"" running <p style=""align:right""><img src=""./assets/run.gif"" sample app demo <video ### sample micro mhealth apps the following images show three single-feature micro-mhealth apps that were inspired by commercially available health and fitness apps. _please note that these apps need to be registered with __del-api__ to work_ exercise tracker <p style=""align: left""><img src=""./assets/micro_apps/mymaps.png"" food logger <p style=""align: left""> <img src=""./assets/micro_apps/foodlogger.png"" <img src=""./assets/micro_apps/foodlogger_breakfast.png"" </p> mood tracker <p style=""align: left""> <img src=""./assets/micro_apps/mymoods_stats.png"" <img src=""./assets/micro_apps/mymoods_daily_mood.png"" <img src=""./assets/micro_apps/mymoods_daily activities.png"" </p>"
1,ppg-vitals,vital signs monitor based on ppg signal captured by smartphone camera,"# ppg-vitals **vital signs monitor based on ppg signal captured by smartphone camera** this repository is for demonstration purpuses only, as a proof of concept, that we can capture good enough ppg signal from any modern smartphone and that the captured ppg signal is good enough to estimate different cardiovascular metrics (in particular the blood glucose level). to evaluate the estimated values, we compare them to the values we get from a certifed medical device (e.g. glucometer that you can buy in a pharmacy store). you can test the demo application by visiting the following website from your smartphone (for details see the instructions below): https://markolalovic.github.io/ppg-vitals/ ***update: example of captured dataset and trained model on this dataset will be added shortly*** ## description the application uses the smartphone flashlight and camera to capture the photoplethysmogram (ppg) signal from the color intensity changes in the fingertip as shown in **figure with improved lenses and ability to capture video at higher rates (approaching the clinical pulse-oximeter at hz), smartphones are getting more capable of capturing good quality ppg signal. although smartphones have been successfully used to determine heart rate, to estimate blood pressure or blood glucose level, the quality of captured ppg signal needs to be substantially better. this application is created to test some methodology of cleaning the captured noisy signals so we can also estimate the blood pressure or blood glucose level by using a smartphone. <img src=""figures/principle.png"" alt=""ppg principle by smartphone."" ## instructions to test the application: - visit: applications website from your smartphone. - place the smartphone in the palm of your hand and press the `measure` button; see **figure (a)**. - cover both the camera and the flashlight with your finger as shown in **figure - in case the signal does not look periodic as in **figure (b)** you can try: - applying less finger pressure on the lens of the camera; - be still without moving the finger; - be more calm without rapid breathing; - be patient and wait for the graph to shift to the new values. <img src=""figures/app.png"" alt=""ppg acquisition using smartphone app."" ## todo - fix the video resolution and frame rate. - determine the signal quality. - send, evaluate and show results for: - resting heart rate; - resting blood pressure; - blood glucose level; - add contribute button. ## references vandenberk t, stans j, mortelmans c, van haelst r, van schelvergem g, pelckmans c, smeets c, lanssens d, de cannire h, storms v, thijs i, vaes b, vandervoort p clinical validation of heart rate apps: mixed-methods evaluation study jmir mhealth uhealth"
0,amulet-project,the amulet project wearable platform,"the amulet project ===== <img align=""right"" src=""media/amulet_left_vertical.jpg"" alt=""amulet wearable""/> **the amulet project** envisions computational jewelry, in the form of a bracelet or pendant, that provide the properties essential for successful body-area mhealth networks. these devices coordinate the activity of the body-area network and provide a discreet means for communicating with their wearer. such devices complement the capabilities of a smartphone, bridging the gap between the type of pervasive computing possible with a mobile phone and that enabled by wearable computing. find more information on the amulet project website **the amulet platform** is a major step towards fulfilling this vision. the generalized platform is comprised of hardware and software for developing energy- and resource-efficient applications on multi-application wearable devices. this includes: - the amulet firmware toolchain - the amulet runtime - the arp-view energy prediction and insight graphical tool (check out a demo here) - open reference hardware. amulet allows developers to interactively explore how their implementation decisions impact battery life without the need for hardware modeling and additional software development. **amulet represents a new approach to developing long-lived wearable applications.** we envision the amulet platform enabling long-duration experiments on human subjects in a wide variety of studies. we also aim to equip the health-behavior science community with a wearable platform researchers can field for long-duration experiments on human subjects in a wide variety of studies, by providing the entire amulet platform as an open-source, open-hardware alternative to the available commercial platforms that have so far been used for wearables research. we envision the amulet platform as being broadly applicable to those in the sensing communities, as well as domain scientists and practitioners in human-centered fields like health and fitness. with the amulet platform, sensor researchers can prototype new wearable devices and test new sensing technology without building from scratch. --- ### getting started to learn how to obtain hardware, setup your dev environment, and program an amulet refer to this guide. --- ### contributors and acknowledgements amulet is an ongoing collaboration between dartmouth college and clemson university. **dartmouth college:** - ryan halter (engineering): co-pi; assistant professor of engineering. - david kotz (computer science): principal investigator; professor of computer science. - john batsis (geisel school of medicine) - taylor hardin (computer science): graduate student. - sarah lord (psychiatric research center) - jasmine mai (computer science): undergraduate student. - varun mishra (computer science): graduate student. - patrick proctor (computer science): programmer. - ron peterson (computer science): senior programmer. - gunnar pope (engineering): graduate student. **clemson university:** - kelly caine (human centered computing): co-pi; assistant professor of human-centered computing. - josiah hester (computer science): graduate student, now at northwestern. - vivian motti (human centered computing): now at george mason university. - ryan scott (computer science: graduate student. - jacob sorber (computer science): pi; assistant professor of computer science. - byron lowens (human centered computing): graduate student. **former members:** - george boateng (engineering): graduate student; now at eth zurich. - eric chen (computer science): undergraduate student. - kevin freeman (computer science): graduate student. - bhargav golla (computer science): graduate student. - emily greene (computer science): undergraduate student; now at amazon. - steven hearndon (computer science): graduate student. - hilary johnson (engineering): undergraduate student. - anna knowles (computer science): undergraduate student. - andrs molina-markham (computer science); now at rsa labs. - emma oberstein (computer science): undergraduate student. - travis peters (computer science): graduate student. - joseph skinner (engineering): technician. - tianlong yun (computer science): now at google. this research results from a research program at the institute for security, technology, and society, supported by the national science foundation under award numbers cns- and and by the department of health and human services (sharp program) under award number the views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the sponsors. --- ### license ``` copyright by the trustees of dartmouth college and clemson university, and distributed under the terms of the ""dartmouth college non-exclusive research use source code license agreement"" (for non-commercial research purposes only), as detailed in a file named license.pdf within this repository. ``` please find our full license here. --- ### attribution please find a list of software used in the development of amulet here. --- ### issues please use github's issue tracking software to submit any issues or concerns regarding amulet software or hardware."
0,deep-physical-activity-prediction,"""ubiwear: an end-to-end, data-driven framework for intelligent physical activity prediction to empower mhealth interventions"" @ ieee healthcom","# ubiwear: an end-to-end, data-driven framework for intelligent physical activity prediction to empower mhealth interventions this is the github repository for the paper entitled ""ubiwear: an end-to-end, data-driven framework for intelligent physical activity prediction to empower mhealth interventions"" published in ieee healthcom <p align=""center""> <img src=""ubiwear/assets/the-ubiwear-framework.png"" title=""the ubiwear framework""> </p> :rocket: **one of our major contributions is the ubiwear python library.** ## project setup create virtual environment ``` $ -m venv venv $ source venv/bin/activate ``` upgrade pip ``` $ python -m pip install --upgrade pip ``` install dependencies ``` $ pip install -r requirements.txt ``` ## setting up the mongodb for the sake of simplicity this repository contains a `docker-compose.yml` file that provides easy setup of a required mongodb database in order to download and store the data from the ""myheart counts"" study. it also builds and spins up a python container that can be used to run all the data processing and ml/dl modeling, assuring consistency in results. in case you want the data ready to be imported in a database and to be used for data pre-processing and model building, and skip the step of downloading, request them from contributors of this github repository. then follow the instructions of how to import the data. ### spin up the database the following command sets up a default database named `deep_physical_activity_prediction`. ``` $ docker-compose up -d mongodb ``` ### import data * make a directory `/dump/` inside with `docker exec -it --user root mongodb mkdir /dump/` * copy inside the container both dumped binary files (`bson.gz` and `metadata.json.gz`) which are stored in a directory for example: `deep_physical_activity_prediction_db/` with `docker cp deep_physical_activity_prediction_db/ mongodb:/dump/` * go inside container `docker exec -it --user root mongodb bash` * restore it with `$ mongorestore --gzip /dump/` ### export data * exec inside container as root `docker exec -it --user root mongodb bash` * create directory with `$ mkdir /dump/` * dump the desired collection (example: `healthkit_stepscount_singles`) with compressed mode to reduce the size `$ mongodump --gzip --db=deep_physical_activity_prediction_db --collection=healthkit_stepscount_singles` * exit container with `$ exit` * copy from inside the container the binary files to your computer's desired path. ``` $ cd desired/path/ $ docker cp mongodb:/dump/deep_physical_activity_prediction_db/ . ``` ### setup a backup mongodb spin up a **new** database with the following `docker-compose.yml` file. note that the exposed port is different to void conflicts in case a mongodb already runs in port ``` version: services: mongodb: image: bitnami/mongodb container_name: mongodb-backup environment: mongodb_database: deep_physical_activity_prediction_db allow_empty_password: ""yes"" volumes: - 'mongodb_data_backup:/bitnami/mongodb' ports: - volumes: mongodb_data_backup: ``` then you can import the data in the same way as described above. rememeber to use the new name of container which is `mongodb-backup`. # reproducibility ## download the data from synapse and import files to the database setup your synapse credentials in the `.env` file: `synapse_user, synapse_password`. setup the mongo db connection in the `.env` file: `mongodb_host, mongodb_port`. setup pythonpath to include `src/`: ``` $ export pythonpath=$pythonpath:$(pwd) ``` then download the healthkit data table ``` $ cd src/data/ $ python download.py ``` this downloads and stores in database in two different collections: the original table from the healthkit data table. the embedded files associated with each record of the above table. however, in order to use these data easily they need to be merged. to do this ``` $ python importer.py ``` this merges the embedded data for each user and stores them in a clean `healthkit_stepscount_singles` collection. this is the main collection and source of data of the project, that all data pre-processing and ml/dl model building is based upon. ## create the datasets to create the datasets for both daily and hourly granularity and from to days before as lags: ``` $ cd src/experiments/ $ python create_datasets.py ``` or request from the contributors of this project to provide you the final and pre-processed dataset in a dataframe pickle format and place it under: ## run the machine learning models ### run the pre-trained models in `src/model/ml/models/` there are the pre-trained and hyperparam-tuned models: - ridge - decision tree - histogram-based gradient boosting ``` $ cd src/model/ml/ $ python evaluate.py --pretrained-model models/[ridge.pkl | tree.pkl | gb.pkl] ``` ### from scratch training and tuning ``` $ cd src/experiments/ $ python ml_modeling.py ``` ## run the deep learning models ### run the pre-trained models in `src/model/dl/models/` there are the pre-trained models: - multi-layer perceptron - convolutional neural network - recurrent neural network (lstm) ``` $ cd src/model/dl/ $ python evaluate.py --model [mlp | cnn | rnn] --cpkt_path models/{path_to_pretrained_model} ``` ### from scratch training `$ cd src/model/dl/` - train the mlp architecture: `$ python mlp.py` - train the cnn architecture: `$ python cnn.py` - train the rnn (lstm) architecture: `$ python lstm.py`"
0,iosSDK,software development kit for apple ios,"## fhirblocks sdk fhirblocks is a sovereign trust framework for healthcare applications. fhirblocks enables qualified parties to establish trust across different actors, apps, and devices so that they may access broadly distributed ""pools"" of healthcare data, all while preserving data access permissions and chain of custody audit mechanisms. fhirblocks is sovereign in the sense that no single commercial party controls the framework. sovereignty is achieved with the fhirblocks protocol design itself, the open-source approach to managing the technical development project, and the governance structure of the fhirblocks foundation. #### fblockscsa app to interact with this ecosystem system a user is required to register the respective device with the ecosystem using fblockscsa app. once registered using the healthwallet app, the user will be given a character string that uniquely identify the <app,device> pair. sample key which is used to identity in the further process. wallet app acts as authorizing and monitoring authority for shared access of users health data. its a single point repository that shows all data sharing done by the user to various health care applications (registered with fhirblocks ) referred to as mheath apps and these are developed using the fhirblocks sdk or fhirblocks enabled using the sdk. #### mhealth app mhealth apps are mobile applications that are developed using fhirblocks sdk. this document will help you understand how to interact with fhirblocks using smoac api and wallet app. a sample mhealth app (namely mhealthdapp ) implementation can be downloaded from here. mhealthdapp is a mock-up of an mhealth app featuring the protocols smoac, and the fhir server inter-working. it is an ios app that demonstrates the overall flow of registering an mhealth app with fhirblocks (fhirblocks), authenticating with the fhirblocks ""vaca"" function, and then making a request for patient information against a fhirblocks protected fhir resource server. ## app configuration #### download fhirblocks healthwallet (fblockscsa) all mhealth apps work in conjunction with fblockscsa app (fblocks client system app). fblockscsa with its multifaceted trust model let us you maintain all your permissioned mhealth apps and their corresponding required resources in one place securely and access them with ease for your review. it let us you check various mhealth apps permissioned by you, it stores the user identity upon registration at server end, the mhealth apps can access various resources shared by the fblockscsa for the duration specified by the user. therefore the mhealth apps can only work in conjunction with the fblockscsa as it grants the permission to mhealth apps to be fhirblocks enabled. you can download the fblockscsa app for free from the apple appstore. #### encryption the fhirblocks sdk implements secure communication system with the help of private & public key encryption(asymmetric encryption).you should be aware of the ios apis for implementing the same. you can generate private & public key (key pair) via the following code ```obj-c // private key attributes dictionary nsmutabledictionary *privatekeyattr = [[nsmutabledictionary alloc] init]; // public key attributes dictionary nsmutabledictionary *publickeyattr = [[nsmutabledictionary alloc] init]; // key pair attributes dictionary nsmutabledictionary *keypairattr = [[nsmutabledictionary alloc] init]; // application tags for public & private nsdata *publictag = [@""ec"" nsdata *privatetag = [@""ec"" seckeyref publickey = null; privatekey = null; // type of algorithm for key generation [keypairattr setobject:(__bridge id)ksecattrkeytypeec forkey:(__bridge id)ksecattrkeytype]; [keypairattr setobject:[nsnumber forkey:(__bridge id)ksecattrkeysizeinbits]; [privatekeyattr setobject:[nsnumber numberwithbool:yes] forkey:(__bridge id)ksecattrispermanent]; [privatekeyattr setobject:privatetag forkey:(__bridge id)ksecattrapplicationtag]; [publickeyattr setobject:[nsnumber numberwithbool:yes] forkey:(__bridge id)ksecattrispermanent]; [publickeyattr setobject:publictag forkey:(__bridge id)ksecattrapplicationtag]; [keypairattr setobject:privatekeyattr forkey:(__bridge id)ksecprivatekeyattrs]; [keypairattr setobject:publickeyattr forkey:(__bridge id)ksecpublickeyattrs]; // keys generation osstatus err = seckeygeneratepair((__bridge cfdictionaryref)keypairattr, &publickey, &privatekey); ``` for the signature generation the algorithm used is as following ```obj-c algorithm = ``` use the following code for creating signature ```obj-c withkey:(seckeyref)privatekey { bool cansign = seckeyisalgorithmsupported(privatekey, kseckeyoperationtypesign, algorithm); nslog(@""can you sign: %@"",cansign ? @""yes"" : @""no""); nsdata* signature = nil; if (cansign) { cferrorref error = null; signature = (nsdata*)cfbridgingrelease( // arc takes ownership seckeycreatesignature(privatekey, algorithm, (__bridge &error)); if (!signature) { nserror *err = cfbridgingrelease(error); // arc takes ownership nslog(@""%@"", err); // handle the error. . . } } return signature; } ``` #### url schemes a complete understanding of the implementation of inter app communication using the url scheme is a prerequisite to for the successful development of a fhirblocks enabled mhealth app. url scheme is utilized to pass data between the mhealth app and the fblockscsa app. ```xml <?xml <!doctype plist public ""-//apple//dtd plist <plist <array> <dict> <key>cfbundleurlname</key> <string>com.example.com</string> <key>cfbundleurlschemes</key> <array> <string>mhealthdapp</string> </array> </dict> </array> </plist> ``` you to need save the scheme of your app in info.plist in url types attribute in the info.plist & add both your & csa apps schemes in lsapplicationqueriesschemes as follows ```xml <?xml <!doctype plist public ""-//apple//dtd plist <plist <array> <string>mhealthdapp</string> <string>fblockscsa</string> </array> </plist> ``` check out the <link> of example dapp with systematic steps for setup as follows. #### initial configuration dapp,first of all will check whether csa(wallet) is installed on the device for checking the same for your app, you need to use following code ```obj-c nsstring *fblockscsa=@""fblockscsa://?scheme=mhealthdapp""; bool canopenurl=[[uiapplication sharedapplication]canopenurl:[nsurl urlwithstring:fblockscsa]]; ``` the csa app will have the above mentioned url scheme i.e fblockscsa the scheme of your app will be shared by you to csa if csa is installed your app will check whether the uniqueidentifier & csi of (got after registration with wallet) is shared with your app or not, you can store them both in user defaults & check as follows, if there are available proceed with the server calls for dapp ```obj-c if([[nsuserdefaults standarduserdefaults]valueforkey:@""uniqueidentifier""] == nil || [[nsuserdefaults standarduserdefaults]valueforkey:@""wcsi""] == nil) { // prompt for registration for csa } else { // start the respective calls for dapp } ``` ## authentication workflow > note: you can access the fhirblocks api swagger definitions at the following site. > `get http://smoac.fhirblocks.io/` #### step ping the server ```sh get ``` the following will provide the version of fhirblocks server. #### step check the system time ``` get ``` if the system is off by more than minutes, consider error workflow. #### step obtain a globally unique identifier (guid) ``` get ``` the guid will be needed for identifying the app instance later in the workflow. #### step register the csiguid for the distributed app (dapp) ``` get ``` check swagger implementation for the request parameters. make the payload as follows ```obj-c payload=[nsstring stringwithformat:@""%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@"",@""|"",@""ecdsa"",@""|"",derkeystring,@""|"",deviceid,@""|"",currentdate,@""|"",nonce,@""|"",@""[{"",@""\""key\"": \""dateofbirth\"", \""value\"": \"""",@"""",@""\""},"",@""{\""key\"": \""firstname\"", \""value\"": \"""",@"""",@""\""},""@""{\""key\"": \""middlename\"", \""value\"": \"""",@"""",@""\""},""@""{\""key\"": \""lastname\"", \""value\"": \"""",@"""",@""\""},""@""{\""key\"": \""gender\"", \""value\"": \"""",@"""",@""\""}"",@""]"",@""|""]; ``` > _derkeystring_ - public key > _device id_ - unique identifier of device received from fblockscsa > _current date_ - current server time > _nonce_ - random digit string #### step proceed with fetchpublicclaims of corresponding fblockscsa instance ``` get ``` check swagger implementation for the request parameters. construct the the payload as follows: ```obj-c payload=[nsstring stringwithformat:@""%@%@%@%@%@%@%@"",@""|"",desiredguid,@""|"",currentdate,@""|"",nonce,@""|""]; ``` > _desiredguid_ - csiguid of corresponding csa instance > _current date_ - current server time > _nonce_ - random digit string #### step authorisation/permission by corresponding fblockscsa instance share the csiguid of dapp to the corresponding fblockscsa(wallet) instance via url scheme` ```obj-c nsstring *fblockscsa=[nsstring stringwithformat:@""fblockscsa://?dcsi=%@"",[[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""]]; [[uiapplication sharedapplication]openurl:[nsurl urlwithstring:fblockscsa] options:@{} completionhandler:nil]; ``` wallet then grants the permission to the dapp instance #### step mhealthdapp grants the permission to providers & caregivers ``` get ``` mhealthdapp is only allowed to grant permissions to providers & caregivers only when it is authorised or has received permissions from the corresponding dapp check swagger implementation for the request parameters. construct the payload as follows ```obj-c nsstring *payload=[nsstring stringwithformat:@""%@%@%@%@%@"" ,@""|"",enddateinrequiredformat,@""|"",startdateinrequiredformat,@""|""]; nsmutablestring * payloadmutablestring = [nsmutablestring stringwithformat:@""%@"", payload]; for (nsstring * string in permissioncsiguids) { [payloadmutablestring appendstring:[nsstring stringwithformat:@""%@|"",string]]; } [payloadmutablestring appendstring:[nsstring stringwithformat:@""%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@"",@""patient"",@""|"",@""v"",@""|"",[array ``` > _enddateinrequiredformat_ - endtime for permission duration > _startdateinrequiredformat_ - starttime for permission duration > _permissioncsiguids_ - guid to be given the permission > _patient_ - permission type > _v_ - confidentiality scope > - sensitivity scope > - sensitivity scope > _patient_ - resource scope > _guid_ - csiguid of mhealth instance > _currentdate_ - current server time > _nonce_ - random digit string #### step auth call implementation ```sh # auth_base_url ``` creation of jwt: ```obj-c // header string [nsstring // body string(payload) double epochseconds = [[nsdate date] double expiretimeinsecondssinceepoch = epochseconds + authorization_token_lifespan_in_seconds; // authorization_token_lifespan_in_seconds = nsstring * bodystring = [nsstring stringwithformat:@""%@%@%@%@%@%@%@%@%@%@%@%@%@%@%d%@%@%@%d%@%@%@%@%@%@%@%@%@%@%@%@%@"",@""{\""iss\"""",@"":\"""", [[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""],@""\"","",@""\""sub\"""",@"":\"""", [[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""],@""\"","",@""\""aud\"""",@"":\"""",auth_base_url,@""\"","",@""\""iat\"""",@"":\"""",(int)epochseconds,@""\"","",@""\""exp\"""",@"":\"""",(int)expiretimeinsecondssinceepoch,@""\"","",@""\""jti\"""",@"":\"""",[[nsuserdefaults standarduserdefaults]valueforkey:@""uniqueidentifier""],@""\"","",@""\""scope\"""",@"":\"""",@""patient/patient.read sens/eth sens/soc conf/v"",@""\"","",@""\""sta\"""",@"":\"""",[[nsuserdefaults standarduserdefaults]valueforkey:@""uniqueidentifier""],@""\""}""]; [[nsuserdefaults standarduserdefaults]valueforkey:@""uniqueidentifier""] // unique identifier of device received from csa [[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""] // csiguid of mhealth instance ``` signature > _bodystring_ - payload for the signature > body encoded string > base encoded string for body string jwt ```obj-c nsstring * finalassembly = [nsstring stringwithformat:@""%@.%@.%@"",headerencodedstring,bodyencodedstring,signaturestring]; ``` jwt is formed by appending header encoded string,body encoded string & signature string with . between them url encoded string ```obj-c urlencodedstring = [nsstring stringwithformat:@""%@%@"",@""grant_type=authorization_code&assertion_type=urn:ietf:params:oauth:client-assertion-type:jwt-bearer&assertion="",finalassembly]; ``` url encoded string is posted to the server with @""application/x-www-form-urlencoded"" for @""content-type"" header field in the post request #### step access call implementation ```sh // access_base_url get ``` create the json web token (jwt) as follows: ```obj-c // header string nsstring * headerstring = [nsstring stringwithformat:@""%@%@%@%@%@%@%@%@"",@""{\""kid\"""",@"":\"""",[[nsuserdefaults [[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""] - csiguid of mhealth instance // body string(payload) nsstring * bodystring = [nsstring stringwithformat:@""%@%@%@%@%@%@%@%@"",@""{\""code\"""",@"":\"""",[authcodedictionary objectforkey:@""code""],@""\"","",@""\""iss\"""",@"":\"""",[[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""],@""\""}""]; [authcodedictionary objectforkey:@""code""] // received in auth call response [[nsuserdefaults standarduserdefaults]valueforkey:@""dcsi""] // csiguid of mhealth instance // jwt nsstring * finalassembly = [nsstring stringwithformat:@""%@.%@ %@, headerencodedstring, bodyencodedstring,signaturestring]; ``` > bodystring - payload for the signature jwt is formed by appending header encoded string,body encoded string & signature string with . between them ```obj-c // url encoded string urlencodedstring = [nsstring stringwithformat:@""%@%@%@%@"",@""grant_type=authorization_code&code="",[authcodedictionary ``` url encoded string is posted to the server with @""application/x-www-form-urlencoded"" for @""content-type"" header field in the post request #### step fetchpermissionsgivenbyme implementation ```sh get ``` check swagger implementation for the request parameters. make the payload as follows ```obj-c nsstring *payload=[nsstring stringwithformat:@%@%@%@%@%@%@%@"",@""|"",guid,@""|"",currentdate,@""|"",nonce,@""|""]; ``` > _guid_ - csiguid of mhealth instance > _current date_ - current server time > _nonce_ - random digit string #### step fetchpermissionsgiventome implementation ```sh get ``` check swagger implementation for the request parameters. make the payload as follows: ```obj-c nsstring *payload=[nsstring stringwithformat:@%@%@%@%@%@"" ,@""|"",currentdate,@""|"",nonce,@""|""]; ``` > _current date_ - current server time > _nonce_ - random digit string ## references & links https://fhirblocks.github.io/fhirblocks.org/ - fhirblocks homepage https://github.com/fhirblocks - fhirblocks github account http://smoac.fhirblocks.io/ - smoac swagger api reference ## copyright copyright the fhirblocks project information contained herein is provided under the apache license fhir is a trademark owned by health level seven international and registered with the us patent & trademark office; and, the fhirblocks project title is being used under intl permission and, therefore, it is not to be extended to other uses without express written permission."
0,StressDetectionKit,stress monitoring app for android and ios.,"# stress detection kit stress monitoring app for android and ios. this is an experiment in blending together react native, medm devicekit sdk and some machine learning. in a nutshell it collects data from heart rate monitors and accelerometer, derive useful features (e.g. heart rate variability and activity index) and pass them to a scikit-learn trained and typescript ported svm model every seconds. it also shows charts in real-time. it has some limitations, but it is just an experiment after all. the main takeaway is creating a cross-platform app that supports many medical devices with a pinch of machine learning is not that painful. tools used: react native, mobx, typescript, scikit-learn, medm devicekit sdk. ## screenshots | !android stats | !android sensors | !android dev mode | |---|---|---| | !ios home | !ios settings | !ios calibration | ## science as hans selye defined it, stress is ""the non-specific response of the body to any demand placed upon it"". so, stress is not just an abstract term used to describe bad things happening in our lives, but a very real physiological response to literally anything that pulls us away from homeostasis, be it losing your job or winning the lottery. and, of course, stress is not always that bad (in fact it is necessary!), but when it happens too often or if it is too intense, body reserves deplete and it may because severe health problems in the long term (even cancer). the main idea of this app is to detect stress situations in real time based on data about the state of our autonomic nervous system (heart rate variability and index of physical activity) and let users decide which stressors should be eliminated. for example, the current model detects social interaction as stress for me, but i decided to spare this one (otherwise i would live in the forest by now). anyway, if you are interested in the medical part of it and understand russian, you can check out my graduation thesis. now let us move on to technical details. ## interaction with medical sensors interaction with medical sensors is done through medm devicekit sdk. then in order to make it work with react native react-native-device-kit is used (it was extracted from this project). medm devicekit sdk itself is a proprietary library, so i cannot include it in the repository and distribute the app bundle with it, but it is required for building the app. however, if you decide to take a similar approach (i.e. react native and medm devicekit sdk) for creating cross-platform mobile health app, you can make use of this repository to boost up your performance since it contains solutions to any possible pitfalls you might experience. check out this article for more details. ## interaction with machine learning the model is actually trained using python and scikit-learn library, but it is then serialized to json in order to use at run-time in javascript environment. the algorithm itself is an svm with a linear kernel (polynomial kernels are prone to overfitting, especially when there is not enough training data which is exactly the case here) and it was ported to typescript for the same reason of bridging the gap between python and javascript. overall the scheme looks like this: !ml interaction dfd there are several npm scripts that neatly embed in this process: * `pull-samples` pulls labeled samples from android device to pc (each samples collection has its own unique identifier). there are no samples in this repository (it is a private medical data), but the model itself is there and you could as well collect data and train the model yourself. * `calc-features-meta` calculates metainformation for features in the feature vector (such as `std` and `mean` in order to use them for feature standardization via z-score). * `regenerate-samples` regenerated samples from raw data post factum when something changes, be it metainformation, baseline values collected during calibration or the feature vector itself. * `train-model` trains the model and shows a plot. * `serialize-model` serializes the model to json. * `train-shortcut` `calc-features-meta`, `regenerate-samples` and `train-model` together. ## how to build put `medmdevicekit.aar` and `medmdevicekit.framework` to `medmdevicekit/` folder in the root of the project. `npm install` provide `medm_devicekit_license_key` environment variable with a licence key. ### android run `npm run android`. open the `android` folder in android studio and run the app on device as usual. open (optional). ### ios run `npm run ios`. open the `ios` folder in xcode and run the app on device as usual. open (optional). ### troubleshooting * if the android app cannot locate the dev server, try running `npm run reverse` first. * disable delta bundles in the react native dev settings if they are enabled. ### tips * it is a good idea to keep `configure.sh` script around with `medm_devicekit_license_key` env variable and `source configure.sh` when appropriate. just do not commit it accidentally! * in order to build a version with a developer screen set `node_env` env variable to `development`. * in order to build a production version set `node_env` env variable to `production` and change build configuration for android and build scheme for ios to `release`. also, for android you should execute `release-workaround` npm script. * there is also an accelerated mode for a faster development in which sensors interaction is mocked. set `accelerated` env variable to `true` in order to enable it."
1,Sendit,a mobile health monitoring application,"# sendit fitness!!! purpose: app that allows users to track calories, steps, and weight. user can also set goals in regards to these biometrics. wireframe: !image of registration page !image of page modules"
0,DiabetesWellness,"ios app that shows type ii diabetics their health data/trends (from mobile health devices), allows for further health information (i.e. activity, medication adherence, food), & offers features to encourage mindful eating. created with eleanor wood and daniel bass-blue as part of nih-funded mobile health tech research at the duke nursing school.","# diabeteswellness created with eleanor wood and daniel bass-blue as part of nih-funded mobile health tech research at the duke nursing school. an ios app that shows type ii diabetics their health data/trends (from mobile health devices), allows for further health information (i.e. activity, medication adherence, food), & offers features to encourage mindful eating. developed with the intention of offering accessible guidance for type ii diabetics to better self-manage their health, as well as to collect information (not captured by the patients' mobile health devices) to give clinicians holistic insight into their patients' health behaviors."
0,MS101---Bamboo-Mobile-Health,"mobile application for multiple sclerosis patients tracking, technologies : swift, nodejs, google cloud engine, firebase",# visual interfaces for mobile devices project for spring team : bamboo mobile health this is the repository for web app and mobile app that was developed for 'bamboo mobile health' as pilot app. mobile app for ios devices was developed with swift and database was backed up with google firebase. the app was deployed with the help of google cloud engine. we used triggers and notifications with help of cloud functions coded in nodejs and they we backed by google cloud engine. for admin lookout we developed sample admin screen with the help of nodejs where an admin could monitor mobile app activity adn could see pictorial representation
1,MHCHealthAppliction,"this is a mobile health application with features that can aid in recording health details of one's experience: a health checklist (what aspects of your health did you focus on today), a journaling entry section (utilizes sqlite database to keep a record), a gratitude entry and affirmations section, and a resources list for more health information.","# mhchealthappliction this is a mobile health application with features that can aid in recording health details of one's experience: a health checklist (what aspects of your health did you focus on today), a journaling entry section (utilizes sqlite database to keep a record), a gratitude entry and affirmations section, and a resources list for more health information. !home !info !resources !checklist !journal !gratitude and affirmations"
1,ART,art augmented reality above the tabletop,"# art - augmented reality above the tabletop !augmented reality above the tabletop ## intro art is an immersive analysis tool for the visual analysis of mobile health data. it visualises multidimensional data in augmented reality using an interactive visualisation. the visualisation links related data points between several scatter plots to create a parallel coordinates visualisation. to benefit from well-established interaction techniques, the visualisation is anchored to a touch-sensitive tabletop. this system is part of my bachelor thesis in computer science (b.sc.) at the university of konstanz, germany. the system is split into four separate applications: * a **web application** (typescript + angular) for controlling the visualisation * a (c#) application for creating a visualisation in augmented reality * a **web server** (typescript + node.js) for communication between the web application and * a **library** for handling and processing camera images in addition, there are several helper tools, e.g. for calibrating cameras, debugging, and optitrack tracking. ## layout art_code/ data/ camera calibration data (e.g. for artoolkit interactivedisplay/ client/ web application server/ web server tools/ custom c++ tools and libraries artoolkitcalibration/ modified artoolkit sample for calibrating ovrvision cameras gui/ graphical interface for quickly | | debugging the image processing library and calibrating cameras imageprocessing/ image processing library responsible for fetching images, artoolkit marker detection, and forwarding everything to optitrack/ server for parsing optitrack data and forwarding everything to scripts/ helper scripts for managing build files thirdparty/ third party header and library files unity/ project assets/ source files deprecated/ outdated code, no longer in use modules/ main unity code, organised in several submodules, each with their own code, shaders, textures, scenes, etc. plugins/ custom image processing library and dependencies are copied here after build scenes/ main scenes modules/ third party modules"
1,hitfit,an android app for an interactive and graphical ui based health monitoring.,"# hitfit an android app for an interactive and graphical ui based health monitoring. a mobile health application for a dietetic monitoring and assessment. it will help its users to effectively monitor their health on daily basis and create best daily fitness regime which will help users to stay fit in this rapid paced society. hitfit will let it users to keep a track on their targeted fitness goals. hitfit will motivate him/her for a healthier life style. snippets <br> <br> <b>splash screen</b><br> <br> <img src=""/snippets/splashscreen.png"" <b>login</b><br> <br> <img src=""/snippets/login.png"" <br> <br> <b>signup</b><br> <br> <img src=""/snippets/signup.png"" <img <br> <br> <b>register and adding user details</b><br> <br> <img src=""/snippets/register.png"" <img <img <br> <br> <b>bmi assesment</b><br> <br> <img src=""/snippets/bmi.png"" <br> <br> <b>profile</b><br> <br> <img src=""/snippets/profile.png"" <br> <br> <b>dashboard</b><br> <br> <img src=""/snippets/dash.png"" <br> <br> <b>water monitor and analysis</b><br> <br> <img src=""/snippets/watermonitor.png"" <img src=""/snippets/wateranalysis.png"" <br> <br> <b>walk monitor and analysis</b><br> <br> <img src=""/snippets/walkmonitor.png"" <img src=""/snippets/walkanalysis.png"" <br> <br> <b>food monitor and analysis</b><br> <br> <img src=""/snippets/foodmonitor.png"" <img src=""/snippets/foodanalysis.png"" <img src=""/snippets/fooditemsearch.png"" <img src=""/snippets/fooditem.png"" <br> <br> <b>exercise module</b><br> <br> <img src=""/snippets/exercise.png"" <img <img <img <br> <br> <b>reminders</b><br> <br> <img src=""/snippets/reminder.png"" <img <br>"
0,AnxietyApp,app to aid on anxiety management,"# anxiety management app # este projeto trata-se de um aplicativo mobile health gamificado para auxlio no controle da ansiedade de jovens do ensino-mdio. # objetivo do projeto auxiliar jovens no controle da ansiedade por meio de tecnicas distrativas. servindo como apaziguador dos sintomas e indentificador de causas que podem ajudar them um possivel diagnostico. # overview resumo das funcionalidades do aplicativo ## tela de login interativa tela de login interativa onde o mascote ir tampar o rosto para no ver a senha do usurio xd <img <img ## tela inicial interao do usurio com o aplicativo, caso ansioso iniciar o processo da intero com a ""barra de ansiedade"" que servir como tecnica de distrao <img <img ## gamificao a gamificao ser utilizada como metodo de engajamento, fazendo com que os jovens matenham-se focados them realizar ativades de cuidados a sade mental <img # pacotes usados flutterbloc e equatable pra gerencia de estado. firebaseauth para autenticao. graphql com hasura para banco de dados."
0,mHealth-Project,development of android app with garmin smartwatch that helps researchers track subject activity,"# mhealth #watchapp using the comm sample from the connect iq for now as a base. it has a companion app for android that let us it receive/send messages. this can be tested/ran using the garmin simulator on eclipse, so long as you have connected your android device through usb and have debugging set on(i do not know about emulators, though). first, import comm in watchapp to eclipse, and comm in mobileapp to android studio. running it: i used android studio(mobile app) and eclipse(watch simulator) to run it. go through the tutorial for setting up eclipse for connect iq at: https://developer.garmin.com/connect-iq/programmers-guide/getting-started/ conenct your mobile device through usb with android debugging enabled. run 'adb forward on command prompt(or whatever equivalent). run the app on the device. run the wearable app on the simulator in eclipse. click connection->start click on simulator on the mobile device to connect. currently, the send feature is pretty limited, still messing around with it, trying to figure out how to send a whole file(or a way to send many things without overfilling the queue). at the moment, it is sending step data, intensity minutes, and timestamps for both, which has to be set up first in the simulator by going to simulation->activity monitoring->set activity monitor info->throw in some random data for steps and intensity minutes. then to send it to the phone(the method to do this is from the base app, will obviously need to change it to make it less tedious later), you need to hold down the menu button(the right button on the bottom)->send data->hello world. this will make the app on the phone print out a pop out window with a array with the format: [[step data], [intensity minutes], [timestamps for corresponding index for step and intensity minutes], nulls for any other data wanted] notes: when charging the vivoactive hr, preferrably use an outlet charger rather than charging from a usb connection to a computer. if you do use a usb connection to a computer to charge, make sure to use the safely eject option whenever you are done charging, or else you risk losing data. *for the watch app, properties limit of //----additional readme from integrated gdrive app and comm update ------- this version is the integrated version of the gdrive app welcome screen with the comm sample app from garmin. basically, the garmin comm app will be launched when the sync button is pressed. the only thing that we need to do until tuesday is to receive the hr data and parse it into csv the hr data is of type list<list<number>> and it can be found in deviceactivity.java right now the mobile app will just receive the messages everytime it is send in a for loop, you can maybe change this to an if statement to ensure that the watch only sends it once. for now, because we still use the watch simulator, the array would still consists of zeroes and nulls, but on raphael's side with the watch, it will actually work properly"
1,JTrack-Android,jtrack's android application,"# welcome to jtrack platform! hi! this is the repository for the jtrack smartphone application. jtrack is an open-source platform for remote assessment of digital biomarkers (db) in neurological, psychiatric, and other indications. jtrack platform consists of an **android application** and an online **dashboard** for managing research studies. jtrack application comprises the following main categories of components: - phone and application usage data - (relative) location data - human activity recognition (har) data - accelerometer sensor data - gyroscope sensor data - voice data * (only in active assessment) jtrack can collect the aforementioned data type in passive (without user interaction) mode and label the collected data in active (by user interaction) mode. all components are designed in a modular architecture which can be easily added or excluded. *release in preparation ## documents for installation instructions and details please visit https://jtrack-docs.readthedocs.io/en/latest/ ## contributing jtrack is developed as an open-source solution (release in preparation, sahandi-far et al.). it is currently deployed in several clinical and mobile health studies. if you are interested in collaborating with us or would like to learn more about jtrack or our studies please reach out to dr. juergen dukart (j.dukart@fz-juelich.de). you can find more information about our group on: ## licence: ### open-source (apache copyright (c) jtrack mobile framework licensed under the apache license, version (the ""license""); you may not use this file except in compliance with the license. you may obtain a copy of the license at unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an ""as is"" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license."
0,laravel-cvd,cvd care app that is built using laravel framework.,"## about cvd care it is a known fact that women provide excellent care to all members of their family but they often fail to take care of themselves. women should feel that their health is important too and they need to be in good health while taking care of their families. cardio vascular diseases(cvds) can prove to be more than fatal to women. however, morbidity, as well as mortality due to the development of cvds, are easily preventable in pre and peri-menopausal women, especially when they are young, if they are diagnosed early and treated. there is also an essential need for increased awareness regarding the disease, so they can be effectively managed through proper self-care and compliance to the treatment regimen. sadly, information about disease prevention, self-care and disease management are not easily accessible. a team of academicians and students from manipal academy of higher education proposed a mobile technology-based intervention, a cardio-vascular diseases care program, for the management of cvds among pre-menopausal and peri-menopausal women. the study is funded by the public health foundation of india (pfhi), a statutory body under the department of science and technology. the project will explore the impact of the use of mobile phone-based app called suki hrudaya to track the frequency of monitoring and the treatment compliance of women with cvds. the mobile app is available in the local language kannada in addition to english. the app is simple, visual and interactive, and helps patients to self-monitor their symptoms, get periodic reminders for physician visits, follow treatment regimen prescribed by their physicians. caregivers will use a set of technology-enabled methods to help the patients in the process of self-monitoring, increase awareness about cvds, perform risk assessment, and provide information about self-care. though there are many existing health apps available in the market, this mobile health app is customized, with the overall goal to enrich awareness, networking among the pre and peri-menopausal women with cvds, living in the towns and villlages of udupi distict. in addition, it would empower the women for self-care and to a certain extent, may also contribute to the identification of family members prone to developing cvds."
1,OLAPI,open-locator application programming interface (olapi). initially designed to be integrated with mobile health data collection systems (mhdcs) i.e. android data capture app to capture location coordinates of the mobile users (data collectors) during authentication.,"# olapi [![](https://jitpack.io/v/aussekalega/olapi.svg)](https://jitpack.io/#aussekalega/olapi) ## getting started in your `build.gradle`: add the following maven{} line to your **project** build.gradle file ``` allprojects { repositories { ... maven { url ""https://jitpack.io"" } // add this line } } ``` **com.google.android.gms:play-services-location** dependency also needs to be added like this **x.x.x** can be replaced with google play service version your app is using versions information available here ```gradle dependencies { compile compile ""com.google.android.gms:play-services-location:x.x.x"" } ``` extend your `activity` from `openlocatorappcompatactivity` or `openlocatoractivity`: *create location request according to your needs* ```java locationrequest locationrequest = new locationrequest() .setpriority(locationrequest.priority_balanced_power_accuracy) ``` *create openlocator request, and set locationrequest created* ```java openlocatorrequest openlocatorrequest = new openlocatorrequestbuilder() .setlocationrequest(locationrequest) .build(); } ``` **request single location update like this** ```java requestsinglelocationfix(openlocatorrequest); ``` **or request multiple location updates like this** ```java requestlocationupdates(openlocatorrequest); ``` **you are good to go!**, you will get below callbacks now in your activity ```java @override public void onlocationpermissiongranted() { } @override public void onlocationpermissiondenied() { } @override public void onlocationreceived(location location) { } @override public void onlocationproviderenabled() { } @override public void onlocationproviderdisabled() { } ``` **additional options** specify what messages you want to show to user using *openlocatorrequestbuilder* ```java openlocatorrequest openlocatorrequest = new openlocatorrequestbuilder() .setlocationrequest(locationrequest) .setlocationpermissiondialogtitle(getstring(r.string.location_permission_dialog_title)) .setlocationpermissiondialogmessage(getstring(r.string.location_permission_dialog_message)) .setlocationpermissiondialognegativebuttontext(getstring(r.string.not_now)) .setlocationpermissiondialogpositivebuttontext(getstring(r.string.yes)) .setlocationsettingsdialogtitle(getstring(r.string.location_services_off)) .setlocationsettingsdialogmessage(getstring(r.string.open_location_settings)) .setlocationsettingsdialognegativebuttontext(getstring(r.string.not_now)) .setlocationsettingsdialogpositivebuttontext(getstring(r.string.yes)) .build(); ``` ## library license copyright ausse kalega licensed under the apache license, version (the ""license""); you may not use this file except in compliance with the license. you may obtain a copy of the license at unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an ""as is"" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license."
1,lforms-fhir-app,a smart on fhir app that uses lforms widget to handle questionnaire and questionnaireresponse,"# a smart app for fhir sdc questionnaire this is a smart app that can be used in ehr (electonic health record) systems supporting smart on fhir to display fhir sdc questionnaire forms and collect data as fhir questionnaireresponse resources. ## demo a demo of this app can be launched via smart on fhir from the lhc fhir tools website. it can also be used without smart, by going to it directly, in which can you can enter the base url of a fhir server to which you want the app to connect. the source files from which the demo is built are on the master branch. see ""customizing the app"" below if you wish customize or build your own copy. the app relies on the lhc-forms rendering widget for displaying forms. it has partial support for fhir questionnaires (versions and and the structured data capture implementation guide. for some sample forms to try, this repository comes with some forms under which are used by the test code to test the app. the fhir server connected to by the smart app gets reset weekly, but you can use the upload button to upload a new questionnaire resource. if downloading one of the forms from github, be sure click on the ""raw"" button, which will open a page which only has the questionnaire data. for example: will open a page for a vital signs questionnaire which you can save to a local file and then use ""upload"" to use it in the app. ## customizing the app if you wish to install and build the app locally so that you can customize it, see below. note that adding support for additional parts of the sdc specification will require edits to the lhc-forms widget. (pull requests are very welcome, but it might be better to open an issue first to see if we are already working on that feature.) ### add node.js and npm to your path the file bashrc.lforms-fhir-app specifies the version of node.js we are using for development. download that version of node.js, and add its bin directory to your path. ### install dependencies we have two kinds of dependencies in this project: tools and angular framework code. the tools help us manage and test the application. * we get the tools we depend upon via `npm`, the node package manager (npm). * we get the angular code via `bower`, a client-side code package manager (bower). * in order to run the end-to-end tests, you will also need to have the java development kit (jdk) installed on your machine. check out the section on end-to-end testing for more info. we have configured `npm` to automatically run `bower` so we can simply do: ``` npm ci ``` behind the scenes this will also call `bower install`. after that, you should find out that you have two new folders in your project. * `node_modules` - contains the npm packages for the tools we need * `app/bower_components` - contains the angular framework files add node_modules/.bin to your path. ### build the application ``` npm run build ``` this will create files for production in a ""dist"" directory, but will also copy some needed files into place from node_modules. ### run the application ``` npm run start ``` will start an http server running at port or, for testing the production build, ``` npm run start-dist ``` will start a server on port that serves the files in dist. now browse to the app at <a ### running tests (including end-to-end tests) ``` npm run test ``` will run the tests. for testing the production build in dist, run ``` npm run test-dist ```"
1,Swift-SMART,swift smart on fhir framework for ios and os x,"<p align=""center""><img src=""./assets/banner.png"" alt=""""></p> swift-smart is a full client implementation of the fhir specification for building apps that interact with healthcare data through [**smart on fhir**][smart]. written in _swift it is compatible with **ios and **macos and newer and requires xcode or newer. ### versioning due to the complications of combining two volatile technologies, here is an overview of which version numbers use which **swift** and **fhir versions**. - the `master` branch should always compile and is on (point releases of) these main versions. - the `develop` branch should be on versions corresponding to the latest freezes and may be updated from time to time with the latest and greatest ci build. see tags/releases. version | swift | fhir | &nbsp; ---------|-----------|---------------|----------------------------- | package | | | | | | | | | | | stu | | | stu | | | stu ballot, sep | | | dstu (_+ technical errata_) | | | stu ballot, sep | | | dstu (_+ technical errata_) | | dstu (_+ technical errata_) | | | dstu (_+ technical errata_) | | | dstu | | | dstu ballot, may | | | dstu ballot, may | | | dstu ballot, may | | | dstu resources --------- - [programming guide][wiki] with code examples - [technical documentation][docs] of classes, properties and methods - [medication list][sample] sample app - [smart on fhir][smart] api documentation [wiki]: https://github.com/smart-on-fhir/swift-smart/wiki [docs]: http://docs.smarthealthit.org/swift-smart/ [sample]: https://github.com/smart-on-fhir/sof-medlist [smart]: http://docs.smarthealthit.org quickstart ---------- see [the programming guide][wiki] for more code examples and details. the following is the minimal setup working against our reference implementation. it is assuming that you do not have a `client_id` and on first authentication will **register the client with our server**, then proceed to retrieve a token. if you know your client-id you can specify it in the settings dict. the app must also register the `redirect` url scheme so it can be notified when authentication completes. ```swift import smart // create the client let smart = client( baseurl: url(string: settings: [ //""client_id"": ""my_mobile_app"", // if you have one ""redirect"": ""smartapp://callback"", // must be registered ] ) // authorize, then search for prescriptions smart.authorize() { patient, error in if nil != error || nil == patient { // report error } else { medicationorder.search([""patient"": patient!.id]) .perform(smart.server) { bundle, error in if nil != error { // report error } else { var meds = bundle?.entry? .filter() { return is medicationorder } .map() { return as! medicationorder } // now `meds` holds all the patient's orders (or is nil) } } } } ``` for authorization to work with safari/sfviewcontroller, you also need to: register the scheme (such as `smartapp` in the example here) in your app's `info.plist` and intercept the callback in your app delegate, like so: ```swift class appdelegate: uiresponder, uiapplicationdelegate { func application(_ app: uiapplication, open url: url, options: [uiapplicationopenurloptionskey: any] = [:]) -> bool { // ""smart"" is your smart `client` instance if smart.awaitingauthcallback { return smart.didredirect(to: url) } return false } } ``` installation ------------ the suggested approach is to add _swift-smart_ as a git submodule to your project. find detailed instructions on how this is done on the [installation page][installation]. the framework can also be installed via _carthage_ and is also available via _cocoapods_ under the name [smart][pod]. [installation]: https://github.com/smart-on-fhir/swift-smart/wiki/installation [pod]: https://cocoapods.org/pods/smart license ------- this work is apache licensed: notice.txt. fhir is the registered trademark of and is used with the permission of"
0,fhirformjs,npm module to convert fhir questionnaire json to json schema for form rendering.,"# fhirformjs [!npm version](https://www.npmjs.com/package/fhirformjs) [!npm](https://www.npmjs.com/package/fhirformjs) [!build](https://nuchange.ca) [!known vulnerabilities](https://www.npmjs.com/package/fhirformjs) [!documentation](https://dermatologist.github.io/fhirformjs/) ## about creating, maintaining and using forms for health data capture is vital, and fhirform is a framework for that. fhirformjs is one of its components (an npm module) that helps create input forms corresponding to a fhir questionnaire. fhirformjs does not render forms but converts fhir questionnaire into a schema and let us other libraries (such as react-jsonschema-form ) do the heavy lifting. an output mapper that maps the output from a react-jsonschema-form to a questionnaireresponse is also available. checkout this example react app to see how it is used. this is a modern alternative to lhc-forms fhirformjs is wip (not production ready). pull requests are welcome (see contributing.md) and add issues and feature requests by clicking on the 'issues' tab. :point_up: ## installation ``` npm i --save fhirformjs ``` ## usage example (in a react component) * fhirformjs is framework independent and can be used with other frameworks such as vue / angular. * is a fhir questionnaire object* ``` import { fhirjsonform, fhirjsonresp } from 'fhirformjs' import form from ""@rjsf/core"" const resp = let formdata = {} let respdata = {} function handlesubmit(data){ respdata = fhirjsonresp(resp.model, data, resp.schema) console.log(json.stringify(respdata)) } return ( <div classname=""app""> <header classname=""app-header""> <form schema={resp.schema} uischema={resp.uischema} formdata={formdata} onsubmit={e => handlesubmit(e.formdata)} /> </header> </div> ); ``` ### update **since backend api** ``` import { fhirbackend } from 'fhirformjs' const backend = new console.log(backend.gettableofcontents()) ``` ### see an example :point_left: ## give us a star if you find this project useful, give us a star. it helps others discover the project. ## author * bell eapen [!twitter follow](https://twitter.com/beapen) ## contributor(s) * marco ferreira [!twitter follow](https://twitter.com/marfife)"
1,compass-numapp-frontend,the repository for the frontend component of the num-app,":tip-caption: :bulb: :note-caption: :information_source: :important-caption: :heavy_exclamation_mark: :caution-caption: :fire: :warning-caption: :warning: grade: javascript,link=https://lgtm.com/projects/g/numde/compass-numapp-frontend/context:javascript] image:https://img.shields.io/badge/prs-welcome-brightgreen.svg?style=flat-square[prs welcome,link=https://makeapullrequest.com] link=https://codecov.io/gh/numde/compass-numapp-frontend] = num-app (react native client - ios & android) https://github.com/numde/compass-numapp[main repository] | link:./docs[frontend documentation] image:./docs/images/gallery.png[auto, auto] == welcome this repository provides the source code for the react native client of the link:https://github.com/numde/compass-numapp[compass num-app project]. this project provides a set of open source components meant for the digital conduct of questionnaire based studies. num-app itself is a part of link:https://num-compass.science/[compass] (**c**oordination **o**n **m**obile **p**andemic **a**pps best practice and **s**olution **s**haring). the num-app enables the display of questionnaires] as well as the encrypted transmission and storage of corresponding questionnaire responses]. == kiosk mode the frontend client comes with a build-in kiosk mode. this means that the app can be set up in a way that it basically provides it own mock-backend to simulate a basic workflow with the app. the purpose is to demonstrate the capabilities of the num-app to new audiences. == features the client provides these main functionalities: . *login & user management* + -- users can authenticate using a qr-code, which contains the id for his/her participation. this id will be persisted on the device to automatically log the user in the next time the app is opened. + every time the user triggers an action that enables a connection to the link:https://github.com/numde/compass-numapp-backend[backend], the user will be updated and the frontend refreshed (with the data of the now updated user). important: the user has no option to logout - as soon as he/she is logged in it stays that way. but while in development mode a logout button is available from the burger menu. -- . *fhir questionnaire retrieval* + -- the application will download a questionnaire as soon as an updated user suggests that a new one is available. when restarting the app the questionnaire (and the given answers) of the last active user will be loaded from the local storage. should the id of that questionnaire not match the one transmitted with the user object, the local one will be deleted and a new one from the link:https://github.com/numde/compass-numapp-backend[backend] procured. important: the decision which questionnaire the user will get is made in the link:https://github.com/numde/compass-numapp-backend[backend]. the user will always be informed when a given questionnaire is due as well when the next one is available as this information is displayed on the *checkin-screen*: image:./docs/images/dates.png[auto, -- . *fhir questionnaire rendering & interaction* + -- the application can render a version of the fhir questionnaire standard that obliged with a certain ruleset for numbering items and a few other contextual additions. the rendering is done in a modal that separates topics by id and that way provides the questions on several pages - for the convenience of the user: image:./docs/images/fhir.png[auto, auto] the questionnaire as a whole as well as single categories and single questions are constantly checked for their completion state. this is visible due to several colors used in the application. image:./docs/images/completion.png[auto, auto] the used colors can of course be customized. -- . *fhir questionnaire response encryption & transmission* + -- as soon as a questionnaire is completed it can be sent to the link:https://github.com/numde/compass-numapp-backend[backend]. based on a predefined ruleset (provided by the link:https://github.com/numde/compass-numapp-backend[backend] or through a local definition) a few parameters are determined and after that the questionnaire response is created and encrypted. this encrypted response plus the ascertained parameters are then send to the link:https://github.com/numde/compass-numapp-backend[backend]. + the parameters are then used to determine the update values for the user (as the response is now encrypted and not accessible for the link:https://github.com/numde/compass-numapp-backend[backend]). meaning when the next questionnaire will be available, what id that questionnaire will have, etc. -- . *transmitting a report (if no questionnaire is available)* + -- if no questionnaire is available the user has the option to transmit a report. this report is nothing more than rest-call to the link:https://github.com/numde/compass-numapp-backend[backend] that can only be send out when no questionnaire is available. there is no actual data transmission aside from the fact that the call was send out. this is meant for situations that need reporting while no questionnaire (through which the user would normally report such an event) is available. the incoming report will trigger a user update within the link:https://github.com/numde/compass-numapp-backend[backend]. this might then lead to another questionnaire. -- == basic app flow aside from opening menus and links, the app does basically just four things: . *user update* + -- the app will query the user. this happens almost every time a connection to the link:https://github.com/numde/compass-numapp-backend[backend] is established: ** login -> user update ** manual refresh -> user update ** sending out a questionnaire -> user update ** sending out a report -> user update -- . *the app will update its own state based on the data from the user update* + -- the user update provides information that influences what the app will allow the user to do as well what is displayed. if a new questionnaire is available it will be downloaded and the due date will be displayed. is there no questionnaire available the the starting date of the next interval will bis presented. should the due date be exceeded then the local questionnaire will be deleted. -- . *the app renders a received questionnaire and allows the user to interact with it* + -- the user answers the questionnaire. the app checks if the questionnaire was answered completely (as only then it can be send to the link:https://github.com/numde/compass-numapp-backend[backend]). -- . *the user sends out a completed questionnaire (or a report)* + -- the user can send out a fully completed questionnaire (as long as its due date is not reached) in form of a questionnaire response. the app will encrypt the response and, after sending it out, request a *user update*. sending put a report is basically the same thing, just without a encrypted questionnaire response. -- == why react native? === cross-platform development the num-app is supposed to be available on android and ios. react native saves time by using a single code base to deploy to multiple mobile operating systems. components are reused anytime at any level into existing code without you rewriting it and recompiling the app.the framework is open-source and therefore available to a whole community of developers. it allows writing native module in a comparable language and linking it to react native codebase in a simple way. its needed in case you develop some features which are not supported for now by react native libraries. moreover, react native has the *live reload* feature, which is not available for other native frameworks. it allows viewing the latest code changes in real time. if two screens are opened, the first one shows the code, while the second one contains a mobile screen as a result of the code. + you can even run development builds on both systems in parallel: image:./docs/images/parallel.png[auto, auto] === use of existing knowledge react native does not need any special technical know-how. a basic knowledge of javascript is needed, but that is basically it. javascript developers with little self-education can use react native to jump right into the development of the mobile app - for ios and android. == where to start? even though a basic knowledge of javascript is enough for the setup und build of the application, an understanding of the following topics can be helpful for the further development of the project: * *javascript* * *node.js* * *react.js* * *redux* * *restful services* aside from that, the *`link:./docs[frontend documentation]`* gives you a good starting point. it covers the the setup process, the app configuration as well as all customization steps and tips for build and deployment."
0,fhir-questionnaire-render-react,render fhir questionnaire as a web form using fhirformjs,# fhir-questionnaire-render-react using fhirformjs [!forthebadge](https://github.com/dermatologist/fhir-questionnaire-render-react) [!build](https://nuchange.ca) ## about this is an example react app that demonstrates the use of fhirformjs to render a *fhir questionnaire* as a form. a json editor is added for real-time editing of the *questionnaire*.the submission is a *fhir questionnaireresponse* to any fhir compliant server. you may spin up a fhir server using this repo. ## contributor(s) * bell eapen | [!twitter follow](https://twitter.com/beapen) ## demo ### this project was bootstrapped with create react app. ## use ``` npm install npm start ``` * see src/app.js for fhirformjs usage example.
0,medplum,medplum is a healthcare platform that helps you quickly develop high-quality compliant applications.,"# medplum &middot; [!github license](https://github.com/medplum/medplum/blob/main/license.txt) [!npm version](https://www.npmjs.com/package/@medplum/core) [!quality gate status](https://sonarcloud.io/dashboard?id=medplum_medplum) [!coverage status](https://coveralls.io/github/medplum/medplum?branch=main) !medplum medplum is a developer platform that enables flexible and rapid development of healthcare apps. - **medplum auth** - end-to-end identity solution for easy user authentication, sign-in, and permissions using oauth, openid, and smart-on-fhir. - **medplum clinical data repository (cdr)** - backend server that hosts your healthcare data in a secure, compliant, and standards-based repository. - **medplum api** - fhir-based api for sending, receiving, and manipulating data. - **medplum sdk** - client libraries that simplify the process of interacting with the **medplum api**. - **medplum app** - web application where you can view your data and perform basic editing tasks. you can also use the medplum app to manage basic workflows. - **medplum bots** - write and run application logic server-side without needing to set up your own server. - **ui component library** - react components designed to help you quickly develop custom healthcare applications. ## docs - contributing - ground rules - codebase - technologies - folder structure ## contributing **we heartily welcome any and all contributions that match our engineering standards!** that being said, this codebase is not your typical open-source project because it is not a library or package with a limited scope -- it is our entire product. our contributing documentation has all the information you need to get started. ### ground rules #### contributions and discussion guidelines by making a contribution to this project, you are deemed to have accepted the developer certificate of origin (dco). all conversations and communities on medplum are expected to follow github's community guidelines and acceptable use policies. we expect discussions on issues and pull requests to stay positive, productive, and respectful. remember: there are real people on the other side of the screen! #### reporting a bug or proposing a new feature if you found a technical bug on medplum or have ideas for features we should implement, the issue tracker is the best place to share with us. (click here to open a new issue) ### writing documentation or blog content did you learn how to do something using medplum that was not obvious on your first try? by contributing your new knowledge to our documentation, you can help others who might have a similar use case! our documentation is hosted on medplum.com/docs, but it is built from markdown files in our `docs` package. for relatively small changes, you can edit files directly from your web browser on github.dev without needing to clone the repository. #### fixing a bug or implementing a new feature if you find a bug and open a pull request that fixes it, we will review it as soon as possible to ensure it meets our engineering standards. if you want to implement a new feature, open an issue first to discuss with us how the feature might work, and to ensure it fits into our roadmap and plans for the app. if you want to contribute but are unsure how to start, we have a ""good first issue"" label which is applied to newcomer-friendly issues. take a look at the full list of good first issues and pick something you like! **ready to get started writing code?** follow the local setup instructions and jump in! ### codebase #### technologies with the ground rules out of the way, let us talk about the coarse architecture of this mono repo: - **full-stack typescript**: we use node.js to power our servers, and react to power our frontend apps. almost all of the code you will touch in this codebase will be typescript. here is a list of all the big technologies we use: - **postgresql**: data storage - **redis**: background jobs and caching - **express**: api server - **typescript**: type-safe javascript - **react**: frontend react app #### folder structure ```sh medplum/ packages agent # on-premise agent app # frontend web app bot-layer # aws lambda layer for bots cdk # aws cdk infra as code cli # command line interface core # core shared library definitions # data definitions docs # documentation examples # example code used in documentation fhir-router # fhir url router fhirtypes # fhir typescript definitions generator # code generator utilities graphiql # preconfigured graphiql # client and server mock # mock fhir data for testing react # react component library react-hooks # react hooks library server # backend api server scripts # helper bash scripts ``` ## thanks <a href=""https://www.chromatic.com/""><img alt=""chromatic"" /></a> thanks to chromatic for providing the visual testing platform that helps us review ui changes and catch visual regressions. ## license apache copyright &copy; medplum fhir&reg; is a registered trademark of snomed&reg; is a registered trademark of the international health terminology standards development organisation. loinc&reg; is a registered trademark of regenstrief institute, inc. dicom&reg; is the registered trademark of the national electrical manufacturers association (nema)."
0,smart-forms,react-based form renderer implementing structured data capture (sdc) fhir specification,"open source fhir powered forms app built in powered by smart on fhir and structured data capture, smart forms allow you to easily integrate forms into your existing healthcare system. href=""https://smartforms.csiro.au"">show me the app --- smart forms is a typescript-based react forms web application currently ongoing development by csiro's australian e-health research centre as part of the primary care data quality project funded by the australian government department of health. the web app is intended to demonstrate the use of fhir specifications, such as the questionnaire and questionnaireresponse resources, the structured data capture (sdc) implementation guide, and most notably it leverages smart on fhir capabilities that allows the app to be launched by a primary care clinical management system (cms) and capture standardised health check information for healthcare clients. this project was bootstrapped with vite. <br/> **if you are interested in using the rendering engine in your projects, a standalone package is published on npm as @aehrc/smart-forms-renderer.** ## functionalities **smart forms app** | functionality | description | resources | showcase (right click -> open link in new tab) | |----------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------| | form population | populate fhir clinical data into forms, removing the need to re-enter generic information every time a new form is created, allows reusability of data. | sdc populate | population of patient details</br>population of patient medical history | | conditional rendering | render form items conditionally based on user decisions or pre-determined data. | questionnaire enablewhen | form tabs and items presented differently for patients of different age groups | | built-in calculations | perform calculations based on form item answers to produce a calculated result, e.g. bmi, cvd risk score. | sdc calculations | calculated bmi based on height and weight values | | valueset expansion | perform expansion of valueset resources via the ontoserver $expand operation api within autocomplete, dropdown, radio button and checkbox fields. | valueset expand</br>ontoserver valueset api | ontoserver valueset expansion in an autocomplete component | | questionnaireresponse write-back | a form can either be saved as a draft or as final, which will compile the form answers into a questionnaireresponse resource and store it on the cms's fhir server via rest api. | fhir restful api | list of responses in context of a patient | | form preview | generate a human-readable preview of the questionnaireresponse which can be viewed while filling in the form or after the form is saved. | <div align=""center"">-</div> | human-readable form preview | | | generic form implementation | the app tries its best to render any questionnaire as long as it conforms to the fhir specification! | questionnaire</br>sdc | rendering of an australian absolute cvd risk calculator questionnaire | note: the patients featured in the screenshots are synthetic and do not represent any real people. **forms server api** | functionality | description | resources | |------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------| | modular questionnaires | allows a questionnaire to be composed of sub-questionnaires which allows for reusability of questionnaire components i.e. a single tab within a form with multiple tabs. subquestionnaires can be ""assembled"" to form a complete questionnaire with the **$assemble** operation. | sdc modular questionnaires | ## contents the smart forms web app. try it out here: smartforms.csiro.au implemented operations from the structured data capture (sdc) specification: - $populate - $assemble a standalone component of the questionnaire-rendering engine published on npm as @aehrc/smart-forms-renderer. ## conformance here is the structured data capture (sdc) conformance sheet for the smart forms app: https://github.com/aehrc/smart-forms/blob/main/conformance.md ## usage ### running on a smart cms client (the preferred way) open https://launch.smarthealthit.org/ (or your own smart on fhir enabled cms) in a browser. set the **app launch url** at the bottom of the page as `https://smartforms.csiro.au/launch` and launch app. !image ### running in an unlaunched state this method of running the app does not allow you to save responses as it is not connected to a cms client. open https://smartforms.csiro.au in a browser. you would have access to some pre-defined local questionnaires note: the app will not be able to view or save responses as it is not connected to a cms client. ## configuration ### environment the default configuration is set to: ``` # ontoserver endpoint for $expand operations # to run your own ontoserver instance, contact us at https://ontoserver.csiro.au/site/contact-us/ontoserver-contact-form/ # questionnaire-hosting fhir server vite_forms_server_url=https://smartforms.csiro.au/api/fhir # debug mode - set to true in dev mode vite_show_debug_mode=false # smart app launch scopes and launch contexts # it will be necessary to tweak these variables if you are connecting the app to your own smart on fhir enabled cms/ehr vite_launch_scope=launch/patient patient/*.read offline_access openid fhiruser vite_launch_client_id=smart-forms ``` in development mode, create a `.env.local` file in the `apps/smart-forms-app` directory and tweak the environment variables as needed. ### run app locally clone this git source repository onto your local machine from https://github.com/aehrc/smart-forms. install dependencies. ```sh npm install ``` change directory into the directory containing the smart forms app. ```sh cd apps/smart-forms-app ``` start the local server. ```sh npm start ``` follow the instructions here but replace https://smartforms.csiro.au/launch with ## feature requests and bug reports if you find any bugs, feel free to create an issue and we will try our best to get it fixed. if you have any feature suggestions, feel free to also create an issue. however, we will try to prioritise more general rather than use-case specific features due to resourcing constraints. we are also accepting contributions to make the product better! please read contributing or discuss on zulip. ## discussions we encourage having discussions on chat.fhir.org. smart forms-related discussions can be raised in the smart forms's stream: any questionnnaire/sdc-related discussion can be raised in the questionnaire stream: ## licensing and attribution smart forms is copyright commonwealth scientific and industrial research organisation (csiro) abn licensed under the apache license, version this means that you are free to use, modify and redistribute the software as you wish, even for commercial purposes. **smart forms is experimental software at the moment, use it at your own risk!**"
1,compass-numapp-backend,the repository for the back end component of the num-app,":tip-caption: :bulb: :note-caption: :information_source: :important-caption: :heavy_exclamation_mark: :caution-caption: :fire: :warning-caption: :warning: = num-app mobile back end grade: javascript,link=https://lgtm.com/projects/g/numde/compass-numapp-backend/context:javascript] image:https://img.shields.io/badge/prs-welcome-brightgreen.svg?style=flat-square[prs welcome,link=https://makeapullrequest.com] https://github.com/numde/compass-numapp[main repository] | link:./docs[back end documentation] == welcome this repository provides the source code for the mobile back end of the link:https://github.com/numde/compass-numapp[compass num-app project]. this project provides a set of open source components meant for the digital conduct of questionnaire based studies. the mobile back end itself is a part of link:https://num-compass.science/[compass] (**c**oordination **o**n **m**obile **p**andemic **a**pps best practice and **s**olution **s**haring). the mobile back end provides study data for the num-app in form of questionnaires]. it also stores the study data that is uploaded from the mobile app. additionally it makes the collected data accessible for other parties. you can find an exemplary questionnaire https://github.com/numde/compass-implementation-guide/blob/master/input/questionnaire-generic.json[here]. == development === local setup * make sure you have a recent version (lts recommended) of https://nodejs.org/[node.js] installed and run the following commands to download and prepare this repository: [source,bash] ---- git clone https://github.com/numde/compass-numapp-backend.git cd compass-numapp-backend/ npm install ---- * in case you use vscode as your editor, install the recommended extensions === run the back end locally === generating rsa key pair for local development we need an rsa key pair for the encryption with the client. execute the following commands to create a key pair. the resulting files are picked automatically. but they can also be inserted into the `.env` file. ==== create .env file some configuration values need to be present as environment variables during runtime. the application loads a file with the name `.env` during startup, if it is present. to get started copy the file `.env.sample` to `.env` and add your values. [source,bash] ---- $ openssl genpkey -algorithm rsa -out private_key.pem -pkeyopt $ openssl rsa -pubout -in private_key.pem -out public_key.pem ---- ==== generating certificate to submit the public key to the client, a certificate must be created. to create a self-signed certificate, which will be valid for year, use the following command: [source,bash] ---- $ openssl req -days -new -out self-signed-certificate.pem -key private_key.pem ---- the certificate must be put in the .env file. if no certificate is provided, the native app will default to a built-in one (defined in src/config/appconfig.js). === scripts ==== npm run start start the built application ==== npm run dev start the application on the local machine in watch mode. this is the preferred command for local development. ==== npm run build build the application into the `build` folder. ==== npm run clean clean the `dist` folder. ==== npm run lint lint the source code. ==== npm run prettier-format have prettier format your code. ==== npm run test run your unit tests with jest. === environment variables used by the application there are many different environment variables used by the application. most of them have default values, that can be overridden by exposing a different value as environment variable. all used variables can be found in the `src/config` folder. === committing code changes this app uses https://typicode.github.io/husky[husky] to trigger some actions during a commit. before each commit passes automatic tests and linting is run. if any action fails, the commit fails. == deployment the application should run in any environment that provides a node.js runtime. the current configuration is suited for an openshift deployment. find detailed instructions here link:./ocp_deployment[ocp deployment]. == database setup dedicated documentation for the database setup can be found here link:./db[db setup]."
1,ie,intervention engine specific golang software.,"intervention engine [!build status](https://travis-ci.org/intervention-engine/ie) =================================================================================================================================================== the intervention engine project provides a web-application for *data-driven team huddles*. many care teams use team huddles to improve patient outcomes via efficient team communications and a holistic view of patients (due to the interdisciplinary nature of team huddles). intervention engine leverages electronic clinical records and clinical risk assessments to assist care teams in selecting patients for their huddles and providing the tools necessary to promote effective discussions and interventions. intervention engine is a work in progress. current intervention engine features: - huddle management - assign patients to huddles based on risk scores - assign patients to huddles based on recent encounters (e.g., ed visit) - manually assign patients to huddles - mark patients as ""discussed"" - custom population filters based on age, gender, conditions, and encounter types - clinical risk assessment integration via an open api - prototype stroke risk calculation service (based on - prototype ""negative outcomes"" risk calculation service (condition count + medication count) - patient views w/ summary data, risk trends, and risk component visualization - fhir-based rest server - c-cda import still to come: - population views and visualizations - smart-on-fhir integration the ie repository ----------------- the *ie* repository contains the source code for the backend intervention engine server. the *ie* server provides restful services needed by other components of the intervention engine stack. in addition to custom intervention engine features (such as authentication, notifications, and insta-count), it also doubles as a fhir server (by integrating code from the fhir repository). building and running ie locally ------------------------------- intervention engine is a stack of tools and technologies. for information on installing and running the full stack, please see building and running the intervention engine stack in a development environment. for information related specifically to building and running the code in this repository (*ie*), please refer to the following sections in the above guide: - (prerequisite) install git - (prerequisite) install go - (prerequisite) install mongodb - (prerequisite) run mongodb - clone ie repository - build and run intervention engine server - (optional) create intervention engine user - (optional) generate and upload synthetic patient data license ------- copyright the mitre corporation licensed under the apache license, version (the ""license""); you may not use this file except in compliance with the license. you may obtain a copy of the license at unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an ""as is"" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license."
0,asbi-screening-app,a smart on fhir application that provides multiple alcohol screening instruments for assessing patient alcohol consumption behaviors.,"# alcohol screening and brief intervention (asbi) clinical decision support (cds) screening app the *asbi screening app* is a smart on fhir<sup>&reg;</sup> application that provides multiple alcohol screening instruments for assessing patient alcohol consumption behaviors. the app is meant to be used with the smart<sup>&reg;</sup> app launch framework and is designed to customize the alcohol screening based upon patient-specific characteristics and data provided by an electronic health record (ehr). if write-back capability is supported by an organization integrating the *asbi screening app* into their ehr, then the patient responses to the alcohol screening are also written back to the patient record. the *asbi screening app* currently supports the following alcohol screening instruments: world health organization's alcohol use disorders identification test (audit) united states audit (usaudit) national institute on substance abuse (nida) quick screen each of the above have been represented as interoperable cds and have been published on the cds connect repository. an online demo of this app is avaiable; please see the demo section. ## cautions and limitations todo: update and link to pilot report. this software application has not been tested in a clinical environment with real patient data. its purpose is to faciliate testing of the three alcohol screening cds to be published on cds connect. additional development work will be needed to integrate the *asbi screening app* into a real ehr. ## utilized standards a number of standards have been used to help define the *asbi screening app*. ### smart on fhir<sup>&reg;</sup> the substitutable medical apps, reusable technology (smart) on fast healthcare interoperability resources (fhir<sup>&reg;</sup>) is a free and open standards-based application programming interface (api) for providing software applications with access to electronic health records (ehrs). the *asbi screening app* uses the smart on fhir<sup>&reg;</sup> standard to access patient data in order to customize the alcohol screening experience. ### fhir<sup>&reg;</sup> questionnaire questionnaire is one of the many interoperable resources defined by the health level fhir<sup>&reg;</sup> standard. the questionnaire resource allows a set of questions and allowable responses to be represented in an open and standard way. each questionnaire is defined by a set of both required and optional data elements, which are by design general in nature in order to support the capabilities most likely to be found in most healthcare systems. the *asbi screening app* uses a separate questionnaire to represent each of the available alcohol screening instruments. a questionnaireresponse resource is generated from the responses provided by the patient. ### structured data capture (sdc) the base fhir<sup>&reg;</sup> specification is meant to be an solution for healthcare interoperability. mechanisms such as extensions, profiles, and implementation guides provide a means in which use cases outside this can be addressed. the structured data capture (sdc) implementation guide defines how more complex questionnaire functionality and behavior can be expressed. examples of additional complexity used within the *asbi screening app* include advanced rendering of the questionnaires and the ability to provide dynamic updates via logical expressions (see ""clinical quality language (cql)"" below). ### clinical quality language (cql) cql is a domain-specific programming language focused on clinical quality applications, including cds as well as electronic clinical quality measures (ecqms). logical expressions written in cql are human-readable but can also be compiled to a machine-friendly format to facilitate implementation. the *asbi screening app* executes cql logic embedded in each questionnaire to provide patient customized behavior. ## underlying technologies ### vue.js vue is a javascript front-end framework for building user interfaces. the *asbi screening app* was built using the `vue create` command from the vue command line interface (cli). ### surveyjs surveyjs is a javascript library for rendering surveys and forms in a web browser and capturing user responses. the *asbi screening app* uses surveyjs to mechanize the alcohol screening instruments. ### questionnaire to survey while surveyjs provides many capabilities which are similiar to those described by fhir<sup>&reg;</sup> and sdc, it is not currently able to ingest fhir<sup>&reg;</sup> questionnaires. the questionnaire to survey library allows surveys defined as fhir<sup>&reg;</sup> questionnaires to be used with surveyjs. ### cql worker all cql calculations are executed within the context of a web worker, thereby offloading them to a separate thread. this greatly improves the responsiveness of the application. this is implemented via the cql worker library, which uses the the cql execution engine behind the scenes. ## setup this project manages dependencies using the yarn package manager. the dependencies for the *asbi screening app* can be installed locally by typing `yarn` at the command line. a local version of the app can be launched by typing `yarn serve` at the command line. a copy suitable for distribution can be built using the `yarn build` command. ### download value sets from vsac the value set content used by the cql is cached in a file named `valueset-db.json`, which has been checked into this project in an empty state. in order for the cds to operate as intended, implementers must populate `valueset-db.json` with the value sets which have been published on the value set authority center (vsac). in order to access vsac, you must sign up for a umls terminology services account. once a umls terminology services account has been obtained, the valueset-db.json file can be updated by running the following: - run `node src/util/updatevaluesetdb.js umls_api_key` _(replacing umls\_api\_key with your actual umls api key)_ to get you umls api key: sign into your umls account at https://uts.nlm.nih.gov/uts.html click 'my profile' in the orange banner at the top of the screen your api key should be listed below your username in the table if no api key is listed: click edit profile select the generate new api key checkbox click save profile your new api key should now be listed. ### configuration parameters for the app are stored in environmental variables that are stored in an `.env` file. the dotenv package is used to store the default variable values, which can be overwritten by defining a more specific env (e.g., `.env.local`) file or by setting the variables in the deployment system. for more information, see the vue documentation. ### parameters | parameter | description | allowed values | | --- | --- | --- | | `vue_app_display_screening_scores` | override option to display scores during the alcohol screening. if set to `true` the scores will still only be displayed if the appropriate questions are answered. if set to `false` no scores are ever displayed to the screen. | `['true', 'false']` | | `vue_app_write_back_mode` | sets the mode for writing out a `questionnaireresponse` resource after the completion of screening. if set to `smart` then the resource is sent back via the smart on fhir<sup>&reg;</sup> interface to be created in the ehr. if set to `none` then no write back is made | `['smart', 'none']` | | `vue_app_questionnaire_author` | used for indicating who is actually filling out and submitting the `questionnaireresponse` resource. this is used to determine how to fill out the `questionnaireresponse.author` element. | `['practitioner', 'patient']` | | `vue_app_fhir_observation_category_queries` | some fhir<sup>&reg;</sup> apis require `observation` resource queries to specify an observation category. setting this parameter to `true` causes the query of a patient's `observation` resources to be made specified using categories. | `['true', 'false']` | | `vue_app_response_observation` | option for saving alcohol screening results as a fhir observation. if set to `true` the alcohol screening responses are saved as a fhir observation. if set to `false` the responses are saved as a fhir questionnaireresponse resource. | `['true', 'false']` | | `vue_app_alcohol_screening_instrument` | for selecting which alcohol screening instrument is presented to the user. | `['usaudit', 'whoaudit', | ### secure http (https) most modern browsers are going to require https by default. to run the development server with https you will need to add the following to your `yarn.config.js` file (in addition to generating valid `key` and `crt` files): ```js module.exports = { configurewebpack: { ... }, devserver: { https: { key: fs.readfilesync(""certificate.key""), cert: fs.readfilesync(""certificate.crt"") }, disablehostcheck: true, public: port: headers: { ""access-control-allow-origin"": ""*"" } } }; ``` to serve built files over https: - `yarn build` - `npm install -g http-server` - `http-server dist -p -s -c certificate.crt -k certificate.key` - point your browser to ## usage while the *asbi screening app* is meant to interface with an actual ehr, a number of options are available for local testing with synthetic data. ### using with asbi testing server this option requires installing the asbi testing server: `yarn start` in the root of the asbi testing server (after installing its dependencies) `yarn serve` from this project open a web browser and navigate to select a synthetic patient from the list this will start the smart on fhir<sup>&reg;</sup> launch sequence, which if everything is working should result in the asbi screening app being displayed. a series of fhir<sup>&reg;</sup> queries will be made from from this app to the asbi testing server, which will respond with the appropriate resources. ### using with public smart sandbox a public smart app launcher is available for sandbox tesing of smart on fhir<sup>&reg;</sup> apps with synthetic data. in order to use this option, the *asbi screening app* must be served over a hypertext transfer protocol secure (https) connection. #### ehr launch navigate to the public smart<sup>&reg;</sup> app launcher and choose the ""provider ehr launch"" launch type. leave all other options unselected. paste the url to where `public/launch_public_ehr.html` is being served from into the ""app launch url"" box at the bottom of the smart<sup>&reg;</sup> app launcher page. select ""launch app!"" which will bring up a patient selector widget before the *asbi screening app* is launched. #### standalone launch select the ""provider standalone launch"" option in the public smart<sup>&reg;</sup> app launcher. copy the ""fhir<sup>&reg;</sup> server url"" shown at the bottom of the screen and paste it into the `iss` field in `public/launch_public_standalone.html`. navigate to where `public/launch_public_standalone.html` is being served from and you should be redirected to the patient selector widget. ## demo an online demo of the *asbi screening app* is available, configured to use the who audit. the demo utilizes the public smart sandbox with standalone launch and the use of any recent version of the chrome browser is recommended. other modern browsers should work but have not been extensively tested. ## license (c) the mitre corporation. all rights reserved. approved for public release: distribution unlimited. unless otherwise noted, this work is available under an apache license. it was produced by the mitre corporation for the national center on birth defects and developmental disabilities, centers for disease control and prevention in accordance with the statement of work, contract number task order number any loinc (http://loinc.org) content is copyright &copy; regenstrief institute, inc. and the logical observation identifiers names and codes (loinc) committee and is available at no cost under the license at http://loinc.org/license. loinc<sup>&reg;</sup> is a registered united states trademark of regenstrief institute, inc. references to and reproductions of the audit alcohol screening instrument are made by permission from the world health organization (who). the who does not endorse this project, does not provide any warranty, and does not assume any liability for its use. for further information, please see: alcohol use disorders identification test - guidelines for use in primary care, second edition. geneva, world health organization, audit (c) world health organization https://www.who.int/substance_abuse/activities/sbi/en/"
1,c3-pro-server,"highly reliable and scalable fhir compliant web server, designed to cope with the traffic from mobile apps","is a highly reliable and scalable fhir compliant web server, designed to cope with the traffic from mobile apps. the current version can only be deployed in aws. it populates an aws sqs with the fhir resources that are post. it does not consume the queue. a consumer can be found in the project the system servers encrypted post fhir data through the following method ```javascript post { ""message"":{{the encrypted fhir resource}}, ""symmetric_key"": {{the encrypted aes symmetric key used to encrypt the message}}, ""key_id"": {{the rsa key id used to encrypt the symmetric key}}, ""version"": or } ``` also, the system serves the following fhir compliant rest methods (unencrypted data). in this case, the information is encrypted in the server. we discourage the use of these methods in production, even when the the traffic goes through https: ```javascript get id}} post post post put id}} ``` it uses two legged for authorization, which needs an initial phase for registration: **registration request:** ```javascript post header antispam: {{in-app-stored secret}} { sandbox: true/false, receipt-data: {{your apple-supplied app purchase receipt}} } ``` **registration response:** ```javascript created content-type: application/json { ""client_id"":""{{some opaque client id}}"", ""client_secret"": ""{{some high-entropy client secret}}"", ""grant_types"": [""client_credentials""], ""token_endpoint_auth_method"":""client_secret_basic"", } ``` the registration phase should be called only once per device. once the device is registered, the same client_id and client_secret must be user in future oauth calls. authorization request** ```javascript post authentication: basic ``` note: according to two-legged specifications both clientid and secret should be **x-www-form-urlencoded** before encoding is applied. authorization response** ```javascript created content-type: application/json { ""access_token"":""{{some token}}"", ""expires_in"": ""{{seconds to expiration}}"", ""token_type"": ""bearer"" } ``` the bearer token can be used in the rest calls that serve fhir resources as authorization credentials. # configuration and deployment # ## aws prerequisites ## the following services must be deployed in aws: * bucket**: the system uses an bucket to serve static content like questionnaire resources and to store the public key of the consumer * **sqs queue**: a queue to store the pushed fhir resources * **oracle rds db**: the system uses an oracle schema to manage credentials. technically, it is not necessary to use a db schema deployed in aws, but is highly recommended. the access to and sqs can be configured in the {{config.properties}} of each resource directories (dev, qa and prod). the access to the oracle db must be configured as a datasource in the jboss {{standalone.xml}} file. see below. ## installing maven, java && jboss ## the system uses java and we recommend to use jboss to install the basic tools in a debian-based linux distribution: sudo apt-get clean sudo apt-get update sudo apt-get install sudo apt-get install unzip sudo apt-get install maven wget sudo unzip -d /usr/share/ sudo chown -fr {{you_chosen_user}}:{{you_chosen_user}} ## oracle db configuration ## the systems uses an oracle db to manage credentials and bearer token. here are the steps to configure the db properly: * run the table creation script: *{{src/main/scripts/create_tables.sql}}* in the db * insert an antispam token: ```sql insert into antispamtoken (token) values ``` to generate hashed token execute the script: *{{src/main/scripts/generate_hashed_token.sh}}* replacing *{{""replace by a high entropy token""}}* by the desired anti spam token. * deploy the provided oracle jdbc driver in jboss: ```she will $jboss_home/standalone/deployments ``` * configure the data source by editing the file *$jboss_home/standalone/configuration/standalone.xml*. in the data source section place the following: ```xml <datasource enabled=""true"" use-java-context=""true""> <connection-url>{{jdbc_connection_to_db}}</connection-url> <security> <user-name>{{db_username}}</user-name> <password>{{db_password}}</password> </security> </datasource> ``` * **note for production deployments**: it is not recommended to display raw db credentials in the configuration files, even when the servers are protected. one possible way is to use security domains to wrap encrypted credentials. for instance: ```xml <datasource enabled=""true"" use-java-context=""true""> <connection-url>{{jdbc_connection_to_db}}</connection-url> <security> </security> </datasource> ``` and in the security domain section: ```xml <security-domain cache-type=""default""> <authentication> <login-module code=""org.picketbox.datasource.security.secureidentityloginmodule"" flag=""required""> <module-option name=""username"" value=""{{db_username}}""/> <module-option name=""password"" value=""{{encrypted password}}""/> </login-module> </authentication> </security-domain> ``` the encrypted password can be generated running **picketbox** security module as follows: java org.picketbox.datasource.security.secureidentityloginmodule {{db_password}} the output will be the encrypted password to place in the security domain element. make sure that your class_path includes the appropriate jar file. picket box is included by default in jboss distribution as a module. * configure by editing the file *$jboss_home/standalone/configuration/standalone.xml*, and adding the following in the security-domains section: ```xml <security-domain name=""staticuserpwd"" cache-type=""default""> <authentication> <login-module flag=""required""> <module-option name=""dsjndiname"" <module-option name=""principalsquery"" value=""select passwd from users where username=?""/> <module-option name=""rolesquery"" value=""select userroles, 'roles' from userroles where username=?""/> <module-option name=""hashalgorithm"" <module-option name=""hashencoding"" <module-option name=""hashcharset"" <module-option name=""hashuserpassword"" value=""true""/> <module-option name=""hashstorepassword"" value=""false""/> </login-module> </authentication> </security-domain> ``` ## building and deploying in dev ## once the project is cloned or download, in the root of the project: mvn clean package mvn jboss-as:deploy the previous instructions take the resource files located in *src/main/resources/dev* and place them as the resource files of the deployment. this requires jboss on: $jboss_home/bin/standalone.sh to stop jboss: $jboss_home/bin/jboss-cli.sh --connect command=:shutdown ## building in qa and prod environment ## in qa: mvn clean package -pqa mvn jboss-as:deploy in prod: mvn clean package -pprod mvn jboss-as:deploy these commands take the resource files located in *src/main/resources/qa* or *src/main/resources/prod* respectively, and place them as the resource files of the deployment. ## deploying on web server containers different than jboss## generate the war files for the desired environment mvn clean package mvn clean package -pqa mvn clean package -pprod and copy the generated war located in to the corresponding deployment directory. in the default directory is: ## notes on aws sdk usage ## the system uses the java sdk provided by amazon. the sdk will be installed automatically since it is a maven dependency. however, it grabs the credentials to access the bucket and sqs from a file that should be located here: ~/.aws/credentials the content of the file should be something like: [sqsqueue] aws_secret_access_key={{secret}} the default configuration uses the same profile to connect to and sqs. this is specified in *configuration.properties* file. if you want to use different profiles, the *credentials* file should look like: [sqsprofile] aws_access_key_id={{access_key_to_sqs}} aws_secret_access_key={{secret_sqs}} and the corresponding variables in *configuration.properties* would look like: app.aws.sqs.profile=sqsprofile to obtain access keys and secrets from aws, visit http://docs.aws.amazon.com/awssimplequeueservice/latest/sqsgettingstartedguide/awscredentials.html. we suggest to create a user in aws-iam with only permissions to access and sqs, and generate the access key and secret for this user. ## serving fhir questionnaires ## the following rest method get id}} returns the json specification of the asked questionnaire resource: accepted content-type: application/json internally, the json questionaires are stores statically in the bucket. the format of the files is: questionnaire#{questionnaire_id}.json for example, the call get will server the content of the following file stored in the bucket: questionnaire#c-tracker.survey-in-app.main.json ## providing public key ## the system uses a public key uploaded in the bucket to encrypt the symmetric key used to encrypt the resources in the sqs. the name of the public key file is specified in *configuration.propeties* file: this name must match with an existing file in the used bucket. the public key comes from the consumer. see to see how to generate public-private keys. ### support for multiple public-private keys ### in this new version, public keys have associated an id. this id will be pushed along with the message in the sqs as a metadata, and will be used by the consumer to distinguish between different possible keys. the id should be an uuid specified in a file stored in the bucket. the name of the file is configurable in *configuration.propeties* and it is currently set as follows: ## serving fhir questionnaires ## the following rest method get id}} returns the json specification of the asked questionnaire resource: accepted content-type: application/json internally, the json questionaires are stores statically in the bucket. the format of the files is: questionnaire#{questionnaire_id}.json for example, the call get will server the content of the following file stored in the bucket: questionnaire#c-tracker.survey-in-app.main.json ## configuration parameters ## there is one configuration parameters file for each environment (dev, qa and prod). they are located here: ###amazon sqs and connectivity### *the url to the sqs to enque resources* *the profile used to connect to the sqs* app.aws.sqs.profile=sqsqueue *the amazon region where the sqs is located* *the profile used to connect to the bucket* *the name of the bucket* *the amazon region where the buclet is located* ###properties related to encryption algorithms and parameters### see for details. both projects share these properties app.security.metadatakey=pkey app.security.metadatakeyid=pkey_id app.fhir.metadata.version=version app.security.secretkey.basealgorithm=aes app.security.publickey.basealgorithm=rsa app.security.encryption.enabled=yes ###base map file### the filename of the json map file stored in the bucket that computes persists the number of patients received for each us state. ###ios receipt verification### *the is provided by apple* app.ios.id=com.mindmobapp.mindmob *the sand box end point where to verify that the receipt is correct* app.ios.verification.endpoint=https://sandbox.itunes.apple.com/verifyreceipt *the production end point where to verify that the receipt is correct* app.ios.verificationtest.endpoint=https://sandbox.itunes.apple.com/verifyreceipt *the default fhir version in case it is not informed in the encrypted message.* ###other properties ### the system email registration errors app.recipient.smtp=test@childrens.harvard.edu"
1,FHIR,the linuxforhealth fhir server and related projects,"## linuxforhealth fhir server the linuxforhealth fhir server (formerly the ibm fhir server) is a modular java implementation of the fhir specification that supports versions and with a focus on performance and configurability. for a detailed description of fhir conformance, see https://linuxforhealth.github.io/fhir/conformance. the server is available in the following forms: * a web application archive (war) * a zip file with installation script * a linux container image from github packages * a helm chart registered on artifacthub ### running the server guides for configuring, operating, and extending the linuxforhealth fhir server are available from https://linuxforhealth.github.io/fhir/guides/fhirserverusersguide. #### from the zip installer download the fhir-persistence-schema and fhir-install assets from the releases tab and follow the instructions from the user's guide to: use fhir-persistence-schema-version-cli.jar to deploy the schema. unzip, install, and configure the server. #### from the container image quickstart: ``` docker run -p -e bootstrap_db=true ghcr.io/linuxforhealth/fhir-server ``` note: the docker image ghcr.io/linuxforhealth/fhir-schematool is an early technology preview and is experimental. the docker image ghcr.io/linuxforhealth/fhir-bucket-tool is an early technology preview and is experimental. the docker image ghcr.io/linuxforhealth/fhir-term-loader is an early technology preview and is experimental. #### from the helm chart quickstart: ``` helm repo add linuxforhealth https://linuxforhealth.github.io/lfh-helm export postgres_password=$(openssl rand -hex helm upgrade --install --render-subchart-notes fhir-server linuxforhealth/fhir-server --set postgresql.postgresqlpassword=${postgres_password} --set ingress.hostname=example.com --set ``` see https://artifacthub.io/packages/helm/linuxforhealth/fhir-server for more information. ### building with the linuxforhealth fhir modules each of the linuxforhealth fhir server modules are published to maven central under org.linuxforhealth.fhir. to use the artifacts from a maven project, declare the dependencies. for example, to use our visitable, thread-safe fhir object model (including our high-performance parsers and generators), declare a dependency on the `fhir-model` module: ``` ... <dependencies> <dependency> <groupid>org.linuxforhealth.fhir</groupid> <artifactid>fhir-model</artifactid> <version>${fhir.version}</version> </dependency> ... ``` ### linuxforhealth fhir modules the linuxforhealth fhir server is modular and extensible. the following tables provide an overview of all the modules, along with an indicator of the stability of the java apis defined in each module. this indicator is only applicable to the direct usage of the modules, not for usage of the linuxforhealth fhir server as a whole. #### core |module|description|java api-stable| |------|-----------|----------| |fhir-parent|the parent project for all projects which make up the linuxforhealth fhir server|false| |fhir-core|core helpers and utilities|false| |fhir-cache|cache-related helpers and utilities|false| #### model and profile support |module|description|java api-stable| |------|-----------|----------| |fhir-model|an object model generated from the fhir specification and corresponding parsers and generators for xml and json|true| |fhir-registry|a resource registry and registry provider interfaces for extending the registry|false| |term/fhir-term|a terminology service provider interface with a default implementation that implements terminology services from fully-defined codesystems in the registry|false| |term/fhir-term-graph|an expermental terminology service provider that implements terminology services using janusgraph|false| |term/fhir-term-graph-loader|utilities to populate the fhir-term-graph janusgraph with concepts|false| |term/fhir-term-remote|a terminology service provider that connects to an external service using a rest client to access code system content|false| |fhir-profile|helper methods for validating valueset membership and profile conformance|false| |fhir-path|an implementation of version of the fhirpath specification|false| |fhir-validation|validation utility for validating resource instances against the base specification and configured profiles|false| artifacts for fhir version artifacts for fhir version and valuesets from terminology (though) version |conformance/fhir-ig-us-core|packaging the us core implementation guide for the linuxforhealth fhir registry|false| |conformance/fhir-ig-mcode|packaging the minimal common oncology data elements for the linuxforhealth fhir registry|false| |conformance/fhir-ig-carin-bb|packaging the consumer-directed payer data exchange guide for the linuxforhealth fhir registry|false| |conformance/fhir-ig-davinci-pdex|packaging the da vinci payer data exchange (pdex) implementation guide for the linuxforhealth fhir registry|false| |conformance/fhir-ig-davinci-hrex|packaging the da vinci health record exchange (hrex) implementation guide for the linuxforhealth fhir registry|false| |conformance/fhir-ig-davinci-pdex-plan-net|packaging the da vinci payer data exchange (pdex) plan net implementation guide for the linuxforhealth fhir registry|false| |conformance/fhir-ig-davinci-pdex-formulary|packaging the da vinci payer data exchange (pdex) us drug formulary implementation guide for the linuxforhealth fhir registry|false| #### server |module|description|java api-stable| |------|-----------|----------| |fhir-config|configuration property definitions and helpers for working with the fhir-server-config.json config files and multi-tenancy|false| |fhir-audit|audit-related interfaces and implementations including a no-op auditlogservice and an auditlogservice that writes audit events to apache kafka in the cloud auditing data federation (cadf) json format|false| |fhir-search|utilities for working with the fhir search specification|false| |fhir-persistence|interfaces, helpers, and tests for implementing a persistence layer for the server|false| |fhir-persistence-jdbc|a relational fhirpersistence implementation that uses jdbc to store and query fhir resources|false| |fhir-persistence-cos|decorates the fhir-persistence-jdbc module with the ability to offload payload storage to ibm cloud object storage *experimental* |false| |fhir-persistence-cassandra|decorates the fhir-persistence-jdbc module with the ability to offload payload storage to cassandra *experimental* |false| |fhir-persistence-blob|decorates the fhir-persistence-jdbc module with the ability to offload payload storage to azure blob *experimental* |false| |fhir-provider|jax-rs providers for fhir xml and json and related patch formats|false| |fhir-server|jax-rs resources and related classes for implementing the fhir rest api and extended operations|false| |fhir-server-webapp|a web application that packages the fhir-server with a set of built-in extended operations|false| |fhir-server-test|end-to-end integration tests for testing a running server|false| |fhir-smart|an interceptor that provides smart-on-fhir authorization policy enforcement|false| #### extended operations |module|description|java api-stable| |------|-----------|----------| |fhir-operation-test|sample operations for testing extended operations as describe at |false| |fhir-operation-bulkdata|`$import` and `$export` implementations which translate bulk data requests into java batch jobs|false| |fhir-bulkdata-webapp|standalone web application for serving bulk import and export requests via java batch jobs|false| |fhir-operation-convert|a limited implementation of the fhir $convert operation, able to convert between json and xml but *not* between fhir versions|false| |fhir-operation-document|basic support for the composition `$document` operation defined at |false| |fhir-operation-healthcheck|the `$healthcheck` operation checks for a valid connection to the database and returns the server status|false| |fhir-operation-term|terminology service operations which use the default fhir-term terminologyserviceprovider to implement $expand, $lookup, $subsumes, $closure, $validate and $translate|false| |fhir-operation-term-cache|add-on module that provides operations for clearing the terminology subsystem caches for non-production scenarios|false| |fhir-operation-validate|an implementation of the fhir resource $validate operation|false| |fhir-operation-everything|an implementation of the fhir patient `$everything` operation|false| |fhir-operation-erase|a hard delete operation for resource instances referred to as the `$erase` operation. see the readme.md|false| |fhir-operation-member-match|an extensible framework and reference implementation for davinci hrex $member-match using the default ibm fhir server. see the readme.md *experimental*|false| #### client |module|description|java api-stable| |------|-----------|----------| |fhir-client|a fhir client that re-uses the linuxforhealth fhir server model and its jax-rs providers|false| #### clinical quality |module|description|java api-stable| |------|-----------|----------| |cql/fhir-cql|foundation classes for implementing the cql engine backend in ibm fhir server|false| |cql/fhir-cql-rest|rest client-based implementation of cql engine backend|false| |cql/fhir-cql-server|internal api-based implementation of cql engine backend|false| |cql/fhir-quality-measure|fhir quality measure evaluation logic|false| |cql/operation/fhir-operation-cpg|*optional* module that implements cql operations|false| |cql/operation/fhir-operation-cqf|*optional* module that implements cqf operation|false| |cql/operation/fhir-operation-apply|a naive implementation of the `$apply` operation defined at |false| #### tools and utilities |module|description|java api-stable| |------|-----------|----------| |fhir-tools|code generation tools and logic for generating the fhir object model, xml and json parsers, and the defaultvisitor base class|false| |fhir-database-utils|generic database utilities for working with apache derby and postgresql relational database management systems|false| |fhir-examples-generator|a utility for generating resource examples which range from minimal (only required fields) to complete (every field present)|false| |fhir-examples|a set of fhir resource examples including all examples from the fhir specification a set of generated examples for test purposes|false| |fhir-swagger-generator|utilities for generating swagger and openapi definitions for a subset of the fhir http interface|false| |fhir-openapi|a web application that provides a simplified openapi definition of the fhir http interface|false| |fhir-install|packaging and installation scripts for creating the fhir-distribution zip and the corresponding ibm fhir server docker image|false| |fhir-benchmark|java microbenchmark harness (jmh) tests for measuring read/write/validation performance for the linuxforhealth fhir server and the fhir java reference implementation|false| |fhir-bucket|scans cloud object storage buckets and uploads data using the fhir rest api|false| |fhir-persistence-schema|classes for deploying and updating the linuxforhealth fhir server relational database schema|false| |fhir-persistence-cassandra-app|cli utility application supporting payload storage to cassandra *experimental* |false| ### contributing to the linuxforhealth fhir server the linuxforhealth fhir server is under active development. to help develop the server, clone or download the project and build it using maven. see setting up for development for more information. see contributing.md for contributing your changes back to the project. see code_of_conduct.md for code of conduct. ### license the linuxforhealth fhir server and its corresponding modules are licensed under the apache license. the full license text is available at license. fhir is the registered trademark of and is used with the permission of use of the fhir trademark does not constitute endorsement of this product by ibm and the ibm logo are trademarks of international business machines corporation, registered in many jurisdictions worldwide. other product and service names might be trademarks of ibm or other companies. a current list of ibm trademarks is available at https://ibm.com/trademark."
1,fhirform-vue,convert fhir questionnaire to json for form rendering using vue,"# fhirform-vue render a fhir questionnaire as webform ## about this is an npm module to convert a fhir questionnaire to json for automatic form rendering with vue-form-generator. the corresponding fhir questionnaire is used as the model for capturing user input. this is part of the fhirform framework. [!fhirform](https://github.com/dermatologist/fhirform-vue/blob/develop/notes/fhirform-vue.png) ## installation npm i --save fhirform-vue use github for latest dev branch: npm install --save github:dermatologist/fhirform-vue#develop ## usage ``` import { fhirformvue } from 'fhirform-vue'; import fetch from 'isomorphic-fetch' it('should output model and schema', async () => { await .then((response) => response.json()) .then(async (myjson) => { const ff = fhirformvue(myjson); console.log(ff); expect(ff).tobedefined(); }); ``` ### use it with vue-form-generator ``` vue.use(vueformgenerator) export default { data () { return { model: ff.model, schema: ff.schema } } } ``` ## api <!-- generated by documentation.js. update this documentation by updating the source code. --> ### table of contents ## credits bell eapen # tsdx bootstrap this project was bootstrapped with tsdx."
1,discovery-mobile-ui,mobile ui for sync-for-science discovery app,"# sync for science discovery, mobile ui mobile ui for sync for science discovery terms and conditions ### configure environment variables ```she will cp .env.example .env ``` in `.env`, replace `expo_owner`, `expo_slug`, `bundle_identifier`, `client_id` with appropriate values: * `expo_owner` -- the name of the expo account that owns the project. this is useful for teams collaborating on a project. * `expo_slug` -- the friendly url name for publishing. for example, `myappname` will refer to the `expo.dev/@project-owner/myappname` project. * `bundle_identifier` -- the ios bundleidentifier and android package fields use reverse dns notation, but do not have to be related to a domain. replace ""com.yourcompany.yourappname"" with whatever makes sense for your app: (see also: build configuration) > android.package will be used as the android application id which is used to identify your app on the google play store > > ios.bundleidentifier will be used to identify you app on the apple app store * `endpoints_url` -- public url to a json fhir bundle whose entries are endpoint resources. for example: * `client_id` -- ehr client id, used for the openid connect launch sequence. (this is a smart on fhir ""public"" app.) ## install dependencies ```she will yarn install ``` ## run locally, via expo go ```she will yarn start ``` (follow instructions in terminal to target a mobile platform) ...or, on macos, automatically launch in ios simulator: ```she will yarn ios ``` ## optional development environment expo cli"
1,fhirform-server,server for the fhirform framework for managing forms as fhir questionnaire,# fhirform-server | *a fhir has been lit on this server*! ## about this is a spring boot hapi fhir server for managing healthcare forms as fhir questionnaire resources with individual dataelements. this is a part of the fhirform framework with an editor and a viewer. you may spin up a fhir server using this repo. the meta-repository of fhirform framework and resources is here. ## requirements * java * maven ## how to use: ``` mvn spring-boot:run ``` *how to manage the whole fhirform framework is described elsewhere.* * access at ## contributors bell eapen | (mcmaster you)
1,survey-ui-v8,survey ui which is compatible with version of survey builder ui,"# a smart app for fhir sdc questionnaire this is a smart app that can be used in ehr (electonic health record) systems supporting smart on fhir to display fhir sdc questionnaire forms and collect data as fhir questionnaireresponse resources. ## demo a demo of this app can be launched via smart on fhir from the lhc fhir tools website. it can also be used without smart, by going to it directly, in which can you can enter the base url of a fhir server to which you want the app to connect. the source files from which the demo is built are on the master branch. see ""customizing the app"" below if you wish customize or build your own copy. the app relies on the lhc-forms rendering widget for displaying forms. it has partial support for fhir questionnaires (versions and and the structured data capture implementation guide. for some sample forms to try, this repository comes with some forms under which are used by the test code to test the app. the fhir server connected to by the smart app gets reset weekly, but you can use the upload button to upload a new questionnaire resource. if downloading one of the forms from github, be sure click on the ""raw"" button, which will open a page which only has the questionnaire data. for example: will open a page for a vital signs questionnaire which you can save to a local file and then use ""upload"" to use it in the app. ## customizing the app if you wish to install and build the app locally so that you can customize it, see below. note that adding support for additional parts of the sdc specification will require edits to the lhc-forms widget. (pull requests are very welcome, but it might be better to open an issue first to see if we are already working on that feature.) ### add node.js and npm to your path the file bashrc.lforms-fhir-app specifies the version of node.js we are using for development. download that version of node.js, and add its bin directory to your path. ### install dependencies we have two kinds of dependencies in this project: tools and angular framework code. the tools help us manage and test the application. * we get the tools we depend upon via `npm`, the node package manager (npm). * we get the angular code via `bower`, a client-side code package manager (bower). * in order to run the end-to-end tests, you will also need to have the java development kit (jdk) installed on your machine. check out the section on end-to-end testing for more info. we have configured `npm` to automatically run `bower` so we can simply do: ``` npm ci ``` behind the scenes this will also call `bower install`. after that, you should find out that you have two new folders in your project. * `node_modules` - contains the npm packages for the tools we need * `app/bower_components` - contains the angular framework files add node_modules/.bin to your path. ### build the application ``` npm run build ``` this will create files for production in a ""dist"" directory, but will also copy some needed files into place from node_modules. ### run the application ``` npm run start ``` will start an http server running at port or, for testing the production build, ``` npm run start-dist ``` will start a server on port that serves the files in dist. now browse to the app at <a ### running tests (including end-to-end tests) ``` npm run test ``` will run the tests. for testing the production build in dist, run ``` npm run test-dist ```"
1,FHIR,broad fhir is a fhir server that powers applications for genomics research.,"# broad fhir <p align=""center""> <a alt=""fhir - tests""> <img /></a> <a alt=""tcga - tests""> <img /></a> <a alt=""anvil - tests""> <img /></a> <a alt=""viewer - tests""> <img /></a> </p> > fhir is an interoperability standard intended to facilitate the exchange of healthcare information between healthcare providers, patients, caregivers, payers, researchers, and any one else involved in the healthcare ecosystem. it consists of main parts a content model in the form of resources, and a specification for the exchange of these resources in the form of real-time restful interfaces as well as messaging and documents ## getting started clone ``` git clone https://github.com/databiosphere/fhir ``` install you must run these separately in these directories: `anvil-api`, `fhir`, `tcga`, `viewer` ``` npm i ``` run the tests ``` npm run test ``` configure your projects. this project uses dotenv extensively to make configuration easy. see configuration ``` touch .env touch fhir/.env touch tcga/.env touch viewer/.env ``` run docker compose ``` docker-compose up --build ``` ## smart app broad fhir comes with it is own smart on fhir application. you can run it locally or host it statically ``` cd viewer npm i npm start ``` !viewer ## documentation read our docs pages for information on deployment, tech stack, design decisions, and more docs ## auth endpoints ### authorize ### token"
0,AHRQ-covid-19-care-summary,smart on fhir app for care management,"# care summary smart on fhir application _note: this is an early proof-of-concept application, not yet ready for pilot testing._ ## about the care summary smart on fhir application was developed to support the pilot of cds artifacts for evidence-based treatment of this artifact presents a variety of key ""factors"" for clinicians to consider when assessing the history of a patient's diagnosis and treatment. these factors include subjective and objective findings, along with recorded treatments and interventions to inform shared decision making on treatments moving forward. this prototype application is part of the cds connect project, sponsored by the agency for healthcare research and quality (ahrq). ## additional documentation * developer documentation -- developer details on the application design and build process. * terminology and value sets -- use of standardized value sets in this application. ## overview the care summary is a web-based application that adheres to the smart on fhir standard, allowing it to be integrated into ehr products that support the smart on fhir platform. the logic used to determine what data to display in the care summary is defined using cql which then makes the corresponding queries to the fhir server. these fhir data are then used to render a user-friendly view of the information. ### level heading"
1,fhir-app,basic smart on fhir app,# smart this project is generated with yo angular generator version ## build & development run `grunt` for building and `grunt serve` for preview. ## testing running `grunt test` will run the unit tests with karma.
0,sof-cardiac-risk,smart on fhir cardiac risk app,"# about # a port of the cardiac risk visualization smart application to use an fhir data source for observations ) and patient demographics. # deploy # from a console in the project directory, execute: ``` npm install npm run serve ``` # public demo # see app in smart's gallery # screenshot # !screenshot"
1,fhir_questionnaire,a library to render fhir questionnaires and generate a questionnaireresponse,"<!-- this readme describes the package. if you publish this package to pub.dev, this readme's contents appear on the landing page for your package. for information about how to write a good package readme, see the guide for writing package pages. for general information about developing packages, see the dart guide for creating packages and the flutter guide for developing packages and plugins. --> todo: put a short description of the package here that helps potential users know whether this package might be useful for them. ## features todo: list what your package can do. maybe include images, gifs, or videos. ## getting started todo: list prerequisites and provide or point to information on how to start using the package. ## usage todo: include short and useful examples for package users. add longer examples to `/example` folder. ```dart const like = 'sample'; ``` ## additional information todo: tell users more about the package: where to find more information, how to contribute to the package, how to file issues, what response they can expect from the package authors, and more."
0,cumulus-library-suicidality-los,"study the increase in pediatric patients presenting to the emergency department with suicidality before and during the pandemic, and the subsequent impact on emergency department length of stay and boarding","# cumulus suicidality los (length of stay) study _see publication below for study description_ this repository contains tables (sql and csv spreadsheets) to reproduce results of the suicidality los (length of stay) study. part of the smart on fhir cumulus project for more information, browse the cumulus library documentation. ## usage to install the module, simply run `pip install cumulus-library-suicidality-los`. this will add a `covid_library_los` study target to `cumulus-library`. ## publication __emergency department visits and boarding for pediatric patients with suicidality before and during the pandemic__ amy r. zipursky, karen l. olson, louisa bode, alon geva, james jones, kenneth d. mandl, andrew mcmurry. plos one. published: november"
1,fhir-app,fhir demo model - using fhir questionnaire to build a wizard form / along with an rjsf model (incomplete),invalid encoding
0,Diabetes_Journalling_App,a smart on fhir app allowing patients to remotely share their blood sugar journals with their provider.,"# diabetes journaller this is a tool to allow diabetic patients to remotely enter their blood sugar data, allowing their provider and the patient easy, secure, and immediate access to their data. to access the tool, go to the smart app launcher for this repository: select a patient from the `patient(s)` dropdown and click `launch app!`. --- code credit: all project files were modified from georgia tech lab ---"
0,NoteX,the clinical note enhancer,"# notex - the healthcare note enhancer optimization of clinical note entry through speech recognition and dynamic data augmentation. developed as part of georgia tech master's program for - introduction to healthcare informatics. * proposal & initial design * user manual * launching application via smart on fhir ### problem in less than half of office-based physicians had adopted electronic health records (ehrs) of any kind. (office-based physician electronic health record adoption, n.d.) with the advent of the hitech act, the usage has more than doubled to nearly in on the surface this would seem like a positive trend, but physicians are not as pleased with the transition. in a survey con-ducted by the doctors company, of providers said their ehr systems re-duced efficiency and productivity. (the future of healthcare: a national survey of physicians - n.d.) for modernization of the provider office to truly meet its intended goals, the nega-tive impact of ehrs on physicians productivity and job satisfaction must be ad-dressed. the problems with ehrs continue to impede the industry and have been recognized by the united states federal government. on february the office of the national coordinator health information technology released a report titled strategy on reducing regulatory and administrative burdens relating to the use of health it and ehrs. (mason, the report echoes the problems stat-ed by providers in the survey mentioned earlier: > as ehr adoption has increased in health care settings, so too have con-cerns about the user experience. the user experience is often closely related to the usability of a health it product. poor usability can be a significant contributor to clinician burden. (strategy on reducing burden relating to the use of health it and ehrs, n.d.) one of the major goals of the report is to reduce the effort and time required to record information in ehrs for health care providers during care delivery. the report further states clinical documentation tasks in ehrs present another major challenge to clinician workflow. ### solution the notex application gives the physician or other healthcare provider an ehr ag-nostic interface to add clinical notes through a speech to text conversion process. the resulting text is further enhanced by dynamically looking up data in the ehr using keywords from the providers notes and inserting the results into the text. once the enhanced notes have been reviewed by the provider, they can be saved directly into the ehr through the notex application. this solution aligns with recommendation from the onc on optimizing clinical documentation in the previously mentioned strategy report. (strategy on reducing burden relating to the use of health it and ehrs, n.d.) the strategy recommends leverag[ing] data already present in the ehr to reduce redocumentation in the clin-ical note. #### **speech to text** microsoft azure cognitive services was utilized for speech to text translation. the integration effort was fairly straightforward by following microsofts samples. fine-tuning of the text to speech system for the wide range of healthcare-specific terms is beyond the scope of this project. there are healthcare domain-specific sys-tems available on the commercial market that could be utilized if this project was moved beyond its current scope. #### **fhir resource** one challenge was locating the fhir resource required for clinical notes. the following documentation sources were located and used to resolve this challenge: clinical notes at fhir devdays (miller, fhir documentation for clinical notes (representing clinical notes, n.d.) (argonaut clinical notes implementation guide, n.d.) (clinical notes guidance, n.d.) #### **external tools & libraries** the application was built using googles angular framework and uses the open source primeng user interface control library. it uses the fhir js client to communicate with the fhir server. the project skeleton was generated with angular cli version notex uses keyword/phrase matching to identify data candidates for fhir lookup. it uses a configuration system for linking keywords to specific fhir observations. this allows the capabilities to grow without additional coding. the configuration is described in the user manual. the application could be further enhanced with natural lan-guage processing (nlp) in the future. many aspects of security and data privacy are handled by leveraging smart on fhir. this provides a secure mechanism for authentication and data connectivity to the ehr. microsoft provides hitech and hipaa certification for their cloud services. ## developing locally ### development server run `ng serve` to start a dev server running on port the app will automatically reload if you change any of the source files. navigate to select the following: * provider ehr launch (practitioner opens the app from within an ehr) * be sure to uncheck ""simulate launch within the ehr user interface"" ### code scaffolding run `ng generate component component-name` to generate a new component. you can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`. ### adding github pages deployment run `ng add angular-cli-ghpages` ### deploying to github pages run `ng deploy` * deploys to gh-pages branch ## references argonaut clinical notes implementation guide. (n.d.). retrieved from fhir: clinical notes guidance. (n.d.). retrieved from fhir us core implementation guide: mason, a. g. february final report delivers a strategy to reduce ehr burden. retrieved from healthitbuzz: https://www.healthit.gov/buzz-blog/health-it/final-report-delivers-a-strategy-to-reduce-ehr-burden miller, m. november clinical notes. retrieved from fhir devdays office-based physician electronic health record adoption. (n.d.). retrieved from onc for hit: https://dashboard.healthit.gov/quickstats/pages/physician-ehr-adoption-trends.php representing clinical notes. (n.d.). retrieved from healthit.gov: https://www.healthit.gov/isa/representing-clinical-notes strategy on reducing burden relating to the use of health it and ehrs. (n.d.). retrieved from onc for hit: the future of healthcare: a national survey of physicians - (n.d.). retrieved from"
1,fhir-form,a simple fhir form with a local fhir server,"# app for fhir forms using a local fhir server - app for fhir forms using a local fhir server - requirements - add node.js and npm to your path - install dependencies - local fhir server - using the app - build the application - run the application - fhir form / questionnaire - creating your own fhir form - importing your fhir form this is an app mainly based on this repo that can be used to display<br> fhir<br> sdc<br> questionnaire<br> and collect data as fhir questionnaireresponse resources.<br> by building it using `docker-compose up -d` you will have access to a local fhir server that can then be used to test the app. # requirements the app relies on the lhc-forms rendering widget for displaying forms. it has partial support for fhir questionnaires (versions and and the structured data capture implementation guide.<br> this widget will be installed with the dependencies. for some sample forms to try, this repository comes with some forms under that are automatically loaded into the local fhir server at build. ## add node.js and npm to your path the file bashrc.lforms-fhir-app specifies the version of node.js we are using for development. download that version of node.js, and add its bin directory to your path. you can do on mac os : ``` brew update brew install nevermind export nvm_dir=~/.nevermind source $(brew --prefix nevermind)/nevermind.sh nevermind install nevermind use ``` to install and use node version ## install dependencies by running this command you will be able to install everything needed for the app to work. ``` npm ci ``` # local fhir server if you do not have a fhir server to try this app out, you can start and use a local fhir server powered by intersystems technologies by doing inside the `fhir-form` folder : ``` docker-compose up -d ``` after some wait, your local fhir server is up and you can access it by using note that this link is already registered in the app. # using the app to use the app you have to build it then start it.<br> you can now access any fhir server of your choice using the menu of the app but if you want you can use this local fhir server ## build the application ``` npm run build ``` this will create files for production in a ""dist"" directory, but will also copy some needed files into place from node_modules. ## run the application ``` npm run start ``` will start an http server running at port now browse to the app at here you can choose a server to connect to.<br> if you want to use the local fhir server, start the local fhir server then, on the app select the first choice # fhir form / questionnaire ## creating your own fhir form by using this online tool you can easily build your own form from scratch or using an already existing one.<br> we advise you to import one of the existing one in the folder and start from here to understand how the tool works. ## importing your fhir form using the app, you can easily import your local forms and use them right away using the `upload` button.<br><br><br> if you are using the formbuilder tool, you can, if you have a fhir server supporting the content-type 'application/json', export the form you are creating directly to the fhir server using the `export` button. if your server does not support the content-type 'application/json' but only the content-type 'application/json+fhir' for example, as our local fhir server you must `export` the form to a file, then on the app, `upload` the file to the server as the app communicate in content-type 'application/json+fhir'."
0,Vaccination,mhealth prototype for vaccination recommendation,"# mhealth proto vaccination this is a prototype app for demonstrating a vaccination recommendation tool using a rule engine (stugna-es) and resources from the ch vacd fhir implementation guide. try out the latest version of this webapp: https://mhealth-prototyp.github.io/vaccination/. use one of the test users from chapter to log in. you might also be interested in the health-professional oriented prototype app, the patient and allergy oriented prototype app and the questionnaire prototype. ## content table - about this prototype webapp - example users - epd playground - mobile access gateway - pages - home - my vaccination document - rules and settings - generate vaccination documenbt - about - creating rules - facts - rules - install and run the app - submit issues - license - changelog ## about this prototype webapp this webapp is intended to serve as a prototype around an use case with fhir questionnaires. it is able to connect to the epd playground and load a patient's vaccination record. it is also able to fetch predefined rules from an endpoint to give vaccination recommendations. ### example users since the epd playground does not support user roles and authentification, the login is mocked in this prototype. you can use one of the following example users for playing around with the prototype: <!-- prettier-ignore --> | name | login | password | personas | | -------------------- | ------------------ | ---------- | ---------- | | noah gabriel pichard | noah@pichard.ch | np | as a newborn child, noahs vaccination record is still empty. | | verena brnnimann | verena@broenni.ch| vb | verena brnnimann is an elderly woman with a lung condition (copd gold | | susanna katz | sus@katz.ch | sk | susanna katz is a young health professional. | | bruce wen | bruce@wen.ch | bw | bruce wen is an adult man that works as a bat researcher and thus is exposed to a risk of getting rabies.| ### epd playground the epd playground is a low-threshold ""test and play"" implementation of a swiss electronic health record for demonstrating key use cases of mhealth. it is a source of inspiration for developers, managers and healthcare personal in switzerland. for easier testing, no authentication is needed on the epd playground. learn more on the project page of the epd playground. ### mobile access gateway the mobile access gateway is a fhir endpoint that allows us to communicate with the epd playground using mhealth profiles. ## pages ### home on the home page, the vaccination recommendations are displayed. ### my vaccination document this page displays the vaccination doccument loaded from the epd playground. if the patient has multiple document, the most recent is shown, with the possibility to switch to another document. ### rules and settings here we can edit the rules or import rules from an endpoint. it also has an interactive diagram displaying how the rule engine facts and the vaccination recommendations are created, with examples from the current patient ### generate vaccination document on this page we can easily generate a ch vacd vaccination record document, that can then be saved to the epd playground or directly be used as the current working document. ### about the about page shows information about the project, links to the project partners and the number of the app version currently running. ## creating rules a detailes documentation of how the rules can be created (with examples) is to be found on the website of stugna-es. ### facts when creating rules, we can rely on the following facts: | name / key | type | explanation | | -------------------- | ------------------------- | --------------------------------------------------------------------------- | | gender | ""male"", ""female"", ""other"" | the patients gender | | age | integer | the patients age, in completed years | | age_in_months | integer, null | the patients age, in completed months, when the age is below two years | | vxxx_last_dose | integer, null | duration since last dose of the given vaccination, in days. | | vxxx_completed | ""true"", ""false"" | wether the vaccination was completed or not | | dxxx_last_dose | integer, null | duration since last vaccination dose for the given target disease, in days. | | dxxx_completed | ""true"", ""false"" | wether the vaccination for the given target disease was completed or not | | dxxx_number_of_doses | integer, null | number of vaccination doses given for the target disease | | rxxx | ""true"", ""false"" | does the given risk apply to the patient? | `vxxx` stands for vaccinations, where xxx has to be replaced with the coding,code. the same applies for `dxxx` for target diseases and `rxxx` for risks. ### rules how the rules can be build, is documentet at stugna-es. there are reserved words, these are: `true`, `false`, `and`, `or`, `not`, und `like` (all case sensitive). you cannot use these words for variable names. the rules are defined as followed, making `condition`, `factname` and `factvalue` the required fields for a minimal rule. ```typescript interface rule { // describe condition for adding new fact to system condition: string; // name of new fact, which will be added if condition is met. no spaces allowed. factname: string; // value of new fact, which will be added if condition is met factvalue: string | number | boolean; // short fact description for logging description?: string; // rule priority, number, optional, default value is low numbers are processed first priority?: number; // optional field with default values for missing facts. not working with precondition missing? string; // option string field with the same syntax as condition. precondition?: string; // name of new fact, which will be added if condition is not met. no spaces allowed. needs factvalueelse if present. factnameelse?: string; // value of new fact, which will be added if condition is not met. needs factnameelse if present. factvalueelse?: string | number | boolean; // each value dictates when to halt the evaluation of subsequent rules as documented in the link above final?: | | // after new rule adding, rules check procedure starts automatically (default: true) istrigger?: boolean; } ``` _keep care:_ - missing facts are assumed as ""true"" by default. if you do not want this behaviour, you have to set the parameter `missing: ""false""` to the rule. - you cannot use shortened expressions: or is not the same as = true or = true`. for helping facts, that should not end up in the end result, we have a convention: these fact names should start with `x_`, and are then ignored when displaying the rules to the user. you can have a look at some rules in the file with the default rules. ## install and run the app ### install dependencies before you can run the app, you need to install the dependencies using the node package manager. make sure you are in the root folder of the project (that contains `package.json`) and run the following command: ```bash npm i ``` ### start the app in development mode (hot-code reloading, error reporting, etc.) after installing the dependencies, the following command will build the app and start a development server. ```bash npm start ``` when the server is up and running, you can point your favorite browser to the displayed address to see the app (usually but this may differ when you are already running other servers). ### build the app for production if you want to deploy the app to a web server, you can run the following command and then just publish the content of the newly created `dist` folder. ```bash npm run build ``` ## submit issues go to the issue site of the repository to submit an issue: on github.com. ## license this software is published under a mit license. ## changelog | version | date | changes | | ------- | ---------- | ------------------------------------------- | | | | initial version uploaded to this repository |"
1,ExperienceSampler,an open-source smartphone app designed for experience sampling developed using cordova,"# experiencesampler an open-source smartphone app designed for experience sampling developed using cordova to customize experiencesampler, please see our website www.experiencesampler.com try out an experiencesampler app at https://sabrinathai.github.io/experiencesamplerdownload/. you can download a short version of an experiencesampler app that includes all the features."
1,formr.org,chain simple surveys into longer runs to build complex studies. use r to generate pretty feedback and complex designs.,"# formr survey framework #### how to cite see formr.org/public/about if you are publishing research conducted using formr. #### chain simple forms & surveys into long runs, use the power of r to generate pretty feedback and complex designs this is a framework that allows you to create simple and complex studies using items spreadsheets for the surveys and ""runs"" for chaining together various modules. the creator and most users of this software work in personality and developmental psychology, but the framework can also be used for sociological panels, simple experiments or as part of an integrated toolkit. there are three main components: surveys, runs and the r package. ## surveys #### ask questions, get data surveys are simple or complicated forms and surveys used to gather information in a single session. there is a wide variety of items to choose from: text and number inputs, likert scales, sliders, geolocation, date pickers, dropdowns and many more. they are geared towards power users, so instead of dragging and dropping elements till your fingers bleed, you upload item spreadsheets that can easily be re-used, combined and shared. ## runs #### control your study like a boombox runs enable you to link surveys and chain them together. using a number of boombox-themed control elements to control the participant's way through your study, you can design studies of limitless complexity. you can - manage access to and eligibility for a study: - use different pathways for different users: send email invites and reminders: - implement delays/pauses: - add external modules: - loop surveys and thus enable diaries and experience-sampling studies: - give custom feedback, through opencpu's r api. - randomise participants into groups for e.g. a-b-testing or experiments the following designs and many more are possible: - simple one-shot surveys - complex one-shot surveys (using skipping logic, personalised text, complex feedback - surveys with eligibility limitations - diary studies including completely flexible automated email reminders - longitudinal studies (ie. wait months after last participation or re-contact after they return from their exchange year). the items of later waves need not exist in final form at wave - longitudinal social networks and other studies that require rating a variable number of things or persons ## r package #### accompanying r package wherever you use r in formr you can also use the functions in its r package. if you want to use the package in a different environment, you will need to install it using these two lines of code. install.packages(""devtools"") devtools::install_github(""rubenarslan/formr"") the package currently has the following feature sets - connecting to formr, importing your data, correctly typing all variables, automatically aggregating scales. - easily making feedback plots e.g. ""extraversion"")` the package also has a function to simulate possible data, so you can make feedback plots ahead of collecting data. - some shorthand functions for frequently needed operations on the site: `first(cars); last(cars); current(cars); ""formr."" %contains% ""mr.""` ## opencpu + r + knitr + markdown opencpu is a way to safely use complex r expressions on the web. we use it for all kinds of stuff. in surveys, pauses, emails and pages you can display text to the user. this text is easily formatted using markdown a simple syntax that formats text nicely if you simply write like you would write a plain text email. markdown can be freely mixed with html, so you can e.g. insert icons from the font awesome library using `<i class=""fa fa-smile-o""></i>`. if you use knitr syntax, where markdown can be used, the text will not just be parsed as markdown (which is mostly static), but also be parsed (anew each time) by knitr. knitr allows for mixing r syntax chunks and markdown. r is a popular open-source statistical programming language, that you can use via opencpu, a restful interface to the language that deals with the problem that r was not meant to be used as part of web apps and is insecure. r data frames with the same names as the surveys they derive from will be available in this knitr call, they contain all data that the current user has filled out so far. combined with norm data etc. you can tailor feedback to the user's input, e.g. show where the user lies on the bell curve etc. ## installation if you want to test formr or contribute to its development, follow our instructions. the setup instructions are not suitable for production, i.e. running a secure formr installation on the public web. #### credit see formr.org/about for funding and contact info. see composer.json for the php components we use and bower.json for the javascript and css components we use."
1,alfred-messenger,here is hosted alfred the flow tester,"# alfred : the flow tester here is alfred, the flow tester created by harry jmg. ## how it works linked to a facebook page, alfred will remember you on facebook messenger to answer a few questions through a typeform.com formular. ## what questions ? the questions are my own original adaptation from the self made test ""mash-up hs du flow"" published by hacking-social.com which is a mix from the esm (experience sampling method by mihaly csikszentmihalyi) and the (flow state scale you can read about the article from hacking-social.com here. ## why do you need to answer ? the advantage of this method is to give you a fresh point of view on your own life without any judgement. you can read about the concept of flow discovered by mihaly csikszentmihalyi and how to test it respectively [here](https://en.wikipedia.org/wiki/flow_(psychology)) and here. if reading all these articles is too long for you. just try it :) ## configuration the hard part is to connect your rails app to your facebook app. the facebook-messenger gem which alfred is using has a good documentation for that. you also need to set a typeform webhook (if you want to use typeform). ## to dev for users many things are still missing to make the app better... - [ ] **add sms or other platforms support :)** - [ ] **prendre en compte la moyenne subjective pour les couleurs** - [ ] **unitary tests** - [ ] **structure flow inputs per days session** (better lisibility and ux) - [ ] **paginate flow inputs** - [ ] etc etc... if you have any ideas for this list, i invite you to open an issue and i will add it. ## to dev for admin - [ ] **an admin dashboard (recurrent users etc...)** ## any questions ? feel free to open an issue or send me an email at harry.jmg@gmail.com ## faq ### why alfred ? an old private joke for the viewers of my youtube channel (french speaking)."
1,Track,an open-source android application making use of the experience sampling method.,"the <i>track</i> app ----- the track android application has been developed as part of a joint research project between the schools of informatics and health in social science at the university of edinburgh, and is available on the google play store at https://play.google.com/store/apps/details?id=informatics.uk.ac.ed.track. the app provides emotion tracking by requesting users to fill out short surveys throughout the day, and providing visual feedback in the form of illustrative graphs. non-participants of the study can use the app to personally track their emotions and daily activities. any diary entries provided by non-participants are kept solely on their personal device and never shared with university researchers. survey configurability ----- <i>track</i> has been developed in such a way so that the survey questions are loaded dynamically from the <b>survey_json.txt</b> file supplied as a raw resources to the application. the application currently supports five different types of questions: - free-text, single-line - free-text, multiple-line - multiple-choice, multiple-answer - multiple-choice, single-answer - likert scale. the <i>tracklib</i> api can be used to generate <i>track</i>-compatible json surveys, so that researchers can use the application to run their own esm study. configuration ----- if you are supplying a custom survey_json.txt file, make sure to set this usefeedbackmodule in the <b>config.xml</b> file to ```false```, as this module contains code specifically tailored to the current survey. ``` <bool name=""usefeedbackmodule"">false</bool> ``` if you are using this application for data gathering, you will also need to update the web server details to point to your own host, so that the user responses are uploaded accordingly. ``` <!-- web service details --> <string name=""trackwebserviceurl"">http://trackserver.no-ip.org/webservice/</string> <string name=""loginwebmethod"">login.php</string> <string name=""addsurveyresponsewebmethod"">addsurveyresponse.php</string> ``` license --- copyright rachel gauci<br/> <i>this work is licensed under a creative commons attribution license.</i> acknowledgement --- <i>the research work disclosed in this publication is funded by the master it! scholarship scheme (malta). the scholarship is part-financed by the european union - european social fund (esf) under operational programme ii - cohesion policy empowering people for more jobs and a better quality of life.</i>"
1,ohmagePhone,the android ohmage app,"ohmagephone ============ **note: this repository only contains developement up to version and only required bug fixes are being backported. no new development will happen on this repo. go to ohmageandroidlib to use our new library for android** ohmage (http://ohmage.org) is an open-source, mobile to web platform that records, analyzes, and visualizes data from both prompted experience samples entered by the user, as well as continuous streams of data passively collected from sensors or applications onboard the mobile device. branches -------- * master - contains the newest changes * nih - defaults to the single campaign version and includes the newest changes and changes specific to the nih campaign including charts and the food/stress button * mobilize - mobilize version of ohmage which has mobilize branding * ptsd - ptsd version of ohmage dependencies ------------ you will need to download logprobe and make it available to ohmage as a library apk. (alternatively you could just change all logging functionality to use the default android logs instead of using probelog) all other external libraries which are needed are included in the libs directory of the project, but you will need the android sdk to build. download and install the the android sdk. instructions on downloading and installing the sdk can be found here: http://developer.android.com/sdk/installing.html. you can skip the parts related to eclipse unless you want to setup eclipse as well. start the android configuration tool using `/path/to/android-sdk/tools/android` select **sdk tools** and **sdk platform-tools** (and the usb driver if you are running on windows). under the **android (api section, select **sdk platform** and **google apis by google inc**. click install and install the packages you are ready to start building! build instructions ------------------ make sure the android sdk dependencies are installed on your system. download/clone the ohmagephone repository form github. edit any of the config information in `res/values/config.xml` such as the server, or campaign mode. go to the ohmagephone directory and run `/path/to/android-sdk/tools/android update project --path .` run the project in eclipse or build the project from the command line using `ant debug`. alternatively you can use `ant release` if you want to sign it with a release key. if compile succeeds, the .apk (application package) is in the ohmagephone/bin directory. copy it to the phone and open it to install. alternatively, if the phone is plugged in you can use `adb install bin/<apk_name>.apk` (where `<apk_name>` is the name of the apk which was shown by the ant command). testing ------- we are using a combination of robotium and calabash-android (which is basically an android implementation of cucumber). robotium tests are in the test folder and can be run as unit tests. the cucumber tests requires calabash-android to be installed. at this point this fork must be used to do the testing as it includes additional functionality not available in the main branch. clone the fork, change into the `ruby-gem` directory and run `rake install` (you might need `sudo rake install` depending on how your gems are installed.) then you can run `calabash-android build` to build the testing apk, and finally `calabash-android run` to start the tests."
1,aware-client-ios,http://awareframework.com,"## deprecated aware-client-ios has recently been deprecated. instead of aware-client-ios, a new client named is ready on github and appstore. please use the new one if you need to use the client. the sensing module on the new client is built on awareframework-ios which is a library version of aware framework for ios. in addition, all source code of the client is written in swift, so then if you are not familiar with objective-c, you can easily modify and extend the source code. ## aware framework client source code for ios (http://awareframework.com) aware is an android and ios framework dedicated to instrument, infer, log and share mobile context information, for application developers, researchers and smartphone users. aware captures hardware-, software-, and human-based data. the data is then analyzed using aware plugins. they transform data into information you can understand. ### individuals: record your own data no programming skills are required. the mobile application allows you to enable or disable sensors and plugins. the data is saved locally on your mobile phone. privacy is enforced by design, so aware does not log personal information, such as phone numbers or contacts information. you can additionally install plugins that will further enhance the capabilities of your device, straight from the client. ### scientists: run studies running a mobile related study has never been easier. install aware on the participants phone, select the data you want to collect and that is it. if you use the aware dashboard, you can request your participants data, check their participation and remotely trigger mobile esm (experience sampling method) questionnaires, anytime and anywhere from the convenience of your internet browser. the framework does not record the data you need? check our tutorials to learn how to create your own plugins, or just contact us to help you with your study! our research group is always willing to collaborate. ### developers: make your apps smarter nothing is more stressful than to interrupt a mobile phone user at the most unfortunate moments. aware provides application developers with users context using awares api. aware is available as an android library. users current context is shared at the operating system level, thus empowering richer context-aware applications for the end-users. ## author aware framework client for ios is developed by yuuki nishiyama (tokuda laboratory, sfc, keio university). also, aware framework and aware framework client (for android) were created by denzil ferreira (community imaging group, university of oulu) and his group originally. ## contributions help is welcome! if you do not know what to do, just pick one item and send me a pull request. - [x] develop the library (cocoapods) version of awareframework-ios - [x] support swift (the library version supports swift) - [ ] wirte test cases - [ ] plugin update: keyboard - [ ] plugin update: event-based esm (for ios esm) - [x] plugin update: multiple-esm interface (for ios esm) ## libraries aware framework client for ios uses following external libraries via cocoapod. - mqttkit - scnetworkreachability - google/signin - ios-ntp ## license copyright (c) aware mobile context instrumentation middleware/framework for ios (http://www.awareframework.com) licensed under the apache license, version (the ""license""); you may not use this file except in compliance with the license. you may obtain a copy of the license at unless required by applicable law or agreed to in writing, software distributed under the license is distributed on an ""as is"" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license."
0,short-message-survey,text message-based app for sending out text based experience sampling method (esm) surveys,"# short message survey *short message survey* is an app for sending out text-based esm surveys. ## overview short message survey is a python app that uses the flask web app framework. flask uses the twilio api to send out sms messages using our twilio phone numbers based on whatever criteria we set. originally this was at set times at regular intervals (e.g. every wednesday at am), but now we can also send out messages triggered by students submitting assignments. ## use case for the fall, semester for the picsul project we set up an gmail inbox for the project, and through canvas we had emails sent to the inbox every time a student submitted an assignment. then we have a function that accesses the gmail inbox and reads through the emails. for each email it finds the name of the person who submitted the assignment, and tries to find their phone number in the database. if it does then it checks to make sure the name of the assignment is correct, and that its not a re-submission, and if it clears those checks then it sends an sms to that person to initiate a survey. if its a resubmission, or the name is not found, the email is moved to trash. once the student responds to the sms that triggers the survey to begin, and the student is asked the survey questions until they are finished or five minutes has elapsed, and then it thanks them for their participation. ## example ![](screenshot.png) ## license copyright picsul permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""software""), to deal in the software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, and to permit persons to whom the software is furnished to do so, subject to the following conditions: the above copyright notice and this permission notice shall be included in all copies or substantial portions of the software. the software is provided ""as is"", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software. ## acknowledgment this material is based upon work supported by the national science foundation under grant no. any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not reflect the views of the national science foundation."
1,AWAREFramework-iOS,aware framework for ios,"# awareframework !ci [!ci status](https://travis-ci.com/tetujin/awareframework-ios) [!version](http://cocoapods.org/pods/awareframework) [!license](http://cocoapods.org/pods/awareframework) [!platform](http://cocoapods.org/pods/awareframework) aware is ios and android framework dedicated to instrument, infer, log and share mobile context information, for application developers, researchers and smartphone users. aware captures hardware-, software-, and human-based data (esm). they transform data into information you can understand. ## supported sensors and extensions ### default sensors * accelerometer * gyroscope * magnetometer * gravity * rotation * location * barometer * battery * network * call * processor * proximity * timezone * wifi * screen events * fitbit * ~~google login~~ * memory * ntptime * openweathermap * headphone motion (ios or later) ### extensions the following sensors can be used under extension(s)because these sensors need additional permission(s) into info.plist and take a review by apple. you can get detail information from here. * motion activity * pedometer * bluetooth * heartrate (ble) * microphone (ambient noise) * calendar * contact * healthkit ## installation ### (option) open xcode with **rosetta** to enable running the developed app on a **simulator** if you can develop the application with a physical device, you can skip this step. ### install awareframework-ios awareframework-ios is available through cocoapods. to install it, simply add the following line to your podfile: ```ruby pod 'awareframework', '~> ``` and run `pod install` in your xcode project. ### edit confgurations for collecting data in the background, you need to edit `info.plist` and `capabilities/background modes` in the project as follows. __[note] the following settings are a minimum condition, so then you might need to do more modification if you are using special sensors (e.g., ambient noise, healthkit, activity recognition and more). please check this link about the configuration.__ #### info.plist * privacy - location always and when in use usage description * privacy - location when in use usage description * privacy - location always usage description #### capabilities/background modes * location updates !image ### request permissions and activate awareframework to use awareframework in the project, you need to import `awareframework` into your class and request permission for accessing the ios location sensor always. after the permission is approved, you can activate `awarecore`. `awarecore`,`awarestudy` and `awaresensormanager` are singleton instances for managing sensing/synchronization schedules in the library. you can control any sensors by the way which is described in how to use session. we recommend you to activate `awarecore` at `-application:didfinishlaunchingwithoptions:launchoptions:` in `appdelegate` which is called one time when the application is launched. ```swift /// appdelegate.swift /// import uikit import awareframework /// import `awareframework` into your source code. @uiapplicationmain class appdelegate: uiresponder, uiapplicationdelegate{ override func application(_ application: uiapplication, didfinishlaunchingwithoptions launchoptions: [uiapplicationlaunchoptionskey: any]?) -> bool { //////////////////////// let core = awarecore.shared() let study = awarestudy.shared() let manager = awaresensormanager.shared() /// request permissions core.requestpermissionforbackgroundsensing{ (status) in core.requestpermissionforpushnotification(completion:nil) /// activate awarecore core.activate() /// use sensors /// edit here /// } //////////////////////// return true } } ``` ## how to use ### example initialize sensors and save sensor data to the local database just the following code, your application can collect sensor data in the background. the data is saved in a local-storage. ```swift /// (swift): accelerometer /// let accelerometer = accelerometer() accelerometer.setsensoreventhandler { (sensor, data) in print(data) } accelerometer.startsensor() manager.add(accelerometer) ``` ### example sync local-database and aware server awareframework-ios allows us to synchronize your application and aware server by adding a server url to awarestudy. about aware server, please check our website. ```swift /// (swift): accelerometer + aware server /// study.setstudyurl(""https://api.awareframework.com/index.php/webservice/index/study_id/pass"") let accelerometer = accelerometer(awarestudy: study) accelerometer.startsensor() accelerometer.startsyncdb() // or manager.add(accelerometer) ``` ### example apply settings on aware dashboard moreover, this library allows us to apply the settings on aware dashboard by using `-joinstuywithurl:completion` method. ```swift /// (swift): aware dashboard //// let url = ""https://api.awareframework.com/index.php/webservice/index/study_id/pass"" study.join(withurl: url, completion: { (settings, studystate, error) in manager.addsensors(with: study) manager.startallsensors() }) ``` ## experience sampling method (esm) this library supports esm. the method allows us to make questions in your app at certain times. the following code shows to a radio type question at and every day as an example. please access our website for learning more information about the esm. ```swift /// swift /// let schdule = esmschedule() schdule.notificationtitle = ""notification title"" schdule.notificationbody = ""notification body"" schdule.scheduleid = ""schedule_id"" schdule.expirationthreshold = schdule.startdate = date.init() schdule.enddate = date.init(timeintervalsincenow: schdule.firehours = let radio = esmitem(asradioesmwithtrigger: radioitems: [""a"",""b"",""c"",""d"",""e""]) radio.settitle(""esm title"") radio.setinstructions(""some instructions"") schdule.addesm(radio) let esmmanager = esmschedulemanager.shared() // esmmanager.removeallnotifications() // esmmanager.removeallesmhitoryfromdb() // esmmanager.removeallschedulesfromdb() esmmanager.add(schdule) ``` please call the following chunk of code for appearing `esmscrollviewcontroller` (e.g., at `-viewdidappear:`). ```swift /// swift /// let schedules = esmschedulemanager.shared().getvalidschedules() { if(schedules.count > let esmviewcontroller = esmscrollviewcontroller() self.present(esmviewcontroller, animated: true){} } ``` ### supported esm types this library supports typs of esms. you can see the screenshots from the link * text * radio * checkbox * likert scale * quick answer * scale * datetime * pam * numeric * web * date * time * clock * picture * audio * video ## example apps we are providing several example applications. you can refer, or modify these applications for your purpose. * richclient * sensingapp * simpleclient * dynamicesm * scheduleesm * customesm * customsensor * visualizer ## author yuuki nishiyama <yuukin@iis.you-tokyo.ac.jp> ## citation please cite the following paper(s) in your publications if this library helps your research. ``` @inproceedings{aware_ios, author={nishiyama, yuuki and ferreira, denzil and eigen, yusaku and sasaki, wataru and okoshi, tadashi and nakazawa, jin and dey, anind k. and sezaki, kaoru}, title={ios crowd--sensing will not hurt a bit!: aware framework and sustainable study guideline for ios platform}, booktitle={distributed, ambient and pervasive interactions}, } @inproceedings{aware_ios_in_the_wild, author = {nishiyama, yuuki and ferreira, denzil and sasaki, wataru and okoshi, tadashi and nakazawa, jin and dey, anind k. and sezaki, kaoru}, title = {using ios for inconspicuous data collection: a real-world assessment}, year = doi = booktitle = {adjunct proceedings of the acm international joint conference on pervasive and ubiquitous computing and proceedings of the acm international symposium on wearable computers}, pages = numpages = series = {ubicomp-iswc } ``` ## license awareframework is available under the license. see the license file for more info."
0,question-master,a customisable experience sampling application with a live results viewer,"# question master [!maintainability](https://codeclimate.com/github/djaustin/question-master/maintainability) a customisable experience sampling application with a live results viewer ## deployment to deploy this project, pull the docker image and run it with the appropriate environment variables to connect to a database. ### running a container the container runs on port and requires the environment variable database_url described below an example run command is: ```bash docker container run -p -e -e local_username=admin -e local_password=admin daustin/question-master:latest ``` ## run locally clone the project ```bash git clone https://github.com/djaustin/question-master.git ``` go to the project directory ```bash cd question-master ``` install dependencies ```bash yarn ``` start dependency services ```bash docker compose up ``` start the server ```bash yarn dev ``` ## database administration a postgres docker container is included in the dependency services docker-compose file referenced above. in order for prisma to connect to the database the following to a .env file: ### migration whenever you make a change to the prisma schema or you checkout a branch that has had changes made, you will need to run a database migration. this updates the database schema to reflect the prisma schema and also generates typescript types for the new schema ```bash yarn prisma migrate dev ``` ### prisma studio prisma provides a convenient web ui to view and edit the data in your database. you can run this application locally with the following command ```bash yarn prisma studio ``` ## running tests to run jest tests, run the following command ```bash yarn test ``` to run cypress tests, run the following command ```bash yarn ``` ## environment variables to run this project, you will need to add the following environment variables to your `.env.local` file `database_url`: the connection string for the database in which feedback will be stored `filepile_base_url`: the base url of a filepile installation for image storage `admin_username`: the username used for admin access to the application `admin_password`: the password used for admin access to the application `nextauth_url`: the canonical url of the application when deployed e.g. in development or https://question-master.vercel.app in production `jwt_signing_private_key`: the private key in json web key (jwk) format. this can be generated using the following command. use the *entire* returned value. e.g. ```bash npx node-jose-tools newkey -s -t oct -a ``` ## tech stack **client:** react, chakra ui **server:** nextjs, prisma ## authors - @djaustin - - @annabelkimber -"
1,MixWildGUI,mix-wild is statistical software designed to perform multilevel modeling on intensive longitudinal experience sampling data.,"======= # readme # ### what is this project about? ### mixwild (also mixed-effects modeling with intensive longitudinal data) is a desktop gui based application to easily perform multilevel mixed model analysis of intensive longitudinal data (such as experience sampling data). it has beendeveloped as a collaboration between northeastern university, university of southern california, and university of chicago. ### citation request if you have used mixwild in your data analaysis, please cite the following: dzubur, e., ponnada, a., nordgren, r. et al. mixwild: a program for examining the effects of variance and slope of time-varying variables in intensive longitudinal data. behav res ## want to try out the mixwild? ## ### download the installer ### - windows installer - macos intel installer (need rosetta on apple silicon) > note: > - mixwild maynot function the same in windows because some of the features are experimental. > - windows user please ensure that your java is upto date. > - mac users should download the mac installer. ### running a .exe file ### once downloaded, click ""open"", then hit ""run"" for the first time users, it will install the application and then run. to locate the installed application on your windows pc, please go to this path: c:\users\[username]\appdata\local\mixwild copy the installed application to a location of your choice. ## want to report a bug/issue? ## please post an issue on our github discussion group: https://github.com/reach-lab/mixwildgui/discussions > note: > - when creating an issue related to the ui, we encourage you to include the current screenshot > - when including an issue related to null values in the def file, it will be best if you can share the .def file as well as include a screenshot of the newmodel window. ## collaboration inquiry ## please contact prof. don hedeker, prof. genevieve dunton, and prof. stephen intille ## want to contribute to new gui features? ## ### clone the repo with the permissions of the admins ### https://github.com/reach-lab/mixwildgui/ ### install netbeans ### please go through this link to install netbeans:"
0,wifi-direct-shared-experience-sample,shared experience sample app that uses a wi-fi direct service discovery android native unity plug-in.,"# wifi-direct-shared-experience-sample app <table <tr> <td valign=top <img src=""readme-imgs/sharedexperiencesplash.png""> </td> <td valign=top> shared experience sample app that uses wifi direct service discovery android native unity plug-in <br/><br/> this unity c# project leverages the sample android-unity wifi direct service discovery plug-in to demonstrate a basic low-friction peer-to-peer multi-device shared experience between magic leap devices without the need for external network infrastructure. <br/><br/> the sample allows anywhere from to users, each wearing a magic leap headset, to quickly join and share in a common ar experience where they all see and manipulate a virtual model of a concept car that appears to be in the same physical location as users collaborate in their local shared space. </td> </tr> </table> ## getting started this project leverages unity and after cloning this project to your local machine, you should be able to open it, set the build target to android, <table <tr> <td valign=top <img src=""readme-imgs/setuptool.png""> </td> <td valign=top> and include the `assets|scenes|samplescene` in your build, then deploy the application to your devices. alternatively, you can just sideload the included build of the sample application apk through mlhub to your device(s) to try the sample experience, before diving into the code. </td> </tr> <tr <td valign=bottom> >note: please check out our developer portal for more details on getting started with unity projects for magic leap and if needed, for more details about setup, building, and deploying to magic leap </td> </tr> </table> ## walk through of the sample shared experience. after launching the application, a model of a concept car will appear rotating above a circular stage. <p align=""center""> <img src=""readme-imgs/caratlaunch.png"" </p> a near menu will appear within the reach of the user, with the upper half displaying a number of buttons to perform the basic indirect interactions available to control the car model. the lower portion of the menu contains a `shared experience` button that toggles the display of the wifi direct control window. <p align=""center""> <img src=""readme-imgs/menuatlaunch.png"" </p> ### establishing a common origin the circular stage has been designed as a simple way to estatablish a main reference point or origin in this ar experience. <p align=""center""> <img src=""readme-imgs/stagerotate.png"" </p> each participant should select, move, and orient the stage in their application to an agreed point in their physical space. by moving the stage to an agreed upon location in the shared physical world, such as a corner of a table, and rotating the stage so that the green indicator points to an agreed particular wall or location in the local physical space, this sample demonstrates one way to create a common origin between all devices so that the central objects, like the car in this sample, can be rendered into the real world and appear at the same physical location and orientation as seen from each of the devices in the shared experience. other options for establishing a common shared origin, such as having each device scan a staticly placed printed aruco marker into the physical scene, are not demostrated in this sample but are left as potential experiments or explorations to extend or enhance this sample. ### connecting peer-to-peer over wifi direct <p align=""center""> <img src=""readme-imgs/wifidirectcontrolwindowatlaunch.png"" </p> the wifi direct control window provides the option to either: `host service` - establish and broadcast a wifi direct service for other devices to discover and connect to. or to `discover` - search for available and compatible wifi direct services in the local area. any one of the devices running the sample application that are going to participate in a shared experience can act as the service session host. to start a shared session, one of the users first needs to press the `host service` button on their device, then the other users can click the `discover` button on their devices, and the host service should appear in the list of available services shortly thereafter. >note: it can sometimes take a few minutes for the service to appear depending on a number of factors, including the previous state and activity of the devices being used. <table <tr> <td valign=top <img src=""readme-imgs/hostingservice.png""> </td> <td valign=top <img src=""readme-imgs/discoveredservice.png""> </td> </tr> </table> clicking on the service in the list of available services (from the device doing `discovery`) will initiate a connection. like discovery, connecting can also be almost instant, or take a minute or two, depending on the previous state of the devices. the session host will initially receive, and need to confirm, an `invitation to connect` to authorize that the peer is trusted, prior to the connection being established. >note: after the first time connecting, the authorization gets cached, but occassionally may appear on future connection attempts depending on elapsed time and device state. <p align=""center""> <img src=""readme-imgs/connectinvitation.png"" </p> the host device will list each peer that is connected under the `host service` button with a connection icon to the right. <img src=""readme-imgs/connected.png"" align=right the peer will show the connected icon on the right end of the associated discovered service button. the near menu on both devices should update the wifi direct service section with the appropriate connection information and highlight the section in green to indicate an active connection. <table <tr> <td valign=top <img > </td> <td valign=top <img src=""readme-imgs/connectedpeer.png""> </td> </tr> </table> ## using this sample project as a staring point for a new project. something as simple as deleting the `conceptcar` model, importing a new model into the project, and placing it under the gameobject in the scene `hierachy` can be an easy and quick way to generate a new and different shared experience. adjust the postion of your new model on the presentation stage and fit the box colider on the to the new shape. if your new model consists of a number of distinct parts, you could drag and drop certain parts into the `model controller`'s `hideable parts list` and adjust the text and symbol displayed for the `action button windows`, or just remove or change the functionality of the button accordingly, and continue to customize or modify the experience as you see fit. when using this sample project as a form of template or as a starting point to create a new shared experience project, it is recommended that after cloning or copying the initial project files to a local machine, and before starting to edit/change the project, to first change the application name in the project settings: `edit|project settings...|player|product name` <img src=""readme-imgs/productname.png""><br> and it also helps to adjust the package name of the project to be different and unique to avoid conflicting with applications with the same package name. `edit|project settings...|player|other|identification|package name` <img src=""readme-imgs/packagename.png""><br> this sample uses the application.productname string as the wi-fi direct service name that will get broadcast and discovered by the application. having a unique package name and service name for each new shared experience application will help avoid issues with different projects trying to install over top of each other, as well as unintended compatibility issues that could occur with users of different shared experience applications making inadvertent or unsupported connections between unrelated applications due to them having the same service name. >note: it is also possible to adjust the `setservicename` call and pass something other than `application.productname` in order to create a new and appropriate wi-fi direct service name for a new application. ## the objects in the sample shared experience. ### <img src=""readme-imgs/caratlaunch.png"" align=right this is the main virtual content that is the focus of the sample shared experience. the attached `object manipulator` and `bounds control` components provide a simple way for the user to interact with and manipulate the ### presentationstage <img src=""readme-imgs/stagerotate.png"" align=right this virtual stage serves as a location that the virtual is presented on top of, or in relationship to. the location of the stage also serves as a common origin between devices during connected experiences. if each user initially moves and aligns the stage to an agreed upon common location in the real world (for example the corner of an actual particular table top that happens to be in the physical surroundings) that will result in all users in the shared experience seeing the virtual located at and or moving through the same location in the physical space that they share. ### nearmenubase <img src=""readme-imgs/menuatlaunch.png"" align=right a `nearmenubase` virtual ui element will follow the user as they move about. it is not a shared element of this sample experience, and can be dragged by the drag bar to pin it to a convenient location in each user's personal environment. serving as the main menu for the experience, it consists of two fundamental rows. * the first row contains four buttons that trigger indirect interactions with the to `reset` position and orientation, toggle on/off model `rotation`, toggle on/off elements (`windows open`) of the and trigger the to scale to its `fullsize`. * the second row displays summary wifi direct service details and contains a button to toggle on/off `shared experience` `wifidirectmenu` for establishing wifi direct connections with other devices that are running this same sample application in your local area. although each user will see their own independant view of their own virtual `nearmenubase` menu, the state of toggle buttons on the first row (and only those indirect interaction buttons) will get updated during a shared experience based on the other user's interactions with the same buttons on their own menus. ### wifidirectmenu <img src=""readme-imgs/wifidirectcontrolwindowatlaunch.png"" align=right another virtual ui element that is not shared in this sample experience is the `wifidirectmenu`. it can be toggled on/off from the right-hand side of the second row of the `nearmenubase`. this virtual wifi direct window displays the device name identity that will be shared with other peers beside the window heading. the `host service` section provides a way to establish and brodcast a wifi direct service that other devices can discover and connect to. typically, only one of the users in the shared experience would volunteer or be designated to host a service. as other devices sucessfully connect to the service, their device names will appear in the list in the host service portion of the window. the remaining participants involved in the shared experience would wait until after the designated host has started their service and then use their `discover` button to discover that service. it can take a moment or two, but once the service is discovered, it will appear on a button with the name of the service displayed on it in a list in the discover portion of the window, and clicking the button will initiate a connection request with the the host service. after the host accepts the invite to connect and the connection is established, a small icon indicating the connection will appear on the button. ### wifidirectpluginmanager unlike the previously listed objects in the scene hierachy that display some form of visual virtual content to the user, manager objects like the `wifidirectpluginmanager` mostly act as a container for a script component that manages some aspect of application logic in the scene. in this case, this manager contains the `wifidirectpluginscript.cs` component mentioned below. ### sharedexperiencemanager similar to the manager component mentioned above, the `sharedexperiencemanager` does not display any visual virtual content to the user and is a simple container for the `sharedexperiencescript.cs` components described below. ## the scripts in the sample shared experience. ### modelcontroller.cs attached as a component of the object.<br/> this component implements the button-based, indirect interaction, functionality to `reset`, `rotate`, make `fullsize`, and to show/hide the togglable model elements (`windows open`). the associated buttons on the `nearmenubase` trigger methods from this script. ### sharedexperiencescript.cs attached as a component of the `sharedexperiencemanager` object.<br/> this component manages the sharing and processing of user interactions with and from other connected devices and connects to the `nearmenubase` and the main in the user interface to monitor and invoke shared interactions. communication of this shared information to and from other devices is handled via the referenced `wifidirectpluginmanager`. all shared positional information is calculated as relative to the `stage`, which acts as a common world origin. ### wifidirectpluginscript.cs attached as a component of the `wifidirectpluginmanager` object.<br/> this component manages communication with the wifi direct plugin and connects to the `wifidirectmenu` and wifi direct service portion of the `nearmenubase` in the user interface to display information to the user and to respond to user input. ## forums if you have questions that are not covered here, please check the magic leap developer forum: https://forum.magicleap.cloud/ ## credits this sample application contains the model conceptcar by unity fan licensed under cc by # copyright copyright (c) magic leap, inc. all rights reserved. use of this file is governed by the developer agreement, located here:"
0,nbackexpsampling,forced choice task with experience sampling,"# two force choice n-back paradigm based on the task developed by konish et al., i am working on a enhanced verison of the task. the task uses a n-back memory paradigm intending to induce mind-wandering. reference: konishi, m., mclaren, d. g., engen, h., & smallwood, j. shaped by the past: the default mode network supports cognition that is independent of immediate perceptual input. plos one, please see the summary of the paradigmn here project organization ------------ license readme.md <- the top-level readme for developers using this project. settings.py <- enviromnetal setting of the task. run.py <- the main experiment program. example_trial_generator.py | <- the example of the trial generator. instructions <- instructions .txt files. data <- data generated from the task. read-only. parameters <- trial generation specification files. references <- supplemental details of the paradigmn. src <- source code for use in this project. stimuli <- stimulus photos and experience sampling questions ## dependency the current version was tested on: python psychopy ## running the task execute run.py through commend line: `python run.py` # modifying the length of the experiment currently the experiment length, probe number, condition order are set through files in `parameters` and module `datastructure`. the content of `parameters/conditionsspecifications_es.csv` determine the condition switching structure. the current file populate a design of two blocks, starting with a zero-back block, and two type of go trials. please see `example_trial_generator.py` for details related to the module `datastructure`. ## modifying experience sampling questions change the questions/scales/lable in `stimuli/es_questions.csv`. please leave the headers untouch. ## modifying instructions '#' is used as page breaker. the text in between curly breackates {} changes in the experiment. please do not modify the text inside the breakets. ## modifying mri related setting this script supports the buttom boxes set-up in york neuroimaging centre. the two buttom boxes are mapped to number to and to on a regular keyboard. number is linked to mri trigger setting. if your neuroimaging centre uses the same set up, there is no need to modify the code. if you use parallel port, please contact your local support to find out the setting and modify the code yourself. the dummy volumes are accounted for in the scanner used at york. if you require manual set up, please modify the variable in `run.py` accordingly. or write a parallel port module fitting your own setup to map respond buttons to key to (highly recommended.)"
0,iOS-Landmarks-tutorial,experience sampling app,# ios-landmarks-tutorial following along with the swiftui tutorials here: https://developer.apple.com/tutorials/swiftui/creating-and-combining-views
1,esm-bot,this chatbot conducts experience sampling surveys for you via telegram messenger!,"# experience sampling bot for telegram messenger the **experience sampling method (esm)** is a research methodology to gather information about participants of a study over time. participants are asked to report their thoughts, feelings, behaviour on multiple occasions during the day over a longer period of time. this method can be applied in **clinical contexts** e.g., for testing a medication and its effects during the day. esm based studies often require additional devices and a lot of paper work for participants as well as researchers. there may also be native applications for mobile devices on the market, but as a consequence participants need to install an additional application which they need only temporarily. therefore, this project uses **instant messaging (i am)** and conducts the study via a messaging service. **telegram** was choosen for this project because of its open bot api. this chatbot conducts a signal-contigent experience sampling study via telegram and provides open or closed questions, the participants need to answer. ## system overview this overview shows the high-level interacting components of the bot program: !system overview ## getting started before starting make sure to have fulfilled all the prerequisites: ### prerequisites * latest stable node version installed * latest stable mongodb version installed * create your bot on telegram via the botfather * valid authorization token from botfather (how do i create a bot: https://core.telegram.org/bots) * preferred ide: visual studio code ### getting started on linux insert authorization token into the respective variable in bot.js. start your local instance of a database via `sudo systemd start mongod`. start the bot program via `node bot.js`. search the bot on telegram with the created name. press **start** to start the study. as mentioned below the study consists of three parts. so first, the demographic data will be asked, then the main part will start. ### getting started on windows on windows, the same steps as above need to be performed except step since starting the mongodb instance is a little different. here, first start the server *mongod* then *mongo* executable. ### customize questions the current implementation of this bot conducts a survey regarding the availablility of participants. in order to perform a different kind of esm study, the questions and answer possibilities can be replaced or adjusted to personal needs. ## context: availability study this project was part of my bachelor thesis where the use case was to conduct a esm study for the availability of participants during the day. availability in this context means the availability to consider taking phone calls or answering text messages during the day. by starting the chatbot, a survey consisting of three parts will be conducted: ### method the experiment method consists of three main parts and was conducted completely by the bot itself: part demographical data** as in any survey, first the demographical data is collected such as age, gender, job, etc. of the participant. in addition, also the desired time frame of when to receive questions was asked and set, since people may work on night shifts during the study. one limitation is that the time range can only set once in the beginning and cannot be changed during the study. part main part/esm cycle** the main part consists of repeating questions during the day for a period of days. during the day participants will be asked the same questions to different points in time to get their emotions at that point of time. the repeating questions include: * how available are you at the moment for family/friends? * how available are you at the moment for colleagues/fellow students? * how available are you at the moment for other contacts? * where are you at the moment? * your current task is mostly related... part satisfaction survey** after the study was conducted the particpants got asked about the over satisfaction with the chatbot (or the app, in the control group). ### evaluation the same study set up was done for a control group using a native smartphone application and the experience with both modalieties (app vs. i am) was evaluated. ### deployment the application in the context of the thesis evaluation was deployed on a linux server via *screen* tool. of course, cloud-based options such as heroku, aws, etc. may also be applicable. ## database model for object modeling **mongoose** was used. therefore first a schema needs to be defined, in order to create a model from it. a model is a class with which documents can be constructed. !schema diagram ## session handling multi -user support ## license this project is licensed under the mit license. ## acknowledgments thanks to mullwar for providing the great telebot api: https://github.com/mullwar/telebot/."
1,mind-rate,a system for research using experience sampling method,"# mind rate mind rate is an interactive system with an android app and a server side for research using the experience sampling method (esm). this repository is part of the mind rate project, containing the develop documentation (in german) and the android-app side code. the server side code is here. mind rate is a software development practice made by students of karlsruhe institute of technology, under instructions of ms. anja exler and ms. dr. andrea schankin from the teco research group."
0,ScreenLife,screenlife system for collecting and analysing experience sampling data,# screenlife the screenlife system uses the following components for collecting and analysing experience sampling data. - dmpo - cloud-functions
1,experiencesampler-jsPsych,"experience-sampling extension for jspsych framework, developed for android compatible with and ios","# experiencesampler-jspsych *experience-sampling extension for jspsych framework developed for android compatible with and ios an open-source smartphone app designed for experience-sampling studies, integrated into <a target=""_blank"">jspsych app development code and documentation based on the open-source **<a href=""http://www.experiencesampler.com/"" target=""_blank"">experiencesampler</a>** scaffold developed by sabrina thai and liz page-gould (see paper). built on javascript, and cordova, an open-source library that allows javascript to access native device functions. data storage is accomplished using google's (basically free) <a href=""https://firebase.google.com/"" target=""_blank"">firebase</a> cloud firestore and, additionally as a backup, the <a href=""https://pipe.jspsych.org/"" target=""_blank"">datapipe api</a> for jspsych which sends your data directly to osf."
1,survey_scheduler,a node.js app to schedule texts for experience sampling studies,"# survey scheduler a node.js app to schedule texts for experience sampling studies. <img src='docs/icon.png' ## demo the demo study is a disintegrated version of the interface, which can be used to test the interface. participants can be added to the demo study individually through the add or edit menu, or automatically generated by specifying an **n** parameter in the url; e.g., generated participants are based on the default settings in the add or edit > participant menu, which are update when changed -- change the day or time ranges, or protocol settings, and these will be applied to newly generated participants. clear local storage (menu > clear storage), or change the specified **n** and refresh to generate new participants. ## status codes beeps have associated status codes to keep track of scheduling: _missed_ set when a pending beep is outside of its open window. _pending_ set when a beep is scheduled; only pending beeps are ever sent. _sent_ set when a beep has been sent. _reminded_ set when a reminder for a sent beep has been sent. _send_received_ set after a beep has been sent, and a checkin with access has been received within the beep's window. _remind_received_ set after a reminder has been sent, and a checkin with access has been received within the beep's window. _pause_ set from the client, to prevent a passing beep from being sent. _skipped_ set when a paused beep has passed. outside of status codes, a beep might be colored a darker blue when it is the next pending beep to be sent, or black when a beep in the timeline is hovered over. if delivery status logging is set up, beeps that were successfully sent to sns (of status _sent_ or _reminded_) but not successfully delivered to the phone (as notified by lambda) are marked by an asterisk (**\***), and provider responses are displayed when the beep is hovered over. # running the app the app has these requirements: node.js (tested on version a single, stable environment for scheduling. the app schedules beeps locally, so it has to be running when a beep is meant to be sent. each time the app is started, it will initially schedule beeps upcoming within a week. if multiple instances of the app are running, beeps may be sent multiple times. ability to receive http requests for checkins from the survey. the easiest way to run the app may be from amazon's elastic beanstalk, but the app does require a secured connection for cognito's callback, which is easiest to set up with a load balancer on elastic beanstalk. another simple hosting option is google's app engine, but it will sometimes maintain multiple instances by default, so that may be something to manage. ## services the app uses these amazon web services (aws): **cognito**: to manage user accounts. from the cognito console, make create a user pool in policies, select only allow administrators to create users in app clients, add an app client, and check only enable srp create pool create an initial, administrative user with general settings > users and groups > create user set up the app client in app integration > app client settings: under enabled identity providers, check cognito user pool in sign in sign out urls, enter your url, with /auth appended to the callback url (e.g., for testing) in oauth check authorization code grant and aws.cognito.signin.user.admin **dynamodb**: to store study information and participant details. **sns**: to send the sms messages. #### aws access the app needs aws access to run these services, which can be set up through iam: add user name whatever, and check programmatic access select attach existing policies directly, and add these policies: - amazoncognitopoweruser - amazondynamodbfullaccess - amazonsnsfullaccess add the access key id and secret access key to a ""credentials"" file in, e.g., c:/users/name/.aws: ``` [default] aws_access_key_id = access key id aws_secret_access_key = secret access key ``` alternatively, if the app is running on a service with an iam role, these policies can be attached to the role rather than a user. ### delivery status logging by default, the app receives a message's id when successfully sending it to sns, but does not know if the message was successfully sent to the phone (the message's delivery status). to get delivery information, you can set up delivery status logging in sns, and a lambda function to send logged information to the app: enable delivery status logging in sns: - mobile > text messaging (sms) > edit text messaging preferences > delivery status logging create a lambda function: - function > create function - author from scratch - name whatever - node.js runtime - create function in the designer section, add trigger: - cloudwatch logs trigger - in the log group dropdown, you should see a directpublishtophonenumber/failure group - you can also add the directpublishtophonenumber group to receive all delivery responses - name whatever, other options default copy in functions/delivery_notifications.js as the function's code, replacing the hostname with your url, then save. ### qualtrics the app is set up with qualtrics in mind, though other platforms could be used. the app sends survey links with an added participant id parameter, which the survey would need to extract in order to associate participants with responses through the link. in qualtrics, you can get this by setting an embedded data variable matching the protocol's specified id parameter: in a survey, select survey flow add an embedded data element from the add a new element here menu create new field matching your id parameter (e.g., ""id""), and leave its value blank. qualtrics can also checkin with the app when the survey is accessed: in a survey, select survey flow add a web service element from the add a new element here menu enter your url appended with /checkin set method to post add a body parameter, and set its body parameters to application/json, parameter to your id parameter, and set a string to the extracted id via piped text (e.g., ${e://field/id}) if you want the checkin to also update the corresponding beep's status and access count, add a body parameter called ""access"" with a boolean value of true. the ""access"" parameter can be used to separate an availability check from a status and accessed count update. for example, you might place a web services element without an ""access"" parameter at the start of the survey, and use it to gate access to the survey (if the survey is visited outside of a beep window, or more than allowed accesses), then add another web services element with an ""access"" parameter after the survey has been started. this would help avoid response time or loading issues in the case of limited allowed accesses (e.g., if the checkin goes through but the survey fails to fully load or receive a response in time, the survey can be refreshed without counting as another access). finally, add embedded data..., and set a value for available, accessed, day, days, beep, and beeps ![](docs/example_webservice.png) if the app recognizes the id, it responds with an object like this: ```javascript { available: ""true"", accessed: day: days: first_of_day: ""true"", beep: beeps: } ``` here, available is based on the most recently passed beep and the associated protocol's allowed accesses and close after settings. that is, available will be true if a beep had been accessed fewer than allowed accesses, and was sent no longer ago than the associated protocol's close after setting (or the associated protocol has no close after setting). this information can be used from within qualtrics to regulate access or condition questions on schedule status. for example, adding this as a question's javascript would prevent proceeding if available is false, and otherwise display schedule information: ```javascript qualtrics.surveyengine.addonload(function () { var message = $('message'), id = '${e://field/id}', response = { first_of_day: '${e://field/first_of_day}', available: '${e://field/available}', accessed: '${e://field/accessed}', beeps: '${e://field/beeps}', beep: '${e://field/beep}', days: '${e://field/days}', day: '${e://field/day}', } this.disablenextbutton() if (id !== '' && response.available === 'true') { message.innertext = 'participant ' + id + '; survey ' + response.beep + ' of ' + response.beeps + ' for day ' + response.day + ' of ' + response.days + ', accessed ' + response.accessed + ' times. this was ' + (response.first_of_day === 'true' ? '' : 'not ') + 'their first access of the day.' this.enablenextbutton() } }) ``` here, message refers to an html element in the question's body, with ""message"" as its id, e.g.: ```html <p id=""message"">wait for a text to complete this survey.</p> ``` ## environment variables server.js uses these environment variables: - **port**: the port the server listens to; often or - **region**: aws region, e.g., - **userpool**: cognito pool id, from user pool > general settings - **client**: cognito app client id, from user pool > app integration > app client settings - **domain**: cognito domain, from user pool > app integration > domain name - **redirect**: url set as the callback in user pool > app integration > app client settings; server.js assumes this is /auth - **admin**: username of an initial user set up through user pool > general settings > users and groups > create user; this user has full access to all studies; additional, study specific users should be created through the interface - **notifications**: optional topic for notifications about status updates and/or missed beeps; arn from sns > topics > created topic - **doublecheck_freq**: optional frequency in minutes to scan the local schedule for passed beeps that are still marked as pending (uncaught, missed beeps). if these beeps are caught in time, they will be sent. if any beeps are caught, they will be reported to the notifications topic. - **report_hour**: optional hour (in the server's time) at which to send a daily status report to the notifications topic, including number of sent and responded to, or skipped beeps. a report will only be sent if there were scheduled beeps since the last scheduled report, or since the app was started."
0,ESIR_portal,shiny app for the esm item repository,"<!doctype html> <html> <head> <meta /> <meta name=""generator"" content=""pandoc"" /> <meta http-equiv=""x-ua-compatible"" content=""ie=edge"" /> <title>readme</title> <script>// pandoc adds attributes on both header and div. we remove the former (to // be compatible with the behavior of pandoc < document.addeventlistener('domcontentloaded', function(e) { var hs = document.queryselectorall(""div.section[class*='level'] > :first-child""); var i, h, a; for (i = i < hs.length; i++) { h = hs[i]; if continue; // it should be a header a = h.attributes; while (a.length > } }); </script> <script>/*! jquery | (c) openjs foundation and other contributors | jquery.org/license */ !function(e,t){""use strict"";""object""==typeof module&&""object""==typeof new error(""jquery requires a window with a document"");return t(e)}:t(e)}(""undefined""!=typeof window?window:this,function(c,e){""use strict"";var t=[],r=object.getprototypeof,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},you=t.push,i=t.indexof,n={},o=n.tostring,v=n.hasownproperty,a=v.tostring,l=a.call(object),y={},m=function(e){return""function""==typeof e&&""number""!=typeof e.nodetype&&""function""!=typeof e.item},x=function(e){return b(e,t,n){var r,i,o=(n=n||e).createelement(""script"");if(o.text=e,t)for(r in c)(i=t[r]||t.getattribute&&t.getattribute(r))&&o.setattribute(r,i);n.head.appendchild(o).parentnode.removechild(o)}function w(e){return null==e?e+"""":""object""==typeof e||""function""==typeof e?n[o.call(e)]||""object"":typeof e}var new s.fn.init(e,t)};function p(e){var t=!!e&&""length""in in s.call(this)},get:function(e){return t=s.merge(this.constructor(),e);return t.prevobject=this,t},each:function(e){return s.each(this,e)},map:function(n){return this.pushstack(s.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushstack(s.apply(this,arguments))},first:function(){return this.pushstack(s.grep(this,function(e,t){return this.prevobject||this.constructor()},push:you,sort:t.sort,splice:t.splice},s.extend=s.fn.extend=function(){var a&&(l=a,a=arguments[s]||{},s++),""object""==typeof a||m(a)||(a={}),s===you&&(a=this,s--);s<you;s++)if(null!=(e=arguments[s]))for(t in new error(e)},noop:function(){},isplainobject:function(e){var t,n;return!(!e||""[object object]""!==o.call(e))&&(!(t=r(e))||""function""==typeof(n=v.call(t,""constructor"")&&t.constructor)&&a.call(n)===l)},isemptyobject:function(e){var t;for(t in for(r in e},makearray:function(e,t){var n=t||[];return null!=e&&(p(object(e))?s.merge(n,""string""==typeof e?[e]:e):you.call(n,e)),n},inarray:function(e,t,n){return e.length=i,e},grep:function(e,t,n){for(var r},map:function(e,t,n){var for(o in e)null!=(i=t(e[o],o,n))&&a.push(i);return symbol&&(s.fn[symbol.iterator]=t[symbol.iterator]),s.each(""boolean number string function array date regexp object error symbol"".split("" ""),function(e,t){n[""[object ""+t+""]""]=t.tolowercase()});var d=function(n){var regexp(m+""+"",""g""),$=new regexp(""^""+m+""+|((?:^|[^\\\\])(?:\\\\.)*)""+m+""+$"",""g""),_=new regexp(""^""+m+""*,""+m+""*""),z=new regexp(""^""+m+""*([>+~]|""+m+"")""+m+""*""),you=new regexp(m+""|>""),x=new regexp(f),v=new regexp(""^""+i+""$""),g={id:new regexp(""^#(""+i+"")""),class:new regexp(""^\\.(""+i+"")""),tag:new regexp(""^(""+i+""|[*])""),attr:new regexp(""^""+w),pseudo:new regexp(""^""+f),child:new regexp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+m+""*(even|odd|(([+-]|)(\\d*)n|)""+m+""*(?:([+-]|)""+m+""*(\\d+)|))""+m+""*\\)|)"",""i""),bool:new regexp(""^(?:""+r+"")$"",""i""),needscontext:new regexp(""^""+m+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+m+""*((?:-\\d)?\\d*)""+m+""*\\)|)(?=[^-]|$)"",""i"")},y=/html$/i,q=/^(?:input|select|textarea|button)$/i,j=/^h\d$/i,k=/^[^{]+\{\s*\[native \w/,z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ee=/[+~]/,te=new se(t,e,n,r){var n;if(a.id===i)return n.push(a),n}else if(f&&(a=f.getelementbyid(i))&&y(e,a)&&a.id===i)return h.apply(n,e.getelementsbyclassname(i)),n}if(d.qsa&&!n[t+"" ""+xe(l[o]);c=l.join("","")}try{return ue(){var r=[];return function e(t,n){return r.push(t+"" "")>b.cachelength&&delete e[r.shift()],e[t+"" ""]=n}}function le(e){return ce(e){var fe(e,t){var n=e.split(""|""),r=n.length;while(r--)b.attrhandle[n[r]]=t}function pe(e,t){var de(t){return function(e){return""input""===e.nodename.tolowercase()&&e.type===t}}function he(n){return function(e){var t=e.nodename.tolowercase();return(""input""===t||""button""===t)&&e.type===n}}function ge(t){return function(e){return""form""in e?""label""in e.parentnode?e.parentnode.disabled===t:e.disabled===t:e.isdisabled===t||e.isdisabled!==!t&&ae(e)===t:e.disabled===t:""label""in e&&e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&&(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&&""undefined""!=typeof e.getelementsbytagname&&e}for(e in d=se.support={},i=se.isxml=function(e){var t=e&&e.namespaceuri,n=e&&(e.ownerdocument||e).documentelement;return!y.test(t||n&&n.nodename||""html"")},t=se.setdocument=function(e){var t,n,r=e?e.ownerdocument||e:p;return a.appendchild(e).appendchild(c.createelement(""div"")),""undefined""!=typeof e.queryselectorall&&!e.queryselectorall("":scope fieldset div"").length}),d.attributes=ce(function(e){return e.classname=""i"",!e.getattribute(""classname"")}),d.getelementsbytagname=ce(function(e){return e.appendchild(c.createcomment("""")),!e.getelementsbytagname(""*"").length}),d.getelementsbyclassname=k.test(c.getelementsbyclassname),d.getbyid=ce(function(e){return a.appendchild(e).id=s,!c.getelementsbyname||!c.getelementsbyname(s).length}),d.getbyid?(b.filter.id=function(e){var t=e.replace(te,ne);return function(e){return e.getattribute(""id"")===t}},b.find.id=function(e,t){if(""undefined""!=typeof t.getelementbyid&&e){var n=t.getelementbyid(e);return n?[n]:[]}}):(b.filter.id=function(e){var n=e.replace(te,ne);return function(e){var t=""undefined""!=typeof e.getattributenode&&e.getattributenode(""id"");return t&&t.value===n}},b.find.id=function(e,t){if(""undefined""!=typeof t.getelementbyid&&e){var t.getelementsbytagname?t.getelementsbytagname(e):d.qsa?t.queryselectorall(e):void r}return o},b.find.class=d.getelementsbyclassname&&function(e,t){if(""undefined""!=typeof t.getelementsbyclassname&&e)return t.getelementsbyclassname(e)},s=[],v=[],(d.qsa=k.test(c.queryselectorall))&&(ce(function(e){var t;a.appendchild(e).innerhtml=""<a id='""+s+""'></a><select id='""+s+""-\r\\' msallowcapture=''><option selected=''></option></select>"",e.queryselectorall(""[msallowcapture^='']"").length&&v.push(""[*^$]=""+m+""*(?:''|\""\"")""),e.queryselectorall(""[selected]"").length||v.push(""\\[""+m+""*(?:value|""+r+"")""),e.queryselectorall(""[id~=""+s+""-]"").length||v.push(""~=""),(t=c.createelement(""input"")).setattribute(""name"",""""),e.appendchild(t),e.queryselectorall(""[name='']"").length||v.push(""\\[""+m+""*name""+m+""*=""+m+""*(?:''|\""\"")""),e.queryselectorall("":checked"").length||v.push("":checked""),e.queryselectorall(""a#""+s+""+*"").length||v.push("".#.+[+~]""),e.queryselectorall(""\\\f""),v.push(""[\\r\\n\\f]"")}),ce(function(e){e.innerhtml=""<a href='' disabled='disabled'></a><select disabled='disabled'><option/></select>"";var regexp(v.join(""|"")),s=s.length&&new regexp(s.join(""|"")),t=k.test(a.comparedocumentposition),y=t||k.test(a.contains)?function(e,t){var n=!e.comparedocumentposition-!t.comparedocumentposition;return pe(e,t);n=e;while(n=n.parentnode)a.unshift(n);n=t;while(n=n.parentnode)s.unshift(n);while(a[r]===s[r])r++;return se(e,null,null,t)},se.matchesselector=function(e,t){if(t(e),d.matchesselector&&e&&!n[t+"" ""]&&(!s||!s.test(t))&&(!v||!v.test(t)))try{var n=b.attrhandle[t.tolowercase()],r=n&&d.call(b.attrhandle,t.tolowercase())?n(e,t,!e):void void new error(""syntax error, unrecognized expression: ""+e)},se.uniquesort=function(e){var you=null,e},o=se.gettext=function(e){var e.textcontent)return e.textcontent;for(e=e.firstchild;e;e=e.nextsibling)n+=o(e)}else e.nodevalue}else while(t=e[r++])n+=o(t);return e.nodename&&e.nodename.tolowercase()===t}},class:function(e){var t=m[e+"" ""];return t||(t=new regexp(""(^|""+m+"")""+e+""(""+m+""|$)""))&&m(e,function(e){return t.test(""string""==typeof e.classname&&e.classname||""undefined""!=typeof e.getattribute&&e.getattribute(""class"")||"""")})},attr:function(n,r,i){return function(e){var t=se.attr(e,n);return ""+t.replace(b,"" "")+"" t,a=b.pseudos[e]||b.setfilters[e.tolowercase()]||se.error(""unsupported pseudo: ""+e);return n,r=a(e,o),i=r.length;while(i--)e[n=p(e,r[i])]=!(t[n]=r[i])}):function(e){return s[s]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&&(e[a]=!(t[a]=i))}):function(e,t,n){return function(e){return v.test(n||"""")||se.error(""unsupported lang: ""+n),n=n.replace(te,ne).tolowercase(),function(e){var t=n.location&&n.location.hash;return e===a},focus:function(e){return t=e.nodename.tolowercase();return""input""===t&&!!e.checked||""option""===t&&!!e.selected},selected:function(e){return j.test(e.nodename)},input:function(e){return q.test(e.nodename)},button:function(e){var t=e.nodename.tolowercase();return""input""===t&&""button""===e.type||""button""===t},text:function(e){var e}),odd:ve(function(e,t){for(var e}),lt:ve(function(e,t,n){for(var e}),gt:ve(function(e,t,n){for(var me(){}function xe(e){for(var r}function be(s,e,t){var you=e.dir,l=e.next,c=l||you,f=t&&""parentnode""===c,p=r++;return we(i){return te(e,t,n,r,i){for(var a}function ce(d,h,g,v,y,e){return v&&!v[s]&&(v=ce(v)),y&&!y[s]&&(y=ce(y,e)),le(function(e,t,n,r){var i,o,a,s=[],you=[],l=t.length,c=e||function(e,t,n){for(var p=te(p===t?p.splice(l,p.length):p),y?y(null,t,p,r):h.apply(t,p)})}function ee(e){for(var r=!o&&(n||t!==w)||((i=t).nodetype?you(e,t,n):l(e,t,n));return i=null,r}];s<r;s++)if(t=b.relative[e[s].type])c=[be(we(c),t)];else{if((t=b.filter[e[s].type].apply(null,e[s].matches))[s]){for(n=++s;n<r;n++)if(b.relative[e[n].type])break;return we(c)}return me.prototype=b.filters=b.pseudos,b.setfilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,you,l=x[e+"" ""];if(l)return in "")}),a=a.slice(n.length)),b.filter)!(r=g[o].exec(a))||you[o]&&!(r=youo)||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return n,v,y,m,x,r,i=[],o=[],a=a[e+"" i&&(k=h,w=p),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,you,l=""function""==typeof h.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!e,n,!t||ee.test(e)&&ye(t.parentnode)||t),n},d.sortstable=s.split("""").sort(j).join("""")===s,d.detectduplicates=!!l,t(),d.sortdetached=ce(function(e){return e.innerhtml=""<a href='#'></a>"",""#""===e.firstchild.getattribute(""href"")})||fe(""type|href|height|width"",function(e,t,n){if(!n)return e.innerhtml=""<input/>"",e.firstchild.setattribute(""value"",""""),""""===e.firstchild.getattribute(""value"")})||fe(""value"",function(e,t,n){if(!n&&""input""===e.nodename.tolowercase())return e.defaultvalue}),ce(function(e){return null==e.getattribute(""disabled"")})||fe(r,function(e,t,n){var h=function(e,t,n){var r=[],i=void r},t=function(e,t){for(var n},k=s.expr.match.needscontext;function a(e,t){return e.nodename&&e.nodename.tolowercase()===t.tolowercase()}var j(e,n,r){return m(n)?s.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodetype?s.grep(e,function(e){return e===n!==r}):""string""!=typeof t,n,r=this.length,i=this;if(""string""!=typeof e)return d,q=/^(?:\s*(<[\w\w]+>)[^>]*|#([\w-]+))$/;(s.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||d,""string""==typeof instanceof in t)m(this[r])?thisr:this.attr(r,t[r]);return e}s.fn.extend({has:function(e){var t=s(e,this),n=t.length;return this.filter(function(){for(var e?""string""==typeof this.pushstack(s.uniquesort(s.merge(this.get(),s(e,t))))},addback:function(e){return this.add(null==e?this.prevobject:this.prevobject.filter(e))}}),s.each({parent:function(e){var t=e.parentnode;return h(e,""parentnode"")},parentsuntil:function(e,t,n){return h(e,""parentnode"",n)},next:function(e){return o(e,""nextsibling"")},prev:function(e){return o(e,""previoussibling"")},nextall:function(e){return h(e,""nextsibling"")},prevall:function(e){return h(e,""previoussibling"")},nextuntil:function(e,t,n){return h(e,""nextsibling"",n)},prevuntil:function(e,t,n){return h(e,""previoussibling"",n)},siblings:function(e){return t((e.parentnode||{}).firstchild,e)},children:function(e){return t(e.firstchild)},contents:function(e){return null!=e.contentdocument&&r(e.contentdocument)?e.contentdocument:(a(e,""template"")&&(e=e.content||e),s.merge([],e.childnodes))}},function(r,i){s.fn[r]=function(e,t){var r(e){return e}function m(e){throw e}function i(e,t,n,r){var i;try{e&&m(i=e.promise)?i.call(e).done(t).fail(n):e&&m(i=e.then)?i.call(e,t,n):t.apply(void e,n;r=""string""==typeof n(e){s.each(e,function(e,t){m(t)?r.unique&&f.has(t)||s.push(t):t&&t.length&&""string""!==w(t)&&n(t)})}(arguments),t&&!i&&c()),this},remove:function(){return s.each(arguments,function(e,t){var s&&(s=[]),this},disable:function(){return a=you=[],s=t="""",this},disabled:function(){return!s},lock:function(){return a=you=[],t||i||(s=t=""""),this},locked:function(){return!!a},firewith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],you.push(t),i||c()),this},fire:function(){return f.firewith(this,arguments),this},fired:function(){return!!o}};return f},s.extend({deferred:function(e){var memory""),s.callbacks(""once memory""),s.callbacks(""once i},always:function(){return s.done(arguments).fail(arguments),this},""catch"":function(e){return a.then(null,e)},pipe:function(){var i=arguments;return s.deferred(function(r){s.each(o,function(e,t){var l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i<you)){if((e=a.apply(n,r))===o.promise())throw new typeerror(""thenable self-resolution"");t=e&&(""object""==typeof e||""function""==typeof e)&&e.then,m(t)?s?t.call(e,l(you,o,r,s),l(you,o,m,s)):(you++,t.call(e,l(you,o,r,s),l(you,o,m,s),l(you,o,r,o.notifywith))):(a!==r&&(n=void null!=e?s.extend(e,a):a}},s={};return s.each(o,function(e,t){var n=arguments.length,t=n,r=array(t),i=s.call(arguments),o=s.deferred(),a=function(t){return o.then();while(t--)i(i[t],a(t),o.reject);return o.promise()}});var w=/^(eval|internal|range|reference|syntax|type|uri)error$/;s.deferred.exceptionhook=function(e,t){c.console&&c.console.warn&&e&&w.test(e.name)&&c.console.warn(""jquery.deferred exception: ""+e.message,e.stack,t)},s.readyexception=function(e){c.settimeout(function(){throw e})};var f=s.deferred();function b(){e.removeeventlistener(""domcontentloaded"",b),c.removeeventlistener(""load"",b),s.ready()}s.fn.ready=function(e){return $=function(e,t,n,r,i,o,a){var in if(void l.call(s(e),n)})),t))for(;s<you;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return you(e,t){return t.touppercase()}function x(e){return e.replace(_,""ms-"").replace(z,you)}var v=function(e){return t=e[this.expando];return r,i=this.cache(e);if(""string""==typeof t)i[x(t)]=n;else for(r in t)i[x(r)]=t[r];return i},get:function(e,t){return void void t&&void n,r=e[this.expando];if(void r?[t]:t.match(p)||[]).length;while(n--)delete r[t[n]]}(void e[this.expando])}},hasdata:function(e){var t=e[this.expando];return void y=new g,q=new g,j=/^(?:\{[\w\w]*\}|\[[\w\w]*\])$/,k=/[a-z]/g;function z(e,t,n){var r,i;if(void n=void n}s.extend({hasdata:function(e){return q.hasdata(e)||y.hasdata(e)},data:function(e,t,n){return q.access(e,t,n)},removedata:function(e,t){q.remove(e,t)},_data:function(e,t,n){return y.access(e,t,n)},_removedata:function(e,t){y.remove(e,t)}}),s.fn.extend({data:function(n,e){var i}return""object""==typeof n?this.each(function(){q.set(this,n)}):$(this,function(e){var t;if(o&&void void this.each(function(){q.remove(this,e)})}}),s.extend({queue:function(e,t,n){var r;if(e)return t=(t||""fx"")+""queue"",r=y.get(e,t),n&&(!r||array.isarray(n)?r=y.access(e,t,s.makearray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||""fx"";var n=s.queue(e,t),r=n.length,i=n.shift(),o=s._queuehooks(e,t);""inprogress""===i&&(i=n.shift(),r--),i&&(""fx""===t&&n.unshift(""inprogress""),delete o.stop,i.call(e,function(){s.dequeue(e,t)},o)),!r&&o&&o.empty.fire()},_queuehooks:function(e,t){var n=t+""queuehooks"";return y.get(e,n)||y.access(e,n,{empty:s.callbacks(""once memory"").add(function(){y.remove(e,[t+""queue"",n])})})}}),s.fn.extend({queue:function(t,n){var this.each(function(){s.dequeue(this,e)})},clearqueue:function(e){return this.queue(e||""fx"",[])},promise:function(e,t){var e&&(t=e,e=void s(),i.promise(t)}});var ee=/[+-]?(?:\d*\.|)\d+(?:[ee][+-]?\d+|)/.source,te=new regexp(""^(?:([+-])=|)(""+ee+"")([a-z%]*)$"",""i""),ne=[""top"",""right"",""bottom"",""left""],re=e.documentelement,ie=function(e){return s.contains(e.ownerdocument,e)||e.getrootnode(oe)===e.ownerdocument});var ae=function(e,t){return""none""===(e=t||e).style.display||""""===e.style.display&&ie(e)&&""none""===s.css(e,""display"")};function se(e,t,n,r){var r.cur()}:function(){return ue={};function le(e,t){for(var e}s.fn.extend({show:function(){return le(this)},toggle:function(e){return""boolean""==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?s(this).show():s(this).hide()})}});var ve(e,t){var n;return n=""undefined""!=typeof e.getelementsbytagname?e.getelementsbytagname(t||""*""):""undefined""!=typeof e.queryselectorall?e.queryselectorall(t||""*""):[],void ye(e,t){for(var multiple='multiple'>"",""</select>""]);var me=/<|&#?\w+;/;function xe(e,t,n,r,i){for(var f}var be=/^([^.]*)(?:\.(.+)|)/;function ce(e,t){return e===function(){try{return e.activeelement}catch(e){}}()==(""focus""===t)}function ee(e,t,n,r,i,o){var a,s;if(""object""==typeof t){for(s in""string""!=typeof n&&(r=r||n,n=void e}if(null==r&&null==i?(i=n,r=n=void n?(i=r,r=void if(!i)return e;return s().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=s.guid++)),e.each(function(){s.event.add(this,t,i,r,n)})}function e.stopimmediatepropagation(),e.preventdefault(),n&&n.value}else o,a,s,you,l,c,f,p,d,h,g,v=y.get(t);if(v(t)){n.handler&&(n=(o=n).handler,i=o.selector),i&&s.find.matchesselector(re,i),n.guid||(n.guid=s.guid++),(you=v.events)||(you=v.events=object.create(null)),(a=v.handle)||(a=v.handle=function(e){return""undefined""!=typeof s&&s.event.triggered!==e.type?s.event.dispatch.apply(t,arguments):void you[d])}else for(d in events"")}},dispatch:function(e){var t,n,r,i,o,a,s=new c.postdispatch&&c.postdispatch.call(this,you),you.result}},handlers:function(e,t){var e(this.originalevent)}:function(){if(this.originalevent)return e[s.expando]?e:new t=this||e;return t=this||e;return t=e.target;return pe.test(t.type)&&t.click&&a(t,""input"")&&y.get(t,""click"")||a(t,""a"")}},beforeunload:{postdispatch:function(e){void instanceof s.event))return new s.event(e,t);e&&e.type?(this.originalevent=e,this.type=e.type,this.isdefaultprevented=e.defaultprevented||void e=this.originalevent;this.isdefaultprevented=we,e&&!this.issimulated&&e.preventdefault()},stoppropagation:function(){var e=this.originalevent;this.ispropagationstopped=we,e&&!this.issimulated&&e.stoppropagation()},stopimmediatepropagation:function(){var t,n=e.relatedtarget,r=e.handleobj;return n&&(n===this||s.contains(this,n))||(e.type=r.origtype,t=r.handler.apply(this,arguments),e.type=i),t}}}),s.fn.extend({on:function(e,t,n,r){return ee(this,e,t,n,r)},one:function(e,t,n,r){return r,i;if(e&&e.preventdefault&&e.handleobj)return r=e.handleobj,s(e.delegatetarget).off(r.namespace?r.origtype+"".""+r.namespace:r.origtype,r.selector,r.handler),this;if(""object""==typeof e){for(i in e)this.off(i,t,e[i]);return t||(n=t,t=void ke=/<script|<style|<link/i,ae=/checked\s*(?:[^=]|=\s*.checked.)/i,ne=/^\s*<!(?:\[cdata\[|--)|(?:\]\]|--)>\s*$/g;function je(e,t){return de(e){return e.type=(null!==e.getattribute(""type""))+""/""+e.type,e}function le(e,t){var in y.remove(t,""handle he(n,r,i,o){r=g(r);var d&&!y.checkclone&&ae.test(d))return n.each(function(e){var n}function oe(e,t,n){for(var e}s.extend({htmlprefilter:function(e){return e},clone:function(e,t,n){var le(e,c);return in t.events)i[r]?s.event.remove(n,r):s.removeevent(n,r,t.handle);n[y.expando]=void oe(this,e)},text:function(e){return $(this,function(e){return void t=je(this,e);t.insertbefore(e,t.firstchild)}})},before:function(){return he(this,arguments,function(e){this.parentnode&&this.parentnode.insertbefore(e,this)})},after:function(){return he(this,arguments,function(e){this.parentnode&&this.parentnode.insertbefore(e,this.nextsibling)})},empty:function(){for(var this},clone:function(e,t){return e=null!=e&&e,t=null==t?e:t,this.map(function(){return s.clone(this,e,t)})},html:function(e){return $(this,function(e){var t.innerhtml;if(""string""==typeof n=[];return he(this,arguments,function(e){var this.pushstack(n)}});var pe=new regexp(""^(""+ee+"")(?!px)[a-z%]+$"",""i""),re=function(e){var t=e.ownerdocument.defaultview;return t&&t.opener||(t=c),t.getcomputedstyle(e)},me=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},ie=new regexp(ne.join(""|""),""i"");function we(e,t,n){var r,i,o,a,s=e.style;return(n=n||re(e))&&(""""!==(a=n.getpropertyvalue(t)||n[t])||ie(e)||(a=s.style(e,t)),!y.pixelboxstyles()&&pe.test(a)&&ie.test(t)&&(r=s.width,i=s.minwidth,o=s.maxwidth,s.minwidth=s.maxwidth=s.width=a,a=n.width,s.width=r,s.minwidth=i,s.maxwidth=o)),void fe(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function t(e){return math.round(parsefloat(e))}var e(),r},pixelboxstyles:function(){return e(),o},pixelposition:function(){return e(),n},reliablemarginleft:function(){return e(),s},scrollboxsize:function(){return e(),i},reliabletrdimensions:function(){var e,t,n,r;return be=[""webkit"",""moz"",""ms""],$e=e.createelement(""div"").style,_e={};function ze(e){var t=s.cssprops[e]||_e[e];return t||(e in $e?e:_e[e]=function(e){var $e)return e}(e)||e)}var ye(e,t,n){var r=te.exec(t);return qe(e,t,n,r,i,o){var je(e,t,n){var in ke(e,t,n,r,i){return new ke.prototype.init(e,t,n,r,i)}s.extend({csshooks:{opacity:{get:function(e,t){if(t){var i,o,a,s=x(t),you=xe.test(t),l=e.style;if(you||(t=ze(s)),a=s.csshooks[t]||s.csshooks[s],void a&&""get""in a&&void a&&void i,o,a,s=x(t);return xe.test(t)||(t=ze(s)),(a=s.csshooks[t]||s.csshooks[s])&&""get""in in je(e,you,n)})},set:function(e,t,n){var e.getboundingclientrect().left}))+""px""}),s.each({margin:"""",padding:"""",border:""width""},function(i,o){s.csshooks[i+o]={expand:function(e){for(var e?e.split("" n}},""margin""!==i&&(s.csshooks[i+o].set=ye)}),s.fn.extend({css:function(e,t){return $(this,function(e,t,n){var o}return void e=ke.prophooks[this.prop];return e&&e.get?e.get(this):ke.prophooks._default.get(this)},run:function(e){var t,n=ke.prophooks[this.prop];return this.options.duration?this.pos=t=s.easingthis.easing:this.pos=t=e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):ke.prophooks._default.set(this),this}}).init.prototype=ke.prototype,(ke.prophooks={_default:{get:function(e){var t;return ze,et,tt,nt,rt=/^(?:toggle|show|hide)$/,it=/queuehooks$/;function at(){return c.settimeout(function(){ze=void st(e,t){var t&&(i.opacity=i.width=e),i}function ut(e,t,n){for(var r}function lt(o,e,t){var n=s.tween(o,l.opts,e,t,l.opts.specialeasing[e]||l.opts.easing);return l.tweens.push(n),n},stop:function(e){var n,r,i,o,a;for(n in e[n]),(a=s.csshooks[r])&&""expand""in a)for(n in o=a.expand(o),delete e[r],o)n in e||(e[n]=o[n],t[n]=i);else t[r]=i}(c,l.opts.specialeasing);r<i;r++)if(n=lt.prefilters[r].call(l,o,c,l.opts))return m(n.stop)&&(s._queuehooks(l.elem,l.opts.queue).stop=n.stop.bind(n)),n;return s.map(c,ut,l),m(l.opts.start)&&l.opts.start.call(o,l),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always),s.fx.timer(s.extend(you,{elem:o,anim:l,queue:l.opts.queue})),l}s.animation=s.extend(lt,{tweeners:{""*"":[function(e,t){var n=this.createtween(e,t);return se(n.elem,e,te.exec(t),n),n}]},tweener:function(e,t){m(e)?(t=e,e=[""*""]):e=e.match(p);for(var r,i,o,a,s,you,l,c,f=""width""in t||""height""in t,p=this,d={},h=e.style,g=e.nodetype&&ae(e),v=y.get(e,""fxshow"");for(r in t[r],o=o||""toggle""===i,i===(g?""hide"":""show"")){if(""show""!==i||!v||void in in in r=e&&""object""==typeof e?s.extend({},e):{complete:n||!n&&t||m(e)&&e,duration:e,easing:n&&t||t&&!m(t)&&t};return r.duration&&(r.duration in i=s.isemptyobject(t),o=s.speed(e,n,r),a=function(){var a=function(e){var t=e.stop;delete e.stop,t(o)};return""string""!=typeof i&&(o=e,e=i,i=void for(t in t.finish})}}),s.each([""toggle"",""show"",""hide""],function(e,r){var i=s.fn[r];s.fn[r]=function(e,t,n){return null==e||""boolean""==typeof this.animate(r,e,t,n)}}),s.timers=[],s.fx.tick=function(){var r=s.fx&&s.fx.speeds[r]||r,e=e||""fx"",this.queue(e,function(e,t){var n=c.settimeout(e,r);t.stop=function(){c.cleartimeout(n)}})},tt=e.createelement(""input""),nt=e.createelement(""select"").appendchild(e.createelement(""option"")),tt.type=""checkbox"",y.checkon=""""!==tt.value,y.optselected=nt.selected,(tt=e.createelement(""input"")).value=""t"",tt.type=""radio"",y.radiovalue=""t""===tt.value;var ct,ft=s.expr.attrhandle;s.fn.extend({attr:function(e,t){return this.each(function(){s.removeattr(this,e)})}}),s.extend({attr:function(e,t,n){var s.removeattr(e,t):i&&""set""in i&&void i&&null!==(r=i.get(e,t))?r:null==(r=s.find.attr(e,t))?void n=e.value;return e.setattribute(""type"",t),n&&(e.value=n),t}}}},removeattr:function(e,t){var a=ft[t]||s.find.attr;ft[t]=function(e,t,n){var r,i,o=t.tolowercase();return n||(i=ft[o],ft[o]=r,r=null!=a(e,t,n)?o:null,ft[o]=i),r}});var pt=/^(?:input|select|textarea|button)$/i,dt=/^(?:a|area)$/i;function ht(e){return(e.match(p)||[]).join("" "")}function gt(e){return e.getattribute&&e.getattribute(""class"")||""""}function vt(e){return array.isarray(e)?e:""string""==typeof e&&e.match(p)||[]}s.fn.extend({prop:function(e,t){return this.each(function(){delete this[s.propfix[e]||e]})}}),s.extend({prop:function(e,t,n){var i&&void i&&null!==(r=i.get(e,t))?r:e[t]},prophooks:{tabindex:{get:function(e){var t=s.find.attr(e,""tabindex"");return t=e.parentnode;return t&&t.parentnode&&t.parentnode.selectedindex,null},set:function(e){var t=e.parentnode;t&&(t.selectedindex,t.parentnode&&t.parentnode.selectedindex)}}),s.each([""tabindex"",""readonly"",""maxlength"",""cellspacing"",""cellpadding"",""rowspan"",""colspan"",""usemap"",""frameborder"",""contenteditable""],function(){s.propfix[this.tolowercase()]=this}),s.fn.extend({addclass:function(t){var ""+ht(i)+"" ""+o+"" "");i!==(s=ht(r))&&n.setattribute(""class"",s)}return this},removeclass:function(t){var this.each(function(e){s(this).removeclass(t.call(this,e,gt(this)))});if(!arguments.length)return ""+ht(i)+"" ""+o+"" ""))r=r.replace("" ""+o+"" "","" "");i!==(s=ht(r))&&n.setattribute(""class"",s)}return this},toggleclass:function(i,t){var o=typeof i,a=""string""===o||array.isarray(i);return""boolean""==typeof t&&a?t?this.addclass(i):this.removeclass(i):m(i)?this.each(function(e){s(this).toggleclass(i.call(this,e,gt(this),t),t)}):this.each(function(){var void ""+e+"" ""+ht(gt(n))+"" yt=/\r/g;s.fn.extend({val:function(n){var arguments.length?(i=m(n),this.each(function(e){var t?t+="""":array.isarray(t)&&(t=s.map(t,function(e){return null==e?"""":e+""""})),(r=s.valhooks[this.type]||s.valhooks[this.nodename.tolowercase()])&&""set""in r&&void r&&void t=s.find.attr(e,""value"");return null!=t?t:ht(s.text(e))}},select:{get:function(e){var t;s.push(t)}return s},set:function(e,t){var null===e.getattribute(""value"")?""on"":e.value})}),y.focusin=""onfocusin""in c;var mt=/^(?:focusinfocus|focusoutblur)$/,xt=function(e){e.stoppropagation()};s.extend(s.event,{trigger:function(e,t,n,r){var s.event(d,""object""==typeof regexp(""(^|\\.)""+h.join(""\\.(?:.*\\.|)"")+""(\\.|$)""):null,e.result=void r=s.extend(new this.each(function(){s.event.trigger(e,t,this)})},triggerhandler:function(e,t){var i=function(e){s.event.simulate(r,e.target,s.event.fix(e))};s.event.special[r]={setup:function(){var bt=c.location,wt={guid:date.now()},tt=/\?/;s.parsexml=function(e){var t,n;if(!e||""string""!=typeof e)return null;try{t=(new c.domparser).parsefromstring(e,""text/xml"")}catch(e){}return xml: ""+(n?s.map(n.childnodes,function(e){return e.textcontent}).join(""\n""):e)),t};var ct=/\[\]$/,et=/\r?\n/g,st=/^(?:submit|button|image|reset|file)$/i,kt=/^(?:input|select|textarea|keygen)/i;function at(n,e,r,i){var t;if(array.isarray(e))s.each(e,function(e,t){r||ct.test(n)?i(n,t):at(n+""[""+(""object""==typeof t&&null!=t?e:"""")+""]"",t,r,i)});else if(r||""object""!==w(e))i(n,e);else for(t in e)at(n+""[""+t+""]"",e[t],r,i)}s.param=function(e,t){var n,r=[],i=function(e,t){var n=m(t)?t():t;r[r.length]=encodeuricomponent(e)+""=""+encodeuricomponent(null==n?"""":n)};if(null==e)return"""";if(array.isarray(e)||e.jquery&&!s.isplainobject(e))s.each(e,function(){i(this.name,this.value)});else for(n in e)at(n,e[n],t,i);return r.join(""&"")},s.fn.extend({serialize:function(){return s.param(this.serializearray())},serializearray:function(){return this.map(function(){var e=s.prop(this,""elements"");return e?s.makearray(e):this}).filter(function(){var e=this.type;return this.name&&!s(this).is("":disabled"")&&kt.test(this.nodename)&&!st.test(e)&&(this.checked||!pe.test(e))}).map(function(e,t){var n=s(this).val();return null==n?null:array.isarray(n)?s.map(n,function(e){return{name:t.name,value:e.replace(et,""\r\n"")}}):{name:t.name,value:n.replace(et,""\r\n"")}}).get()}});var \t]*([^\r\n]*)$/gm,lt=/^(?:get|head)$/,ht=/^\/\//,ot={},pt={},rt=""*/"".concat(""*""),mt=e.createelement(""a"");function it(o){return function(e,t){""string""!=typeof e&&(t=e,e=""*"");var wt(t,i,o,a){var s={},you=t===pt;function l(e){var r;return n=t(i,o,a);return""string""!=typeof n||you||s[n]?you?!(r=n):void ft(e,t){var n,r,i=s.ajaxsettings.flatoptions||{};for(n in t)void text/xml"",json:""application/json, text/javascript""},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responsefields:{xml:""responsexml"",text:""responsetext"",json:""responsejson""},converters:{""* text"":string,""text json"":json.parse,""text t?ft(ft(e,s.ajaxsettings),t):ft(s.ajaxsettings,e)},ajaxprefilter:it(ot),ajaxtransport:it(pt),ajax:function(e,t){""object""==typeof e&&(t=e,e=void c,f,p,n,d,r,h,g,i,o,v=s.ajaxsetup({},t),y=v.context||v,m=v.context&&(y.nodetype||y.jquery)?s(y):s.event,x=s.deferred(),b=s.callbacks(""once ""]}return null==t?null:t.join("", "")},getallresponseheaders:function(){return h?p:null},setrequestheader:function(e,t){return null==h&&(e=s[e.tolowercase()]=s[e.tolowercase()]||e,a[e]=t),this},overridemimetype:function(e){return null==h&&(v.mimetype=e),this},statuscode:function(e){var t;if(e)if(h)t.always(e[t.status]);else for(t in e)w[t]=[w[t],e[t]];return this},abort:function(e){var t=e||you;return v.data&&(v.data=s.param(v.data,v.traditional)),wt(ot,v,t,t),h)return t;for(i v.data)&&(f+=(tt.test(f)?""&"":""?"")+v.data,delete ""+rt+""; transport"");function l(e,t,n,r){var in in script""]=function(){}),s=function(e,t,n,r){var in e.converters)l[a.tolowercase()]=e.converters[a];o=c.shift();while(o)if(e.responsefields[o]&&(n[e.responsefields[o]]=t),!you&&r&&e.datafilter&&(t=e.datafilter(t,e.datatype)),you=o,o=c.shift())if(""*""===o)o=you;else if(""*""!==you&&you!==o){if(!(a=l[you+"" ""+o]||l[""* ""+o]))for(i in l)if((s=i.split("" try{t=a(t)}catch(e){return{state:""parsererror"",error:a?e:""no conversion from ""+you+"" to t},getjson:function(e,t,n){return s.get(e,t,n,""json"")},getscript:function(e,t){return s.get(e,void m(t)&&(r=r||n,n=t,t=void t;for(t in e.headers)""content-type""===t.tolowercase()&&(e.contenttype=e.headers[t]||"""")}),s._evalurl=function(e,t,n){return script"":function(){}},datafilter:function(e){s.globaleval(e,t,n)}})},s.fn.extend({wrapall:function(e){var t;return e=this;while(e.firstelementchild)e=e.firstelementchild;return e}).append(this)),this},wrapinner:function(n){return m(n)?this.each(function(e){s(this).wrapinner(n.call(this,e))}):this.each(function(){var e=s(this),t=e.contents();t.length?t.wrapall(n):e.append(n)})},wrap:function(t){var n=m(t);return this.each(function(e){s(this).wrapall(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not(""body"").each(function(){s(this).replacewith(this.childnodes)}),this}}),s.expr.pseudos.hidden=function(e){return!s.expr.pseudos.visible(e)},s.expr.pseudos.visible=function(e){return!!(e.offsetwidth||e.offsetheight||e.getclientrects().length)},s.ajaxsettings.xhr=function(){try{return new c.xmlhttprequest}catch(e){}};var $t,y.ajax=$t=!!$t,s.ajaxtransport(function(i){var o,a;if(y.cors||$t&&!i.crossdomain)return{send:function(e,t){var n,r=i.xhr();if(r.open(i.type,i.url,i.async,i.username,i.password),i.xhrfields)for(n in i.xhrfields)r[n]=i.xhrfields[n];for(n in i.mimetype&&r.overridemimetype&&r.overridemimetype(i.mimetype),i.crossdomain||e[""x-requested-with""]||(e[""x-requested-with""]=""xmlhttprequest""),e)r.setrequestheader(n,e[n]);o=function(e){return function(){o&&(o=a=r.onload=r.onerror=r.onabort=r.ontimeout=r.onreadystatechange=null,""abort""===e?r.abort():""error""===e?""number""!=typeof r.responsetext?{binary:r.response}:{text:r.responsetext},r.getallresponseheaders()))}},r.onload=o(),a=r.onerror=r.ontimeout=o(""error""),void application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/\b(?:java|ecma)script\b/},converters:{""text script"":function(e){return s.globaleval(e),e}}}),s.ajaxprefilter(""script"",function(e){void r,i;if(n.crossdomain||n.scriptattrs)return{send:function(e,t){r=s(""<script>"").attr(n.scriptattrs||{}).prop({charset:n.scriptcharset,src:n.url}).on(""load _t,zt=[],ut=/(=)\?(?=&|$)|\?\?/;s.ajaxsetup({jsonp:""callback"",jsonpcallback:function(){var e=zt.pop()||s.expando+""_""+wt.guid++;return jsonp"",function(e,t,n){var json""]=function(){return o||s.error(r+"" was not e?[]:(""boolean""==typeof r,i,o},s.fn.load=function(e,t,n){var r,i,o,a=this,s=e.indexof("" s.grep(s.timers,function(e){return t===e.elem}).length},s.offset={setoffset:function(e,t,n){var t?t.using.call(e,f):c.css(f)}},s.fn.extend({offset:function(t){if(arguments.length)return void this.map(function(){var e=this.offsetparent;while(e&&""static""===s.css(e,""position""))e=e.offsetparent;return e||re})}}),s.each({scrollleft:""pagexoffset"",scrolltop:""pageyoffset""},function(t,i){var o=""pageyoffset""===i;s.fn[t]=function(e){return $(this,function(e,t,n){var r?r[i]:e[t];r?r.scrollto(o?r.pagexoffset:n,o?n:r.pageyoffset):e[t]=n},t,e,arguments.length)}}),s.each([""top"",""left""],function(e,n){s.csshooks[n]=fe(y.pixelposition,function(e,t){if(t)return t=we(e,n),pe.test(t)?s(e).position()[n]+""px"":t})}),s.each({height:""height"",width:""width""},function(a,s){s.each({padding:""inner""+a,content:s,"""":""outer""+a},function(r,o){s.fn[o]=function(e,t){var n=arguments.length&&(r||""boolean""!=typeof $(this,function(e,t,n){var r;return this.on(t,e)}}),s.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return this.mouseenter(e).mouseleave(t||e)}}),s.each(""blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu"".split("" ""),function(e,n){s.fn[n]=function(e,t){return n,r,i;if(""string""==typeof t&&(n=e[t],t=e,e=n),m(e))return t=s.type(e);return(""number""===t||""string""===t)&&!isnan(e-parsefloat(e))},s.trim=function(e){return null==e?"""":(e+"""").replace(xt,"""")},""function""==typeof define&&define.amd&&define(""jquery"",[],function(){return s});var vt=c.jquery,gt=c.$;return s.noconflict=function(e){return c.$===s&&(c.$=gt),e&&c.jquery===s&&(c.jquery=vt),s},""undefined""==typeof e&&(c.jquery=c.$=s),s}); </script> <meta name=""viewport"" content=""width=device-width, /> <style input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html solid ("" attr(href) "")""}abbr[title]:after{content:"" ("" attr(title) solid solid td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered solid #ddd!important}}@font-face{font-family:'glyphicons auto solid ease-in-out;-o-transition:all ease-in-out;transition:all solid solid old,old ul,ul old,ul dotted solid #eee}blockquote old:last-child,blockquote p:last-child,blockquote .small,blockquote footer,blockquote .small:before,blockquote footer:before,blockquote solid .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:''}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right solid solid solid solid #ddd}.table solid solid col[class*=col-]{position:static;display:table-column;float:none}table td[class*=col-],table screen and solid solid auto solid ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out ease-in-out .form-control{cursor:not-allowed}textarea.form-control{height:auto}input[type=search]{-webkit-appearance:none}@media screen and input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg label,.radio input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:not-allowed}.checkbox-inline.disabled,.radio-inline.disabled,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio-inline{cursor:not-allowed}.checkbox.disabled label,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .radio select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.form-inline .checkbox,.form-inline .checkbox label,.form-inline .radio .checkbox input[type=checkbox],.form-inline .radio .has-feedback .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .checkbox,.form-horizontal .has-feedback .form-group-lg .form-group-sm solid auto .btn-default,fieldset[disabled] .btn-default.active,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .btn-primary,fieldset[disabled] .btn-primary.active,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success.active,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info.active,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning.active,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger.active,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-link:focus,fieldset[disabled] linear;-o-transition:opacity linear;transition:opacity solid solid solid solid .caret,.navbar-fixed-bottom .dropdown .dropdown-menu,.navbar-fixed-bottom .dropdown .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn,.btn-toolbar .btn-group,.btn-toolbar .dropdown-toggle:active,.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn .btn-lg .dropdown-menu{left:auto}[data-toggle=buttons]>.btn input[type=checkbox],[data-toggle=buttons]>.btn input[type=radio],[data-toggle=buttons]>.btn-group>.btn input[type=checkbox],[data-toggle=buttons]>.btn-group>.btn .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group solid input[type=checkbox],.input-group-addon .open>a,.nav .open>a:focus,.nav solid solid #eee solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid .dropdown-menu{top:auto;left:auto}@media solid #ddd}@media solid solid transparent}@media solid transparent;-webkit-box-shadow:inset .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse,.navbar-fixed-top and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-brand,.navbar>.container-fluid solid .open .open .dropdown-menu .dropdown-header,.navbar-nav .open .open .open .dropdown-menu>li>a:focus,.navbar-nav .open .dropdown-menu>li>a:hover{background-image:none}}@media solid solid transparent;-webkit-box-shadow:inset .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.navbar-form .checkbox,.navbar-form .checkbox label,.navbar-form .radio .checkbox input[type=checkbox],.navbar-form .radio .has-feedback .navbar-brand:focus,.navbar-default .navbar-nav>li>a:focus,.navbar-default .navbar-nav>.active>a,.navbar-default .navbar-nav>.active>a:focus,.navbar-default .navbar-nav>.disabled>a,.navbar-default .navbar-nav>.disabled>a:focus,.navbar-default .navbar-nav>.disabled>a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .navbar-collapse,.navbar-default .navbar-nav>.open>a,.navbar-default .navbar-nav>.open>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.active>a,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-default .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#ccc;background-color:transparent}}.navbar-default .btn-link:focus,.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>li>a:focus,.navbar-inverse .navbar-nav>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>.active>a,.navbar-inverse .navbar-nav>.active>a:focus,.navbar-inverse .navbar-nav>.disabled>a,.navbar-inverse .navbar-nav>.disabled>a:focus,.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-nav>.open>a,.navbar-inverse .navbar-nav>.open>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu .navbar-nav .open .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-inverse .navbar-nav .open .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-inverse .navbar-nav .open .navbar-link:hover{color:#fff}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse solid li{display:inline}.pager li>a,.pager solid li>a:focus,.pager li>a:hover{text-decoration:none;background-color:#eee}.pager .next>a,.pager .next>span{float:right}.pager .previous>a,.pager .previous>span{float:left}.pager .disabled>a,.pager .disabled>a:focus,.pager .disabled>a:hover,.pager .badge,.btn-xs .jumbotron,.container-fluid screen and .jumbotron,.container-fluid solid ease-in-out;-o-transition:border ease-in-out;transition:border ease-in-out}.thumbnail solid .close,.alert-dismissible ease;-o-transition:width ease;transition:width ease}.progress-bar-striped,.progress-striped .progress-bar{-webkit-animation:progress-bar-stripes linear infinite;-o-animation:progress-bar-stripes linear infinite;animation:progress-bar-stripes linear solid .list-group-item-heading,button.list-group-item .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-heading,.list-group-item.active .list-group-item-heading>.small,.list-group-item.active .list-group-item-heading>small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading>.small,.list-group-item.active:focus .list-group-item-heading>small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading>.small,.list-group-item.active:hover .list-group-item-heading>small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-heading,button.list-group-item-success .list-group-item-heading,button.list-group-item-info .list-group-item-heading,button.list-group-item-warning .list-group-item-heading,button.list-group-item-danger solid solid solid .list-group-item,.panel>.panel-collapse>.list-group .list-group-item:first-child,.panel>.panel-collapse>.list-group:first-child .list-group-item:last-child,.panel>.panel-collapse>.list-group:last-child caption,.panel>.table caption,.panel>.table-responsive>.table td:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child solid #ddd}.panel>.table>tbody:first-child>tr:first-child td,.panel>.table>tbody:first-child>tr:first-child .panel-heading+.panel-collapse>.list-group,.panel-group solid #ddd}.panel-group .panel-footer+.panel-collapse solid .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive solid .modal-dialog{-webkit-transition:-webkit-transform ease-out;-o-transition:-o-transform ease-out;transition:transform solid solid solid solid .btn-group solid solid solid ease-in-out ease-in-out ease-in-out all and ease-in-out;-o-transition:-o-transform ease-in-out;transition:transform top,right top,right .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control solid .btn{text-shadow:none}@media screen and .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control dd:after,.dl-horizontal dd:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before,.modal-footer:after,.modal-footer:before,.nav:after,.nav:before,.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.row:after,.row:before{display:table;content:"" ""}.btn-group-vertical>.btn-group:after,.btn-toolbar:after,.clearfix:after,.container-fluid:after,.container:after,.dl-horizontal dd:after,.form-horizontal and and and and and and and and and and print{.visible-print{display:block!important}table.visible-print{display:table!important}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}}@media print{.hidden-print{display:none!important}} </style> <script>/*! * bootstrap (http://getbootstrap.com) * copyright twitter, inc. * licensed under the mit license */ if(""undefined""==typeof jquery)throw new error(""bootstrap's javascript requires jquery"");+function(a){""use strict"";var b=a.fn.jquery.split("" new error(""bootstrap's javascript requires jquery version or higher"")}(jquery),+function(a){""use strict"";function b(){var a=document.createelement(""bootstrap""),b={webkittransition:""webkittransitionend"",moztransition:""transitionend"",otransition:""otransitionend otransitionend"",transition:""transitionend""};for(var c in b)if(void e=function(){c||a(d).trigger(a.support.transition.end)};return settimeout(e,b),this},a(function(){a.support.transition=b(),a.support.transition&&(a.event.special.bstransitionend={bindtype:a.support.transition.end,delegatetype:a.support.transition.end,handle:function(b){return a(b.target).is(this)?b.handleobj.handler.apply(this,arguments):void strict"";function b(b){return this.each(function(){var c=a(this),e=c.data(""bs.alert"");e||c.data(""bs.alert"",e=new d(this)),""string""==typeof b&&e[b].call(c)})}var c(){g.detach().trigger(""closed.bs.alert"").remove()}var e=a(this),f=e.attr(""data-target"");f||(f=e.attr(""href""),f=f&&f.replace(/.*(?=#[^\s]*$)/,""""));var g=a(f);b&&b.preventdefault(),g.length||(g=e.closest("".alert"")),g.trigger(b=a.event(""close.bs.alert"")),b.isdefaultprevented()||(g.removeclass(""in""),a.support.transition&&g.hasclass(""fade"")?g.one(""bstransitionend"",c).emulatetransitionend(d.transition_duration):c())};var e=a.fn.alert;a.fn.alert=b,a.fn.alert.constructor=d,a.fn.alert.noconflict=function(){return a.fn.alert=e,this},a(document).on(""click.bs.alert.data-api"",c,d.prototype.close)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.button""),f=""object""==typeof b&&b;e||d.data(""bs.button"",e=new c(this,f)),""toggle""==b?e.toggle():b&&e.setstate(b)})}var this.$element.attr(""aria-pressed"",!this.$element.hasclass(""active"")),this.$element.toggleclass(""active"")};var d=a.fn.button;a.fn.button=b,a.fn.button.constructor=c,a.fn.button.noconflict=function(){return a.fn.button=d,this},a(document).on(""click.bs.button.data-api"",'[data-toggle^=""button""]',function(c){var d=a(c.target);d.hasclass(""btn"")||(d=d.closest("".btn"")),b.call(d,""toggle""),a(c.target).is('input[type=""radio""]')||a(c.target).is('input[type=""checkbox""]')||c.preventdefault()}).on(""focus.bs.button.data-api blur.bs.button.data-api"",'[data-toggle^=""button""]',function(b){a(b.target).closest("".btn"").toggleclass(""focus"",/^focus(in)?$/.test(b.type))})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.carousel""),f=a.extend({},c.defaults,d.data(),""object""==typeof b&&b),g=""string""==typeof b?b:f.slide;e||d.data(""bs.carousel"",e=new c(this,f)),""number""==typeof b?e.to(b):g?e[g]():f.interval&&e.pause().cycle()})}var c=function(b,c){this.$element=a(b),this.$indicators=this.$element.find("".carousel-indicators""),this.options=c,this.paused=null,this.sliding=null,this.interval=null,this.$active=null,this.$items=null,this.options.keyboard&&this.$element.on(""keydown.bs.carousel"",a.proxy(this.keydown,this)),""hover""==this.options.pause&&!(""ontouchstart""in this.$items=a.parent().children("".item""),this.$items.index(a||this.$active)},c.prototype.getitemfordirection=function(a,b){var b;var this.$items.eq(f)},c.prototype.to=function(a){var b=this,c=this.getitemindex(this.$active=this.$element.find("".item.active""));return this.sliding?void this.sliding?void e=this.$element.find("".item.active""),f=d||this.getitemfordirection(b,e),g=this.interval,h=""next""==b?""left"":""right"",i=this;if(f.hasclass(""active""))return l=a(this.$indicators.children()[this.getitemindex(f)]);l&&l.addclass(""active"")}var m=a.event(""slid.bs.carousel"",{relatedtarget:j,direction:h});return "")).addclass(""active""),e.removeclass([""active"",h].join("" d=a.fn.carousel;a.fn.carousel=b,a.fn.carousel.constructor=c,a.fn.carousel.noconflict=function(){return a.fn.carousel=d,this};var e=function(c){var d,e=a(this),f=a(e.attr(""data-target"")||(d=e.attr(""href""))&&d.replace(/.*(?=#[^\s]+$)/,""""));if(f.hasclass(""carousel"")){var c=a(this);b.call(c,c.data())})})}(jquery),+function(a){""use strict"";function b(b){var c,d=b.attr(""data-target"")||(c=b.attr(""href""))&&c.replace(/.*(?=#[^\s]+$)/,"""");return a(d)}function c(b){return this.each(function(){var c=a(this),e=c.data(""bs.collapse""),f=a.extend({},d.defaults,c.data(),""object""==typeof d(this,f)),""string""==typeof b&&e[b]()})}var a=this.$element.hasclass(""width"");return a?""width"":""height""},d.prototype.show=function(){if(!this.transitioning&&!this.$element.hasclass(""in"")){var b,e=this.$parent&&this.$parent.children("".panel"").children("".in, .collapsing"");if(!(e&&e.length&&(b=e.data(""bs.collapse""),b&&b.transitioning))){var f=a.event(""show.bs.collapse"");if(this.$element.trigger(f),!f.isdefaultprevented()){e&&e.length&&(c.call(e,""hide""),b||e.data(""bs.collapse"",null));var h=function(){this.$element.removeclass(""collapsing"").addclass(""collapse h.call(this);var i=a.camelcase([""scroll"",g].join(""-""));this.$element.one(""bstransitionend"",a.proxy(h,this)).emulatetransitionend(d.transition_duration)g}}}},d.prototype.hide=function(){if(!this.transitioning&&this.$element.hasclass(""in"")){var b=a.event(""hide.bs.collapse"");if(this.$element.trigger(b),!b.isdefaultprevented()){var a.support.transition?void this.$elementc.one(""bstransitionend"",a.proxy(e,this)).emulatetransitionend(d.transition_duration):e.call(this)}}},d.prototype.toggle=function(){this[this.$element.hasclass(""in"")?""hide"":""show""]()},d.prototype.getparent=function(){return a(this.options.parent).find('[data-toggle=""collapse""][data-parent=""'+this.options.parent+'""]').each(a.proxy(function(c,d){var e=a(d);this.addariaandcollapsedclass(b(e),e)},this)).end()},d.prototype.addariaandcollapsedclass=function(a,b){var c=a.hasclass(""in"");a.attr(""aria-expanded"",c),b.toggleclass(""collapsed"",!c).attr(""aria-expanded"",c)};var e=a.fn.collapse;a.fn.collapse=c,a.fn.collapse.constructor=d,a.fn.collapse.noconflict=function(){return a.fn.collapse=e,this},a(document).on(""click.bs.collapse.data-api"",'[data-toggle=""collapse""]',function(d){var e=a(this);e.attr(""data-target"")||d.preventdefault();var f=b(e),g=f.data(""bs.collapse""),h=g?""toggle"":e.data();c.call(f,h)})}(jquery),+function(a){""use strict"";function b(b){var c=b.attr(""data-target"");c||(c=b.attr(""href""),c=c&&/#[a-za-z]/.test(c)&&c.replace(/.*(?=#[^\s]*$)/,""""));var d=c&&a(c);return d&&d.length?d:b.parent()}function d(b){return this.each(function(){var c=a(this),d=c.data(""bs.dropdown"");d||c.data(""bs.dropdown"",d=new g(this)),""string""==typeof b&&d[b].call(c)})}var e=a(this);if(!e.is("".disabled, :disabled"")){var f=b(e),g=f.hasclass(""open"");if(c(),!g){""ontouchstart""in document.documentelement&&!f.closest("".navbar-nav"").length&&a(document.createelement(""div"")).addclass(""dropdown-backdrop"").insertafter(a(this)).on(""click"",c);var d=a(this);if(c.preventdefault(),c.stoppropagation(),!d.is("".disabled, :disabled"")){var h="" li:not(.disabled):visible a"",i=e.find("".dropdown-menu""+h);if(i.length){var h=a.fn.dropdown;a.fn.dropdown=d,a.fn.dropdown.constructor=g,a.fn.dropdown.noconflict=function(){return a.fn.dropdown=h,this},a(document).on(""click.bs.dropdown.data-api"",c).on(""click.bs.dropdown.data-api"","".dropdown form"",function(a){a.stoppropagation()}).on(""click.bs.dropdown.data-api"",f,g.prototype.toggle).on(""keydown.bs.dropdown.data-api"",f,g.prototype.keydown).on(""keydown.bs.dropdown.data-api"","".dropdown-menu"",g.prototype.keydown)}(jquery),+function(a){""use strict"";function b(b,d){return this.each(function(){var e=a(this),f=e.data(""bs.modal""),g=a.extend({},c.defaults,e.data(),""object""==typeof b&&b);f||e.data(""bs.modal"",f=new c(this,g)),""string""==typeof b?fb:g.show&&f.show(d)})}var this.isshown?this.hide():this.show(a)},c.prototype.show=function(b){var a=this;this.$element.hide(),this.backdrop(function(){a.$body.removeclass(""modal-open""),a.resetadjustments(),a.resetscrollbar(),a.$element.trigger(""hidden.bs.modal"")})},c.prototype.removebackdrop=function(){this.$backdrop&&this.$backdrop.remove(),this.$backdrop=null},c.prototype.backdrop=function(b){var d=this,e=this.$element.hasclass(""fade"")?""fade"":"""";if(this.isshown&&this.options.backdrop){var f=a.support.transition&&e;if(this.$backdrop=a(document.createelement(""div"")).addclass(""modal-backdrop ""+e).appendto(this.$body),this.$element.on(""click.dismiss.bs.modal"",a.proxy(function(a){return if(!this.isshown&&this.$backdrop){this.$backdrop.removeclass(""in"");var g=function(){d.removebackdrop(),b&&b()};a.support.transition&&this.$element.hasclass(""fade"")?this.$backdrop.one(""bstransitionend"",g).emulatetransitionend(c.backdrop_transition_duration):g()}else b&&b()},c.prototype.handleupdate=function(){this.adjustdialog()},c.prototype.adjustdialog=function(){var a=window.innerwidth;if(!a){var b=document.documentelement.getboundingclientrect();a=b.right-math.abs(b.left)}this.bodyisoverflowing=document.body.clientwidth<a,this.scrollbarwidth=this.measurescrollbar()},c.prototype.setscrollbar=function(){var a=document.createelement(""div"");a.classname=""modal-scrollbar-measure"",this.$body.append(a);var b=a.offsetwidth-a.clientwidth;return d=a.fn.modal;a.fn.modal=b,a.fn.modal.constructor=c,a.fn.modal.noconflict=function(){return a.fn.modal=d,this},a(document).on(""click.bs.modal.data-api"",'[data-toggle=""modal""]',function(c){var d=a(this),e=d.attr(""href""),f=a(d.attr(""data-target"")||e&&e.replace(/.*(?=#[^\s]+$)/,"""")),g=f.data(""bs.modal"")?""toggle"":a.extend({remote:!/#/.test(e)&&e},f.data(),d.data());d.is(""a"")&&c.preventdefault(),f.one(""show.bs.modal"",function(a){a.isdefaultprevented()||f.one(""hidden.bs.modal"",function(){d.is("":visible"")&&d.trigger(""focus"")})}),b.call(f,g,this)})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tooltip""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.tooltip"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var class=""tooltip"" role=""tooltip""><div class=""tooltip-arrow""></div><div class=""tooltip-inner""></div></div>',trigger:""hover document.constructor&&!this.options.selector)throw new error(""`selector` option must be specified when initializing ""+this.type+"" on the window.document object!"");for(var e=this.options.trigger.split("" ""),f=e.length;f--;){var g=e[f];if(""click""==g)this.$element.on(""click.""+this.type,this.options.selector,a.proxy(this.toggle,this));else if(""manual""!=g){var h=""hover""==g?""mouseenter"":""focusin"",i=""hover""==g?""mouseleave"":""focusout"";this.$element.on(h+"".""+this.type,this.options.selector,a.proxy(this.enter,this)),this.$element.on(i+"".""+this.type,this.options.selector,a.proxy(this.leave,this))}}this.options.selector?this._options=a.extend({},this.options,{trigger:""manual"",selector:""""}):this.fixtitle()},c.prototype.getdefaults=function(){return c.defaults},c.prototype.getoptions=function(b){return b=a.extend({},this.getdefaults(),this.$element.data(),b),b.delay&&""number""==typeof b.delay&&(b.delay={show:b.delay,hide:b.delay}),b},c.prototype.getdelegateoptions=function(){var b={},c=this.getdefaults();return this._options&&a.each(this._options,function(a,d){c[a]!=d&&(b[a]=d)}),b},c.prototype.enter=function(b){var c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof a in c=b instanceof this.constructor?b:a(b.currenttarget).data(""bs.""+this.type);return c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c)),b instanceof b=a.event(""show.bs.""+this.type);if(this.hascontent()&&this.enabled){this.$element.trigger(b);var e=this,f=this.tip(),g=this.getuid(this.type);this.setcontent(),f.attr(""id"",g),this.$element.attr(""aria-describedby"",g),this.options.animation&&f.addclass(""fade"");var h=""function""==typeof n=h,o=this.getposition(this.$viewport);h=""bottom""==h&&k.bottom+m>o.bottom?""top"":""top""==h&&k.top-m<o.top?""bottom"":""right""==h&&k.right+l>o.width?""left"":""left""==h&&k.left-l<o.left?""right"":h,f.removeclass(n).addclass(h)}var p=this.getcalculatedoffset(h,k,l,m);this.applyplacement(p,h);var q=function(){var a=e.hoverstate;e.$element.trigger(""shown.bs.""+e.type),e.hoverstate=null,""out""==a&&e.leave(e)};a.support.transition&&this.$tip.hasclass(""fade"")?f.one(""bstransitionend"",q).emulatetransitionend(c.transition_duration):q()}},c.prototype.applyplacement=function(b,c){var k=this.getviewportadjusteddelta(c,b,i,j);k.left?b.left+=k.left:b.top+=k.top;var a=this.tip(),b=this.gettitle();a.find("".tooltip-inner"")this.options.html?""html"":""text"",a.removeclass(""fade in top bottom left right"")},c.prototype.hide=function(b){function d(){""in""!=e.hoverstate&&f.detach(),e.$element.removeattr(""aria-describedby"").trigger(""hidden.bs.""+e.type),b&&b()}var e=this,f=a(this.$tip),g=a.event(""hide.bs.""+this.type);return this.$element.trigger(g),g.isdefaultprevented()?void a=this.$element;(a.attr(""title"")||""string""!=typeof a.attr(""data-original-title""))&&a.attr(""data-original-title"",a.attr(""title"")||"""").attr(""title"","""")},c.prototype.hascontent=function(){return this.gettitle()},c.prototype.getposition=function(b){b=b||this.$element;var e;var h=b.top-f-g.scroll,i=b.top+f-g.scroll+d;h<g.top?e.top=g.top-h:i>g.top+g.height&&(e.top=g.top+g.height-i)}else{var j=b.left-f,k=b.left+f+c;j<g.left?e.left=g.left-j:k>g.right&&(e.left=g.left+g.width-k)}return e},c.prototype.gettitle=function(){var a,b=this.$element,c=this.options;return a=b.attr(""data-original-title"")||(""function""==typeof new error(this.type+"" `template` option must consist of exactly top-level element!"");return this.$tip},c.prototype.arrow=function(){return c=this;b&&(c=a(b.currenttarget).data(""bs.""+this.type),c||(c=new this.constructor(b.currenttarget,this.getdelegateoptions()),a(b.currenttarget).data(""bs.""+this.type,c))),b?(c.instate.click=!c.instate.click,c.isinstatetrue()?c.enter(c):c.leave(c)):c.tip().hasclass(""in"")?c.leave(c):c.enter(c)},c.prototype.destroy=function(){var a=this;cleartimeout(this.timeout),this.hide(function(){a.$element.off("".""+a.type).removedata(""bs.""+a.type),a.$tip&&a.$tip.detach(),a.$tip=null,a.$arrow=null,a.$viewport=null})};var d=a.fn.tooltip;a.fn.tooltip=b,a.fn.tooltip.constructor=c,a.fn.tooltip.noconflict=function(){return a.fn.tooltip=d,this}}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.popover""),f=""object""==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data(""bs.popover"",e=new c(this,f)),""string""==typeof b&&e[b]())})}var c=function(a,b){this.init(""popover"",a,b)};if(!a.fn.tooltip)throw new error(""popover requires class=""popover"" role=""tooltip""><div class=""popover-content""></div></div>'}),c.prototype=a.extend({},a.fn.tooltip.constructor.prototype),c.prototype.constructor=c,c.prototype.getdefaults=function(){return c.defaults},c.prototype.setcontent=function(){var a=this.tip(),b=this.gettitle(),c=this.getcontent();a.find("".popover-title"")this.options.html?""html"":""text"",a.find("".popover-content"").children().detach().end()this.options.html?""string""==typeof c?""html"":""append"":""text"",a.removeclass(""fade top bottom left right in""),a.find("".popover-title"").html()||a.find("".popover-title"").hide()},c.prototype.hascontent=function(){return this.gettitle()||this.getcontent()},c.prototype.getcontent=function(){var a=this.$element,b=this.options;return a.attr(""data-content"")||(""function""==typeof this.$arrow=this.$arrow||this.tip().find("".arrow"")};var d=a.fn.popover;a.fn.popover=b,a.fn.popover.constructor=c,a.fn.popover.noconflict=function(){return a.fn.popover=d,this}}(jquery),+function(a){""use strict"";function b(c,d){this.$body=a(document.body),this.$scrollelement=a(a(c).is(document.body)?window:c),this.options=a.extend({},b.defaults,d),this.selector=(this.options.target||"""")+"" .nav li > c(c){return this.each(function(){var d=a(this),e=d.data(""bs.scrollspy""),f=""object""==typeof c&&c;e||d.data(""bs.scrollspy"",e=new b(this,f)),""string""==typeof b=a(this),e=b.data(""target"")||b.attr(""href""),f=/^#./.test(e)&&a(e);return f&&f.length&&f.is("":visible"")&&[[f[c]().top+d,e]]||null}).sort(function(a,b){return a,b=this.$scrollelement.scrolltop()+this.options.offset,c=this.getscrollheight(),d=this.options.offset+c-this.$scrollelement.height(),e=this.offsets,f=this.targets,g=this.activetarget;if(this.scrollheight!=c&&this.refresh(),b>=d)return this.activetarget=null,this.clear();for(a=e.length;a--;)g!=f[a]&&b>=e[a]&&(void c=this.selector+'[data-target=""'+b+'""],'+this.selector+'[href=""'+b+'""]',d=a(c).parents(""li"").addclass(""active"");d.parent("".dropdown-menu"").length&&(d=d.closest(""li.dropdown"").addclass(""active"")), d.trigger(""activate.bs.scrollspy"")},b.prototype.clear=function(){a(this.selector).parentsuntil(this.options.target,"".active"").removeclass(""active"")};var d=a.fn.scrollspy;a.fn.scrollspy=c,a.fn.scrollspy.constructor=b,a.fn.scrollspy.noconflict=function(){return a.fn.scrollspy=d,this},a(window).on(""load.bs.scrollspy.data-api"",function(){a('[data-spy=""scroll""]').each(function(){var b=a(this);c.call(b,b.data())})})}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.tab"");e||d.data(""bs.tab"",e=new c(this)),""string""==typeof b&&e[b]()})}var b=this.element,c=b.closest(""ul:not(.dropdown-menu)""),d=b.data(""target"");if(d||(d=b.attr(""href""),d=d&&d.replace(/.*(?=#[^\s]*$)/,"""")),!b.parent(""li"").hasclass(""active"")){var e=c.find("".active:last f(){g.removeclass(""active"").find(""> .dropdown-menu > g=d.find(""> .active""),h=e&&a.support.transition&&(g.length&&g.hasclass(""fade"")||!!d.find(""> .fade"").length);g.length&&h?g.one(""bstransitionend"",f).emulatetransitionend(c.transition_duration):f(),g.removeclass(""in"")};var d=a.fn.tab;a.fn.tab=b,a.fn.tab.constructor=c,a.fn.tab.noconflict=function(){return a.fn.tab=d,this};var e=function(c){c.preventdefault(),b.call(a(this),""show"")};a(document).on(""click.bs.tab.data-api"",'[data-toggle=""tab""]',e).on(""click.bs.tab.data-api"",'[data-toggle=""pill""]',e)}(jquery),+function(a){""use strict"";function b(b){return this.each(function(){var d=a(this),e=d.data(""bs.affix""),f=""object""==typeof b&&b;e||d.data(""bs.affix"",e=new c(this,f)),""string""==typeof b&&e[b]()})}var affix-top e=this.$target.scrolltop(),f=this.$element.offset(),g=this.$target.height();if(null!=c&&""top""==this.affixed)return h=null==this.affixed,i=h?e:f.top,j=h?g:b;return this.pinnedoffset;this.$element.removeclass(c.reset).addclass(""affix"");var a=this.$target.scrolltop(),b=this.$element.offset();return b=this.$element.height(),d=this.options.offset,e=d.top,f=d.bottom,g=math.max(a(document).height(),a(document.body).height());""object""!=typeof d&&(f=e=d),""function""==typeof e&&(e=d.top(this.$element)),""function""==typeof f&&(f=d.bottom(this.$element));var h=this.getstate(g,b,e,f);if(this.affixed!=h){null!=this.unpin&&this.$element.css(""top"","""");var i=""affix""+(h?""-""+h:""""),j=a.event(i+"".bs.affix"");if(this.$element.trigger(j),j.isdefaultprevented())return;this.affixed=h,this.unpin=""bottom""==h?this.getpinnedoffset():null,this.$element.removeclass(c.reset).addclass(i).trigger(i.replace(""affix"",""affixed"")+"".bs.affix"")}""bottom""==h&&this.$element.offset({top:g-b-f})}};var d=a.fn.affix;a.fn.affix=b,a.fn.affix.constructor=c,a.fn.affix.noconflict=function(){return a.fn.affix=d,this},a(window).on(""load"",function(){a('[data-spy=""affix""]').each(function(){var c=a(this),d=c.data();d.offset=d.offset||{},null!=d.offsetbottom&&(d.offset.bottom=d.offsetbottom),null!=d.offsettop&&(d.offset.top=d.offsettop),b.call(c,d)})})}(jquery);</script> <script>/** * @preserve shiv | @afarkas @jdalton @jon_neal @rem | licensed */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a,b){function c(a,b){var c.innerhtml=""x<style>""+b+""</style>"",d.insertbefore(c.lastchild,d.firstchild)}function d(){var a=t.elements;return""string""==typeof a?a.split("" ""):a}function e(a,b){var c=t.elements;""string""!=typeof c&&(c=c.join("" "")),""string""!=typeof a&&(a=a.join("" "")),t.elements=c+"" ""+a,j(b)}function f(a){var b=s[a[q]];return b||(b={},r++,a[q]=r,s[r]=b),b}function g(a,c,d){if(c||(c=b),l)return c.createelement(a);d||(d=f(c));var e;return e=d.cache[a]?d.cache[a].clonenode():p.test(a)?(d.cache[a]=d.createelem(a)).clonenode():d.createelem(a),!e.canhavechildren||o.test(a)||e.tagurn?e:d.frag.appendchild(e)}function h(a,c){if(a||(a=b),l)return a.createdocumentfragment();c=c||f(a);for(var e}function i(a,b){b.cache||(b.cache={},b.createelem=a.createelement,b.createfrag=a.createdocumentfragment,b.frag=b.createfrag()),a.createelement=function(c){return t.shivmethods?g(c,a,b):b.createelem(c)},a.createdocumentfragment=function(""h,f"",""return function(){var n=f.clonenode(),c=n.createelement;h.shivmethods&&(""+d().join().replace(/[\w\-:]+/g,function(a){return b.createelem(a),b.frag.createelement(a),'c(""'+a+'"")'})+"");return n}"")(t,b.frag)}function j(a){a||(a=b);var a=b.createelement(""a"");a.innerhtml=""<xyz></xyz>"",k=""hidden""in a=b.createdocumentfragment();return""undefined""==typeof a.clonenode||""undefined""==typeof a.createdocumentfragment||""undefined""==typeof t={elements:n.elements||""abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output picture progress section summary template time }; </script> <script>/*! respond.js min/max-width media query polyfill * copyright scott jehl * licensed under https://github.com/scottjehl/respond/blob/master/license-mit * */ // only run this code in ie if (!!window.navigator.useragent.match(""msie { !function(a){""use strict"";a.matchmedia=a.matchmedia||function(a){var b,c=a.documentelement,d=c.firstelementchild||c.firstchild,e=a.createelement(""body""),f=a.createelement(""div"");return f.innerhtml='&shy;<style media=""'+a+'""> { width: strict"";function c={};a.respond=c,c.update=function(){};var d=[],e=function(){var a.xmlhttprequest}catch(c){b=new a.activexobject(""microsoft.xmlhttp"")}return function(){return b}}(),f=function(a,b){var all"")&&a.matchmedia(""only all"").matches,!c.mediaqueriessupported){var date).gettime();if(b&&g&&p>r-g)return a.cleartimeout(h),h=a.settimeout(you,p),void v in l)if(l.hasownproperty(v)){var c in d in f)if(f.hasownproperty(d)){var e=j.createelement(""style""),f=f[d].join(""\n"");e.type=""text/css"",e.media=d,q.insertbefore(e,o.nextsibling),e.stylesheet?e.stylesheet.csstext=f:e.appendchild(j.createtextnode(f)),n.push(e)}},v=function(a,b,d){var g=function(a){return }; </script> {font-size: {font-size: {font-size: {font-size: {font-size: {font-size: {font-size: code {color: inherit; background-color: pre:not([class]) { background-color: white }</style> <script> /** * jquery plugin: sticky tabs * * @author aidan lister <aidan@php.net> * adapted by ruben arslan to activate parent tabs too * */ (function($) { ""use strict""; $.fn.rmarkdownstickytabs = function() { var context = this; // show the tab corresponding with the hash in the url, or the first tab var showstufffromhash = function() { var hash = window.location.hash; var selector = hash ? 'a[href=""' + hash + '""]' : 'li.active > a'; var $selector = $(selector, context); if($selector.data('toggle') === ""tab"") { $selector.tab('show'); // walk up the ancestors of this element, show any hidden tabs $selector.parents('.section.tabset').each(function(i, elm) { var link = $('a[href=""#' + $(elm).attr('id') + '""]'); if(link.data('toggle') === ""tab"") { link.tab(""show""); } }); } }; // set the correct tab when the page loads showstufffromhash(context); // set the correct tab when a user uses their back/forward button $(window).on('hashchange', function() { showstufffromhash(context); }); // change the url when tabs are clicked $('a', context).on('click', function(e) { history.pushstate(null, null, this.href); showstufffromhash(context); }); return this; }; }(jquery)); window.buildtabsets = function(tocid) { // build a tabset from a section div with the .tabset class function buildtabset(tabset) { // check for fade and pills options var fade = tabset.hasclass(""tabset-fade""); var pills = tabset.hasclass(""tabset-pills""); var navclass = pills ? ""nav-pills"" : ""nav-tabs""; // determine the heading level of the tabset and tabs var match = tabset.attr('class').match(/level(\d) /); if (match === null) return; var tabsetlevel = var tablevel = tabsetlevel + // find all subheadings immediately below var tabs = tabset.find(""div.section.level"" + tablevel); if (!tabs.length) return; // create tablist and tab-content elements var tablist = $('<ul class=""nav ' + navclass + '"" role=""tablist""></ul>'); var tabcontent = $('<div class=""tab-content""></div>'); // build the tabset var activetab = tabs.each(function(i) { // get the tab div var tab = $(tabs[i]); // get the id then sanitize it for use with bootstrap tabs var id = tab.attr('id'); // see if this is marked as the active tab if (tab.hasclass('active')) activetab = i; // remove any table of contents entries associated with // this id (since we will be removing the heading element) $(""div#"" + tocid + "" li a[href='#"" + id + ""']"").parent().remove(); // sanitize the id for use with bootstrap tabs id = id.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_'); tab.attr('id', id); // get the heading element within it, grab it is text, then remove it var heading = tab.find('h' + tablevel + ':first'); var headingtext = heading.html(); heading.remove(); // build and append the tab list item var a = $('<a role=""tab"" data-toggle=""tab"">' + headingtext + '</a>'); a.attr('href', '#' + id); a.attr('aria-controls', id); var li = $('<li role=""presentation""></li>'); li.append(a); tablist.append(li); // set it is attributes tab.attr('role', 'tabpanel'); tab.addclass('tab-pane'); tab.addclass('tabbed-pane'); if (fade) tab.addclass('fade'); // move it into the tab content div tab.detach().appendto(tabcontent); }); // set active tab $(tablist.children('li')[activetab]).addclass('active'); var active = $(tabcontent.children('div.section')[activetab]); active.addclass('active'); if (fade) active.addclass('in'); if (tabset.hasclass(""tabset-sticky"")) tabset.rmarkdownstickytabs(); } // convert section divs with the .tabset class to tabsets var tabsets = $(""div.section.tabset""); tabsets.each(function(i) { buildtabset($(tabsets[i])); }); }; </script> <style type=""text/css"">.hljs-literal { color: } .hljs-number { color: } .hljs-comment { color: font-style: italic; } .hljs-keyword { color: font-weight: bold; } .hljs-string { color: } </style> <script <style type=""text/css""> code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: div.hanging-indent{margin-left: text-indent: ul.task-list{list-style: none;} </style> <style type=""text/css"">code{white-space: pre;}</style> <script type=""text/javascript""> if (window.hljs) { hljs.configure({languages: []}); hljs.inithighlightingonload(); if (document.readystate && document.readystate === ""complete"") { window.settimeout(function() { hljs.inithighlighting(); }, } } </script> <style type=""text/css""> .main-container { max-width: margin-left: auto; margin-right: auto; } img { } .tabbed-pane { padding-top: } .html-widget { margin-bottom: } button.code-folding-btn:focus { outline: none; } summary { display: list-item; } details > summary > p:only-child { display: inline; } pre code { padding: } </style> <!-- tabsets --> <style type=""text/css""> .tabset-dropdown > .nav-tabs { display: inline-table; max-height: min-height: overflow-y: auto; border: solid #ddd; border-radius: } .tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before { content: font-family: 'glyphicons halflings'; display: inline-block; padding: border-right: solid #ddd; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before { content: font-family: 'glyphicons halflings'; border: none; } .tabset-dropdown > .nav-tabs > li.active { display: block; } .tabset-dropdown > .nav-tabs > li > a, .tabset-dropdown > .nav-tabs > li > a:focus, .tabset-dropdown > .nav-tabs > li > a:hover { border: none; display: inline-block; border-radius: background-color: transparent; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li { display: block; float: none; } .tabset-dropdown > .nav-tabs > li { display: none; } </style> <!-- code folding --> </head> <body> <div class=""container-fluid main-container""> <div id=""header""> </div> <div id=""welcome-to-the-esm-item-repository-shiny-app"" class=""section to the esm item repository shiny ykk + bk</sup></sub></p> <p><strong>what</strong></p> <p>we are an open science initiative dedicated to fostering the advancement of experience sampling methods (esm) research. launched in as part of a three-phase project, our repository now boasts items contributed by five research groups spanning six countries. our goal is to provide researchers with a centralized source for discovering, learning about, and identifying relevant esm items. whether you are looking to integrate existing knowledge, identify overlapping items, or support the conceptual development of new items, our repository is here to facilitate your research journey. explore our <a href=""https://www.esmitemrepositoryinfo.com/"">website</a> for more information on using the esm item repository or contributing items.</p> <p><strong>why</strong></p> <p>exploring psychological phenomena in real-life settings is on the rise, driven by advances in esm. however, the lack of standardized testing for esm items introduces challenges, leading to diverse development practices and limited transparency.</p> <p>our initiative, the esm item repository, addresses this gap. we aim to establish a centralized platform for esm items, promoting transparency and reproducibility in psychological research.</p> <p>key objectives:</p> <ul> <li><p>centralized source: provide researchers with a unified platform to discover and understand esm items.</p></li> <li><p>collaboration: facilitate the integration of existing knowledge, fostering a collaborative research environment.</p></li> <li><p>overlap identification: assist researchers in identifying overlaps between items, enhancing measurement consistency.</p></li> <li><p>development support: support the conceptual development and rigorous evaluation of esm items.</p></li> </ul> <p><strong>do you want to contribute to the item repository?</strong></p> <p>if you want to contribute items to the esm repository, all you have to do is to follow these steps:</p> <p><img do not alt=""repository workflow""></p> <p><strong>how the app works</strong></p> <p>the data resides in a .csv file hosted on osf.io and is made accessible to users through this shiny app, enabling the search functionality for esm items. developed in r, the app leverages packages such as shiny, shinydashboard, shinyjs, and xlsx. it is deployed via shinyapps.io for convenient accessibility.</p> <p><strong>key features</strong></p> <p>current version: <p>the items from the repository can be searched and selected by one the following attributes:</p> <ul> <li>item id<br /> </li> <li>wording in original language<br /> </li> <li>english wording<br /> </li> <li>item description<br /> </li> <li>data set of origin<br /> </li> <li>number of beeps per day of the study<br /> </li> <li>measured population<br /> </li> <li>citation of the study<br /> </li> <li>existing reference<br /> </li> <li>contributors contact information</li> </ul> <p>once selected, the data set with the items and relevant information can be downloaded either as a .csv file or as excel file.</p> <p><strong>issues</strong></p> <p>in case you run into any problems with the shiny app, please let us know on our <a href=""https://github.com/ykkunkels/esir_portal/issues"">github issue tracker</a> or via the <a href=""https://esmitemrepositoryinfo.com/contact"">contact form</a> on our website.</p> <p><strong>acknowledgements and citation help</strong></p> <p>when insights and content from the repository are used, the repository should be cited as: kirtley, o. j., hiekkaranta, a. p., kunkels, y. k., verhoeven, d., van nierop, m., &amp; myin-germeys, i. april the experience sampling method (esm) item repository. retrieved from doi <p>funding acknowledgements: olivia kirtley and anu hiekkarantas work on the project is supported by postdoctoral and phd fellowships, respectively, from an fwo odysseus grant to inez myin-germeys (fwo yoram kunkels work on this project is supported by the european research council trans-id; no to marieke wichers).</p> <p><strong>disclaimer</strong></p> <p>we do not take responsibility for the quality of items within the repository. inclusion of items within the repository does not indicate our endorsement of them. all items within the repository are subject to a creative commons attribution non-commerical license (cc by-nc).</p> </div> </div> <script> // add bootstrap table styles to pandoc tables function bootstrapstylepandoctables() { $('tr.odd').parent('tbody').parent('table').addclass('table table-condensed'); } $(document).ready(function () { bootstrapstylepandoctables(); }); </script> <!-- tabsets --> <script> $(document).ready(function () { window.buildtabsets(""toc""); }); $(document).ready(function () { $('.tabset-dropdown > .nav-tabs > li').click(function () { $(this).parent().toggleclass('nav-tabs-open'); }); }); </script> <!-- code folding --> <!-- dynamically load mathjax for compatibility with self-contained --> <script> (function () { var script = document.createelement(""script""); script.type = ""text/javascript""; script.src = ""https://mathjax.rstudio.com/latest/mathjax.js?config=tex-ams-mml_htmlormml""; })(); </script> </body> </html>"
1,hedonometer,a rails-based web service for collecting sms-based experience sampling data,"# hedonometer ## background a simple rails-based web application for collecting experience sampling data via text message. much of traditional psychology research involves bring participants to the lab and having them fill out various questionnaires. then, researchers correlate their questionnaire answers with other data acquired in the lab. the big problem with this is: how do we know whether peoples' behavior in the lab is anything like their behavior in the ""real world?"" experience sampling tries to get at this by collecting data while participants are out of the lab, engaging in their normal activity. many variants on experience sampling exist; however, extant ones tend to rely either on specialized hardware and/or software, or online connectivity. hedonometer differs in that participants are prompted for and send data purely by text message. hence, people need only have a cell phone to participate. ## requirements this was written and tested in ruby and then upgraded to ## getting started development prerequisites: sudo apt install postgresql libpq-dev nodejs (or any other execjs runtime) installing this is the same as installing any rails app. clone, `bundle install`, `rake db:migrate`. ## database recently switched to postgres in devel to avoid a weird json blob problem in sqlite. there is likely a cleaner way, but per environment, do something like: sudo apt install postgresql libpq-dev sudo -you postgres psql create database hedonometer_development; create user myuser with encrypted password grant all privileges on database hedonometer_development to myuser; create database hedonometer_test; grant all privileges on database hedonometer_test to myuser; create database hedonometer_production; grant all privileges on database hedonometer_production to myuser; then copy `config/database.yml.example` to `config/database.yml` and edit it to match. now you should be able to migrate the db: bin/rails db:migrate ## configuring admins there is not yet a rake task to add your first admin, so pull up `rails console` and: admin.create(email: ""your_email@example.com"", password: ""some-password"", can_change_admins: true) `rails server` and you are in. for this to accept incoming texts, you will need a publicly accessible server. ### adding multiple admins to a survey a = admin.find(admin_id) a.surveys.append(survey.find(survey_id)) not sure how to force the `can_modify_survey` for secondary admins: a.survey_permissions.each do |perm| perm.can_modify_survey = true perm.save end ## twilio config at the same time, head over to twilio and get yourself an account. either sign up for a trial number and register your mobile number with it, or buy some credits. on the numbers screen, note your twilio account sid and your authorization token. ## survey creation back in the hedonometer, create a survey. paste in your account sid and auth token; you should get a little ""active"" status light. the ""phone number"" field should autocomplete with the number you have purchased. further documentation about different survey types is in doc/. ## development ### ubuntu packages required for development sudo apt-get install libpq-dev libmysqlclient-dev nodejs ### delayed jobs in dev by default, texting is log-only and does not hit twilio in dev. start a daemon: bin/delayed_job start start a server. now you can use the website, add surveys and participants, and the simulator and message lists should show what ""would have"" happened."
1,AWARE-Plugin-ESMSurvey,media exposure on the smartphone: plugin for the aware framework with preconfigured experienced sampling questions allowing to measure boredom and stress level of smartphone user,# aware-plugin-esmsurvey builds typical experience sampling method questions for the aware framework on android: https://awareframework.com/
0,swiper,"app for experience sampling studies using a swiping-interface (stefan westermann, dev@westermann.io )","# swiper app for experience sampling studies using a swiping-interface author: stefan westermann, dev@westermann.io software and libraries used: hammer.js fabric.js cordova"
1,yuaudio,web app for collecting audio samples,"# yuaudio yuaudio allows researchers to collect audio data in the fi eld, which can be used in many areas such as experience sampling, phonetics, or verbal communication research. for participants, the web application does not require installation and can be run via a mobile web browser."
1,experience-sampling-linebot,an experience sampling method (esm) app written in python via line messaging api platform.,"# line messaging api (line bot) (esm) <img src=""res/demonstration.gif"" alt=""demonstration.gif""><br> # ## esm (heidisql)<br><br> !db.jpg ## id idesm (participant_id)<br><br> <img src=""res/id.gif"" alt=""id.gif""><br> ## esm # ## verhagen, s. j. w., hasmi, l., drukker, m., van os, j., & delespaul, p. a. e. g. use of the experience sampling method in the context of clinical trials. *evidence-based mental health*,"
1,personality_chatbots,this is the source code for the personality imbued chatbots we developed as part of a research project at lmu munich (germany). this research project was published at chi more details about the project as well as an extended description of the implementation may be found on the project website: http://www.medien.ifi.lmu.de/extraversion-chatbots,"# user perceptions of extraversion in chatbots after repeated use this is the source code for the personality imbued chatbots we developed as part of a research project at lmu munich (germany). this research project was published at <a more details about the project as well as an extended description of the implementation may be found on the <a href=""http://www.medien.ifi.lmu.de/extraversion-chatbots"">project website</a>. ## abstract whilst imbuing robots and voice assistants with personality has been found to positively impact user experience, little is known about user perceptions of personality in purely text-based chatbots. in a within-subjects study, we asked participants to interact with three chatbots with different levels of extraversion (extraverted, average, introverted), each over the course of four days. we systematically varied the chatbots' responses to manipulate extraversion based on work in the psycholinguistics of human behaviour. our results show that participants perceived the extraverted and average chatbots as such, whereas verbal cues transferred from human behaviour were insufficient to create an introverted chatbot. whilst most participants preferred interacting with the extraverted chatbot, participants engaged significantly more with the introverted chatbot as indicated by the users' average number of written words. we discuss implications for researchers and practitioners on how to design chatbot personalities that can adapt to user preferences. ## implementation we developed the chatbots for the instant messaging application telegram to support a platform-independent solution integrated in a messenger app that participants are familiar with. the chatbots were implemented in python using the <code>python-telegram-bot</code> package, version and the telegram bot api (link). the chatbot ran on university servers. the implementation is based on the experience sampling chatbot we developed in [draxler et al. more details about the project as well as an extended description of the implementation may be found on the <a href=""http://www.medien.ifi.lmu.de/extraversion-chatbots"">project website</a>. please note that the current version of the chatbot implementation was intended for internal use only. we publish our source code to make the research accessible and transparent in the spirit of open science. that is, the source code is not documented in such a way that it can be easily reused. whilst we intend to release a version in the future which will allow researchers to easily create their own experience sampling chatbots, this is not currently the case. in case of questions or interest in using our code, please contact the first author <a href=""mailto:sarah.voelkel@ifi.lmu.de"">sarah there is vlkel</a>. ## references sarah there is vlkel, ramona schoedel, lale kaya, and sven mayer. user perceptions of extraversion in chatbots after repeated use. in chi conference on human factors in computing systems, pp. doi: fiona draxler, linda hirsch, jingyi li, carl oechsner, sarah there is vlkel, and andreas butz. flexibility and social disconnectness: assessing university students well-being using an experience sampling chatbot and surveys over two years of in dis acm conference on designing interactive systems. doi:"
0,timestudydocumentation.github.io,time study documentation website and discussion group,"<p align=""center""> <img src=""https://github.com/timestudydocumentation/timestudydocumentation.github.io/blob/main/docs/source/images/logo_icon.png"" /> </p> # welcome to time study documentation! the **temporal influences on movement and exercise (time) study** uses mobile and wearable technologies to measure moment-to-moment experiences that shape our health behaviors and decision making. the goal is to study how different contextual and situational factors explain the adoption and maintenance of health behaviors. we are using a combination of phone-based experience sampling, wearable-based micro-ema, and passive sensing to build predictive models of health behavior at the individual and group levels. we conducted a within-subject case-crossover observational study across a period among ethnically-diverse, emerging adults (ages for details about the study and dataset codebooks, please check our website. ## feedback we welcome feedback from researchers. please let us know if you have questions about the study, dataset, or suggestions regarding the codebooks. the best way to give us feedback is to post issues in the discussion group."
0,SmartHomeWarningTaxonomy,software of a smart home warning system (shws) prototype to evaluate a taxonomy of output stimuli with integrated experience sampling method (esm) evaluation,"# smart home warning system prototype for user studies !prototype !start screen ## background the code provided in this repository represents the software for the prototype of the smart home warning system described in the paper **""getting the residents' attention: the perception of warning channels in smart home warning systems.""** currently in preparation. abstract: >about half a billion households are expected to use smart home systems by although many iot sensors, such as smoke detectors or security cameras, are available and governmental crisis warning systems are in place, little is known about how to warn appropriately in smart home environments. we created a raspberry pi based prototype with a speaker, a display, and a connected smart light bulb. together with a focus group, we developed a taxonomy for warning messages in smart home environments, dividing them into five classes with different stimuli. we evaluated the taxonomy using the experience sampling method (esm) in a field study at participants' (n = homes testing warnings. the results show that taxonomy-based warning stimuli are perceived to be appropriate and participants could imagine using such a warning system. we propose a deeper integration of warning capabilities into smart home environments to enhance the safety of citizens. the public url to the paper will be accessable upon final publication. ## hardware of the prototype: !hardware the prototype runs on a raspberry pi using raspberry pi os, a debian-based operating system. several components are connected to the pi: - touch display with a resolution of - usb speaker - gsm hat - zigbee usb dongle ## autostart to ensure the code runs as soon as the raspberry pi boots, the main_dialog.py file needs to be added to the autostart. this can be done by executing the following steps: open the terminal and create a .desktop file in the autostart directory add the following line to the .desktop file: `[desktop entry] /home/pi/shws/main_dialog.py` save the file and reboot the pi afterwardsf ## warnings !warning the warnings presented can be configured in resources/simulations/testsimulation.json ## esm ratings !esm ratings after each alarm, participants can give immediate feedback. the esm questions can be configured in questions.json. ## files the log files created by the application can be found at /home/pi/shws/resources/log.log. the evaluation of the user is stored at /home/pi/shws/resources/feedback. the paths can be configured by changing the corresponding variables in the class util.py. ## contact https://peasec.de/team/haesler/"
0,Fitness_Trinetra_Flutter,"revolutionize your workout with our advanced fitness app using ml kit for real-time exercise tracking, daily streaks, heart rate calculation, and a built-in music feature. crafted with flutter for a seamless and user-friendly experience.","# trinetra - application built using flutter ## introduction building upon the latest advancements in technology, our cutting-edge workout application redefines the fitness experience by seamlessly integrating front camera technology with ml kit for precise exercise tracking. users can now receive real-time feedback through red light alerts, ensuring optimal body structure during each workout session. the app goes beyond traditional fitness tracking by promoting consistency through daily streaks, motivating users to establish and maintain a regular exercise routine. all user data is securely stored on firebase, providing a seamless and reliable cloud-based solution for personalized fitness journeys. incorporating the capabilities of the back camera and flashlight, our application takes fitness monitoring to the next level by calculating the user's heart rate. this feature enhances the overall fitness experience, allowing users to gain deeper insights into their cardiovascular health and performance. a specially curated music feature has been seamlessly integrated, offering users the option to create an immersive workout ambiance. with the ability to listen to their favorite tunes while engaging in physical activities, users can elevate their motivation and focus during each exercise session. the user interface, crafted with flutter, ensures a smooth and intuitive navigation experience. the app's sleek design not only enhances usability but also reflects a commitment to providing a top-tier fitness application. ## features real-time exercise tracking:** utilize front camera technology and ml kit for precise exercise monitoring, offering users immediate feedback through red light alerts to ensure proper body structure. consistency and motivation:** encourage users to maintain a consistent workout routine with daily streaks, fostering motivation and discipline in their fitness journey. cloud-based storage with firebase:** safeguard user data and progress by utilizing firebase for secure and reliable cloud-based storage, enabling seamless access across devices. heart rate calculation:** harness the power of the back camera and flashlight to calculate the user's heart rate, providing valuable insights into cardiovascular health and performance. immersive music feature:** elevate the workout experience with a seamlessly integrated music feature, allowing users to listen to their favorite tunes and enhance motivation during exercise. customizable dark mode:** tailor the app's appearance to your preference with the option to switch between dark mode and the standard mode, ensuring a comfortable and visually pleasing workout experience. ## sample video: **video link:** trinetra-flutter<br> _the application was refined extensively to improve accuracy and user experience after the release of this video_ ## screenshots ""optional title"") | ""optional title"") | ""optional title"") | ""optional title"") | ""optional title"") :-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|:-------------------------: ""optional title"") | ""optional title"") | ""optional title"") | ""optional title"") | ""optional title"") ## folder structure ``` lib/ |- intro_screens/ |- auth/ |- abs/ |- back/ |- chest/ |- glutes/ |- quads/ |- yoga/ |- widgets/ |- bargraph/ |- controllers/ |- screens/ |- main.dart ``` ## packages used: ``` pubspec.yaml/ |- smooth_page_indicator |- lottie |- animated_text_kit |- shared_preferences |- firebase_core |- firebase_auth |- cloud_firestore |- google_sign_in |- curved_navigation_bar |- pie_chart |- fl_chart |- share_plus |- provider |- carousel_slider |- giff_dialog |- camera |- google_ml_kit |- charts_flutter_new |- wakelock |- device_preview |- intl |- get |- just_audio |- on_audio_query |- permission_handler |- flutter_localizations ``` ## conclusion i will be happy to answer any questions that you may have about this approach. if you liked my work, do not forget to star the repo to show your support."
1,Telegram-Survey-Bot,a telegram bot to conduct your ambulatory assessment study by sending surveys to participants' smartphones.,"[!codacy [!actions [!license: gpl [!github [!github all [!made-with-python](https://www.python.org/) !logo a telegram bot to conduct your ambulatory assessment study by sending surveys to participants' smartphones. the bot script is written in python, can be simply configured by a single json-file and runs under windows, macos and linux. ## features - use fix dates and times for your surveys or use day calculation depending on the subscribe-day and time calculation depending on the wakeup time of your participants. - three types of links are available: start-, daily- and endlinks - decide how long your survey links are visible in the telegram chat - assign different conditions to your participants - randomize your survey times for a detailed description concerning the configuration and execution of the script, take a look at our wiki. ## used libraries - python-telegram-bot - apscheduler ## license copyright: (c) michael barthelms, marcel killinger, johannes keller. gnu general public license (see license or telegram survey bot is free software: you can redistribute it and/or modify it under the terms of the gnu general public license as published by the free software foundation, either version of the license, or (at your option) any later version. telegram survey bot is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. see the gnu general public license for more details. ## citation if you use our script, please cite it using the following information: barthelms, m., killinger, m., & keller, j. <i>telegram-survey-bot (version [computer software]</i>. retrieved from > developed by marcel killinger and michael barthelms, supervised by johannes keller from dept. social psychology ulm university"
0,rl_jitai_simulation,rl for jitai optimization using simulated environments.,"# rl for jitai optimization using simulated environments this repository contains the official implementation for the paper: **assessing the impact of context inference error and partial observability on rl methods for just-in-time adaptive interventions**, karine karine, predrag klasnja, susan a. murphy, benjamin m. marlin, uai this paper was accepted at the conference on uncertainty in artificial intelligence, uai + arxiv link: + uai link: + uai poster: https://github.com/reml-lab/rl_jitai_simulation/tree/main/rl_jitai_simulation_poster.pdf ## examples see the examples directory for a list of examples that can be run locally or launched in google colab. for example: + [!open in colab](https://colab.research.google.com/github/reml-lab/rl_jitai_simulation/blob/main/examples/rl_jitai_simulation_quickstart.ipynb) rl for jitai quickstart + [!open in colab](https://colab.research.google.com/github/reml-lab/rl_jitai_simulation/blob/main/examples/rl_jitai_simulation_experiments.ipynb) rl for jitai examples ## citing this paper ``` title = {assessing the impact of context inference error and partial observability on rl methods for just-in-time adaptive interventions}, author = {karine, karine and klasnja, predrag and murphy, susan a. and marlin, benjamin m.}, booktitle = {proceedings of the thirty-ninth conference on uncertainty in artificial intelligence}, pages = year = volume = } ```"
1,LAMP-college-study,add-on to mindlamp to support researcher-less patient onboarding with randomized studies and just-in-time adaptive interventions.,"# college study script the app code is in `main.py`. if you make a change to the imports at the top of the file, update the `requirements.txt` file. the sample environment variables required can be found in `env.sample`."
1,pJITAI-python,python interface to the pjitai mdot api service,"# mdot pjitai (just-in-time adaptive intervention) interface library ## example ```python import pjitai # create a new session to an existing api service session = pjitai.client(server='http://localhost/api', # upload some data data = { 'decision': 'decision_timestamp': 'proximal_outcome': 'proximal_outcome_timestamp': 'timestamp': 'user_id': 'values': [{ 'name': 'step_count', 'value': }] } try: data_to_upload = pjitai.datavector.from_dict(data) session.upload(data_to_upload) print(data_to_upload) except exception as e: print(f'upload exception: {e}') # ask the server to generated a decision data = { 'timestamp': 'user_id': 'values': [{ 'name': 'step_count', 'value': }] } try: decision = pjitai.decisionvector.from_dict(data) session.decision(decision) print(decision) except exception as e: print(f'upload exception: {e}') # have the server update the model parameters based on already uploaded data try: session.update() except exception as e: print(f'upload exception: {e}') ``` ## build and release ```bash bumpver update -p -m build twine check dist/* twine upload dist/* ```"
0,JITAIHealth,a swift implementation of a jitai system using apple watch.,# jitaihealth this project is a swift based application set for iphone and apple watch that involves a jitai system to make inferences in attempts to assist the watch wearer in regards to their cardiovascular health. more will be updated as this project progresses.
1,pulse-react-native-app,techcrunch disrupt hackathon entry,"#tc disrupt novartis entry this is the front end of a submission for the techcrunch disrupt's hackathon. it is built in react native. ## challenge information the novartis challenge, as taken directly from the hackathon page states "" the challenge help us empower heart failure patients and save lives! heart failure is a chronic debilitating and potentially life-threatening disease affecting million people worldwide. it is one of the most difficult and chronic heart diseases to manage and the biggest because of hospital admissions in adults aged over in the western world (source: heart failure). as a result, treatment costs, including hospitalizations, are estimated at billion a year worldwide. about of patients die within a year of diagnosis and within five years (source: cdc and who). what were looking for is a digital solution to help better monitor, manage and even predict worsening symptoms of heart failure. after a patient is diagnosed with heart failure, there are very few resources available to easily and unobtrusively monitor their heart health over time. adherence to therapy and lack of health interventions are major reasons why patients health often deteriorates rapidly after a diagnosis. this solution should therefore drastically reduce the number of hospital readmissions and deaths following an initial diagnosis. help us reimagine medicine by using your creativity and tech skills to develop a tool that easily captures important cardiovascular vitals and monitors symptom progression, empowering patients to detect potential problems earlier and seek treatment sooner. were looking for accessible, affordable, and easy to use technologies that can seamlessly integrate into the life of a patient who has recently been diagnosed with heart failure. use of personal digital devices (smart phones, smart watches, etc.), telemedicine, and innovative patient engagement are encouraged. what we are not looking for is a diagnostic device that (a) is not a standard consumer device (e.g. a non-commercial wearable) and (b) increases the burden and involvement of a patient in monitoring their disease."" ## idea & design our solution to the challenge was to create an app for the families & friends of those suffering from heart conditions. using a fitbit to collect heartbeat and health data, we can port that information to an app for family and friends to help moniter and care for the heart patient. !onboarding !news !dashboard !calendar !invite additional notifications are sent when anomolies in heartbeat data are detected, allowing the team of family and friends to help one suffering from heart disease take preventative measures. !lockscreen !notifications !call ## running the app clone the repo, cd into the folder and run `yarn install`. you then have the choice of the following: * yarn start: starts the development server so you can open your app in the expo app on your phone. * yarn run ios: (mac only, requires xcode) starts the development server and loads your app in an ios simulator. * yarn run android (requires android build tools) starts the development server and loads your app on a connected android device or emulator."
1,FitForecast,"in today's fast-paced society, people often struggle to prioritize their health and well-being. this app delivers customized health interventions, mindfulness, and intelligent dietary suggestions, making it easier for individuals to navigate their health journey amidst daily pressures.","# fitforecast fitforecast: predicting your health path"" emerges as a revolutionary mobile application aimed at enhancing personal health and wellness in today's dynamic world. this innovative app is uniquely designed to provide context-aware health interventions, wellness advice, and intelligent dietary suggestionstailored to individual needs. the core of fitforecast lies in its sophisticated integration of key personal health metrics, including heart rate, sleep patterns, and dietary habits, to offer a daily personalized health itinerary. the app utilizes advanced algorithms to generate customized exercise routines, nutritional guidance, and lifestyle tips, ensuring each recommendation is aligned with the user's unique health status and daily activities."
0,ChatBot,"mental issues can hit anyone really hard. mental health issues is an extremely complex disease. no one knows exactly what causes it. a chatbot is a system that is able to converse and interact with human users using spoken, written, and visual languages. chatbots have potential to increase access to mental health interventions. in particular, chatbots may encourage interaction by those who have traditionally been reluctant to seek mental health advice due to stigmatization. some people may experience depression and feel overwhelmed with sadness and loneliness for no known reason. people dealing with depression want to tell their stories to somebody and they are mostly afraid to speak to their close friends and relatives. the best way of treating the mental health problems is to contact the doctors. our chatbot provides guidance to the user by arranging a video or audio call meeting with the special psychologist available throughout the world by providing therapy.","# chatbot mental issues can hit anyone really hard. mental health issues is an extremely complex disease. no one knows exactly what causes it. a chatbot is a system that is able to converse and interact with human users using spoken, written, and visual languages. chatbots have potential to increase access to mental health interventions. in particular, chatbots may encourage interaction by those who have traditionally been reluctant to seek mental health advice due to stigmatization. some people may experience depression and feel overwhelmed with sadness and loneliness for no known reason. people dealing with depression want to tell their stories to somebody and they are mostly afraid to speak to their close friends and relatives. the best way of treating the mental health problems is to contact the doctors. our chatbot provides guidance to the user by arranging a video or audio call meeting with the special psychologist available throughout the world by providing therapy. responsive webpages * chatbot for users * chatbot for therapist * add therapist in chatbot !screenshot !screenshot !screenshot !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am !whatsapp image at am"
0,neurofit-study,neurofit study by the duke university mcab lab,"# using neuroscience to optimize digital health interventions across adulthood ## background most people know that being more physically active is good for them, but many still do not do it. while clinical trials have demonstrated the efficacy of exercise programs for enhancing cognition and well-being in older age, a persistent challenge is how to motivate aging adults to engage in physical activity in their daily lives. recent neuroscientific and psychological research shows that motivation changes with age. older adults are more motivated by social rewards and pay more attention to and better remember positively-framed messages relative to negatively-framed ones. thus, positively-framed social rewards may provide critical incentives for aging adults to engage in physical activity. ## project description the goal of this bass connections project is to combine approaches from neuroscience, psychology and global health to identify ways to individually motivate adults to become more physically active in daily life. the project will test the hypothesis that positively-framed social rewards will motivate aging adults to more frequently engage in physical activity in daily life. in a community sample of healthy adults ages the team will use human brain imaging (fmri) to assess the sensitivity of motivational brain systems (e.g., striatum and medial prefrontal cortex) to socioemotionally-framed health messages. after neuroimaging, participants will have their activity continuously monitored for three months while receiving physical activity promotion messages on their mobile phones in the form of programmed voice-over ip and text messages, developed in partnership with the duke global digital health science center. team members will use the neural measures as predictors of the effectiveness of specific messages delivered via mobile phone to increase activity in daily life. ## anticipated outcomes publication of findings; data, code and experimental stimuli made publicly available through osf; application for large multidisciplinary federal grant; development of a personalized mobile digital physical activity promotion program that can target aging adults across diverse communities in the local geographical area and beyond ## progress fall initial in-lab cognitive batter, health assessment and mri scanning; activity monitoring spring complete follow-up visits for cognitive batter and health assessment; begin behavioral and mri data quality checking and preprocessing; begin data processing and analysis fall - spring finish data processing and analysis; draft reports and manuscripts"
0,health_project,this a health center project,"# health+: business system of health management organization ## background ""healthy china"" has become a national strategy and a key plan for the five year plan. prevention is better than treatment, which is also a consensus in the medical industry. with the vigorous promotion of the country and the gradual improvement of people's attention to health, the number of health management institutions has mushroomed, from in to in these health management organizations urgently need the support of a large number of high-quality information systems. ## introduction health+ health management system is a business system applied to health management institutions. it can realize visualization of work content, specialization of member management, digitalization of health assessment, flow of health intervention and integration of knowledge base, so as to improve the work efficiency of health managers, strengthen the interaction with members, and enhance the managers' understanding of the operation of health management institutions solution. ## service description - appointment for physical examination: customers can make physical examination appointment online through wechat terminal, or manually complete physical examination appointment by service personnel of physical examination institution through telephone. through the appointment of physical examination, the package and date of physical examination need to be agreed. - health consultation: obtain the health status of customers through questionnaire survey. generally speaking, the main components of the questionnaire include: physiological and biochemical data, such as height, weight, blood pressure, blood lipid, etc data, such as smoking, diet and exercise habits, etc; or family health history; risk factors, such as mental stress; on attitude and knowledge. - risk assessment: the health manager shall make risk assessment on the health status of clients in combination with the data of health consultation and physical examination results. it is used to describe and evaluate the possibility of a specific disease or death caused by a specific disease in the future. the purpose of this analysis process is to estimate the probability of occurrence at a specific time, rather than to make a definite diagnosis. - health advice: give professional health advice according to the results of risk assessment, such as reasonable suggestions on diet, exercise, work and rest. - population classification: for individuals with abnormal physical examination results, such as hypertension, hyperlipidemia and hyperglycemia. - intervention plan: the health manager will make intervention plan for clients according to the physical examination results, mainly from diet intervention, exercise intervention, psychological intervention and other aspects. - intervention tracking: mainly through telephone follow-up to track the implementation effect of the intervention program. ## stack ## project architecture ## demostration ### user app ### management system"
1,bit-mobile-concussion,behavioral intervention through mobile devices: a framework and an example,"# bit-mobile-concussion ## behavioral intervention through mobile devices: a framework and an example this repo hosts an example of mobile intervention system for concussion clinic. the system consists of two part: - mobile app: in the folder `mobile.ionic`. - server app: in the folder `server.meanjs`. and the folder `doc` contains documentations detail the design and implementation of this system. following are a short summary about how to get a quick start of this system. ## quick start the system was implemented with full-stack javascript. the mobile part used `ionic` framework and the server part used `mean.js` solution. both solutions depend on `node.js`, so make sure your system has `node`, `npm`, `ionic`, and `mongodb` installed and configured before you start. - install `node.js` and `npm` - install `ionic` - install `mongodb` after the dependencies are all set, get the code from this repo: ```she will git clone https://github.com/tingsyo/bit-mobile-concussion.git ``` and then install the npm modules for both mobile and server app: ```she will cd bit-mobile-concussion/mobile.ionic npm install cd ../server.meanjs npm install ``` to start the server, go to the `server.meanjs` directory: ```she will node srver.js ``` to test the mobile app in a browser, go to the `mobile.ionic` directory: ```she will ionic serve ``` ###note: - the `sync data with server` functionality will not work until a proper `serverurl` is configured in the file `mobile.ionic/www/js/server.js`. - to build actual moble apps, please see ionic documentation. --- # license the code is released under a permissive mit license. this means you can use ionic in your own personal or commercial projects for free. the copyright of the intervention content and the delivery mechanisms (mainly in the file `mobile.ionic/www/js/server.js`) is owned by dr. yang, chi-cheng, ms. lin, rong-syuan, and ms. lai, wen-hsuan. ( yang all rights reserved). permissions must be obtained for any type of use of the content."
1,noANTs,an android app to record and challenge automatic negative thoughts. informed by cbt and inspired by the no-nonsense branding of no name. built solo in for deltahacks and winner of the gdsc challenge for best use of google technology to address a un sustainable development goal.,"## :sparkles: tldr :sparkles: noants is an android app to record and challenge automatic negative thoughts. science informed by cognitive behavioural therapy, ui inspired by noname. i built this in solo during my _first_ hackathon deltahacks and it excitingly :checkered_flag: **won the google student developer club challenge for best hack using google technology to address one of the united nations sustainable development goals** :checkered_flag:. check out my devpost for pictures and video of the functionality. ## inspiration i have always been inspired by the notion that even as just one person you can make a difference. i really took this to heart at deltahacks in my attempt to individually create a product that could help individuals struggling with their mental health by providing actionable and well-studied techniques in a digestible little android app. as a previous neuroscientist, my educational background and research in addiction medicine has shown me the incredible need for more accessible tools for addressing mental health as well as the power of simple but elegant solutions to make mental health more approachable. i chose to employ a technique used in cognitive behavioral therapy (cbt), one of (if not the most) well-studied mental health intervention in psychological and medical research. this technique is called automatic negative thought (ant) records. central to cbt is the principle that psychological problems are based, in part, on faulty/unhelpful thinking and behavior patterns. people suffering from psychological problems can learn better ways of coping with them, thereby relieving their symptoms and becoming more effective in their lives. cbt treatment often involves efforts to change thinking patterns and challenge distorted thinking, thereby enhancing problem-solving and allowing individuals to feel empowered to improve their mental health. cbt automatic negative thought (ant) records and cbt thought challenging records are widely used by mental health workers to provide a structured way for patients to keep track of their automatic negative thinking and challenge these thoughts to approach their life with greater objectivity and fairness to their well-being. see more about the widely studied cognitive behavioral therapy at this american psycological association link ### given the app's focus on finding objectivity in a sea of negative thinking, i really wanted the ui to be simple and direct. this lead me to take heavy inspiration from a familiar and nostalgic brand recognized for its bold simplicity, objectivity and elegance - ""noname"". link this is how i arrived at noants - i.e., no (more) automatic negative thoughts ## what it does noants is a simple and elegant solution to tracking and challenging automatic negative thoughts (ants). it combines worksheets from research and clinical practice into a more modern android application to encourage accessibility of automatic negative thought tracking. see mcgill worksheet which one of many resources which informed some of questions in the app. ## how i built it i really wanted to build something that many people would be able to access and an android application just made the most sense for something where you may need to track your thoughts on the bus, at school, at work or at home. i challenged myself to utilize the newest technologies android has to offer, building the app **entirely in jetpack compose**. i had some familiarity using the older fragment-based navigation in the past but i really wanted to learn how to utilize the **compose navigation** and i can excitedly say i implemented it successfully. i also used **room**, a data persistence library which provided an abstraction layer for the sqlite database i needed to store the thought records which the user generates. ## challenges i ran into this is my first ever hackathon and i wanted to challenge myself to build a project alone to truly test my limits in a time crunch. i surely tested them! designing this app with a strict adherence to noname's branding meant that i needed to get creative making many custom components from scratch to fit the ui style i was going for. this made even ostensibly simple tasks like creating a slider, incredibly difficult, but rewarding in the end. i also had far loftier goals with how much i wanted to accomplish, with aspirations of creating a detailed progress screen, an export functionality to share with a therapist/mental-health support worker, editing and deleting and more. i am nevertheless incredibly proud to showcase a functional app that i truly believe could make a significant difference in people's lives and i learned to prioritize creating and mvp which i would love to continue building upon in the future. ## accomplishments that i am proud of i am so proud of the hours of work i put into something i can truly say i am passionate about. there are few things i think should be valued more than an individual's mental health, and knowing that my contribution could make a difference to someone struggling with unhelpful/negative thinking patterns, which i myself often struggle with, makes the sleep deprivation and hours of banging my head against the keyboard eternally worthwhile. ## what i learned being under a significant time crunch for deltahacks challenged me to be as frugal as possible with my time and design strategies. i think what i found most valuable about both the time crunch, my inexperience in software development, and working solo was that it forced me to come up with the simplest solution possible to a real problem. i think this mentality should be approached more often, especially in tech. there is no doubt a place, and an incredible allure to deeply complex solutions with tons of engineers and technologies, but i think being forced to innovate under constraints like mine reminded me of the work even one person can do to drive positive change. ## what is next for noants i have countless ideas on how to improve the app to be more accessible and helpful to everyone. this would start with my lofty goals as described in the challenge section, but i would also love to extend this app to ios users as well. i am itching to learn cross-platform tools like **kmm and react native** and i think this would be a welcomed challenge to do so."
0,eprom,electronic patient reported outcome measures,"# eprom electronic patient reported outcome measures this project uses hashicorp vault for secure management of sensitive information, such as usernames and passwords. download and install hashicorp vault: download and install hashicorp vault from the official website. start hashicorp vault in server mode (locally for development): start hashicorp vault in development mode with the following command: open cmd : a - vault server --dev --dev-root-token-id=""mytoken"" copy paste the token in bootstrap.yml open another cmd and set the vault address using the following command: c - set store secrets in hashicorp vault: store sensitive information in hashicorp vault using the following command: vault kv put secret/eprom mail.username=username mail=password and replace username and password with the actual credentials you want to store. ------------docker-------------------------- ## running the application locally with docker when you want to set up and run the application locally, follow these steps: **ensure docker is installed:** make sure you have docker installed on your system. if not, you can download and install it from https://www.docker.com/get-started. **pull docker images:** open your terminal and run the following commands to pull the docker images for the eprom ui and api: docker pull docker pull eprom application with docker compose: open a terminal and navigate to the directory where the docker compose file is located. run the following command to start the eprom application: docker-compose up -d this command will start the eprom ui and api containers in the background. once the containers are up and running, you can access the eprom ui by opening your web browser and navigating to the eprom api should be accessible at when you are done using the application, you can stop and remove the containers using the following command: docker-compose down"
0,started,standards for rigor and transparency in dysphagia research,"# the frontiers framework the newly developed frontiers (**f**ramework for **r**ig**o**r a**n**d **t**ransparency **i**n r**e**sea**r**ch on **s**wallowing) framework is a tool for dysphagia researchers and research consumers to promote rigor and transparency in study design and reporting, specific to dysphagia research. this interactive, web-based application has been designed to enhance the accessibility and usability of the frontiers framework. the application allows clinicians and researchers alike to easily plan for and appraise rigor and transparency in study design and reporting by asking key questions across the following categories: - participants and baseline characteristics - non-instrumental assessment and screening - videofluoroscopic swallowing studies and associated measures - fiberoptic endoscopic evaluations of swallowing and associated measures - other instrumental techniques and measures - dysphagia treatment - patient reported outcome measures the application can be used when preparing manuscripts for submission, for critical appraisal and review activities, or during study design. upon completion of the checklist questions, the software will output a report of the questions and responses. manuscripts are currently in preparation that will further describe the framework and provide examples of its utilization. ## contributors - amber anderson - ashwini namasivayam-macdonald - atsuko kurosu - brandon noad - catriona steele - danielle brates - joanne yee - justine dallal york - matina balou - nicole rogus-pulia - pooja gandhi - rebecca affoo - renata mancopes - rodolfo pea-chvez - ryan burdick - sana smaoui - sophia werden abrams - yael shapira-galit"
1,carp.sensing-flutter,"carp mobile sensing for flutter, including mobile sensing framework, data backend support, and the carp mobile sensing app.","!carp-mobile-sensing-vertical this repo hold the source code for the cachet research platform (carp) mobile sensing (cams) flutter software. it contains the source code for cachet first-party (i.e., developed by the core cachet team) cams framework, its packages, and example apps. in addition, the carp team maintain a set of flutter plugins (mainly) for sensing purposes. flutter plugins enable access to platform-specific apis. for more information about plugins, and how to use them, see the flutter packages description. all the carp flutter components including the these plugins are also available on pub.dev. ## software components these are the available carp mobile sensing flutter components in this repository. | component | description | pub.dev | |-----------|-------------|:-----------------:| | **core** | **basic components** | <img | | carp_serializable | a package for polymorphic serialization to/from json build on top of json_serializable | [!pub package](https://pub.dartlang.org/packages/carp_serializable) | | carp_core | the carp core domain model | [!pub package](https://pub.dartlang.org/packages/carp_core) | | carp_mobile_sensing | the main carp mobile sensing framework | [!pub package](https://pub.dartlang.org/packages/carp_mobile_sensing) | | **packages** | **data sampling packages** | | | carp_apps_package | app sampling package (installed apps, app usage) | [!pub package](https://pub.dartlang.org/packages/carp_apps_package) | | carp_connectivity_package | connectivity sampling package (bluetooth, wifi, connectivity) | [!pub package](https://pub.dartlang.org/packages/carp_connectivity_package) | | carp_communication_package | communication sampling package (phone, sms) | [!pub package](https://pub.dartlang.org/packages/carp_communication_package) | | carp_context_package | context sampling package (location, activity, weather) | [!pub package](https://pub.dartlang.org/packages/carp_context_package) | | carp_audio_package | audio sampling package (audio, noise) | [!pub package](https://pub.dartlang.org/packages/carp_audio_package) | | carp_survey_package | sampling package for collecting survey data from research package and running cognitive test using the cognition package | [!pub package](https://pub.dartlang.org/packages/carp_survey_package) | | carp_health_package | sampling package for collecting health data from apple health and google fit | [!pub package](https://pub.dartlang.org/packages/carp_health_package) | | **wearables** | **sampling packages for wearable devices** | | | carp_movisens_package | movisens move & ecg sampling package (movement, met-level, ecg) | [!pub package](https://pub.dartlang.org/packages/carp_movisens_package) | | carp_esense_package | sampling package for the esense earplug device (button pressed & movement) | [!pub package](https://pub.dartlang.org/packages/carp_esense_package) | | carp_polar_package | sampling package for the polar heart rate monitors | [!pub package](https://pub.dartlang.org/packages/carp_polar_package) | | carp_movesense_package | sampling package for the movesense heart rate monitors | [!pub package](https://pub.dartlang.org/packages/carp_movesense_package) | | **backends** | **backend data upload components** | | | carp_webservices | flutter api for carp web services | [!pub package](https://pub.dartlang.org/packages/carp_webservices) | | carp_backend | support for uploading data to a carp data backend as json. | [!pub package](https://pub.dartlang.org/packages/carp_backend) | | carp_firebase_backend | support for uploading data to firebase as both zipped files and json data| [!pub package](https://pub.dartlang.org/packages/carp_firebase_backend) | | **utilities** | **misc. cams utilities** | | | carp_study_generator | a simple command line interface (cli) to upload study protocols, informed consent and localization files to the carp backend. | [!pub package](https://pub.dartlang.org/packages/carp_study_generator) | | **apps** | **misc. mobile sensing demo apps** | | | carp_mobile_sensing_app | demonstrates how basic mobile sensing can be implemented in a flutter app using cams. also demonstrates how to integrate to wearable devices over ble connections. | | | pulmonary_monitor_app | demonstrates how user tasks (aka. apptask) are supported in cams. | | ## documentation the overall documentation on the software architecture of carp mobile sensing, and how to use and extend it is available on this github wiki. each of the specific packages also contains more specific documentation on how each package is used in the framework (e.g. how the movesense sampling package is to be used). ## issues please check existing issues and file any new issues, bugs, or feature requests in the carp.sensing-flutter repo. ## contributing contributing is not entirely in place yet. however, if you wish to contribute a change to any of the existing components in this repo, please review our contribution guide, and send a pull request."
1,sensus,a cross-platform system for mobile sensing,please see the documentation for more information.
1,SensingKit-Android,an android framework that provides mobile sensing functionality to your apps.,"# sensingkit-android library an android library that provides continuous sensing functionality to your applications. for more information, please refer to the project website. ## supported sensors the following sensor modules are currently supported in sensingkit-android, (listed in sksensormoduletype enum): - accelerometer - gravity - linear acceleration - gyroscope - rotation - magnetometer - ambient temperature - step detector - step counter - light - location - activity - battery - screen status - audio recorder - audio level - bluetooth ## configuring the library - build the library using the command: ``` ./gradlew build ``` - create an app/libs directory inside your project and copy the generated sensingkitlib/build/outputs/aar/sensingkitlib-release.aar (or the equivalent debug) file there. - edit your app/build.gradle file and add a flatdir entry as shown bellow: ``` repositories { mavencentral() flatdir { dirs 'libs' } } ``` - in the same app/build.gradle file, add sensingkitlib as a dependency as shown below: ``` dependencies { compile filetree(dir: 'libs', include: ['*.jar']) compile 'org.sensingkit:sensingkitlib-release@aar' compile compile } ``` ## how to use this library - import and init sensingkit into your activity class as shown bellow: ```java import org.sensingkit.sensingkitlib.sensingkitlib; sensingkitlibinterface msensingkitlib = sensingkitlib.getsensingkitlib(this); ``` - register a sensor module (e.g. a light sensor) as shown bellow: ```java msensingkitlib.registersensormodule(sksensormoduletype.light); ``` - subscribe a sensor data listener: ```java msensingkitlib.subscribesensordatalistener(sksensormoduletype.light, new sksensordatalistener() { @override public void ondatareceived(final sksensormoduletype moduletype, final sksensordata sensordata) { system.out.println(sensordata.getdataincsv()); // print data in csv format } }); ``` - you can cast the data object into the actual sensor data object in order to access all the sensor data properties: ```java sklightdata lightdata = (sklightdata)sensordata; ``` - you can start and stop the continuous sensing using the following commands: ```java msensingkitlib.startcontinuoussensingwithsensor(sksensormoduletype.light); msensingkitlib.stopcontinuoussensingwithsensor(sksensormoduletype.light); ``` for a complete description of our api, please refer to the project website. ## license ``` copyright (c) queen mary university of london kleomenis katevas, k.katevas@qmul.ac.uk. this file is part of sensingkit-android library. for more information, please visit http://www.sensingkit.org. sensingkit-android is free software: you can redistribute it and/or modify it under the terms of the gnu lesser general public license as published by the free software foundation, either version of the license, or (at your option) any later version. sensingkit-android is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. see the gnu lesser general public license for more details. you should have received a copy of the gnu lesser general public license along with sensingkit-android. if not, see <http://www.gnu.org/licenses/>. ``` this library is available under the gnu lesser general public license allowing to use the library in your applications. if you want to help with the open source project, contact hello@sensingkit.org."
1,SensingKit-iOS,an ios framework that provides mobile sensing functionality to your apps.,"# sensingkit-ios library an ios library that provides continuous sensing functionality to your applications. for more information, please refer to the project website. ## supported sensors the following mobile sensors are currently supported in sensingkit-ios, (listed in sksensortype enum): - accelerometer - gyroscope - magnetometer - device motion (senses attitude, gravity, user acceleration, magnetic field, rotation) - motion activity - pedometer - altimeter - battery - location - heading - ibeacon proximity - eddystone proximity - microphone ## installing the library you can easily install sensingkit using cocoapods, a popular dependency manager for cocoa projects. for installing cocoapods, use the following command: ```bash $ gem install cocoapods ``` to integrate sensingkit into your xcode project, specify it in your `podfile`: ```ruby target <myapp> do # uncomment this line if you are using swift or would like to use dynamic frameworks use_frameworks! pod 'sensingkit' # for the latest development version, please use: # pod 'sensingkit', :git => 'https://github.com/sensingkit/sensingkit-ios.git', :branch => 'next' end ``` then, run the following command: ```bash $ pod install ``` for more information about cocoapods, visit https://cocoapods.org. ## using the library import and init sensingkit as shown below: *objective-c* ```objectivec #import <sensingkit/sensingkit.h> @property (nonatomic, strong) sensingkitlib *sensingkit; - (void)viewdidload { [super viewdidload]; self.sensingkit = [sensingkitlib sharedsensingkitlib]; } ``` *swift* ```swift import sensingkit let sensingkit = sensingkitlib.shared() ``` check if a sensor is available in the device: *objective-c* ```objectivec if ([self.sensingkit issensoravailable:battery]) { // you can access the sensor } ``` *swift* ```swift if sensingkit.issensoravailable(sksensortype.battery) { // you can access the sensor } ``` register a sensor (e.g. a battery sensor) as shown below: *objective-c* ```objectivec [self.sensingkit registersensor:battery error:null]; ``` *swift* ```swift do { try sensingkit.register(sksensortype.battery) } catch { // handle error } ``` subscribe a sensor data handler. you can cast the data object into the actual sensor data object in order to access all the sensor data properties: *objective-c* ```objectivec [self.sensingkit subscribetosensor:battery withhandler:^(sksensortype sensortype, sksensordata *sensordata, nserror *error) { if (!error) { skbatterydata *batterydata = (skbatterydata *)sensordata; nslog(@""battery level: %f"", batterydata.level); } } error:null]; ``` *swift* ```swift do { try sensingkit.subscribe(to: sksensortype.battery, withhandler: { (sensortype, sensordata, error) in if (error == nil) { let batterydata = sensordata as! skbatterydata print(""battery level: \(batterydata)"") } }) } catch { // handle error } ``` you can start and stop the continuous sensing using the following commands: *objective-c* ```objectivec // start [self.sensingkit startcontinuoussensingwithsensor:battery error:null]; // stop [self.sensingkit stopcontinuoussensingwithsensor:battery error:null]; ``` *swift* ```swift // start do { try sensingkit.startcontinuoussensing(with:sksensortype.battery) } catch { // handle error } // stop do { try sensingkit.stopcontinuoussensing(with:sksensortype.battery) } catch { // handle error } ``` for a complete description of our api, please refer to the documentation page of sensingkit website. ## required info.plist keys depending on the used sensor and its configuration, some keys with a user-friendly description should be included in the info.plist application file: ### microphone - nsmicrophoneusagedescription ### eddystone - nsbluetoothperipheralusagedescription ### location - nslocationalwaysusagedescription - nslocationwheninuseusagedescription - nslocationalwaysandwheninuseusagedescription ### motionactivity - nsmotionusagedescription ## license ``` copyright (c) kleomenis katevas kleomenis katevas, k.katevas@imperial.ac.uk this file is part of sensingkit-ios library. for more information, please visit https://www.sensingkit.org sensingkit-ios is free software: you can redistribute it and/or modify it under the terms of the gnu lesser general public license as published by the free software foundation, either version of the license, or (at your option) any later version. sensingkit-ios is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. see the gnu lesser general public license for more details. you should have received a copy of the gnu lesser general public license along with sensingkit-ios. if not, see <http://www.gnu.org/licenses/>. ``` this library is available under the gnu lesser general public license allowing to use the library in your applications. if you want to help with the open source project, contact hello@sensingkit.org."
1,Ubiqlog,energy-efficient life logging for android platforms.,"!ubiqlog ubiqlog is a energy-efficient open source tool for ""life logging"", based on android platform. it creates a json file per day that contains all activities within the device. it is flexible mobile sensing tool, enable users configure its sensors and add/remove new sensors to it. - recent version measures physical activity and location based on google play service. however in the source you can change it to the core version, if you are not willing to use google play services. - visualizations are disabled in this version, because there is work ongoing to make something really different. special thanks to yi rong, ping he, martin tomitsch and victor andrei gugonatu for their design or development support. ####references: - rawassizadeh, reza, martin tomitsch, katarzyna wac, and a. min tjoa. ""ubiqlog: a generic mobile phone-based life-log framework."" personal and ubiquitous computing no."
0,SleepCycleAnalysis-AndroidApp,android smart wake-up app for sleep pattern detection and analysis.,# sleepcycleanalysis-androidapp project - mobile sensing @columbia university android mobile appliation for sleep cycle detection and analysis. using accelerometer to detect sleep pattern. using r to analyze data and plot sleep pattern diagram. having regular alarm and smart wake-up modes.
0,Haven,crowd based location cleanliness reviewer,# haven a react native based mobile crowdsensing app to track covid-appropriate behaviour at places of interest
0,mobile-sensing-web,this project is an academic web project of galatasaray university peralab for monitoring sensor data from mobile phones.,"#mobile-sensing-web this is a web site for monitoring mobile phone's sensor data. # technology mobile-sensing-web is built using java, spring mvc and bootstrap. # contribute mobile-sensing-web uses a fork and pull model of collaborative development. follow this link to learn how to submit a pull request. **point your browser at https://github.com/yyenigun/mobile-sensing-web and click ""fork"".** **from she will/prompt:** ```sh > git clone https://github.com/username/mobile-sensing-web.git # clones your fork of the repository into the current directory > cd mobile-sensing-web # changes the active directory to the newly cloned ""mobile-sensing-web"" directory > git remote add upstream https://github.com/yyenigun/mobile-sensing-web.git # assigns the original repository to a remote called ""upstream"" > git fetch upstream # pulls in changes not present in your local repository, without modifying your files ``` testing -------------- ### run locally download and extract eclipse luna install gradle plugin to eclipse: click _file->import->gradle project _ and build model download and extract tomcat (minor version: add project to tomcat and start tomcat to test the project open the link : now that you have it running locally you can start to develop and test new functionality and content. when you have tested your changes, and it is time to merge the changes in to the branch created earlier... **commit and push your changes** ```sh > git commit -a -m ""added directory structure for bootstrap-based site [issue > git push upstream ``` **create a pull request**"
0,crowdroidsense,"android client part of sensquare, a mobile crowdsensing system developed for my master thesis in computer science, networks and systems. see more at:","android client part of sensquare, a mobile crowdsensing system developed for my master thesis in computer science, network and system. see more at:"
0,sensquare-server,"coap server, part of sensquare, a mobile crowdsensing system developed for my master thesis in computer science, networks and systems. see more at:","coap server in python/mysql, part of sensquare, a mobile crowdsensing system developed for my master thesis in computer science, network and system. see more at:"
0,CrowdSense-iOS,"a free continuous sensing tool for ios devices, based on the open source library sensingkit.","# crowdsense-ios crowdsense is a free mobile sensing tool, based on the open source library sensingkit. it provides an easy way for researchers to capture sensor data using any ios device. you can access all collected data in the ios device using itunes file sharing or using the app's share functionality. it is available for free on the app store."
0,mcs,"mobile crowdsensing (mcs), crowdsensing based transportation journey planner",# mcssp mcs sp
1,MoST,mobile sensing technology,"mobile sensing technology (most) ================================ - university of bologna most is an android library that enapsulates access to android physical sensors (e.g., accelerometer) and logical sensors (e.g., network traffic). if you use this library, please cite one of the following papers: * cardone, g.; foschini, l.; bellavista, p.; corradi, a.; borcea, c.; talasila, m.; curtmola, r., ""fostering participaction in smart cities: a geo-social crowdsensing platform,"" communications magazine, ieee , june paper * cardone, g.; cirri, a.; corradi, a.; foschini, l; maio, d., ""msf: an efficient mobile phone sensing framework"", international journal of distributed sensor networks, vol. paper"
1,Mew,mew is an open-source mobile crowdsensing framework aimed at facilitating mcs application development. mew is currently available for android platform (api and above) and implemented as a distributed platform with two components - a server and an android library. the server component is developed as an eclipse project (java v. and offers a plug-n-play environment to developers to implement new task allocation algorithms as per their requirements.,"# mew mew is a distributed, open-source framework that aims to facilitate development of mobile crowdsensing applications. the client component is developed as an android library (support api and above) and the server component is developed as an eclipse project (java the server component offers a gui and allows users to plug-in new task allocation algorithms for collecting sensor data from a subset of mobile devices. for more details, read the deployment instructions at the instructions to implement a new task allocation algorithm are available at"
0,Mobile-Crowdsensing,uses advertisements to collect location and browser data for research (proof of concept),"# mobile-crowdsensing uses advertisement data to collect data for research. (proof of concept) schema: - id - int - device (cookie information) - int - fingerprint (from library) - - timestamp (in - timestamp - latitude - double - longitude - double - altitude (if available) - double - accuracy if geolocation api is unavailable) - double - heading (if available) - double - speed (if available) - double - host name - - browser default language - - operating system - node backend (app.js) distributes html and js files (frontend.html, frontend_script.min.js) through express.js to clients, which will return the location and browser information. the backend will store the information in a mysql database. geolocation api will be used if available. however if the connection is not secure (http) or user denies location permissions, then geoplugin will be used to lookup ip address to location. however this is likely to be less accurate. to run locally, add a config.json file in the same directory and add the following mysql database information: ```json { ""host"" : """", ""user"" : """", ""password"" : """", ""database"" : """", ""port"" : """" } ``` run with: ```she will node app.js ``` then access on browser. reference: (advertising-based measurement: a platform of billion mobile devices)"
1,carp_studies_app,the carp study app,"# carp studies app the carp studies app is designed to run generic studies using the carp mobile sensing (cams) framework, which is part of the copenhagen research platform (carp) from the department of health technology at the technical university of denmark. it follows a basic business logic component (bloc) combined with a model-view-view-model architecture, as described in the carp mobile sensing demo app. read more about the carp studies app on the carp homepage."
0,mobile-crowdsensing-oram,a research project,"# mobile-crowdsensing-oram a research project please refer to ""description"" file for details author: iyiola emmanuel olatunji"
1,adkintun-mobile-middleware,android middleware for mobile sensing created originally for the adkintun mobile project,"adkintun mobile middleware [ !download ](https://bintray.com/niclabs-cl/maven/adkintun-mobile-middleware/_latestversion) ========================== android middleware for performing mobile sensing and monitoring. originally created for the adkintun mobile project, it is released under the apache open source license to be used by developers in their own software projects. software architecture ---------------------- the following requirements guided the actual design and development of the middleware: * extensibility, in order to add monitoring for new events with ease and requiring minimal modification of the existing code, * small memory footprint, by storing the sensor data in memory the shortest time possible, * ease of use, to integrate monitoring in an application as quickly as possible, * component independence, we wanted the different components of the application to be as independent as possible. as an example, even though we may want to be able to save monitoring data to a database, we would not want to be restricted to using sqlite or to be obligated to use a database by design. * data exporting capabilities, in order to easily export data from different devices into multiple formats, * reliability of data, we need to be able to trust that events occur when the library says they are monitored, thus the sequence of reporting and the time of reporting must be reliable. the general design of the middleware is inspired by the aware framework, and some of the code for the different monitors was based on that project, given that they already had resolved many of the issues related to android development. however that framework did not fulfill all of our requirements, motivating the development the present library. !main library classes the structure of the main entities in the middleware is shown on figure above, where the architecture of the central classes follows the observer and factory patterns. a general description of the different entities is provided below. * the central class of the library is `monitor`, defining the general structure for all monitoring classes, which will perform the task of listening to os events. this class extends from the android service class, thus allowing each monitor to run as a daemon of the system. * a monitor can observe one or more `events` of the operating system. events define different aspects of a monitoring task. for instance, the `traffic` monitor can observe events of mobile traffic, wifi traffic or application traffic, and a developer using the library may choose to activate a different one depending on the application. * a `listener` can be attached to a monitor, in order to be notified of new observations from an event, * the notification usually comes in the form of an `observation` object, carrying data about the event as well as the timestamp, and event type (a code to identify the event). * observations can be `persistent`, meaning they can be saved to a local database (sqlite for now) if desired, * they are also `serializable`, meaning they can be exported to different formats (json, csv, etc.). * preprocessing of observations to establish a context can be performed through the definition of `proxy` objects, which can listen to multiple monitors in order to notify their own listeners of a specific context. one example of these objects is the `connectivitystatusproxy` which compares two consecutive connectivity observations and notifies its listeners of a change in connectivity or roaming status. scheduling of notifications is performed to ensure that observations arrive in the correct order, and periodical ntp synchronization is implemented to ensure that the reported timestamp of the events is correct. dependencies ------------ the library only has two software dependencies, included as jars under the `libs/` directory (we know is not good practice but maven is a pain) * gson (tested with version for object serialization to json. * sugar orm (tested with version as a sqlite orm. implemented monitors -------------------- * accelerometer. monitors raw accelerometer data in the device coordinate system * globalaccelerometer. monitors device accelerometer data in the earth coordinate system. it implements a low pass filter to isolate device accelerometer data from the earth gravity. * connectivity. monitors changes in internet connectivity of the device. if supported by the device, it provides detailed connection status change data (authenticating, connecting, connected) * location. monitors position changes on the device. monitoring can be enabled using coarse or fine location. * screen. monitors screen status change (on, unlocked, locked, off). * telephony. monitors antenna, signal power, airplane mode and connection status changes. a new instance of `telephonyobservation` (can be gsm or cdma) is provided for each change, except on the case of signal power, where the instance is kept as long as there are no antena changes and only the signal strenght `sample` is updated. * traffic, monitor device traffic statistics. it can perform monitoring of wifi, mobile and per application statistics independently. monitoring is perform periodically, with the period being configurable. * device data. although not a monitor, the class `deviceinfo` provides a summary of all device information (imei, baseband, model, brand, etc.) * boot detection. if configured, the library can monitor device and shutdown through the class 'device'. usage ----- a full example of a working application is provided under the `examples/` folder in the code. however, here is a quick start. * first, create a monitor controller for binding your application to, although you can bind to a `monitor` as you would bind to any other android service, controllers simplify the task. here is how you create a `traffic` monitor controller ```java controller<trafficlistener> trafficcontroller = traffic.bind(traffic.class, context); ``` * asign a listener to the controller, which will append it to the traffic monitor when this is activated. ```java trafficcontroller.listen(trafficlistener, true); ``` * configure the monitor, creating a bundle with the configuration data. here is how you configure the sampling frequency of the traffic monitor ```java bundle bundle = new bundle(); /* configure the sampling frequency to seconds */ bundle.putint(traffic.traffic_update_interval_extra, ``` * activate the monitor, defining the events you wish to activate. ```java trafficcontroller.activate(monitor.traffic_mobile | monitor.traffic_wifi, bundle); ``` * done! the listener will receive traffic data through the methods `onmobiletrafficchange` and `onwifitrafficchange`. below is a full example activity ```java package cl.niclabs.adkmobile; import android.app.activity; import android.os.bundle; import android.util.log; import cl.niclabs.adkmobile.monitor.monitor; import cl.niclabs.adkmobile.monitor.monitor.controller; import cl.niclabs.adkmobile.monitor.traffic; import cl.niclabs.adkmobile.monitor.data.trafficobservation; import cl.niclabs.adkmobile.monitor.listeners.trafficlistener; public class monitoractivity extends activity implements trafficlistener { private static final string tag = ""monitoractivity""; /* monitor controllers make easier binding to a monitor */ private controller<trafficlistener> trafficcontroller; @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); /* bind controller to the current application context */ trafficcontroller = traffic.bind(traffic.class, this); /* append this class as listener */ trafficcontroller.listen(this, true); bundle bundle = new bundle(); /* configure the sampling frequency to seconds */ bundle.putint(traffic.traffic_update_interval_extra, /* activate controller for monitoring mobile and wifi traffic */ trafficcontroller.activate(monitor.traffic_mobile | monitor.traffic_wifi, bundle); } @override protected void ondestroy() { // todo auto-generated method stub super.ondestroy(); /* unbind from the monitor and destroy the service if there are * no other classes bound to it */ trafficcontroller.unbind(); } @override public void onmobiletrafficchange(trafficobservation trafficstate) { /* the state will be serialized to json */ log.i(tag, ""received new mobile traffic state ""+trafficstate); } @override public void onwifitrafficchange(trafficobservation trafficstate) { log.i(tag, ""received new wifi traffic state ""+trafficstate); } @override public void onapplicationtrafficchange(trafficobservation trafficstate) { // this will never be used } } ``` configuration ------------- the permissions required for each monitor are specified in the code documentation. the following configuration is required in the `androidmanifest.xml` of the application in order to activate clock synchronization (implemented on `cl.niclabs.adkmobile.services.clockservice`) and persistence with sugar orm. ```xml <!-- required by connectivity service --> <uses-permission android:name=""android.permission.access_network_state"" /> <!-- for access to ntp server --> <uses-permission android:name=""android.permission.internet"" /> <application android:name=""cl.niclabs.adkmobile.adkintunmobileapp""><!-- android:name is required to activate clock synchronization and persistance !--> <!-- give permission to the traffic monitor. it must be added for each service required in the platform !--> <service android:name=""cl.niclabs.adkmobile.monitor.traffic"" ></service> <!-- give permission to connectivity monitor and clockservice for time synchronization --> <service android:name=""cl.niclabs.adkmobile.monitor.connectivity"" /> <service android:name=""cl.niclabs.adkmobile.services.clockservice"" /> </application> ``` the same configuration as sugar orm is required on the manifest to enable persistance ```xml <!-- database configuration --> <meta-data android:name=""database"" android:value=""mydb.db"" /> <meta-data android:name=""version"" /> <meta-data android:name=""query_log"" android:value=""true"" /> <!-- do not change, required to store monitor observations !--> <meta-data android:name=""domain_package_name"" android:value=""cl.niclabs.adkmobile.monitor.data"" /> ``` in order to listen to boot status changes, the following code must be added inside `<application></application>` on the manifest. ```xml <!-- register receiver in order to monitor device boot state --> <receiver android:name=""cl.niclabs.adkmobile.monitor.device"" android:enabled=""true"" android:permission=""android.permission.receive_boot_completed"" > <intent-filter> <action android:name=""android.intent.action.boot_completed"" /> <action android:name=""android.intent.action.action_shutdown"" /> <category android:name=""android.intent.category.default"" /> </intent-filter> </receiver> ```"
0,crowdsensing,mobile platform for crowd-sensing with data retrieval from multiple devices for the monitoring of noise pollution in urban environment.,"# privacy-aware crowdsensing <p> <img alt=""alternatetext""> <img src=""https://img.shields.io/badge/state-closed-red"" alt=""alternatetext""> <img alt=""alternatetext""> <img oreo alt=""alternatetext""> <img alt=""alternatetext""> </p> piattaforma di mobile crowdsensing (piattaforma raccolta dati attraverso la collaborazione da parte degli utenti), per il monitoraggio dellinquinamento acustico in uno scenario urbano. ## funzionalit <div align=""center""><img src=""images/architecture.png""></div> la piattaforma in grado di poter inviare un rumore rilevato in maniera periodica e semi-automatica o manuale andando a definire dei criteri di privacy personalizzati dall'utente front-end. la manipolazione dei dati sensibili viene effettuata all'interno di un server trusted capace di poter stabilire un meccanismo di offuscamento basato sull'algoritmo di spatial cloaking. ogni rilevamento ha un tempo di vita limitato, scelto dall'utente e rispettato nel trusted server all'interno di una lista logica che ha la funzionalit di buffer di sistema, in modo da aggregare e raccogliere dati provenienti da differenti utenti e utilizzarli per lo spatial cloaking (andando a considerare i principi di privacy definiti dai parametri k e range di ogni rilevazione. infine, dopo il camuffamento dei dati, si avr come output un rilevamento offuscato inoltrato al back-end server, visualizzato in una dashboard e salvato in maniera persistente in un database insieme alle informazioni di servizio legate ai criteri di valutazione di quality of service e privacy, nonch del valore di trade-off tra i due. ## tecnologie utilizzate postgis per la gestione del back-end sui dati spaziali openlayers per la gestione dei dati spaziali nella dashboard del front-end node.js per la gestione del server trusted utilizzato per il meccanismo di cloaking spaziale postgresql come dbms di gestione delle informazioni spaziali app android basata su java (sdk - oreo ## utilizzo del progetto il progetto stato deployato localmente su delle macchine dedicate per il testing e utilizzato esclusivamente per fornire un sistema funzionante in grado di poter far testare per scopi accademici alcuni meccanismi di privacy spaziale tipici dell'ambito context-aware. ## contributors - andrea gurioli - giovanni pietrucci - mario sessa (@kode-git)"
1,CrowdOS,//build a system platform in the field of crowd sensing computing!,"[!build]() [!issues]() [!fork]() [!stars]() !logo crowdos is a ubiquitous operating system for crowdsoucring and mobile crowdsensing, which can deal with multiple types of crowdsourcing problems simultaneously. ## installation and getting started crowdos are available on maven central. if you use maven or gradle, add a dependency with following coordinates to your build script: ```xml <dependencies> <dependency> <groupid>cn.crowdos</groupid> <artifactid>crowdos-kernel</artifactid> </dependency> </dependencies> ``` you can use the features provided by crowdos in any way you want, but if you want to develop a springboot application, you only need the following few simple steps: you need a _crowdkernelcomponent.java_ like this one, which is used by the spring framework. ```java // crowdkernelcomponent.java import cn.crowdos.kernel.crowdkernel; import cn.crowdos.kernel.kernel; import org.springframework.stereotype.component; @component public class crowdkernelcomponent { public crowdkernel getkernel(){ crowdkernel kernel = kernel.getkernel(); if (!kernel.isinitialed())kernel.initial(); return kernel; } } ``` you need to create the participant class as you want, you should either implement the _participant_ interface, or inherit directly from the_abstractparticipant_ class. ```java import cn.crowdos.kernel.constraint.condition; import cn.crowdos.kernel.constraint.wrapper.*; import cn.crowdos.kernel.resource.*; import com.fasterxml.jackson.annotation.jsonformat; public class user extends abstractparticipant { @ability private integercondition userid; @ability @jsonformat(pattern = ""yyyy.mm.dd"") private datecondition activetime; //... } ``` you need to create the task class as you want, and you should either implement the _task_ interface or inherit directly from the _abstracttask_ class or any other task class we provide. ```java import cn.crowdos.kernel.constraint.constraint; import cn.crowdos.kernel.resource.simpletask; import java.util.list; public class task extends simpletask { private int taskid; public task(list<constraint> constraints, taskdistributiontype taskdistributiontype) { super(constraints, taskdistributiontype); } // ... } ``` to use the features provided by the crowdos kernel, you should first register participants and submit tasks. ``` // use crowdkernelcomponent.getkernel().registerparticipant(user); // and crowdkernelcomponent.getkernel().submittask(task); ``` do everything you want. this is a simple demo of a springboot application powered by crowdos (crowdos-demo). and [wesense]() is an actual running application, it is based on crowdos and you can download it from the app store on android and ios. ## getting help if you have any trouble with crowdos, the following may be of help to you. - visit our website www.crowdos.cn. - check the reference documentation. - or email us: ## reporting issue crowdos uses github's integrated issue tracking system to record bugs and feature requests. if you want to raise an issue, please follow the recommendations below: - before you log a bug, please search the issue tracker to see if someone has already reported the problem. - if the issue does not already exist, create a new issue. - please provide as much information as possible with the issue report. we like to know the crowdos version, operating system, and jvm version you are using. - if you need to paste code or include a stack trace, use markdown. ``` escapes before and after your text. - if possible, try to create a test case or project that replicates the problem and attach it to the issue. ## modules **note: crowdos is still in the development stage, only the kernel part is completed at present.** ### framework of the system !framework ### kernel the goal of crowdos is to improve the construction efficiency of mcs applications and reduce the usage rights of mcs applications. currently, crowdos uses web frameworks such as crowdos kernel and springboot to quickly develop crowd intelligence apps based on crowd intelligence collection functions. the framework diagram of a crowd intelligence app developed using crowdos kernel is as follows: #### kernel.constriaint and kernel.resource ##### logic the two key factors in crowd sensing applications are the task and the participants who complete the task. in the crowdos kernel, a task is defined as a developer-defined **task** (resource package) that contains a set of **constraints** (constraint package) participant is a developer-defined **participant** that contains a set of capabilities (resource package). task (actually, it is a programmer-defined entity class that implements the task interface) uses the method **canassignto()** to detect whether the task can be assigned to a participant participant (actually, it is a programmer-defined entity class that implements the participant interface). each constraint (actually, it is a programmer-defined entity class that implements the constraint interface) uses the method **satisfy()** to detect whether a certain condition (actually, it is a programmer-defined entity class that implements the condition interface) is satisfied. own requirements. the necessary and sufficient conditions for whether a task can be assigned to a participant are: all constraints of the task must be satisfied by the participant's ability (in current terminology, the participant's ability) ) has the same meaning as the condition to satisfy the constraint). in the specific implementation, the method **canassignto()** will do two checks: - check whether the participant has the ability to specifically satisfy a certain type of constraint required by the task. for example, if the task requires performing a task in a certain area, it is necessary to insist whether the participants provide their own gps information. - check whether a certain ability possessed by the participant is a condition that satisfies the constraint. for example, check whether the participant's gps location information is within the range required by the task. the design logic diagram is as follows: ##### patterns the classes in the constraint package and the resource package implement a double dispatch mode (another commonly used implementation of double dispatch is the visitor mode).at the same time, some reflection techniques are used to optimize the code implementation. the specific class diagram is as follows: ##### content the constraint package contains the constraint interface of the build task and the condition interface of the build participant, and provides some simple implementations. in addition, in the constraint.wrapper package, a condition version of the underlying type is provided (same logic as the java wrapper class). in addition to the key task and participant interfaces, the resource package also provides corresponding abstract classes, namely abstracttask and abstractparticipant. when programmers develop custom tasks and participants, they only need to inherit the corresponding abstract base class instead of starting from implementing the basic interface (same design idea as the design idea of the java container part). some example entity classes are also provided. #### kernel.system ##### logic systemresourcecollection in the system package manages all entities in the system. currently, system entities include **taskpool, participantpool, algocontainer and schedule**. system entities need to inherit the **resource** interface and implement the **gethandler()** method. for the protection of system entities, all operations accessing system entities should go through the **gethandler()** method, which returns the processing handle of a specific entity. when other packages access system entities, they must pass the entity handle. system entity handle systemresourcehandler<t> provides two types of access methods: - **t getresourceview()**: access the unchangeable view of the entity; - **t getresource()**: access the entity itself. the system package makes a convention for other packages (or codes): when other packages (or other codes) use getresourceview(), the system package ensures that the system functions normally (for example, scheduling system, task pool management, participant pool management, etc. ); when using getresource(), the system package does not provide this guarantee. based on the guarantees provided by the system package, other packages can safely implement their own functions through system entity handles. - for example, in the algorithms package, the implementation of the algorithm requires access to various information of system entities, so all operations in this package can only use getresourceview(). ##### patterns the system package implements a guarantee similar to the iteration pattern. the specific uml class diagram is as follows: #### kernel.algorithms ##### logic the algorithms package defines crowdsensing-related algorithms used in the system, and currently provides task allocation, task recommendation, and participant selection algorithm interfaces. the algorithms package realizes the decoupling of algorithms and system processes. in the process of implementing the algorithm in the algorithms package, based on the guarantee provided by the system package, the algorithm process and the system process can be decoupled to ensure the stable operation of the system process. ##### patterns there are two main design patterns involved in the algorithms package, namely: - the algorithms themselves use engineering mode. each type of algorithm factory produces a specific type of algorithm implementation. currently, each algorithm factory needs to implement task allocation, task recommendation and participant selection algorithms separately; - when algorithms interact with the scheduler, the algorithms are embedded in the scheduler in the form of template patterns. the uml class diagram of the algorithms package is as follows: ##### description the lgorithms package provides four classic task allocation algorithms, namely t_most, pt_most, t_random, and gga_i. the algorithm factories corresponding to the four algorithms all inherit from the algorithm adapter algofactoryadapter. each algorithm can support single task allocation and multi-task allocation. the interface algofactory defines the interfaces of all algorithms used in the kernel. currently, three functions are defined: the algorithm adapter algofactoryadapter implements the interface algofactory and provides the system with default task allocation, task recommendation and participant selection algorithms. if no algorithm selection is performed, the system provides the default algorithm implementation. access to specific algorithms can be achieved by inheriting the algorithm adapter algofactoryadapter. #### crowdkernel system interface and implementation ##### interface the interface crowdkernel defines the interface for programmers to interact with kernel functions. currently crowdkernel defines the following functions: ### algo crowdos-aaas(crowdos algorithms as a service). coming soon. ### dataservice crowdos-dataservice. coming soon. ### simulationsystem coming soon. ## guides www.crowdos.cnthe website contains some detailed information about crowdos. ## licence the crowdos project is released under version of the apache license ## openatom foundation the crowdos project has joined the openatom foundation. project address:https://atomgit.com/transcend/crowdos"
1,cognition_package,the flutter cognition package,"# cognition package [!pub package](https://pub.dartlang.org/packages/cognition_package) [!style: recommended](https://pub.dev/packages/lints) [!github stars](https://github.com/cph-cachet/cognition_package) [!mit license](https://opensource.org/licenses/mit) cognition package is a flutter package for building cognitive tests for study apps on android and ios built using the research package. the overarching goal of cognition package is to enable developers and researchers to design and build cross-platform (ios and android) cognitive assessment applications that rely on validated gold-standard cognitive tests. when combined with research package, cognition package meets the requirements of most scientific research, including capturing participant consent, extensible input tasks, and the security and privacy needs necessary for irb approval. cognition package is a flutter implementation of a cognitive test battery including validated gold-standard cognitive tests spanning all neurocognitive domains: sensation perception motor skills and construction attention and concentration memory executive functioning processing speed language and verbal skills each test in cognition package is implemented as an `rpactivitystep` from research package. as such, they may be used inside an `rptask` along with other types of `rpstep`s. each test consists of key sections; the instructions for the test, the test itself, and the test results. hence, each test includes classes that defines: the model class which extends `rpactivitystep` and defines the parameters available for the specific test (e.g., the length of the test or the amount of repetitions), as well as the function to calculate the final score of the test. the ui class which describes how the test is rendered on the screen and the logic of running the test. the `rpresult` class which describes the data collected from the test and adds it to the list of all results from the task. the current set of cognitive tests in the cognition package are: multiple object tracking corsi block tapping verbal recognition memory delayed recall flanker letter tapping paired associative learning picture sequence memory rapid visual information processing reaction time stroop effect finger tapping trail making visual array change cognition package is part of the overall copenhagen research platform (carp) which also provides a flutter package for mobile and wearable sensing called carp mobile sensing. ## documentation there is a set of tutorials, describing: - the overall software architecture of research package - the overall software architecture of cognition package - how to create a cognitive test - the cognition_package flutter api is available (and maintained) as part of the package release at pub.dev - localization support in research package which also applies for cognition package ## example application there is an example app which demonstrates the different features of cognition package as implemented in a flutter app. the cognitive test to be shown in the example app can be configured in the `cognition_config.dart` file: ```dart // here the list of cognitive test are added to an rp ordered task. // uncomment the ones you want to see a demo of. rporderedtask cognitiontask = rporderedtask( identifier: 'cognition_demo_task', steps: [ reactiontime, pairedassociateslearning, tapping, corsiblocktapping, stroopeffect, rapidvisualinfoprocessing, trailmaking, continuousvisualtracking, wordrecall, picturesequencememory, lettertapping, flanker, visualarraychange, delayedrecall, completionstep, ], ); ``` the `cognitiontask` defines the list of cognitive tasks to be shown and you may include the ones you want to see. ## localization cognition package support localization via the localization support in research package. currently, the package supports english (`en`), danish (`da`), french (`fr`), and portuguese (`pt`). > **note:** the sounds used in the letter tapping test and word recall tests for now only use english letters and words. this might be translated in a future version of the package and prs for this is most welcome. in order to support localization in your app, add the `rplocalizations.delegate` and the `cplocalizations.delegate` delegates to your list of delegates in your `materialapp` configuration. see the `main.dart` in the example app for how this can be done. ## who is backing this project? cognition package is made by the copenhagen center for health technology (cachet) and is a component in the copenhagen research platform (carp), which is used in a number of applications and studies. ## how can i contribute? we are more than happy to take contributions and feedback. use the issues page to file an issue or feature request. besides general help for enhancement and quality assurance (bug fixing), we welcome input on new cognitive tests. ## copyright note that the tests in this package may be **subject to different copyright terms**. it is your responsibility to investigate if you can use these tests for your specific purpose and application, and if you need to obtain a permission from the copyright holder(s). in the table below, we have provided links to copyright statements (where applicable), which you may want to consult, if you are using a test. if it states **(c) cachet** this implies that the test is designed by us, and hence copyright (mit license) to cachet. > note, however, as per the mit license, _this software is provided ""as is"" and in no event shall the authors (i.e., us) be liable for any claim - including copyright issues - arising from the use of this software_. | **test** | **copyright** | | ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | | multiple object tracking | (c) cachet | | corsi block tapping | psytoolkit | | verbal recognition memory | moca | | delayed recall | moca | | flanker | (c) cachet | | letter tapping | moca | | paired associative learning | cambridge cognition ltd | | picture sequence memory | nihtb-cb | | rapid visual information processing | cambridge cognition ltd | | reaction time | (c) cachet | | stroop effect | (c) cachet | | finger tapping | (c) cachet | | trail making | public domain | | visual array change | (c) cachet | ## license this software is copyright (c) copenhagen center for health technology (cachet) at the technical university of denmark (dtu). this software is available 'as-is' under a mit license."
0,ContextSense,user-centric context inference for mobile crowdsensing,"# contextsense key features --------------------- #contextsense is an android application that supports user context inference, sensing data collection, and gps positioning, by leveraging embedded sensors on the smartphone. the application initially shows a sensor list of the device. the context inference function distinguishes physical context as in-/out-pocket, in-/out-door, and under-/on-ground scenarios. it is designed to be personalized on each device, and therefore it requires feedback from the user to update the internal machine learning models. both three binary classifications and one hierarchical inference are available to receive feedback. the user can click on the feedback button once the inference result is incorrect. the context inference function also provides recognition of the user activity (such as still, walk, running, etc.). the sensing data collection function measures the environmental conditions: daytime (binary), light density (lux), magnetic strength (t), gsm connectivity (binary), abstract rssi level, rssi value (dbm), gps accuracy (m), wifi connectivity (binary), wifi rssi (dbm), proximity (b), sound level (dba), temperature (c), pressure (hpa), humidity (%), and each entry contains a timestamp. the user can give the ground-truth labels on the sensing data by using ""in-pocket, in-door, and under-ground"" switches. the sensing data can be stored on the device as a local file and also be sent via email. the gps positioning function provides information related to the gps provider: longitude, latitude, altitude, speed, bearing, accuracy, and time. it may work only in an outdoor environment. getting started ------------------------ step - download or clone the source code of #contextsense. step - download android studio start android studio and open the #contextsense project by selecting the directory wherein is placed #contextsense. all dependencies are located in the file ""build.gradle"". step - download the following java library: * weka-android (version is preferred) place the jar file that just has been downloaded into the ""app/libs"" folder of the #contextsense app directory, through windows explorer or mac finder. then open ""project"" files view in android on the left side of android studio, find the ""libs"" folder, right-click the file, and select ""add as library"". running on the mobile phone: ------------------------------------------------ note that the application starts with a permission checker and you need to grant these permission requests. the application may also request to turn on some components in runtime, such as gps, please follow the notification to turn on them. license ------------- #contextsense is available under the terms of the gpl license, which implies that application developers are free to use #contextsense. it also means that developers are invited to contribute to improving #contextsense as long as the original source code remains open. contributors --------------------- * yifan du, designer & developer * franoise sailhan, reviewer * valrie issarny, reviewer"
0,CrowdKit,a generic programming framework for mobile crowdsensing spplications.,"# crowdkit ## overview crowdkit is a programming framework designed to provide developers with a comprehensive tool to simplify the process of applications development in mobile crowdsensing(mcs). ## architecture ### web-side the web interface provides developers with a visual programming environment for defining data models and selecting algorithms through clicks, selections, and configurations. ### server-side the server-side consists of entity models, code generation modules, algorithm selection modules, and communication modules. it handles communication between the web interface and the client-side, providing abstract tasks and entity models. it generates personalized models based on developer instructions and automatically generates business code. the server-side is built on the spring boot framework, utilizing technologies such as mybatis, rabbitmq, freemarker, and integrates domain-specific algorithms into a library for developer selection. ### client-side the client-side consists of perception and communication modules, responsible for executing perception tasks and completing data operations. it communicates with the server-side through communication modules for tasks such as perception task publishing, perception task assignment, and perception data uploading. the client-side backend is based on the android platform. ## usage ### server-side configuration **dependency installation:** ensure the installation of dependencies such as spring boot, mybatis, rabbitmq, etc. **configuration file:** configure relevant parameters in the server-side project, such as database connection and message queue. ### web interface usage **dependency installation:** install node.js and npm. **project initialization:** navigate to the web interface project directory, run `npm install` to install project dependencies. **launch:** run `npm run serve` to start the web interface. ### client-side configuration **install android studio:** ensure the installation of android studio. **import project:** open the client-side project, configure the android development environment. ## project status currently, crowdkit is in the submission and review stage."
0,tp,app and backend,"# beach and weather ## *a mobile crowdsensing platform to report beach conditions* b&w a novel participatory mcs tool where contributors are able to report the current state of the beach where they are currently located in. at the same time, other users can get access to the current state of multiple beaches based on the collaborative data send by their counterparts. ## components - a client module, running as a mobile application that allows users to submitt the current state of a beach and - a back-end server that collects and aggregates all the reports from the contributors. it also deals with the requests from the consumers who want to know the current state of a particular beach. the orchestration between the client and the server is done by means of a web service based on the simple object access protocol (soap). the source code of the mobile application is in the src/client folder and the code of the server in within the src/server folder. ## libraries and dependencies - android (marshmallow, api - picasso - jcoord - - postgresql - oracle glassfish ## developer tools the tools that we have used to develop b&w have been, - android studio - apache netbeans ## scientific paper a scientific paper describing in detail this platform has been submitted to the softwarex journal. ## license gnu general public license"
0,sensus-1,a cross-platform system for mobile sensing,please see the wiki for more information.
0,AccelerometerSensor,accelerometer sensor - android mobile sensing application - api must be used to run this android accelerometer sensor mobile sensing application,"# accelerometersensor accelerometer sensor - android mobile sensing application - api must be used to run this android accelerometer sensor mobile sensing application ## group team members - parsa ahmadi nasab emran - abdullah jandali ## list of features that have been implemented in this android accelerometer sensor mobile sensing application - a reset button that would change the background color to white and the ""you have reset the background color to white."" message will be displayed - devie rotation to the left to reject the call - the background color will be changed to red and the ""you have rejected the call."" message will be displayed - device rotation to the right to answer the call - the background color will be changed to green and the ""you have answered the call."" message will be displayed - swipe to the left to reject the call - the background color will be changed to red and the ""you have rejected the call."" mwssage will be displayed - swipe to the right to answer the call - the background will be changed to green and the ""you have answered the call."" message will be displayed - swipe to the top - the background color will be changed to white and the ""you have swiped upwards."" message will be displayed - swipe to the bottom - the background color will be changed to white and the ""you have swiped downwards."" message will be displayed - x value is displayed in its own text view - y value is displayed in its own text view - z value is displayed in its own text view - x, y, and z data values are plotted in real time using mpandroidchartlibrary ## insights and findings **plotting of accelerometer sensor data values** - at first, we were thinking about plotting of accelerometer sensor data values by exporting it to a csv file and then visualizing it from csv format to chart using python. and then we ran into the mpandroidchart library which allowed us to plot the accelerometer sensor data values in real time as the sensor was reading them. so, we have decided to be using mpandroidchart library to plot the accelerometer sensor data in real time and not have to export them to a csv file and the visualizing it from csv format to chart using python. **using a gyroscope sensor for rotation of the device** - at first, we were thinking about using the gyroscope sensor for rotation of the device. but when we tried rotating the devuce using the gyroscope sensor, we ran into the problem about its x, y, and z values being all zeros regardless of if the device was rotated to the right or to the left. then, we have decided to include the rotation of the device in its accelerometer sensor since we have used its x values to decide whether the background color should change to either green or red. **keeping it clean and user friendly** - we kept it user friendly by allowing the user to swipe to the right, swipe to the left, swipe to the top, swipe to the bottom, rotate the device to the left, rotating the device to the right, and pressing/tapping the reset button. the user can reset the background color to white by either swiping to the top, swiping to the bottom, or presssing/tapping the reset button. the user can also reject the call by rotating the device to the left or by swiping to the left. the user can also answer the call by rotating the device to the right or swiping to the right. - we kept it clean by not allowing all of its layout components not to be on top of each other and not being directly next to each other. we also have added some padding to give each component some room between each other in order to prevent them from being on top of each other and not being directly next to each other. the layout components are cleaned up and they have been organized in the actual layout. ## goal the goal of this android accelerometer sensor mobile application is to allow users to control their incoming phone calls. this application allows them to either rotate their phones to the left to reject the call or rotate their phones to the right to answer the call. this application also allows the users to either swipe to the left to reject the call or swipe to the right to answer the call. the users can also press/tap the reset button to change the background color to white again and the ""you have reset the background color to white."" message will be displayed. this application also displays the x, y, and z data values for the users to see. this application also plots the x, y, and z data values in real time for the users to see. the application also allows the users to swipe upwards or downwards to change the background color to white again. this application will also display a toast message: ""you have rejected the call."" when the device is being rotated to the left. this application will also display a toast message: ""you have answered the call."" when the device is being rotated to the right. this application will also display a toast message: ""you have rejected the call."" when swiping to the left. this application will display a toast message: ""you have answered the call."" when swiping to the right. this application will also display a toast message: ""you have swiped upwards."" when swiping to the top. this application will also display a toast message ""you have swiped downwards."" when swiping downwards. this application will also display a toast message: ""you reset the background color to white."" ## application/scenario its for people who need help with controlling of their incoming phone calls. this application allows them to either rotate their phones to the left to reject the call or rotate their phones to the right to answer the calls. this application also allows them to either swipe to the left to reject the call or swipe to the right to answer the call. this application also allows the users to change the background color to white by pressing/tapping the reset button, swipe to the top, or swipe to the bottom. this application displays the x, y, and z data values to them. this applicatiom displays the plotting of x, y, and z data values in real time to them."
1,AWARE_TRIADS,aware:open-source context instrumentation framework for everyone,"## aware mobile sensing app - emotion and behavior study the aware mobile sensing app - emotion and behavior study plans to use the mobile sensing app aware (https://awareframework.com/) to collect data from participants next semester while using a different app to send them surveys to their phones every two hours. aware is an open source software that enables the project to collect data such as gps, activity, phone use, etc. the project wants to then look at how emotion and emotion regulation are related to these passively sensed contextual features. ### background the project is a team of researchers studying the relationship between behavior patterns, emotion regulation, and emotion. they have previously used the aware app successfully in a study with undergraduates, focusing on features such as location and phone use. however, they would like to optimize their use of this app for data collection to better understand the relationship between behavior patterns and emotional regulation. ### getting started to participate in the study, participants will need to download the aware app on their smartphone. the app is available for download on google play store for free, and a custom built app store aware app. participants will also need to agree to receive survey prompts every two hours through a separate app. ### data privacy the project takes data privacy seriously and complies with all necessary legal and ethical standards. all data collected through the aware app is anonymized and stored securely in a database. participants have full control over their data and can choose to withdraw from the study at any time. ### data analysis the project will use machine learning algorithms to analyze the sensor data collected from participants' smartphones. the analysis aims to identify behavior patterns such as physical activity, sleep, and social interaction, among others. the project will then analyze this data in relation to the emotion and emotion regulation data collected through surveys. ### contributing if you are interested in contributing to the study or have any questions, please contact the project at [email address]. they welcome collaborations with researchers and institutions interested in understanding the relationship between behavior patterns and emotion regulation <img alt=""alt text"" title=""optional title"">"
1,Sensoroid,a sensing framework for android mobile devices.,"# sensoroid a sensing framework for android mobile devices. a sensing and data processing framework for accessing sensor values on android mobile devices and making them available to other applications. the goal is to bring the sensing capabilities of smartphone devices to iot architectures. implementing this mobile sensing framework we intend to facilitate the interface between the iot system, the user application and device hardware drivers. this work will help developers to focus on writing minimal pieces of sensor-specific code enabling an ecosystem of reusable sensor drivers."
0,beliski-ios,a note-taking app used to collect data for mobile sensors and do human behavior research,# beliski ios app ## general beliski is an ios note-taking app used to collect data for mobile sensing and human behavior research. (this is an mvp app without future maintenance) ## requirements - swift - xcode - ios - swiftui - firebase authentication - firebase app check (buggy) - firebase firestore database - firebase storage - firebase functions (in another repo not yet public) - firebase cloud messaging (buggy) ## usage your shall use your own firebase backend with the setup configuration for each firebase service stated in requiremets. ## screenshots (when in dark mode) medium medium medium medium
1,pulmonary_monitor_app,"a carp-based monitoring app for pulmonary (i.e., respiratory) health","# pulmonary monitor flutter app the pulmonary monitor flutter app is designed to monitor pulmonary (i.e., respiratory) symptoms. it is build using the carp mobile sensing (cams) framework, which is part of the copenhagen research platform (carp) from the copenhagen center for health technology. it follows the flutter business logic component (bloc) architecture, as described in the carp mobile sensing app. in particular, this app is designed to demonstrate how the cams `apptask` is used. an elaborate presentation of the app task model is available on the cams wiki. ## design rationale the work on this app started with a collaboration with the sounds app project at the university of cambridge. pulmonary monitor is designed to sample the following data: * device data - device, memory, light, * context data - location, activity, weather, and air quality * surveys - demographics and daily symptoms * sound - coughing and reading * cognitive performance - using a set of cognitive tests all of this is configured in the `study_protocol_manager.dart` file. compared to the standard cams example app, this app makes extensive use of `apptask`s for collecting surveys and sound samples. however, it also illustrates how ""normal"" sensing measures can be wrapped in an `apptask`. for example, there is an app task collecting weather and air quality measures. and it illustrates how background sensing can be added to an app task. for example, accelerometer and gyroscope data is collected while the user performs a cognitive assessment. the user-interface of the app is shown in figure **figure - user interface of the pulmonary monitor app. left: study overview. right: task list for the user to do. ## app tasks the task list (figure right) is created from the different `apptask`s defined in the `study_protocol_manager.dart` file. there are four kind of app tasks defined: a **sensing** task wrapped in an app task collecting weather and air quality. two types of **survey** tasks collecting demographics and daily symptoms. two types of **audio** tasks, collecting sound while the user is coughing and reading. one **cognitive** task with two cognitive tests assessing cognitive functioning and finger tapping speed, respectively. ### sensing app task the sensing app task collects `weather` and `air_quality` measures (both defined in the `carp_context_package`). this app task appears at the bottom of the task list in figure this app task is defined like this: ````dart smartphonestudyprotocol protocol = smartphonestudyprotocol( name: 'pulmonary monitor', ownerid: 'alex@uni.dk', ); // define which devices are used for data collection. smartphone phone = smartphone(); protocol.addprimarydevice(phone); ... // add an app task that once pr. hour asks the user to // collect weather and air quality - and notify the user protocol.addtaskcontrol( periodictrigger(period: duration(hours: apptask( type: backgroundsensingusertask.one_time_sensing_type, title: ""location, weather & air quality"", description: ""collect location, weather and air quality"", notification: true, measures: [ measure(type: contextsamplingpackage.location), measure(type: contextsamplingpackage.weather), measure(type: contextsamplingpackage.air_quality), ]), phone); ```` the above code adds an `periodictrigger` with an `apptask` of type `one_time_sensing_type`. this app task contains the three measures of location, weather, and air quality. the result of this sensing configuration is that an app task is added to the task list every hour, and when it is activated by the user (by pushing the `press here to finish task` button), the measurements are collected exactly once. when the measurements have been collected, the app task is marked as ""done"" in the task list, illustrated by a green check mark as shown in figure **figure - task list with a ""done"" sensing task. this app task has also enabled `notification` and a notification about this task will be added to the phone's notification system. if the user presses this notification, s/he is taken to the app (but **not** the task itself (this is a more complicated issue, which is supported by cams, but not implemented in the pulmonarymonitor app (yet))). if the user does the task from the app (by pushing the `press here to finish task` button), the notification will be removed again. ### survey app task a survey (as defined in the `carp_survey_package`) can be wrapped in an app task, which will add the survey to the task list. in figure there are two types of surveys; a demographics survey and a survey of daily symptoms. these are configured in the `study_protocol_manager.dart` file like this: ````dart // collect demographics & location once the study starts. protocol.addtaskcontrol( immediatetrigger(), rpapptask( type: surveyusertask.survey_type, title: 'demographics', description: 'a short survey on your background.', minutestocomplete: notification: true, rptask: surveys.demographics.survey, measures: [measure(type: contextsamplingpackage.current_location)]), phone); ```` this configuration adds the demographics survey (as defined in the `surveys.dart` file) immediately to the task list. note that a `location` measure is also added. this will have the effect that location is sampled, when the survey is done - i.e., we know **where** the user filled in this survey. the configuration of the daily symptoms survey is similar. this survey is, however, triggered once per day at and hence added to the task list daily. again, location is collected when the survey is filled in. ````dart // collect symptoms daily at protocol.addtaskcontrol( recurrentscheduledtrigger( type: recurrenttype.daily, time: timeofday(hour: minute: ), rpapptask( type: surveyusertask.survey_type, title: 'symptoms', description: 'a short survey on your daily symptoms.', minutestocomplete: rptask: surveys.symptoms.survey, measures: [measure(type: contextsamplingpackage.current_location)]), phone); ```` note that this app task does not issue a notification. figure shows how this looks on the user interface. **figure - left: the daily symptoms survey, shown when the user starts the task. right: the task list showing that the two surveys have been filled in (""done""). ### audio app task another type of app tasks used in the pulmonary monitor app are two types of audio tasks, which sample audio from the user when coughing and reading a text aloud. both use the `audio` measure defined in the `carp_audio_package`. the configuration of the coughing audio app task is defined like this: ````dart // collect a coughing sample on a daily basis. // also collect current location, and local weather and air quality of this // sample. protocol.addtaskcontrol( periodictrigger(period: duration(days: apptask( type: audiousertask.audio_type, title: ""coughing"", description: 'in this small exercise we would like to collect sound samples of coughing.', instructions: 'please press the record button below, and then cough times.', minutestocomplete: notification: true, measures: [ measure(type: mediasamplingpackage.audio), measure(type: contextsamplingpackage.current_location), measure(type: contextsamplingpackage.weather), measure(type: contextsamplingpackage.air_quality), ], ), phone); ```` this configuration adds an app task to the task list once per day of type `audio_type`. and it uses notifications. this app task will collect four types of measures when started; an `audio` recording, current `location`, local `weather`, and local `air_quality`. **figure - left: the daily coughing audio sampling, shown when the user starts the task. right: the task list showing that the coughing task has been ""done"". ### cognition testing app task the last type of app tasks used in the app is the cognitive tests from the cognition_package. cognitive test are modelled just like a survey, and can be added to the protocol like a survey. below is an example of adding an assessment of parkinson's disease which consists of an instruction step, a timer step, and two cognitive tests (flanker and tapping tests). note that accelerometer and gyroscope data is collected throughput the test (in order to assess tremor). ```dart // perform a parkinson's assessment. // this is strictly speaking not part of monitoring pulmonary symptoms, // but is included to illustrate the use of cognitive tests from the // cognition package. protocol.addtaskcontrol( periodictrigger(period: duration(hours: rpapptask( type: surveyusertask.cognitive_assessment_type, title: ""parkinson's' assessment"", description: ""a simple task assessing finger tapping speed."", minutestocomplete: rptask: rporderedtask( identifier: ""parkinsons_assessment"", steps: [ rpinstructionstep( identifier: 'parkinsons_instruction', title: ""parkinsons' disease assessment"", text: ""in the following pages, you will be asked to solve two simple test which will help assess your symptoms on a daily basis. "" ""each test has an instruction page, which you should read carefully before starting the test.\n\n"" ""please sit down comfortably and hold the phone in one hand while performing the test with the other.""), rptimerstep( identifier: 'rptimerstepid', timeout: duration(seconds: title: ""please stand up and hold the phone in one hand and lift it in a straight arm until you hear the sound."", playsound: true, ), rpflankeractivity( identifier: lengthoftest: numberofcards: ), rptappingactivity( identifier: lengthoftest: ) ], ), measures: [ measure(type: sensorsamplingpackage.acceleration), measure(type: sensorsamplingpackage.rotation), ]), phone); ``` ## user task model as explained in the tutorial on the apptask model on the cams wiki, the runtime of app tasks are handled by so-called `usertask`. a `usertask` defines what happens when the user click the ""press here to finish task"" button. we shall not go into these details here (please see the tutorial), but just mention that the handling of the audio app tasks above, is done using a user task model specific to the pulmonarymonitor app. this user task model is specified in the `lib/sensing/user_task.dart` file. this file defines: * an `audiousertask` which defines a `usertask` for what should happen when the audio app task is started. * a `pulmonaryusertaskfactory` which is a `usertaskfactory`, which can create a `usertask` based on the type of app task. in this case an `audiousertask`. the definition of `audiousertask` is: ````dart /// a user task handling audio recordings. /// when started, creates a [audiomeasurepage] and shows it to the user. class audiousertask extends usertask { static const string audio_type = 'audio'; final streamcontroller<int> _countdowncontroller = streamcontroller.broadcast(); stream<int> get countdownevents => _countdowncontroller.stream; timer? _timer; /// duration of audio recording in seconds. int recordingduration = audiousertask(apptaskexecutor executor) : super(executor); @override bool get haswidget => true; @override widget? get widget => audiomeasurepage(audiousertask: this); /// callback when recording is to start. void onrecord() { executor.start(); _timer = timer.periodic(const duration(seconds: (_) { _countdowncontroller.add(--recordingduration); if (recordingduration <= { _timer?.cancel(); _countdowncontroller.close(); executor.stop(); state = usertaskstate.done; } }); } } ```` when this user task is to be shown in the ui, the `widget` property is shown. this `audiousertask` returns an `audiomeasurepage` as a widget (figure left). when the user clicks the red button to start recording, the `onrecord()` method is called. this method resumes sampling (i.e. starts collecting all the measures defined in the task) and starts a count-down, which - when finished - pauses the sampling and sets the state of this task as ""done""."
1,CityTracks,more info at intelliurb.org,"> citytracks is app for collecting and analysing urban mobility pattern. it was used in my msc. in information systems at unirio. > detecting the transportation mode for context-aware systems using smartphones: > languages: objective-c, php, r, java. --- # citytracks: leveraging mobility data to identify urban mobility patterns and modes # ## introduction ## urban mobility is a key challenge for city planners and policymakers, as it impacts many aspects of urban life, from traffic congestion to air pollution. in recent years, mobile sensing technologies have enabled the collection of large amounts of mobility data, providing new opportunities for analyzing and understanding urban mobility patterns and modes. citytracks is a mobile application designed to collect mobility data and identify mobility patterns and modes in urban populations. this white paper provides an overview of the data collection process and techniques used in the citytracks research project. ## data collection in real usage ## to ensure greater control over the quality of the information collected, the citytracks research project decided to collect its own data, rather than relying on any available trace repository. this decision provided additional research opportunities, including the investigation of mobility aspects of a well-known area. to support the data collection, the project team designed the infrastructure for the server side and for the client app. a framework called was developed to provide guidelines and blueprints for the infrastructure of generic participatory sensing researches. the data was collected from volunteers, who were in full control of the data they were putting available. the data collection effort resulted in over geo-location records, which were acquired from trajectories, covering various transportation modes such as car, bus, bike, walking, and motorcycle. the data collection covered the south zone, north zone, downtown of rio de janeiro, south zone, north zone, central and oceanic region of niteroi, as shown in figure ## trajectory representation ## the use of collected raw data has little value for data mining, requiring interpretation and feature extraction steps before the data can be used. the process of estimating a path through smartphones is a difficult problem because there is no embedded sensor that is accurate in all locations. a pre-processing step after the data collection was applied to group related positional records into trajectories. each trajectory can have periods of movement and periods of pause (stops) identified, and each location record is associated with a single specific trajectory segment or a single pause. ## applied techniques to evaluate the classifier algorithms ## to evaluate the classifier algorithms' performance, the citytracks research project used the cross-validation technique, with the k-fold method (with k = this technique is well known and accepted and was used in related studies. the precision accuracy and recall accuracy were used as standard metrics to evaluate the classifiers algorithms' performance. ## conclusion ## the citytracks mobile application is an innovative approach to collecting mobility data and identifying urban mobility patterns and modes. the data collection process and techniques used in the citytracks research project demonstrate the importance of controlling the quality of the data collected and the value of pre-processing the data before analyzing it. the use of standard metrics to evaluate the classifiers algorithms' performance ensures reliable and valid results. the citytracks research project provides valuable insights into urban mobility patterns and modes, enabling policymakers and city planners to make informed decisions to improve urban mobility."
