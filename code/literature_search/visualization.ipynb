{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations for the Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for all visualizations in one place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# set style for charts\n",
    "style = 'seaborn-v0_8'  # 'ggplot' and 'seaborn-v0_8-colorblind' are also good\n",
    "plt.style.use(style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sorted_elem_list(col_name: str, na_value: any, lower: bool = True):\n",
    "  df[col_name].fillna(na_value, inplace=True)\n",
    "  if lower:\n",
    "    sort_func = (lambda x: sorted(set(str(y).lower().strip()\n",
    "                                      for y in x.strip().split(\",\"))))\n",
    "  else:\n",
    "    sort_func = lambda x: sorted(set(y.strip() for y in x.strip().split(\",\")))\n",
    "  df[col_name] = df[col_name].apply(sort_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data as is\n",
    "df_raw = pd.read_csv('MA_Questionnare_Answers.csv')\n",
    "\n",
    "# indexes to remove\n",
    "rem_ids: list = [91, 92, 93, 96, 118]  # Google Sheets row number - 2\n",
    "\n",
    "# removing those entries\n",
    "df = (df_raw.drop(index = rem_ids, inplace=False)\n",
    "            .drop(columns='Zeitstempel', inplace=False)\n",
    "            .reset_index(drop=True, inplace=False))\n",
    "\n",
    "# renaming columns for easy access\n",
    "name_dict = {'What is the app called?': 'app_name',\n",
    "             'What year was this paper published?': 'publication_year',\n",
    "             'Is the software a generic tool or a domain specific app?': 'is_generic',\n",
    "             'Which OSs does the application support?': 'supported_OSs',\n",
    "             'Which devices does the application support?': 'supported_devices',\n",
    "             'Is the code available somewhere publicly?': 'code_availability',\n",
    "             'What data collection techniques are employed in-app?': 'data_collection_techniques',\n",
    "             'What EMA sampling strategy is being employed?': 'sampling_strategies',\n",
    "             'Which notifications does the software use?': 'supported_notification_types',\n",
    "             'What domain is the intervention being done for?': 'application_domains',\n",
    "             'What static intervention content is being delivered to the user?': 'static_intervention_contents',\n",
    "             'What dynamic intervention content is being delivered to the user?': 'dynamic_intervention_contents',\n",
    "             'What JITAI components are being used in the interventions?': 'jitai_components',\n",
    "             'Which AI technologies are being used?': 'ai_technologies',\n",
    "             'What is the title of this paper?': 'paper_title',\n",
    "             'Did the intervention according to the authors have benefits that are statistically relevant?': 'is_intervention_benefitial',\n",
    "             'How does the publication explain the code or system?': 'code_explanations',\n",
    "             'Notes': 'notes'}\n",
    "df.rename(columns=name_dict, inplace=True)\n",
    "\n",
    "# converting boolean columns to actual booleans\n",
    "df.is_generic = df.is_generic.apply(lambda x: not x == 'specific app').astype(bool)\n",
    "df.is_intervention_benefitial = df.is_intervention_benefitial.apply(lambda x: x == 'yes').astype(bool)\n",
    "\n",
    "# converting year numbers to integers\n",
    "df.publication_year = df.publication_year.astype(int)\n",
    "\n",
    "# converting all comma-separated entries of list based features to actual lists\n",
    "lst_features = [{'col_name': 'supported_OSs', 'na_value': 'unknown', 'lower': True},\n",
    "                {'col_name': 'app_name', 'na_value': 'not named', 'lower': False},\n",
    "                {'col_name': 'supported_devices', 'na_value': 'Smartphone', 'lower': False},\n",
    "                {'col_name': 'code_availability', 'na_value': 'private', 'lower': False},\n",
    "                {'col_name': 'data_collection_techniques', 'na_value': 'questionnaire', 'lower': True},\n",
    "                {'col_name': 'sampling_strategies', 'na_value': 'event-contingent', 'lower': True},\n",
    "                {'col_name': 'supported_notification_types', 'na_value': 'no notifications', 'lower': True},\n",
    "                {'col_name': 'jitai_components', 'na_value': 'no components', 'lower': True},\n",
    "                {'col_name': 'code_explanations', 'na_value': 'no explanations', 'lower': True},\n",
    "                {'col_name': 'notes', 'na_value': 'no comments', 'lower': False},\n",
    "                {'col_name': 'application_domains', 'na_value': 'no specific domain', 'lower': True},\n",
    "                {'col_name': 'static_intervention_contents', 'na_value': 'no static content', 'lower': True},\n",
    "                {'col_name': 'ai_technologies', 'na_value': 'no AI methods', 'lower': True},\n",
    "                {'col_name': 'dynamic_intervention_contents', 'na_value': 'no dynamic content', 'lower': True}]\n",
    "for config in lst_features:\n",
    "  create_sorted_elem_list(config['col_name'], config['na_value'], config['lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supported_X(df: pd.DataFrame, required_X: list,\n",
    "                    col_name: str, only: bool = False):\n",
    "  '''Given a column name and a list of required feature values this returns the\n",
    "     indexes of all rows that contain all the required values in their feature\n",
    "     value.'''\n",
    "  def has_all_X(supported_X, required):\n",
    "    required_lower = [x.lower() for x in required]\n",
    "    return all(y in set(str(x).lower() for x in supported_X) for y in required_lower)\n",
    "  def has_only_X(supported_X, required):\n",
    "    has_all = has_all_X(supported_X, required)\n",
    "    has_same_elements = len(supported_X) == len(required)\n",
    "    return has_all and has_same_elements\n",
    "  if not only:\n",
    "    return df[df[col_name].apply(lambda x: has_all_X(x, required_X))].index.tolist()\n",
    "  else:\n",
    "    return df[df[col_name].apply(lambda x: has_only_X(x, required_X))].index.tolist()\n",
    "\n",
    "\n",
    "def get_all_X(df: pd.DataFrame, col_name: str, with_usage: bool = False):\n",
    "  '''Given a column name this returns a list of all present feature values.\n",
    "     This should not be used for non list-based columns such as publication_year,\n",
    "     is_generic, is_intervention_benefitial, paper_title, and notes.\n",
    "     \n",
    "     If with_usage is set to True this will return a dict with feature values as\n",
    "     keys and the amount of occurences as value. Otherwise this will return a\n",
    "     list of all feature values.'''\n",
    "  if with_usage:\n",
    "    values: dict[str, int] = {}\n",
    "    for _, row in df.iterrows():\n",
    "      for key in row[col_name]:\n",
    "        if key not in values:\n",
    "          values[key] = 1\n",
    "        else:\n",
    "          values[key] += 1\n",
    "    return values\n",
    "  else:\n",
    "    values = []\n",
    "    for _, row in df.iterrows():\n",
    "      for v in row[col_name]:\n",
    "        values.append(v)\n",
    "    return list(set(values))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data\n",
    "app_usage: dict = get_all_X(df, 'app_name', True)\n",
    "app_usage_mult: dict = {k: v for k, v in app_usage.items() if v > 1}\n",
    "\n",
    "# preparing data\n",
    "num_unnamed = app_usage['not named']  # all apps that are not named\n",
    "# all apps that are named and used >1 times\n",
    "num_mult_use = sum(app_usage_mult.values()) - num_unnamed\n",
    "# all remaining apps are only used once (so far)\n",
    "num_single_use = sum(app_usage.values()) - num_unnamed - num_mult_use\n",
    "\n",
    "# plotting the pie chart\n",
    "xs = [f'not named ({num_unnamed})',\n",
    "      f'multiple uses ({num_mult_use})',\n",
    "      f'single use ({num_single_use})']\n",
    "ys = [num_unnamed, num_mult_use, num_single_use]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.pie(ys, labels=xs, autopct='%1.1f%%')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the apps used multiple times\n",
    "if 'not named' in app_usage_mult:\n",
    "  del app_usage_mult['not named']\n",
    "app_usage_mult = dict(sorted(app_usage_mult.items(),\n",
    "                             key=lambda x: x[1], reverse=True))\n",
    "fig, ax = plt.subplots()\n",
    "xs = list(app_usage_mult.keys())\n",
    "ys = list(app_usage_mult.values())\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_yticks(range(0, 5))\n",
    "ax.set_xlabel('Application Name')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('EMA/EMI Applications used Multiple Times')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.05),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting code explanations\n",
    "xs = ('no explanations', 'external links', 'diagrams', 'screenshots')\n",
    "n_noexp_only = len(get_supported_X(df, ['no explanations'], 'code_explanations', only=True))\n",
    "n_extlinks_only = len(get_supported_X(df, ['external links or papers'], 'code_explanations', only=True))\n",
    "n_diagrams_only = len(get_supported_X(df, ['diagrams'], 'code_explanations', only=True))\n",
    "n_screenshots_only = len(get_supported_X(df, ['screenshots'], 'code_explanations', only=True))\n",
    "n_noexp_partly = len(get_supported_X(df, ['no explanations'], 'code_explanations', only=False)) - n_noexp_only\n",
    "n_extlinks_partly = len(get_supported_X(df, ['external links or papers'], 'code_explanations', only=False)) - n_extlinks_only\n",
    "n_diagrams_partly = len(get_supported_X(df, ['diagrams'], 'code_explanations', only=False)) - n_diagrams_only\n",
    "n_screenshots_partly = len(get_supported_X(df, ['screenshots'], 'code_explanations', only=False)) - n_screenshots_only\n",
    "ys_only = [n_noexp_only, n_extlinks_only, n_diagrams_only, n_screenshots_only]\n",
    "ys_partly = [n_noexp_partly, n_extlinks_partly, n_diagrams_partly, n_screenshots_partly]\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "r = range(len(xs))\n",
    "p1 = ax.bar(r, ys_only, width=width, label='Only this method')\n",
    "p2 = ax.bar(r, ys_partly, bottom=ys_only, width=width, label='At least one other method')\n",
    "for i in range(len(r)):\n",
    "    ax.text(r[i], ys_only[i] / 2, str(ys_only[i]), ha='center', va='center', color='white')\n",
    "    ax.text(r[i], ys_only[i] + ys_partly[i] / 2, str(ys_partly[i]), ha='center', va='center', color='white')\n",
    "    ax.text(r[i], ys_only[i] + ys_partly[i], str(ys_only[i] + ys_partly[i]), ha='center', va='bottom')\n",
    "ax.set_xlabel('Explanations')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks(r)\n",
    "ax.set_xticklabels(xs)\n",
    "ax.set_title('Code Explanation Methods')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out more details for the text\n",
    "df.code_explanations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data\n",
    "n_private_code = len(get_supported_X(df, ['private'],\n",
    "                                     'code_availability', False))\n",
    "n_public_code = df.shape[0] - n_private_code\n",
    "\n",
    "# plotting code availability\n",
    "xs = [f'private ({n_private_code})', f'public ({n_public_code})']\n",
    "ys = [n_private_code, n_public_code]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.pie(ys, labels=xs, autopct='%1.1f%%')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing more textual information\n",
    "df.code_availability.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting domain data\n",
    "xs = ['general mental health',\n",
    "      'mood tracking',\n",
    "      'addiction cessation',\n",
    "      'physical activity',\n",
    "      'dietary habits',\n",
    "      'stress levels',\n",
    "      'cardio-vascular problems',\n",
    "      'sexual health and urology',\n",
    "      'social interactions',\n",
    "      'cancer',\n",
    "      'diabetes',\n",
    "      'orthopedic applications',\n",
    "      'pregnancy and parenthood']\n",
    "ys = []\n",
    "for x in xs:\n",
    "  ys.append(len(get_supported_X(df, [x], 'application_domains', False)))\n",
    "\n",
    "# appending other data\n",
    "y_other = 0\n",
    "xs_other = ['fruit and vegetable consumption', 'empowering',\n",
    "            'motivational deficit', 'tinnitus or hearing loss',\n",
    "            'copd', 'cognitiveâ€affective therapy',\n",
    "            'goal setting and motivation']\n",
    "print('data from the other category')\n",
    "for x in xs_other:\n",
    "  n = len(get_supported_X(df, [x], 'application_domains', False))\n",
    "  print('\\t', x, n)\n",
    "  y_other += n\n",
    "xs.append('other')\n",
    "ys.append(y_other)\n",
    "\n",
    "# plotting the data\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Intervention Domain')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('Support for Techniques in Intervention Domains')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing of data for text\n",
    "for x, y in zip(xs, ys):\n",
    "  print(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for text descriptions\n",
    "df.loc[get_supported_X(df, ['physical activity'], 'application_domains')].application_domains.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual data for is_generic\n",
    "df.is_generic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collection_techniques\n",
    "# sampling_strategies\n",
    "df.sampling_strategies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting code explanations\n",
    "xs = ('diary', 'interview', 'questionnaire', 'microphone',\n",
    "      'camera', 'other sensing')\n",
    "n_diary_only = len(get_supported_X(df, ['diary'], 'data_collection_techniques', only=True))\n",
    "n_interview_only = len(get_supported_X(df, ['interview'], 'data_collection_techniques', only=True))\n",
    "n_questionnaire_only = len(get_supported_X(df, ['questionnaire'], 'data_collection_techniques', only=True))\n",
    "n_microphone_only = len(get_supported_X(df, ['microphone'], 'data_collection_techniques', only=True))\n",
    "n_camera_only = len(get_supported_X(df, ['camera'], 'data_collection_techniques', only=True))\n",
    "sensing_only_ids = [44, 56, 79, 109, 111, 113]  # had to do this manually\n",
    "n_sensing_only = len(sensing_only_ids)\n",
    "n_diary_partly = len(get_supported_X(df, ['diary'], 'data_collection_techniques', only=False)) - n_diary_only\n",
    "n_interview_partly = len(get_supported_X(df, ['interview'], 'data_collection_techniques', only=False)) - n_interview_only\n",
    "n_questionnaire_partly = len(get_supported_X(df, ['questionnaire'], 'data_collection_techniques', only=False)) - n_questionnaire_only\n",
    "n_microphone_partly = len(get_supported_X(df, ['microphone'], 'data_collection_techniques', only=False)) - n_microphone_only\n",
    "n_camera_partly = len(get_supported_X(df, ['camera'], 'data_collection_techniques', only=False)) - n_camera_only\n",
    "n_sensing_partly = len(get_supported_X(df, ['other sensing'], 'data_collection_techniques', only=False)) - n_sensing_only\n",
    "\n",
    "ys_only = [n_diary_only, n_interview_only, n_questionnaire_only,\n",
    "           n_microphone_only, n_camera_only, n_sensing_only]\n",
    "ys_partly = [n_diary_partly, n_interview_partly, n_questionnaire_partly,\n",
    "             n_microphone_partly, n_camera_partly, n_sensing_partly]\n",
    "\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "r = range(len(xs))\n",
    "p1 = ax.bar(r, ys_only, width=width, label='Only this method')\n",
    "p2 = ax.bar(r, ys_partly, bottom=ys_only, width=width, label='At least one other method')\n",
    "for i in range(len(r)):\n",
    "    do_partly = False\n",
    "    if ys_only[i] > 0:\n",
    "      do_partly = True\n",
    "      ax.text(r[i], ys_only[i] / 2, str(ys_only[i]), ha='center', va='center', color='white')\n",
    "    if ys_partly[i] > 0 and do_partly:\n",
    "      ax.text(r[i], ys_only[i] + ys_partly[i] / 2, str(ys_partly[i]), ha='center', va='center', color='white')\n",
    "    ax.text(r[i], ys_only[i] + ys_partly[i], str(ys_only[i] + ys_partly[i]), ha='center', va='bottom')\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Data Input Methods used across all Publications')\n",
    "ax.set_xticks(r)\n",
    "ax.set_xticklabels(xs)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the sensing only techniques for text\n",
    "df.loc[sensing_only_ids].data_collection_techniques.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking combinations for texts\n",
    "df.loc[get_supported_X(df, ['other sensing', 'external hardware sensing'],\n",
    "  'data_collection_techniques', False)].notes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sampling_strategies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting sampling strats\n",
    "xs = ('Event-Contingent', 'Signal-Contingent', 'Continuous')\n",
    "n_event_only = len(get_supported_X(df, ['event-contingent'], 'sampling_strategies', only=True))\n",
    "n_signal_only = len(get_supported_X(df, ['signal-contingent'], 'sampling_strategies', only=True))\n",
    "n_cont_only = len(get_supported_X(df, ['continuous'], 'sampling_strategies', only=True))\n",
    "n_event_partly = len(get_supported_X(df, ['event-contingent'], 'sampling_strategies', only=False)) - n_event_only\n",
    "n_signal_partly = len(get_supported_X(df, ['signal-contingent'], 'sampling_strategies', only=False)) - n_signal_only\n",
    "n_cont_partly = len(get_supported_X(df, ['continuous'], 'sampling_strategies', only=False)) - n_cont_only\n",
    "\n",
    "ys_only = [n_event_only, n_signal_only, n_cont_only]\n",
    "ys_partly = [n_event_partly, n_signal_partly, n_cont_partly]\n",
    "\n",
    "width = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "r = range(len(xs))\n",
    "p1 = ax.bar(r, ys_only, width=width, label='Only this strategy')\n",
    "p2 = ax.bar(r, ys_partly, bottom=ys_only, width=width, label='At least one other strategy')\n",
    "for i in range(len(r)):\n",
    "    do_partly = False\n",
    "    if ys_only[i] > 0:\n",
    "      do_partly = True\n",
    "      ax.text(r[i], ys_only[i] / 2, str(ys_only[i]), ha='center', va='center', color='white')\n",
    "    if ys_partly[i] > 0 and do_partly:\n",
    "      ax.text(r[i], ys_only[i] + ys_partly[i] / 2, str(ys_partly[i]), ha='center', va='center', color='white')\n",
    "    ax.text(r[i], ys_only[i] + ys_partly[i], str(ys_only[i] + ys_partly[i]), ha='center', va='bottom')\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Employed Sampling Strategies among all Publications')\n",
    "ax.set_xticks(r)\n",
    "ax.set_xticklabels(xs)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests for texts\n",
    "df.sampling_strategies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supported notifications date\n",
    "n_no_notifs = len(get_supported_X(df, ['no notifications'], 'supported_notification_types', True))\n",
    "n_inapp_notifs = len(get_supported_X(df, ['in-app notifications'], 'supported_notification_types', False))\n",
    "n_device_notifs = len(get_supported_X(df, ['device notifications'], 'supported_notification_types', False))\n",
    "n_both_notifs = len(get_supported_X(df, ['device notifications', 'in-app notifications'], 'supported_notification_types', True))\n",
    "# plotting\n",
    "fix, axes = plt.subplots(ncols=3, figsize=((18, 4)))\n",
    "m = df.shape[0]\n",
    "k = m - n_no_notifs\n",
    "axes[0].pie([k, n_no_notifs],\n",
    "            labels=[f'supported ({k})', f'not supported ({n_no_notifs})'],\n",
    "            autopct='%1.1f%%')\n",
    "axes[0].set_title('Notifications')\n",
    "k = m - n_inapp_notifs\n",
    "axes[1].pie([n_inapp_notifs, k],\n",
    "            labels=[f'supported ({n_inapp_notifs})', f'not supported ({k})'],\n",
    "            autopct='%1.1f%%')\n",
    "axes[1].set_title('In-App Notifications')\n",
    "k = m - n_device_notifs\n",
    "axes[2].pie([n_device_notifs, k],\n",
    "            labels=[f'supported ({n_device_notifs})', f'not supported ({k})'],\n",
    "            autopct='%1.1f%%')\n",
    "axes[2].set_title('Device Notifications')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for texts\n",
    "df.loc[get_supported_X(df, ['device notifications'], 'supported_notification_types', False)].notes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_static_edu = len(get_supported_X(df, ['educational material'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_exe = len(get_supported_X(df, ['exercises'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_rem = len(get_supported_X(df, ['reminders'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_aud = len(get_supported_X(df, ['listening to audio'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_vid = len(get_supported_X(df, ['watching video'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_mot = len(get_supported_X(df, ['motivational messages'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_app = len(get_supported_X(df, ['links and apps'],\n",
    "                                   'static_intervention_contents', False))\n",
    "n_static_sup = len(get_supported_X(df, ['support calls'],\n",
    "                                   'static_intervention_contents', False))\n",
    "xs = ['Educational Material', 'Exercises', 'Reminders', 'Listening to Audio',\n",
    "      'Watching Video', 'Motivational Messages', 'Links or Apps',\n",
    "      'Support Calls']\n",
    "ys = [n_static_edu, n_static_exe, n_static_rem, n_static_aud, n_static_vid,\n",
    "      n_static_mot, n_static_app, n_static_sup]\n",
    "# plotting a bar chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Content Type')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('Use of Static Intervention Content Types in Literature')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "df.loc[get_supported_X(df, ['links and apps'],\n",
    "                       'static_intervention_contents', False)].static_intervention_contents.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dynamic_pmf = len(get_supported_X(df, ['personalized messages/feedback'],\n",
    "                                   'dynamic_intervention_contents', False))\n",
    "n_dynamic_cxn = len(get_supported_X(df, ['context-aware prompts/notifications'],\n",
    "                                   'dynamic_intervention_contents', False))\n",
    "n_dynamic_ale = len(get_supported_X(df, ['alerting others'],\n",
    "                                   'dynamic_intervention_contents', False))\n",
    "n_dynamic_coa = len(get_supported_X(df, ['coaching'],\n",
    "                                   'dynamic_intervention_contents', False))\n",
    "\n",
    "xs = ['Personalized Messages/Feedback', 'Context-Aware Prompts/Notifications',\n",
    "      'Alerting Others', 'Coaching']\n",
    "ys = [n_dynamic_pmf, n_dynamic_cxn, n_dynamic_ale, n_dynamic_coa]\n",
    "# plotting a bar chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Content Type')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('Usage of Dynamic Intervention Content Types in Literature')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "df.loc[get_supported_X(df, ['coaching'],\n",
    "                       'dynamic_intervention_contents', False)].static_intervention_contents.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nojitai = len(get_supported_X(df, ['no components'],\n",
    "                                'jitai_components', True))\n",
    "n_jitaitriggers = len(get_supported_X(df, ['triggers'],\n",
    "                                      'jitai_components', True))\n",
    "n_jitaiadaptoble = len(get_supported_X(df, ['adaptible intervention content'],\n",
    "                                       'jitai_components', True))\n",
    "n_jitaiboth = len(get_supported_X(df, ['adaptible intervention content', 'triggers'],\n",
    "                                  'jitai_components', True))\n",
    "\n",
    "xs = ['No JITAI Components', 'Triggers', 'Adaptable Content', 'Both']\n",
    "ys = [n_nojitai, n_jitaitriggers, n_jitaiadaptoble, n_jitaiboth]\n",
    "# plotting a bar chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Component')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('JITAI Components supported across all Publications')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "df.loc[get_supported_X(df, ['adaptible intervention content', 'triggers'],\n",
    "                       'jitai_components', True)].notes.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz of this is rather pointless given the eligibility criteria\n",
    "df.supported_devices.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_android = len(get_supported_X(df, ['android'], 'supported_OSs', True))\n",
    "n_ios = len(get_supported_X(df, ['ios'], 'supported_OSs', True))\n",
    "n_xplatform = len(get_supported_X(df, ['cross-platform'], 'supported_OSs', False))\n",
    "n_unknwon = len(get_supported_X(df, ['unknown'], 'supported_OSs', True))\n",
    "\n",
    "xs = ['Android Only', 'iOS Only', 'Cross-Platform', 'Unknown']\n",
    "ys = [n_android, n_ios, n_xplatform, n_unknwon]\n",
    "# plotting a bar chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('OS')\n",
    "ax.set_xticklabels(xs, rotation=30, ha='right')\n",
    "ax.set_title('Supported Operating Systems in EMA/EMI Literature')\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text\n",
    "print('uses Android', len(get_supported_X(df, ['Android'], 'supported_OSs', False)) + 2)\n",
    "print('uses iOS', len(get_supported_X(df, ['iOS'], 'supported_OSs', False)) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = min(df.publication_year.value_counts().keys())\n",
    "max_year = max(df.publication_year.value_counts().keys())\n",
    "xs = list(range(min_year, max_year+1))\n",
    "ys = []\n",
    "for i in xs:\n",
    "  ys.append(df[df.publication_year == i].shape[0])\n",
    "min_y = min(ys)\n",
    "max_y = max(ys)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(xs, ys)\n",
    "ax.set_ylabel('Count')\n",
    "# ax.set_yticks(range(min_y, max_y))\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_title('Number of new EMA/EMI Publications over the Years')\n",
    "ax.set_xticks(range(min_year, max_year+1))\n",
    "for p in ax.patches:\n",
    "  ax.annotate(str(int(p.get_height())),\n",
    "              (p.get_x() + p.get_width() / 2.0, p.get_height() - 0.25),\n",
    "              ha='center', va='center',\n",
    "              xytext=(0, 10), textcoords='offset points')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devices for text\n",
    "df.supported_devices.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_technologies for text\n",
    "df.ai_technologies.value_counts()\n",
    "\n",
    "# len(get_supported_X(df, ['predict potential triggers'], 'ai_technologies', False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
